---
title: LLM-IE1
published: false
date: 2023-05-15 23:24:09
categories:
  - Paper
  - LLM
  - IE
tags:
  - LLM
  - IE
  - Collection
---

# åŸºäºLLMçš„Information Extraction 1

åŸºäºLLMçš„ä¿¡æ¯æŠ½å–å·¥ä½œæ€»ç»“åˆé›†1ã€‚

<!--more-->

## filter-then-rerank

Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!. EMNLP 2023 Findings. å—æ´‹ç†å·¥. [ä»£ç ](https://github.com/mayubo2333/LLM-IE). 

> Large Language Models (LLMs) have made remarkable strides in various tasks. However, whether they are competitive few-shot solvers for information extraction (IE) tasks and surpass fine-tuned small Pre-trained Language Models (SLMs) remains an open problem. This paper aims to provide a thorough answer to this problem, and moreover, to explore an approach towards effective and economical IE systems that combine the strengths of LLMs and SLMs. Through extensive experiments on eight datasets across three IE tasks, **we show that LLMs are not effective few-shot information extractors in general, given their unsatisfactory performance in most settings and the high latency and budget requirements.** However, we demonstrate that LLMs can well complement SLMs and effectively solve hard samples that SLMs struggle with. Building on these findings, **we propose an adaptive filter-then-rerank paradigm, in which SLMs act as filters and LLMs act as rerankers.** By utilizing LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.1% F1-gain on average) on various IE tasks, with acceptable cost of time and money.

ä½œè€…è¯„ä¼°äº†ä»¥Codexï¼ˆ`code-davinci-002`ï¼Œ2023/03/03ä¹‹å‰ï¼‰ä¸ºåŸºå‡†çš„LLM+in-context learningæ–¹æ³•åœ¨ä¿¡æ¯æŠ½å–ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¯¹æ¯”äº†åŸºäºRoBERTaå’ŒT5å°å‹è¯­è¨€æ¨¡å‹çš„ç°æœ‰IE SOTAæ–¹æ³•ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼š

![image-20230515233558514](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515233558514.png)

ä½œè€…å‘ç°å½“æ‰§è¡Œone-shotä»»åŠ¡æ—¶ï¼ŒLLMæ€§èƒ½è¿˜å¯ä»¥ï¼›å½“è®­ç»ƒæ ·æœ¬æ•°é€æ¸å¢åŠ æ—¶ï¼ŒåŸºäºLLMçš„æ–¹æ³•å—é™äºè¾“å…¥é•¿åº¦é™åˆ¶ä»¥åŠé¢„è®­ç»ƒè¿‡ç¨‹ç­‰å› ç´ ï¼Œæ²¡æœ‰åŠæ³•è¾¾åˆ°SOTAçš„IEæ€§èƒ½ã€‚ä¸è¿‡ä½œè€…çš„demonstrationæ˜¯ä¸ºæ¯ä¸ªlabeléšæœºé‡‡æ ·å›ºå®šæ•°é‡çš„ç¤ºä¾‹ï¼Œè€Œä¸æ˜¯ç»™æ¯ä¸ªæµ‹è¯•æ ·ä¾‹éƒ½æœ‰ä¸åŒçš„demonstrationsã€‚

ä¸‹é¢æ˜¯ä½œè€…çš„å®éªŒç»“æœï¼š

![image-20230515233212836](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515233212836.png)

ä¸Šå›¾æœ‰ä¸¤ä¸ªå‘ç°ï¼š

- å½“è¾“å…¥çš„labelç±»å‹å°‘çš„æ—¶å€™ï¼Œå¦‚åœ¨CONLL03æ•°æ®é›†åªæœ‰4ç§labelè¡¨ç°æ•ˆæœä¸é”™ï¼›è€Œåœ¨æ›´å¤šçš„labelæ•°æ®é›†ï¼Œæ¯”å¦‚MAVENæœ‰168ä¸­event typeï¼Œå®é™…ä¸ŠLLMæ¨¡å‹ä¸èƒ½å¤Ÿå¾ˆå¥½çš„ç†è§£ä¸åŒlabelçš„å†…åœ¨å«ä¹‰[*Large language models still canâ€™t plan (a benchmark for llms on planning and reasoning about change. 2022*]ã€‚å¹¶ä¸”è¶Šå¤šçš„labelæ„å‘³ç€éœ€è¦è¶Šå¤šè¶Šå¤æ‚çš„è¾“å…¥demosã€‚
- ä¸‰ç§ä»»åŠ¡æ¯”è¾ƒèµ·æ¥ï¼Œåœ¨NERä»»åŠ¡ä¸Šè¡¨ç°è¿˜å¯ä»¥ã€‚

åŸºäºLLMçš„IEæ–¹æ³•è¿˜æœ‰å¦ä¸€ä¸ªé‡è¦é—®é¢˜æ˜¯æ¥å£è¿”å›å€¼å¾ˆæ…¢ï¼Œç‰¹åˆ«æ˜¯è¾“å…¥ç‰¹åˆ«å¤§çš„æƒ…å†µä¸‹éœ€è¦çš„å¤„ç†æ—¶é—´å°±æ›´é•¿äº†ï¼›è€Œå°çš„æ¨¡å‹æ¨ç†é€Ÿåº¦å¾ˆå¿«ï¼Œå…·ä½“å¯ä»¥å‚è€ƒè®ºæ–‡ä¸­çš„Table 1ã€‚

ä½œè€…æå‡ºï¼ŒLLMæ¨¡å‹å¯ä»¥ç”¨æ¥è§£å†³æ›´åŠ hardçš„æ ·æœ¬ï¼Œå»è§£å†³é‚£äº›å°çš„åŸºäºç›‘ç£è®­ç»ƒçš„æ¨¡å‹æ— æ³•å¾ˆå¥½é¢„æµ‹çš„æ ·æœ¬ï¼Œè¿™äº›hard sampleå¯èƒ½éœ€è¦external knowledgeæˆ–è€…æ›´å¤æ‚çš„reasoningèƒ½åŠ›ï¼Œè¿™äº›æ­£å¥½æ˜¯LLMæ¨¡å‹çš„é•¿å¤„ã€‚å› æ­¤ä½œè€…æå‡ºäº†ä½¿ç”¨å°çš„æ¨¡å‹Small Language Modelï¼ˆSLMï¼‰å…ˆè¿›è¡Œè®­ç»ƒåé¢„æµ‹ï¼Œå¯¹äºæ¯”è¾ƒç®€å•çš„æ ·æœ¬ï¼Œç›´æ¥ä½¿ç”¨SLMçš„è¾“å‡ºç»“æœï¼›å¯¹äºæ¯”è¾ƒéš¾é¢„æµ‹çš„æ ·æœ¬ï¼Œè¾“å‡ºå‡ ä¸ªé¢„æµ‹å¾—åˆ†åœ¨top-nçš„labelï¼Œè®©LLMè¿›è¡Œrerankï¼Œæœ€åè¿›è¡Œè¾“å‡ºã€‚

ä½œè€…åˆ¤æ–­ä¸€ä¸ªæ ·æœ¬æ˜¯å¦éš¾ä»¥è¢«åŸºäºSLMçš„æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„ä¾æ®å°±æ˜¯ä¸åŒlabel scoreä¸­æœ€å¤§scoreè¶Šå°ï¼Œè¡¨ç¤ºè¶Šéš¾åˆ¤æ–­è¿™ä¸ªæ ·æœ¬ã€‚

ä¸‹é¢æ˜¯æ¨¡å‹å›¾ï¼Œä½œè€…åœ¨å®ç°è‡ªå·±çš„æ¨¡å‹ä½¿ç”¨äº†InstructGPTï¼ˆtext-davinci-003ï¼‰ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515234734532.png"   style="zoom:50%;" />

æ–¹æ³•çœ‹èµ·æ¥æ¯”è¾ƒç®€å•ï¼Œæœ‰ä¸€ç‚¹å¯ä»¥æ³¨æ„ä¸‹ï¼Œä½œè€…æŠŠIEä»»åŠ¡ä¸‹å¯èƒ½è¦æ±‚çš„æ ¼å¼åŒ–çš„è¾“å‡ºï¼ˆæ¯”å¦‚ä¸‰å…ƒç»„ï¼‰è½¬æ¢ä¸ºå¥å­çš„å½¢å¼ï¼Œè®©LLMè¡Œå»åšmulti-choice questionï¼Œè¿™æ ·LLMæ¨¡å‹å¯èƒ½å¯ä»¥æ›´å¥½çš„ç†è§£demosä¸­çš„å®ä¾‹ã€‚

![image-20230515235129692](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515235129692.png)

åœ¨few-shotçš„IEä»»åŠ¡ä¸‹å¹³å‡F1æå‡äº†2.1%ã€‚

## CheatGPT IE Evaluation

Evaluating ChatGPTâ€™s Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness

åŒ—å¤§ï¼ŒarXiv 2023.04

> The capability of Large Language Models (LLMs) like ChatGPT to comprehend user intent and provide reasonable responses has made them extremely popular lately. In this paper, we focus on assessing the overall ability of ChatGPT using 7 fine-grained information extraction (IE) tasks. Specially, we present the systematically analysis by measuring ChatGPTâ€™s performance, explainability, calibration, and faithfulness, and resulting in 15 keys from either the ChatGPT or domain experts. **Our findings reveal that ChatGPTâ€™s performance in Standard-IE setting is poor, but it surprisingly exhibits excellent performance in the OpenIE setting, as evidenced by human evaluation.** In addition, our research indicates that ChatGPT provides high-quality and trustworthy explanations for its decisions. However, there is an issue of ChatGPT being overconfident in its predictions, which resulting in low calibration. Furthermore, ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. We manually annotate and release the test sets of 7 finegrained IE tasks contains 14 datasets to further promote the research. The datasets and code are available at this url.

è¿™ç¯‡è®ºæ–‡åŒæ ·æ˜¯è®¨è®ºåŸºäºLLMçš„IEï¼Œåªä¸è¿‡ä½œè€…æ˜¯åŸºäºChatGPTï¼Œä¹Ÿæ²¡æœ‰ä½¿ç”¨æ›´å¤šçš„æŠ€æœ¯ï¼Œæ¯”å¦‚ä¸Šé¢è®ºæ–‡çš„in-context learningã€‚ä½œè€…ä»Performanceï¼ŒExplainabilityï¼ŒCalibrationï¼ˆæ¨¡å‹å¯¹äºè¾“å‡ºç»“æœçš„è‡ªä¿¡ç¨‹åº¦ï¼‰å’ŒFaithfulnessï¼ˆè¾“å‡ºç»“æœæ˜¯å¦ä¸è¾“å…¥å†…å®¹ä¸€è‡´ï¼‰å››ä¸ªå¤§çš„æ–¹é¢ï¼Œç”¨15ä¸ªæŒ‡æ ‡ï¼ˆäººå·¥+è‡ªåŠ¨ï¼‰è¿›è¡Œäº†è¯„ä¼°ï¼š

![](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515235818750.png)

ä½œè€…ä½¿ç”¨äº†ä¸¤ç§åœºæ™¯ä¸‹çš„IEï¼š

- Standard IEï¼šç»™å®šlabel set
- Open IEï¼šä¸ç»™å®šlabel setï¼Œè®©ChatGPTè‡ªå·±å›ç­”ï¼Œäººå·¥åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ­£ç¡®

ä¸ºäº†é¿å…å†å²å›ç­”è®°å½•çš„å½±å“ï¼Œæ¯æ¬¡å›ç­”éƒ½ä¼šæ¸…ç©ºä¸Šä¸€æ¬¡å›ç­”çš„è®°å½•ï¼Œä¸‹é¢æ˜¯ä½œè€…è¿›è¡Œäº‹ä»¶æ£€æµ‹ä»»åŠ¡æ—¶è¾“å…¥çš„æ ·ä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000754165.png"   style="zoom:25%;" />

æœ€ç»ˆå®éªŒç»“æœå¦‚ä¸‹ï¼š

![image-20230516000110009](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000110009.png)

åœ¨entity typingä»»åŠ¡ä¸‹è¡¨ç°ä¸é”™ã€‚æ³¨æ„ä¸€ä¸‹ï¼Œé‡Œé¢çš„relation extractionä»»åŠ¡å®é™…ä¸Šæ˜¯å®ä½“-å…³ç³»è”åˆæŠ½å–ä»»åŠ¡ï¼Œrelation classificationä»»åŠ¡æ˜¯åªé¢„æµ‹relationçš„ä»»åŠ¡ã€‚æ€»ä½“ä¸ŠLLMå’ŒSOTAè¿˜æœ‰è¾ƒå¤§å·®è·ï¼Œä½†æ˜¯ä½œè€…è¿›ä¸€æ­¥å‘ç°å¦‚æœæ˜¯è®¡ç®—top-kæŒ‡æ ‡çš„è¯ï¼Œæ•ˆæœè¿˜ä¸é”™ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000316332.png"   style="zoom:40%;" />

è€Œå¦‚æœåœ¨open IEåœºæ™¯ä¸‹ï¼ŒChatGPTæ•ˆæœä¼šæ›´å¥½ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000408562.png"   style="zoom:40%;" />

å¯¹äºå¯è§£é‡Šæ€§ï¼Œä½œè€…å‘ç°ChatGPTèƒ½å¤Ÿç»™å‡ºä¸é”™çš„è§£é‡Šï¼ˆå…·ä½“ç»“æœå‚è€ƒè®ºæ–‡çš„Table 4ï¼‰ã€‚

å¯¹äºCalibrationï¼Œå‘ç°ChatGPTä¸è®ºæ˜¯å¦åˆ†ç±»æ­£ç¡®ï¼Œæ€»æ˜¯å¯¹è‡ªå·±çš„ç»“æœå¾ˆè‡ªä¿¡ï¼Œç»™å‡ºå¾ˆé«˜çš„å¾—åˆ†ã€‚

æœ€åï¼Œä½œè€…å‘ç°ChatGPTè¾“å‡ºç»“æœåŸºæœ¬ä¸Šå’Œè¾“å…¥æ˜¯ç›¸ç¬¦çš„ã€‚

## ChatIE

Zero-Shot Information Extraction via Chatting with ChatGPT

åŒ—äº¤ï¼ŒarXiv 2023.02ï¼Œ[ä»£ç ](https://github.com/cocacola-lab/ChatIE)ã€‚

> Zero-shot information extraction (IE) aims to build IE systems from the unannotated text. It is challenging due to involving little human intervention. Challenging but worthwhile, zero-shot IE reduces the time and effort that data labeling takes. Recent efforts on large language models (LLMs, e.g., GPT3, ChatGPT) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this work, we ask whether strong IE models can be constructed by directly prompting LLMs. Specifically, we transform the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework (ChatIE). With the power of ChatGPT, we extensively evaluate our framework on three IE tasks: entity-relation triple extract, named entity recognition, and event extraction. Empirical results on six datasets across two languages show that ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL). We believe that our work could shed light on building IE models with limited resources.

ä½œè€…å‘ç°ç›´æ¥è®©ChatGPTé—®ç­”IEä»»åŠ¡æ•ˆæœä¸å¥½ï¼Œå› æ­¤æå‡ºäº†ä¸¤æ­¥çš„å¤šè½®é—®ç­”æ–¹å¼çš„æ–¹æ³•chatIEï¼Œç›®æ ‡æ˜¯zero-shot IEä»»åŠ¡ï¼Œä¸‹é¢æ˜¯æ¨¡å‹å›¾ï¼š

![image-20230516000929739](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000929739.png)

ç¬¬ä¸€æ­¥æé—®è¾“å…¥æ–‡æœ¬ä¸­æœ‰å“ªäº›ç±»çš„å¯èƒ½ï¼Œæ¯”å¦‚æœ‰å“ªäº›ç±»å®ä½“ï¼›

ç¬¬äºŒæ­¥è¿›ä¸€æ­¥æé—®æ¯ä¸€ç±»ä¸‹çš„å…·ä½“ç»“æœï¼Œè¿™ä¸€æ­¥å¯èƒ½æœ‰å¤šè½®é—®ç­”ã€‚

ä¸‹é¢æ˜¯NERä»»åŠ¡çš„å®ä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516001252515.png"  style="zoom:25%;" />

å®éªŒç»“æœï¼š

![image-20230516001208421](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516001208421.png)

## CodeIE

CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors. å¤æ—¦ï¼ŒACL 2023ï¼Œ[ä»£ç ](https://github.com/dasepli/CodeIE)ã€‚

> Large language models (LLMs) pre-trained on massive corpora have demonstrated impressive few-shot learning ability on many NLP tasks. A common practice is to recast the task into a text-to-text format such that generative LLMs of natural language (NL-LLMs) like GPT-3 can be prompted to solve it. However, it is non-trivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text. In this paper, we propose to recast the structured output in the form of code instead of natural language and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, in particular, named entity recognition and relation extraction. In contrast to NL-LLMs, **we show that Code-LLMs can be well-aligned with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks.** Experiment results on seven benchmarks show that our method consistently outperforms fine-tuning moderate-size pre-trained models specially designed for IE tasks (e.g., UIE) and prompting NL-LLMs under few-shot settings. We further conduct a series of in-depth analyses to demonstrate the merits of leveraging Code-LLMs for IE tasks.

ä½œè€…æå‡ºï¼ŒåŸºäºLLMæ¨¡å‹å»åšIEä»»åŠ¡æ—¶ï¼ŒæŠŠè¾“å…¥å’Œè¾“å‡ºéƒ½è½¬åŒ–ä¸ºä»£ç çš„å½¢å¼æ›´å¥½ï¼Œå› ä¸ºä¸€èˆ¬IEä»»åŠ¡çš„è¾“å‡ºæ˜¯æ ¼å¼åŒ–çš„ï¼Œè€Œé¢„è®­ç»ƒæ¨¡å‹å¾ˆå¤šæ˜¯åœ¨è‡ªç„¶è¯­è¨€ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼›å¦å¤–ä½œè€…å‘ç°ä½¿ç”¨ä¸»è¦åˆ†æä»£ç çš„LLMä¾‹å¦‚Codexæ•ˆæœæ¯”ä¸€èˆ¬çš„LLMæ¨¡å‹æ›´å¥½ï¼ˆä½œè€…å®éªŒä¸­ä½¿ç”¨çš„è¿˜æ˜¯code-davinci-002å’Œtext-davinci-002ï¼Œä¸æ¸…æ¥šä¸Šè¿°ç»“è®ºå¯¹äº003ç‰ˆæœ¬ä»¥åŠGPT-4æ˜¯å¦æˆç«‹ï¼‰ã€‚

motivationï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516223705834.png"   style="zoom:30%;" />

ä½œè€…æå‡ºçš„æ–¹æ³•ï¼š

![image-20230516223400913](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516223400913.png)

ä¸»è¦æ˜¯é’ˆå¯¹few-shot IEä»»åŠ¡ï¼ŒåŠ å…¥äº†å‡ ä¸ªdemonstrationã€‚å›ºå®šçš„ä¸ºæ¯ä¸ªentity/relationç±»å‹éšæœºæ‰¾kä¸ªæ ·ä¾‹ä½œä¸ºdemonstrationsã€‚å®šä¹‰çš„promptæ˜¯pythonçš„functionæ ¼å¼ï¼Œè®©Codexå»è¡¥å…¨å‰©ä¸‹çš„ä»£ç ã€‚ä½œè€…ä¹Ÿè¯•éªŒäº†å…¶å®ƒå‡ ä¸ªæ¯”å¦‚ä½¿ç”¨class initå‡½æ•°ç­‰ï¼Œå‘ç°è¿™æ ·å­æ•ˆæœæœ€å¥½ã€‚

- ä½¿ç”¨python functionè¡¨ç¤ºIEä»»åŠ¡
- ä½¿ç”¨function docstringè¯´æ˜ä»»åŠ¡ç›®æ ‡
- å¾…æŠ½å–çš„æ–‡æœ¬ç”¨stringç±»å‹çš„å˜é‡è¡¨ç¤º
- æŠ½å–å‡ºæ¥çš„entity/relationä½¿ç”¨ä¸æ–­appendåˆ°listç±»å‹çš„å˜é‡è¡¨ç¤º

ä½œè€…çš„å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516223639496.png"   style="zoom:30%;" />

text promptå’Œcode promptæ•ˆæœå¯¹æ¯”ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230621155157156.png"   style="zoom:40%;" />

## Code4Struct

Code4Struct: Code Generation for Few-Shot Event Structure Prediction

ACL 2023, [ä»£ç ](https://github.com/xingyaoww/code4struct)ã€‚

> Large Language Model (LLM) trained on a mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code. We observe that semantic structures can be conveniently translated into code and propose CODE4STRUCT to leverage such text-tostructure translation capability to tackle structured prediction tasks. As a case study, **we formulate Event Argument Extraction (EAE) as converting text into event-argument structures that can be represented as a class object using code.** This alignment between structures and code enables us to take advantage of Programming Language (PL) features such as inheritance 1 and type annotation 2 to introduce external knowledge or add constraints. We show that, with sufficient in-context examples, formulating EAE as a code generation problem is advantageous over using variants of text-based prompts. Despite only using 20 training event instances for each event type, Code4Struct is comparable to supervised models trained on 4,202 instances and outperforms current state-of-the-art (SOTA) trained on 20-shot data by 29.5% absolute F1. By leveraging the inheritance feature of PL, Code4Struct can use 10-shot training data from a sibling event type to predict arguments for zero-resource event types and outperforms the zero-shot baseline by 12% absolute F1.

ä½œè€…æå‡ºæŠŠEEæŠ½å–ä»»åŠ¡è½¬åŒ–ä¸ºä»£ç çš„å½¢å¼ï¼Œä¸€æ–¹é¢ä»£ç è¯­è¨€å¤©ç„¶çš„èƒ½å¤Ÿæè¿°å¤æ‚çš„äº‹ä»¶æœ¬ä½“ï¼Œä¸€æ–¹é¢åœ¨zero-shotè®¾ç½®ä¸‹ï¼Œä»£ç ç”Ÿæˆçš„ç»“æœèƒ½å¤Ÿæ›´åŠ ä¸¥æ ¼çš„éµå¾ªpromptçš„è§„å®šã€‚

EAEæŠ½å–å’Œpythonä»£ç å¯¹åº”çš„è¡¨æ ¼ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627155654622.png"   style="zoom:50%;" />

æ–¹æ³•å›¾ï¼š

![image-20230627155624222](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627155624222.png)

å›ºå®šçš„ä¸ºæ¯ä¸ªäº‹ä»¶ç±»å‹æ‰¾å‡ºç°é¢‘ç‡æœ€å¤šçš„kä¸ªeventä½œä¸ºdemonstrationsã€‚

code-promptä¹Ÿæ˜¯å¯ä»¥ç”¨è‡ªç„¶è¯­è¨€çš„å½¢å¼è¿›è¡Œæè¿°çš„ï¼Œåªä¸è¿‡æ›´åŠ çš„ç¹çï¼Œå¹¶ä¸”éš¾ä»¥åœ¨zero-shotè®¾ç½®ä¸‹ä¿è¯æ¨¡å‹è¾“å‡ºæ˜¯æ»¡è¶³è¦æ±‚çš„ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627155855556.png"   style="zoom:30%;" />

å®éªŒç»“æœï¼š

![image-20230627155927744](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627155927744.png)

åœ¨text-davinci-003ä¸‹ï¼Œæ‹¥æœ‰äº†è¶³å¤Ÿå¤šçš„æ ·ä¾‹ï¼Œcode-promptå’Œtext-promptå·®åˆ«ä¸å¤§ã€‚

å¦å¤–ï¼Œä½œè€…åœ¨å®éªŒçš„æ—¶å€™å‘ç°ï¼Œä½¿ç”¨åŒå±‚çº§å…·æœ‰ç›¸åŒparent eventçš„äº‹ä»¶ä½œä¸ºdemonstrationsï¼Œæ•ˆæœæ›´å¥½ã€‚è¿™å°±æä¾›äº†ä¸€ç§å¯èƒ½ï¼Œä¹Ÿå°±æ˜¯ç”¨æ ·ä¾‹æ¯”è¾ƒå¤šçš„event typeï¼Œå»ä½œä¸ºæ ·ä¾‹æ¯”è¾ƒå°‘çš„event typeçš„demonstrationsã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627160039905.png"   style="zoom:50%;" />



## ChatGPT for KG

Enhancing Knowledge Graph Construction Using Large Language Models.

arXiv 2023

> The growing trend of Large Language Models (LLM) development has attracted significant attention, with models for various applications emerging consistently. However, the combined application of Large Language Models with semantic technologies for reasoning and inference is still a challenging task. This paper analyzes how the current advances in foundational LLM, like ChatGPT, can be compared with the specialized pretrained models, like REBEL, for joint entity and relation extraction. To evaluate this approach, we conducted several experiments using sustainability-related text as our use case. We created pipelines for the automatic creation of Knowledge Graphs from raw texts, and our findings indicate that using advanced LLM models can improve the accuracy of the process of creating these graphs from unstructured text. Furthermore, we explored the potential of automatic ontology creation using foundation LLM models, which resulted in even more relevant and accurate knowledge graphs.

ä½œè€…ä½¿ç”¨ChatGPTå»å®Œæ•´çš„æ„é€ ä¸€ä¸ªä¸å¯æŒç»­ç›¸å…³çš„çŸ¥è¯†å›¾è°±ï¼ŒåŒ…æ‹¬å®ä½“å…³ç³»æŠ½å–ä¸æœ¬ä½“åˆ›å»ºç­‰ï¼Œä½œè€…å‘ç°è®©ChatGPTå»å…³è”æŠ½å–å‡ºçš„å®ä½“å…³ç³»ä¸æœ¬ä½“ï¼Œæ•ˆæœä¸å¥½ã€‚è®©ChatGPTç›´æ¥ç”Ÿæˆæœ¬ä½“å¯èƒ½æ˜¯æ›´åˆé€‚çš„æ–¹å¼ã€‚

è®ºæ–‡ä¸­æ²¡æœ‰æä¾›å…·ä½“çš„promptè®¾è®¡æ–¹æ³•ï¼Œå‚è€ƒä»·å€¼ä¸å¤§ã€‚

## VicunaNER

arXiv 2023.05ï¼Œæ–°åŠ å¡å›½ç«‹å¤§å­¦ï¼ˆæˆªæ­¢05/18æ—¥è¿˜åªèƒ½çœ‹åˆ°ä¸å¤ªå®Œæ•´çš„è®ºæ–‡ï¼Œæ²¡æœ‰å®éªŒç»“æœï¼‰

> Large Language Models (LLMs, e.g., ChatGPT) have shown impressive zero- and fewshot capabilities in Named Entity Recognition (NER). However, these models can only be accessed via online APIs, which may cause data leak and non-reproducible problems. In this paper, we propose VicunaNER, a zero/fewshot NER framework based on the newly released open-source LLM â€“ Vicuna. VicunaNER is a two-phase framework, where each phase leverages multi-turn dialogues with Vicuna to recognize entities from texts. We name the second phase as Re-Recognition, which recognizes those entities not recognized in the first phase (a.k.a. Recongition). Moreover, we set entity correctness check dialogues in each phase to filter out wrong entities. We evaluate VicunaNERâ€™s zero-shot capacity on 10 datasets crossing 5 domains and few-shot capacity on Few-NERD. Experimental results demonstrate that VicunaNER achieves superior performance in both shot settings. Additionally, we conduct comprehensive investigations on Vicuna from multiple perspectives.

ä½œè€…åŸºäºç¾Šé©¼æ¨¡å‹è¿›è¡ŒNERä»»åŠ¡ï¼Œä½œè€…é€‰æ‹©open LLMçš„ç†ç”±å¦‚ä¸‹ï¼š

- æ•°æ®é›†æ³„éœ²é—®é¢˜ï¼Œæ¯”å¦‚ä¸‰æ˜Ÿçš„æ•æ„Ÿæ•°æ®è¢«æ³„éœ²åˆ°äº†ChatGPT
- ä¸å¯å¤ç°é—®é¢˜ï¼Œåœ¨çº¿é—­æºçš„LLMéƒ½åœ¨æŒç»­æ›´æ–°ï¼Œå¾ˆéš¾é‡å¤å‰äººçš„ç ”ç©¶ç»“æœ

æ–¹æ³•ä¸»è¦æ˜¯åŸºäºå¤šè½®é—®ç­”çš„NERï¼Œå…·ä½“è€Œè¨€æ˜¯æœ‰å››æ­¥ï¼š

1. è®©VicunaæŠ½å–entity
2. è¯¢é—®VicunaæŠ½å–å‡ºçš„entityæ˜¯å¦æ­£ç¡®ï¼Œè¿‡æ»¤æ‰ä¸æ­£ç¡®çš„å®ä½“ï¼ˆç¬¬ä¸€é˜¶æ®µç»“æŸï¼‰
3. ç»™å®šä¸Šä¸€é˜¶æ®µæŠ½å–åˆ°çš„å®ä½“ï¼Œè®©Vicunaç»§ç»­è¯†åˆ«æœªè¯†åˆ«å‡ºçš„å®ä½“
4. è¯¢é—®VicunaæŠ½å–å‡ºçš„entityæ˜¯å¦æ­£ç¡®ï¼Œè¿‡æ»¤æ‰ä¸æ­£ç¡®çš„å®ä½“ï¼ˆç¬¬äºŒé˜¶æ®µç»“æŸï¼‰

å†åŠ å…¥æ›´å¤šè½®çš„é—®ç­”ä½œè€…å‘ç°å¹¶æ²¡æœ‰æ˜æ˜¾æå‡æ€§èƒ½ã€‚

ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

![image-20230518111407753](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518111407753.png)

ä»è¿™é‡Œå¯ä»¥ä½“ä¼šä¸‹LLMçš„ä¼˜ç‚¹ï¼Œä½œè€…çš„ä¸¤ä¸ªé˜¶æ®µç›¸å½“äºæ˜¯è¾“å…¥ä¸åŒçš„å°ä»»åŠ¡ï¼Œå¯¹äºLLMæ¨¡å‹æ¥è¯´æ²¡æœ‰åŒºåˆ«ï¼Œå®ƒå¯ä»¥ç›´æ¥æ‰§è¡Œè¿™ä¸¤ä¸ªä»»åŠ¡ã€‚ç›¸æ¯”èµ·æ¥ï¼Œä¼ ç»Ÿçš„æ¨¡å‹æ›´åŠ specificï¼Œå¾ˆéš¾è¾¾åˆ°è¿™æ ·çš„æ³›åŒ–æ€§ï¼Œé€šè¿‡é›†æˆå‡ ä¸ªä¸åŒçš„å°ä»»åŠ¡æå‡å¤§ä»»åŠ¡çš„æ•ˆæœï¼Œè€Œä¸”ä¸éœ€è¦åˆ†åˆ«è®­ç»ƒæ¨¡å‹ã€‚ï¼ˆä¸Šé¢çš„å·¥ä½œæ€æƒ³æ ¸å¿ƒåº”è¯¥è¯´å‡ºæ˜¯boostï¼Ÿï¼‰ã€‚

## CodeKGC

CodeKGC: Code Language Model for Generative Knowledge Graph Construction. æµ™å¤§zjunlpï¼ŒACM Transactions on Asian and Low-Resource Language Information Processing 2024ï¼Œ[ä»£ç ](https://github.com/zjunlp/DeepKE/tree/main/example/llm)ã€‚

> Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, **we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph.** As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provide intermediate steps, thereby improving knowledge extraction abilities. Experimental results indicate that the proposed approach can obtain better performance on benchmark datasets compared with baselines.

motivationï¼š

ä½œè€…è®¤ä¸ºå¯¹äºçŸ¥è¯†å›¾è°±æ„å»ºè¿™æ ·çš„ä»»åŠ¡æ¥è¯´ï¼Œç”±äºä¸‰å…ƒç»„ä¹‹é—´å­˜åœ¨ä¾èµ–ï¼Œäº’ç›¸å…³è”ï¼Œè®©è¯­è¨€æ¨¡å‹ç›´æ¥ç”Ÿæˆç»“æ„åŒ–çš„è¾“å‡ºæ¯”è¾ƒéš¾ï¼Œå› æ­¤ä½œè€…å°†çŸ¥è¯†å›¾è°±ä¿¡æ¯æŠ½å–ä»»åŠ¡çœ‹åšæ˜¯ä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œä½¿ç”¨ç¼–ç¨‹è¯­è¨€æ¥æè¿°è¾“å…¥çš„æ–‡æœ¬å’Œè¾“å‡ºï¼Œè€Œä¸æ˜¯ä½¿ç”¨è‡ªç„¶è¯­è¨€ã€‚

methodï¼š

![image-20230519154317958](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519154317958.png)

ä½œè€…åˆ©ç”¨pythonè¯­è¨€æè¿°promptã€‚è¾“å…¥çš„æ–‡æœ¬æ˜¯ä½œä¸ºpythonä¸­çš„`Docstrings`ã€‚

schemaçš„å®šä¹‰æ˜¯é€šè¿‡pythonçš„`class`ï¼Œä½œè€…å®šä¹‰äº†åŸºç¡€çš„ç±»`Entity`ï¼Œ`Rel`å’Œ`Triple`ã€‚å…¶å®ƒçš„å®ä½“å’Œå…³ç³»ç±»ä¼šç»§æ‰¿`Entity`å’Œ`Rel`ã€‚æ¯ä¸€ä¸ªä¸‰å…ƒç»„è¢«å®šä¹‰ä¸ºå¯¹åº”çš„`Triple`ç±»ï¼Œæ¯”å¦‚`(ğ¿ğ‘œğ‘›ğ‘‘ğ‘œğ‘›,ğ‘™ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ‘–ğ‘›,ğ‘ˆğ¾)`å¯¹åº”`Triple(LOC("London"), Rel("located in"), LOC("London"))`ã€‚

ä½œè€…è¿˜å¦å¤–æå‡ºäº†ä¸€ä¸ªå¯é€‰çš„Rationale-enhancedç”Ÿæˆæ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯å…ˆæŠ½å–å‡ºå…³ç³»ï¼Œå†æŠ½å–å®ä½“ï¼Œæœ€åæŠ½å–ä¸‰å…ƒç»„ã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519155533998.png"   style="zoom:40%;" />

åœ¨å®éªŒéƒ¨åˆ†ä½œè€…å®é™…ä¹Ÿä½¿ç”¨äº†`code-davinci-002`ï¼Œä½†æ˜¯ä½œè€…æåˆ°ç”±äºCodexä½¿ç”¨èŒƒå›´æœ‰é™ï¼ˆOpenAIåœ¨3æœˆ23æ—¥åœæ­¢äº†å¯¹Codex APIçš„æŒç»­æ”¯æŒï¼‰ï¼Œå› æ­¤ä½œè€…ä»…ä»…åœ¨æ¶ˆèå®éªŒéƒ¨åˆ†ä½¿ç”¨äº†Codexã€‚

## InstructUIE

InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction

å¤æ—¦ï¼ŒarXiv 2023.04ï¼Œ[ä»£ç ](https://github.com/BeyonderXX/InstructUIE)ã€‚

>  Large language models have unlocked strong multi-task capabilities from reading instructive prompts. However, recent studies have shown that existing large models still have difficulty with information extraction tasks. For example, gpt-3.5-turbo achieved an F1 score of 18.22 on the Ontonotes dataset, which is significantly lower than the state-of-the-art performance. **In this paper, we propose InstructUIE, a unified information extraction framework based on instruction tuning, which can uniformly model various information extraction tasks and capture the inter-task dependency.** To validate the proposed method, we introduce IE INSTRUCTIONS, a benchmark of 32 diverse information extraction datasets in a unified text-to-text format with expert-written instructions. Experimental results demonstrate that our method achieves comparable performance to Bert in supervised settings and significantly outperforms the state-of-the-art and gpt3.5 in zero-shot settings.

åœ¨ä¹‹å‰çš„ä¸€äº›ç ”ç©¶ä¸­å‘ç°LLMæ¨¡å‹åœ¨IEä»»åŠ¡ä¸Šè¡¨ç°å¹¶ä¸å¥½ï¼Œå› æ­¤ä½œè€…å¸Œæœ›èƒ½å¤Ÿå®ç°ä¸€ä¸ªåŸºäºLLMçš„unified information extraction (UIE) modelã€‚ä½œè€…é›†åˆäº†ç°æœ‰çš„NERï¼ŒREå’ŒEEæ•°æ®é›†ï¼Œæ„é€ äº†ä¸€ä¸ªåŠ å…¥instructionçš„benchmarkâ€”â€”IE INSTRUCTIONï¼Œç”¨å…¶æ¥instruction-tuning LLMç”¨äºIEä»»åŠ¡ã€‚

ä½œè€…æŠŠIEä»»åŠ¡çœ‹åšæ˜¯è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ï¼Œä¸€ä¸ªtext-to-textçš„ä»»åŠ¡ã€‚è¾“å…¥æ˜¯å¸¦æœ‰instructionçš„promptï¼Œè¾“å‡ºæ˜¯æ–‡æœ¬ã€‚ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

![image-20230519170242805](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519170242805.png)

æ–¹æ³•æ¯”è¾ƒç®€å•ï¼Œè¾“å…¥çš„promptåŒ…æ‹¬ä¸‹é¢å‡ éƒ¨åˆ†ï¼š

- Task Instructionï¼štype of information to be extracted, the format of the output structure, and any additional constraints or rules that need to be followed during the extraction process.
- Optionsï¼šthe set of possible outputs that can be generated by the model for a given input.
- Textï¼šinput sentence.

ä½œè€…æ„å»ºäº†ä¸€ä¸ªåŸºäºä¿¡æ¯æŠ½å–å…¬å¼€æ•°æ®é›†çš„benchmarkâ€”â€”IE INSTRUCTIONSï¼ŒåŒ…æ‹¬32ä¸ªå°çš„æ•°æ®é›†ï¼Œæ•°æ®åˆ†å¸ƒå¦‚ä¸‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519170702469.png"  style="zoom:30%;" />

ä½œè€…å¯¹æ”¶é›†çš„æ•°æ®é›†è¿›è¡Œäº†ä»¥ä¸‹å¤„ç†ï¼š

- ç»Ÿä¸€ä¸åŒæ•°æ®é›†çš„labelæè¿°
- æŠŠä¸€äº›ç¼©å†™æˆ–ç®€å†™çš„æ ‡ç­¾è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€ï¼Œæ¯”å¦‚`place_of_birth`è½¬åŒ–ä¸º`place of birth`ã€‚
- æŠŠæ‰€æœ‰æ•°æ®é›†éƒ½è½¬åŒ–ä¸ºtext-to-textçš„å½¢å¼

åŒæ—¶ï¼Œä½œè€…æŠŠæ¯ä¸ªIEä»»åŠ¡è¿›ä¸€æ­¥ç»†åˆ†æˆä¸ºäº†ä¸åŒçš„å°ä»»åŠ¡ï¼š

- NER: span extraction and entity typing
- RE: entity pair extraction and relation classification
- EE: trigger extraction and argument extraction

ä½œè€…çš„å®éªŒåŸºäº11B FlanT5ï¼Œä½œè€…è¿›è¡Œäº†æœ‰ç›‘ç£çš„åœ¨IE INSTRUCTIONSä¸Šå¾®è°ƒLLMå’Œæ— ç›‘ç£çš„zero-shotä¸¤ç§å®éªŒ:

- Supervised Settings: 10,000 examples for each dataset
- Zero-shot Settings:
  - Train: 18 NER datasets and 6 RE datasets
  - Test: 7 NER datasets and 2 RE datasets

å…·ä½“å®éªŒç»“æœå‚çœ‹è®ºæ–‡ã€‚

## InstructIE

InstructIE: A Chinese Instruction-based Information Extraction Dataset. 

æµ™å¤§NLPï¼ŒarXiv 2023ï¼Œ[ä»£ç ](Â§https://github.com/zjunlp/KnowLM)ã€‚

> We introduce a new Information Extraction (IE) task dubbed Instructionbased IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, **we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances.** We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task.

ä½œè€…æ„å»ºInstructIEæ•°æ®é›†çš„æµç¨‹ï¼š

![image-20230627160605062](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627160605062.png)

ç»Ÿè®¡æƒ…å†µï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627160631496.png"   style="zoom:40%;" />

è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒåçš„ç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627160708941.png"  style="zoom:50%;" />

è¡¨æ ¼ä¸­çš„CaMAå°±æ˜¯æµ™å¤§æœ€è¿‘æå‡ºçš„æ™ºæZhixiä¿¡æ¯æŠ½å–å¤§æ¨¡å‹ï¼ˆLLaMA 13B basedï¼‰ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627160753724.png"   style="zoom:50%;" />

å›¾ä¸­çš„KG2Instructionå°±æ˜¯InstructIEæ•°æ®é›†ã€‚

## GPT-3 for Clinical IE

Large Language Models are Few-Shot Clinical Information Extractors

EMNLP 2022ï¼ŒMITï¼Œ[ä»£ç ](https://huggingface.co/datasets/mitclinicalml/clinical-ie)ã€‚

> A long-running goal of the clinical NLP community is the extraction of important variables trapped in clinical notes. However, roadblocks have included dataset shift from the general domain and a lack of public clinical corpora and annotations. **In this work, we show that large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain.** Whereas text classification and generation performance have already been studied extensively in such models, here we additionally demonstrate how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs, including span identification, token-level sequence classification, and relation extraction. Further, due to the dearth of available data to evaluate these systems, we introduce new datasets for benchmarking fewshot clinical information extraction based on a manual re-annotation of the CASI dataset (Moon et al., 2014) for new tasks 1 . On the clinical extraction tasks we studied, the GPT-3 systems significantly outperform existing zero- and few-shot baselines.

ä¸´åºŠåŒ»å­¦å¯èƒ½æ˜¯ä¸€ä¸ªèƒ½å¤Ÿä½“ç°LLMåœ¨IEä»»åŠ¡ä¸­ç‰¹æœ‰ä»·å€¼çš„å…·ä½“åœºæ™¯ã€‚ä¸´åºŠä¿¡æ¯æŠ½å–ä»»åŠ¡ä¸€ç›´é¢ä¸´ä¸‹é¢çš„é—®é¢˜ï¼š

1. æ–‡æœ¬ä¸­åŒ…æ‹¬å¾ˆå¤šçš„ä¸“ä¸šæœ¯è¯­å’Œæ¨¡ç³Šçš„æè¿°
2. å¤§å¤šä¸´åºŠæ•°æ®é›†ä¸å…¬å¼€ï¼Œå³ä½¿å…¬å¼€äº†ä¹Ÿæœ‰ä¸¥æ ¼çš„ä½¿ç”¨é™åˆ¶ï¼Œæ— æ³•ç”¨äºåœ¨çº¿çš„OpenAIçš„LLM API

ä¸Šé¢çš„é—®é¢˜åœ¨å¾ˆå¤šæ•°æ®æ•æ„Ÿçš„ä¸“ä¸šé¢†åŸŸåº”è¯¥éƒ½æ˜¯å­˜åœ¨çš„ã€‚ä½¿ç”¨LLMçš„å¥½å¤„ä¹‹ä¸€å°±æ˜¯å®ƒå¯ä»¥ä¸ç»è¿‡è®­ç»ƒï¼Œåœ¨éœ€è¦å¤–éƒ¨çŸ¥è¯†æˆ–è€…å¤æ‚æ¨ç†èƒ½åŠ›çš„åœºæ™¯ä¸‹è¾¾åˆ°è¿˜ä¸é”™çš„æ•ˆæœã€‚

ä½œè€…æ¢ç©¶äº†åˆ©ç”¨GPT-3è¿›è¡Œä¸´åºŠæ•°æ®çš„ä¿¡æ¯æŠ½å–çš„æ•ˆæœï¼ŒåŒæ—¶é‡æ–°æ ‡æ³¨äº†ä¸‰ä¸ªæ•°æ®é›†ä»¥è¯„ä¼°å°‘æ¬¡æŠ½å–æ€§èƒ½ã€‚ä¸‹é¢æ˜¯æ–¹æ³•ï¼ŒåŸºæœ¬å°±æ˜¯ç®€å•çš„ICLï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230520154610827.png"   style="zoom:30%;" />

ä½¿ç”¨`text-davinci-edit-001`ä½œä¸ºå®éªŒå¯¹è±¡ã€‚

## GPT-3 for Biomedical IE

Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again

EMNLP 2022 Findingsï¼Œä¿„äº¥ä¿„å·ç«‹å¤§å­¦ï¼Œ[ä»£ç ](https://github.com/dki-lab/few-shot-bioIE)ã€‚

> Large pre-trained language models (PLMs) such as GPT-3 have shown strong in-context learning capabilities, which are highly appealing for domains such as biomedicine that feature high and diverse demands of language technologies but also high data annotation costs. In this paper, **we present the first systematic and comprehensive study to compare the few-shot performance of GPT-3 in-context learning with fine-tuning smaller (i.e., BERT-sized) PLMs on two representative biomedical information extraction (IE) tasks: named entity recognition and relation extraction.** We follow the true few-shot setting (Perez et al., 2021) to avoid overestimating modelsâ€™ few-shot performance by model selection over a large validation set. We also optimize GPT-3â€™s performance with known techniques such as contextual calibration and dynamic in-context example retrieval. However, **our results show that GPT-3 still significantly underperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3 in-context learning also yields smaller gains in accuracy when more training data becomes available.** More in-depth analyses further reveal issues of in-context learning that may be detrimental to IE tasks in general. Given the high cost of experimenting with GPT-3, we hope our study provides helpful guidance for biomedical researchers and practitioners towards more practical solutions such as fine-tuning small PLMs before better in-context learning is available for biomedical IE.

ä½œè€…ä½¿ç”¨GPT-3è¿›è¡Œç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„IEä»»åŠ¡ï¼Œä¸»è¦ä½¿ç”¨ICLæŠ€æœ¯ï¼Œå‘ç°GPT-3è¿˜ä¸èƒ½å¤Ÿè¶…è¶Šç›®å‰åŸºäºSLMçš„SOTAæ–¹æ³•ï¼ŒåŒæ—¶å¾€ICLä¸­åŠ å…¥æ›´å¤šçš„demoså¹¶æ²¡æœ‰èƒ½å¤ŸæŒç»­æå‡æ•ˆæœã€‚

æ–¹æ³•ï¼š

![image-20230520164636198](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230520164636198.png)

ä½œè€…çš„æ–¹æ³•ä¸»è¦æ˜¯ä½¿ç”¨ICLæŠ€æœ¯ï¼Œä¸ºäº†èƒ½å¤Ÿé€‰æ‹©å’Œå½“å‰æ ·ä¾‹ç›¸è¿‘çš„demosï¼Œä½œè€…åŸºäºRoBERTa-largeä½œä¸ºç¼–ç å™¨ï¼Œä½¿ç”¨kNNæ–¹æ³•ä»100ä¸ªå›ºå®šçš„è®­ç»ƒé›†æ ·ä¾‹é›†åˆä¸­åŠ¨æ€é€‰æ‹©ã€‚NERæœ€å¤šé€‰æ‹©10ä¸ªæ ·ä¾‹ï¼ŒREæœ€å¤šé€‰æ‹©5ä¸ªæ ·ä¾‹ã€‚

é¢å¤–çš„ä¸¤ä¸ªå®ç°ç»†èŠ‚ï¼š

- Logit Biasesï¼šè°ƒç”¨OpenAI APIçš„*logit bias*å‚æ•°ï¼Œç»™æ‰€æœ‰å‡ºç°åœ¨åŸå§‹å¥å­ä¸­çš„tokensã€ä½œè€…é€‰æ‹©çš„chosen separatorå’Œnewline tokenå¢å¤§æ¦‚ç‡ã€‚é€‰æ‹©çš„logit biaså€¼æ˜¯$10$ã€‚
- Contextual Calibrationï¼šä½œè€…åœ¨å‰æœŸå®éªŒé‡Œå‘ç°ï¼Œé€‰å®šäº†ä¸€ç»„demonstrationsåï¼Œä¸ç®¡test queryæ˜¯ä»€ä¹ˆï¼Œè¿™ç»„demonstrationséƒ½æœ‰å¯¹äºæŸä¸ªç‰¹å®šlabelçš„åå¥½biasã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç‚¹ï¼Œä½œè€…å¯¹äºREä»»åŠ¡ï¼Œé‡‡ç”¨äº†Contextual calibratingæŠ€æœ¯[*Calibrate Before Use: Improving Few-shot Performance of Language Models. ICML 2021*]ã€‚ä¹Ÿå°±æ˜¯ç”¨ç‰¹æ®Šçš„NULL token `N/A` æ›¿æ¢å¥å­å’Œå¤´å°¾å®ä½“ï¼Œå¾—åˆ°null promptè¾“å…¥LLMï¼Œè·å¾—å…¶å¯¹äºlabelçš„åŸå§‹åå¥½åˆ†å¸ƒï¼Œç”¨å…¶æ¥æ›´æ–°REæŠ½å–çš„åˆ†å¸ƒã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230520164836464.png"   style="zoom:40%;" />

å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ä½œè€…çš„å®éªŒç¯å¢ƒä¸‹ï¼Œä½¿ç”¨GPT-3å’Œå½“å‰çš„SOTAæ–¹æ³•è¿˜æ˜¯æœ‰å·®è·ã€‚

## ChatGPT for ED

Exploring the Feasibility of ChatGPT for Event Extraction

arXiv 2023.03ï¼Œå“ˆå·¥å¤§-æ·±åœ³ã€‚

> Event extraction is a fundamental task in natural language processing that involves identifying and extracting information about events mentioned in text. However, it is a challenging task due to the lack of annotated data, which is expensive and time-consuming to obtain. The emergence of large language models (LLMs) such as ChatGPT provides an opportunity to solve language tasks with simple prompts without the need for task-specific datasets and fine-tuning. While ChatGPT has demonstrated impressive results in tasks like machine translation, text summarization, and question answering, it presents challenges when used for complex tasks like event extraction. **Unlike other tasks, event extraction requires the model to be provided with a complex set of instructions defining all event types and their schemas.** To explore the feasibility of ChatGPT for event extraction and the challenges it poses, we conducted a series of experiments. **Our results show that ChatGPT has, on average, only 51.04% of the performance of a task-specific model such as EEQA in long-tail and complex scenarios.** Our usability testing experiments indicate that ChatGPT is not robust enough, and continuous refinement of the prompt does not lead to stable performance improvements, which can result in a poor user experience. Besides, ChatGPT is highly sensitive to different prompt styles.

å±äºå¯¹LLMçš„capacity evaluationï¼Œä½œè€…ä½¿ç”¨ChatGPTè¿›è¡Œzero-shotçš„event detectionä»»åŠ¡ã€‚ä¸»è¦ç”¨çš„æ–¹æ³•æ˜¯ICLï¼Œä¸‹é¢æ˜¯ç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230521231825422.png"   style="zoom:30%;" />

æ€»ä½“æ•ˆæœå’ŒSOTAè¿˜æ˜¯æœ‰å·®è·ï¼Œä¸‹é¢æ˜¯åœ¨ACE 2005æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230521231945056.png"   style="zoom:30%;" />

ä¸è¿‡ä½œè€…åœ¨è®ºæ–‡ä¸­æåˆ°äº†ä»…ä»…æ˜¯ä½¿ç”¨äº†æµ‹è¯•é›†ä¸­çš„20ä¸ªsampleè¿›è¡Œäº†æµ‹è¯•ï¼Œè¿™ä¸ªç»“æœå¯èƒ½ä¸å¤Ÿå‡†ç¡®ã€‚

ä¸è¿‡ä¸€ä¸ªæœ‰æ„æ€çš„æ˜¯ä½œè€…æ‰¾äº†å››NLPé¢†åŸŸçš„ç ”ç©¶ç”Ÿï¼Œè®©ä»–ä»¬å»5æ¬¡æ”¹å˜promptæ¥è·å¾—æ›´å¥½çš„æ•ˆæœæœºä¼šï¼Œæµ‹è¯•æ ·ä¾‹ä¸€å…±æœ‰10ä¸ªï¼Œä¸‹é¢æ˜¯å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230521232252014.png"   style="zoom:30%;" />

åŒæ ·ï¼Œä¸ªäººè®¤ä¸ºè¿™ä¸ªç»“æœä¹Ÿä¸å¤Ÿé²æ£’ï¼Œæ¯”è¾ƒæµ‹è¯•æ ·ä¾‹åªæœ‰10ä¸ªï¼Œé”™1ä¸ªæ ·ä¾‹å°±æ˜¯10%çš„å·®è·äº†ã€‚

## Wadhwa et al.

Revisiting Relation Extraction in the era of Large Language Models. Northeastern Universityï¼ŒACL 2023.

> Relation extraction (RE) is the core NLP task of inferring semantic relationships between entities from text. Standard supervised RE techniques entail training modules to tag tokens comprising entity spans and then predict the relationship between them. Recent work has instead treated the problem as a sequence-to-sequence task, linearizing relations between entities as target strings to be generated conditioned on the input. **Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision.** We address issues inherent to evaluating generative approaches to RE by doing human evaluations, in lieu of relying on exact matching. Under this refined evaluation, we find that: (1) Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly equivalent to existing fully supervised models; (2) Flan-T5 is not as capable in the few-shot setting, but supervising and fine-tuning it with Chain-of-Thought (CoT) style explanations (generated via GPT3) yields SOTA results. We release this model as a new baseline for RE tasks.

ä½œè€…è¿™ç¯‡è®ºæ–‡ä¸»è¦åšäº†ä¸¤ä¸ªå·¥ä½œï¼š

1. æµ‹è¯•å¹¶è¯„ä¼°GPT-3å¯¹äºREä»»åŠ¡çš„æ€§èƒ½ã€‚ç”±äºä½œè€…å‘ç°GPT-3å¸¸å¸¸ä¼šäº§ç”Ÿå’Œè¾“å…¥è¦æ±‚ä¸ä¸€è‡´çš„å…³ç³»ï¼Œå› æ­¤ä½œè€…è¿˜é‡æ–°äººå·¥è¯„ä¼°äº†æ•ˆæœGPT-3å¯¹REä»»åŠ¡çš„æ€§èƒ½ã€‚ä½œè€…å‘ç°åœ¨CONLL04å’ŒADEæ•°æ®é›†ä¸Šå¯ä»¥è¾¾åˆ°æ¥è¿‘SOTAçš„ç»“æœã€‚
2. ä½œè€…é€šè¿‡ä½¿ç”¨GPT-3è‡ªåŠ¨ç”Ÿæˆçš„explanationsä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡å¾®è°ƒFlanT5-largeè¾¾åˆ°äº†æ–°çš„SOTAã€‚

ä½œè€…æµ‹è¯•GPT-3çš„è¾“å…¥å¦‚å›¾ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524194415967.png"    style="zoom:40%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524194429292.png"   style="zoom:40%;" />

åœ¨æµ‹è¯•çš„æ—¶å€™ä¼šéšæœºé‡‡æ ·12ä¸ªexamplesä½œä¸ºå›ºå®šçš„demonstrationsã€‚ç„¶åä½œè€…å‘ç°GPT-3ä¼šäº§ç”Ÿå’Œè¾“å…¥ä¸ä¸€è‡´çš„è¾“å‡ºrelationï¼Œä½†æ˜¯è¿™äº›relationè®©äººå·¥å»è¯„ä¼°çš„è¯åˆä¼šæ„Ÿè§‰åœ¨è¯­ä¹‰ä¸Šæ˜¯ä¸€è‡´çš„ã€‚å› æ­¤ä½œè€…åˆäººå·¥é‡æ–°è¯„ä¼°äº†æ‰€æœ‰çš„è¾“å‡ºç»“æœï¼ˆé€šè¿‡åœ¨Amazon Mechanical Turkå¹³å°ä¸Šä¼—åŒ…ï¼‰ã€‚æ•°æ®é›†çš„åˆ†å¸ƒå¦‚ä¸‹æ‰€ç¤ºï¼ŒADEè¿™ä¸ªæ•°æ®é›†æ˜¯ç”¨10-foldäº¤å‰éªŒè¯æ¥è¿›è¡Œè¯„ä¼°ã€‚é™¤NYTå¤–ï¼Œå…¶å®ƒä¸¤ä¸ªæ•°æ®é›†æµ‹è¯•é‡æŒºå°çš„ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524194748501.png"   style="zoom:40%;" />

ä¸‹é¢æ˜¯ä½œè€…çš„GPT-3å®éªŒç»“æœï¼ˆè®°ä½è¿™é‡Œçš„GPT-3è¯„ä¼°ç»“æœæ˜¯ç”±äººå·¥é‡æ–°è¯„ä¼°ä¹‹åçš„ï¼ŒåŒæ—¶å…¶å®ƒæ¨¡å‹çš„è¾“å‡ºå¹¶æ²¡æœ‰è¿›è¡Œäººå·¥çš„è¯„ä¼°ï¼Œä¸ªäººè®¤ä¸ºæ˜¯ä¸å‡†ç¡®çš„ï¼‰ï¼š

![image-20230524195229694](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524195229694.png)

ä¸Šé¢çš„ç»“æœæ˜¾ç¤ºï¼ŒGPT-3åœ¨NYTæ•°æ®é›†ä¸Šè¡¨ç°æ•ˆæœä¸å¥½ï¼Œè¿™æ˜¯å› ä¸ºNYTçš„å…³ç³»ç±»å‹å¤ªå¤šï¼Œå¯¼è‡´æ— æ³•å‡†ç¡®çš„æè¿°NYTä¸­ä¸åŒå…³ç³»ç±»å‹ã€‚

ä½œè€…è¿›ä¸€æ­¥æå‡ºï¼Œå¯ä»¥ä½¿ç”¨GPT-3è‡ªåŠ¨ç”Ÿæˆçš„è§£é‡Šä½œä¸ºCoTæ¥è¿›ä¸€æ­¥å¼•å¯¼æ¨¡å‹å¾®è°ƒã€‚ä½œè€…å…ˆè®©GPT-3ç”Ÿæˆè§£é‡Šï¼Œç„¶åç”¨è¿™äº›ç”Ÿæˆçš„è§£é‡Šè¾“å…¥åˆ°Flan-T5-largeï¼ˆ760Mï¼‰ï¼Œéšåè¿›è¡Œå¾®è°ƒè¿›ä¸€æ­¥å¯ä»¥æå‡Flan-T5-largeçš„æ€§èƒ½ã€‚ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524200126966.png"   style="zoom:40%;" />

ä½œè€…åœ¨è®ºæ–‡é‡ŒæŠŠFlan-T5-largeä¹Ÿå«åšæ˜¯LLMï¼Œä¸ªäººè®¤ä¸ºä¸åˆé€‚ã€‚

## QA4RE

Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors. ä¿„äº¥ä¿„å·ç«‹å¤§å­¦ï¼ŒACL 2023 Findingsã€‚[ä»£ç ](https://github.com/OSU-NLP-Group/QA4RE)ã€‚

> Recent work has shown that fine-tuning large language models (LLMs) on large-scale instruction-following datasets substantially improves their performance on a wide range of NLP tasks, especially in the zero-shot setting. However, even advanced instruction-tuned LLMs still fail to outperform small LMs on relation extraction (RE), a fundamental information extraction task. We hypothesize that instruction-tuning has been unable to elicit strong RE capabilities in LLMs due to REâ€™s low incidence in instruction-tuning datasets, making up less than 1% of all tasks (Wang et al., 2022). To address this limitation, **we propose QA4RE, a framework that aligns RE with question answering (QA), a predominant task in instruction-tuning datasets.** Comprehensive zero-shot RE experiments over four datasets with two series of instruction-tuned LLMs (six LLMs in total) demonstrate that our QA4RE framework consistently improves LLM performance, strongly verifying our hypothesis and enabling LLMs to outperform strong zero-shot baselines by a large margin. Additionally, we provide thorough experiments and discussions to show the robustness, few-shot effectiveness, and strong transferability of our QA4RE framework. This work illustrates a promising way of adapting LLMs to challenging and underrepresented tasks by aligning these tasks with more common instruction-tuning tasks like QA.

ä½œè€…è¿™ç¯‡å·¥ä½œçš„æ€æƒ³å¾ˆç®€å•ï¼Œå°±æ˜¯æŠŠrelationé€‰æ‹©è½¬åŒ–ä¸ºmulti-choice optionsé€‰æ‹©çš„QAé—®é¢˜ã€‚ç±»ä¼¼çš„åšæ³•åœ¨filter-then-reranké‡Œæœ‰å®ç°ã€‚

ä½œè€…è¿™ä¹ˆåšçš„å‡ºå‘ç‚¹æ˜¯ä¹‹å‰çš„ç ”ç©¶å‘ç°LLMå¯¹äºREçš„æ•ˆæœä¸å¥½ï¼Œä½œè€…è‡ªå·±ä½¿ç”¨GPT-3.5å’ŒFlanT5è¿›è¡Œäº†å°è¯•å‘ç°åŒæ ·æ•ˆæœä¸å¥½ã€‚ä½œè€…è®¤ä¸ºè¿™æ ·çš„åŸå› æ˜¯LLMæ¨¡å‹åœ¨è¿›è¡Œinstruction tuningè¿‡ç¨‹ä¸­ï¼Œåªæœ‰æå°‘çš„æ ·æœ¬å¯èƒ½æ¶‰åŠäº†REä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç»Ÿè®¡ç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230528105537993.png"   style="zoom:50%;" />

å› æ­¤ä½œè€…å°†REä»»åŠ¡çš„å½¢å¼å’Œåœ¨instruction tuningæ•°æ®é›†ä¸­æ›´å¸¸å‡ºç°çš„QAä»»åŠ¡å½¢å¼å¯¹é½ã€‚ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

![image-20230524234509972](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524234509972.png)

ä½œè€…å®ç°çš„éƒ¨åˆ†ç»†èŠ‚ï¼š

- ä½¿ç”¨SuREæ–¹æ³•[*Summarization as indirect supervision for relation extraction*]ä¸­æå‡ºçš„relation templateæ¥æ„é€ æ¨¡æ¿

- ä½¿ç”¨`text-davinci-003`å’Œ`FLAN-T5-XXLarge`ä½œä¸ºåŸºåº§LLM

- å¯¹äºprompt engineeringï¼Œä½œè€…ä½¿ç”¨text-davinci-002åœ¨TACREDçš„dev setä¸Šé€‰æ‹©250ä¸ªæ ·ä¾‹è¿›è¡Œè¯„ä¼°ã€‚ç„¶åå¯¹æ‰€æœ‰çš„æµ‹è¯•æ•°æ®é›†ä½¿ç”¨ç›¸åŒçš„promptæ ¼å¼ã€‚ä»¥å…³ç³»$org:top\_members/employees$ä¸ºä¾‹ï¼Œä½œè€…è¿›è¡Œäº†å››ç§æ¨¡æ¿çš„å°è¯•ï¼ˆè¿™å››ç§æ¨¡æ¿ä¹Ÿæ˜¯å‰äººçš„å·¥ä½œï¼‰ï¼š

  <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235128751.png"   style="zoom:35%;" />

ä½œè€…çš„zero-shot REå®éªŒç»“æœï¼š

![image-20230524235216668](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235216668.png)

ä¸ºäº†é™åˆ¶OpenAIçš„èŠ±è´¹ï¼Œä½œè€…ä»æµ‹è¯•é›†é‡‡æ ·äº†1000ä¸ªä¾‹å­è¯„ä¼°åŸºäºtext-davinci-003çš„æ•ˆæœã€‚é€šè¿‡ä½œè€…æå‡ºçš„ç®€å•promptæ”¹åŠ¨ï¼Œå°±è·å¾—äº†å¹³å‡8%å·¦å³çš„æå‡â€¦

ä¸è¿‡ä½œè€…è¿›ä¸€æ­¥åœ¨é™„å½•é‡Œæä¾›äº†å¯¹äºFlan-T5åœ¨æ•´ä¸ªæµ‹è¯•é›†ä¸‹çš„æµ‹è¯•ç»“æœï¼š

![image-20230528105952811](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230528105952811.png)

åŒæ ·èƒ½å¤Ÿçœ‹åˆ°ç®€å•çš„æ”¹åŠ¨å¸¦æ¥äº†éå¸¸æ˜æ˜¾çš„æç¤ºã€‚

ä¸‹é¢æ˜¯ä½œè€…åšçš„æ›´å¤šçš„æ¢ç©¶å®éªŒï¼Œä¸ªäººè®¤ä¸ºæœ‰ä¸€å®šå‚è€ƒä»·å€¼ã€‚

å¯¹äº4ç§promptæ ¼å¼çš„å®éªŒï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235402066.png"   style="zoom:35%;" />

å¯ä»¥çœ‹åˆ°promptçš„è®¾è®¡è¿˜æ˜¯å¾ˆå…³é”®çš„ï¼Œæ€ä¹ˆæ ·æ‰¾åˆ°åˆé€‚çš„promptå¼•èµ·äº†10%å·¦å³çš„åå·®ï¼ˆå³ä½¿åœ¨äººç±»çœ‹æ¥ä¸åŒçš„relation optionæ¨¡æ¿éƒ½æ˜¯æ­£ç¡®çš„ï¼‰ã€‚

ä½œè€…è¿˜é¢å¤–åšäº†few-shotå®éªŒï¼Œfew-shotä¸Šè¡¨ç°çš„æ•ˆæœä¸å¥½ï¼Œç‰¹åˆ«æ˜¯å—åˆ°è¾“å…¥é•¿åº¦çš„é™åˆ¶ä¸èƒ½æŒç»­çš„è¾“å…¥shotæ ·ä¾‹ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235554154.png"  style="zoom:35%;" />

å¦ä¸€ä¸ªæœ‰å‚è€ƒæ„ä¹‰çš„å®éªŒæ˜¯ä½œè€…åœ¨task instructionä¸­åŠ å…¥äº†å¯¹äºlabelçš„æè¿°ï¼Œè€Œä¿æŒoptionè¿˜æ˜¯ç¼©ç•¥çš„relationï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235720898.png"  style="zoom:35%;" />

å®éªŒç»“æœå‘ç°ä»…ä»…é€šè¿‡å¯¹labelè¿›è¡ŒæŠ½è±¡çš„è§£é‡Šï¼Œä¸èƒ½å¤Ÿå¾ˆå¥½çš„æå‡LLMçš„å›ç­”ã€‚åè€Œå¦‚æœ¬æ–‡æå‡ºçš„QA4REä¸€æ ·æŠŠä¸åŒlabelçš„è¾“å‡ºç›´æ¥è½¬åŒ–ä¸ºå…·ä½“çš„å¥å­ï¼ŒLLMæ›´å®¹æ˜“ç†è§£ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235816398.png"  style="zoom:35%;" />

ä½œè€…è¿˜æ¯”è¾ƒäº†åŸºäºLLMçš„æ–¹æ³•éšç€model sizeå˜åŒ–çš„æ€§èƒ½å˜åŒ–ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235859346.png"   style="zoom:35%;" />

å¯ä»¥çœ‹åˆ°éšç€æ¨¡å‹sizeçš„å¢å¤§ï¼Œæ•ˆæœè¶Šæ¥è¶Šå¥½ã€‚ä½†æ˜¯æå‡çš„å¹…åº¦å’Œsizeå¤§å°å¹¶ä¸æ˜¯æˆæ¯”ä¾‹çš„

ï¼ˆæ•´ç¯‡è®ºæ–‡æ–¹æ³•éƒ¨åˆ†åªè®¨è®ºäº†1é¡µå·¦å³ï¼Œå®éªŒéƒ¨åˆ†è®¨è®ºäº†4é¡µå¤šï¼‰

## GPT-RE

GPT-RE: In-context Learning for Relation Extraction using Large Language Models. äº¬éƒ½å¤§å­¦. EMLNLP 2023. [ä»£ç ](https://github.com/YukinoWan/GPT-RE).

> In spite of the potential for ground-breaking achievements offered by large language models (LLMs) (e.g., GPT-3), they still lag significantly behind fully-supervised baselines (e.g., fine-tuned BERT) in relation extraction (RE). This is due to the two major shortcomings of LLMs in RE: (1) **low relevance regarding entity and relation in retrieved demonstrations for in-context learning;** and (2) **the strong inclination to wrongly classify NULL examples into other pre-defined labels**.
>
> In this paper, we propose GPT-RE to bridge the gap between LLMs and fully-supervised baselines. GPT-RE successfully addresses the aforementioned issues by (1) incorporating task-specific entity representations in demonstration retrieval; and (2) enriching the demonstrations with gold label-induced reasoning logic. We evaluate GPT-RE on four widely-used RE datasets, and observe that GPT-RE achieves improvements over not only existing GPT-3 baselines, but also fully-supervised baselines. Specifically, GPT-RE achieves SOTA performances on the Semeval and SciERC datasets, and competitive performances on the TACRED and ACE05 datasets.

ä½œè€…è¿™ç¯‡å·¥ä½œæ˜¯å¯¹äº[*Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again*]å·¥ä½œçš„æ”¹è¿›ï¼Œä¸»è¦æ˜¯é’ˆå¯¹å…¶ä¸¤ä¸ªé—®é¢˜è¿›è¡Œæ”¹è¿›ï¼š

- åœ¨ICLä¸­çš„demonstrationsçš„é€‰æ‹©åªæ˜¯ä»sentence-levelè¿›è¡Œæ¯”è¾ƒï¼Œå¿½ç•¥äº†å®ä½“å’Œå…³ç³»çš„è¯­ä¹‰
- LLMå¾ˆéš¾å‡†ç¡®åœ°åˆ†ç±»NULLå…³ç³»

ä¸‹é¢æ˜¯ç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527155614789.png"   style="zoom:35%;" />

ä½œè€…æäº†ä¸¤ç‚¹æ”¹è¿›ï¼š

- é€šè¿‡ä¿®æ”¹promptæ ¼å¼ï¼Œè®©promptæ›´åŠ å¼ºè°ƒå¥å­ä¸­çš„å®ä½“ä¿¡æ¯ï¼›æˆ–è€…ç›´æ¥ä½¿ç”¨ä¸€ä¸ªåœ¨REä»»åŠ¡ä¸Šfine-tunedå¥½çš„BERTæ¨¡å‹æ¥è·å–å¤´å°¾å®ä½“çš„embeddingï¼›ä¹‹åå†è¿›è¡ŒåŸºäºkNNçš„demonstrationsæ£€ç´¢
- åŠ å…¥äº†CoTï¼Œä¹Ÿå°±æ˜¯è®©GPTè‡ªå·±ç”Ÿæˆä¸€ä¸ªè§£é‡Šï¼ŒåŠ å…¥åˆ°ICLçš„demonstrationsä¸­ã€‚

æ–¹æ³•å›¾ï¼š

![image-20230527160412848](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527160412848.png)

demonstrationsæ£€ç´¢æ–¹æ³•çš„æ”¹è¿›ï¼š

- æ–¹æ¡ˆ1ï¼šä¿®æ”¹contextæ ¼å¼ï¼Œä¾‹å¦‚â€™He has a sister Lisaâ€˜ä¿®æ”¹ä¸ºâ€™The relation between â€˜Heâ€™ and â€˜Lisaâ€™ in the context: He has a sister Lisa.â€˜
- æ–¹æ¡ˆ2ï¼šæ›´åŠ ç›´æ¥ï¼Œä½¿ç”¨fine-tunedå¤´å°¾å®ä½“è¡¨å¾æ¥è¿›è¡ŒkNNæ£€ç´¢ã€‚ä½œè€…è‡ªå·±å¾®è°ƒäº†ä¸€ä¸ªé’ˆå¯¹REä»»åŠ¡çš„BERTæ¥è·å–å¤´å°¾å®ä½“è¡¨å¾ã€‚ï¼ˆä¸€ä¸ªç®€å•ç²—æš´ï¼Œæ³›åŒ–æ€§å¼±çš„æ–¹æ³•ï¼Œä½†æ˜¯æ•ˆæœæœ€å¥½ï¼‰

CoTä¸­çš„explanationsæ˜¯ä½¿ç”¨GPTè‡ªåŠ¨ç”Ÿæˆçš„ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230528111844081.png"   style="zoom:40%;" />

ä½œè€…ä½¿ç”¨SimCSEæ–¹æ³•æ¥è¡¡é‡ç›¸ä¼¼åº¦ã€‚ä¸‹é¢æ˜¯å®éªŒç”¨çš„æ•°æ®é›†å’Œå®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527214328082.png"   style="zoom:40%;" />

![image-20230527214353436](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527214353436.png)

å®éªŒç»“æœä¸­ï¼ˆåŸºäºtext-davinci-003ï¼‰ï¼Œ

- Randomï¼šéšæœºæ‰¾few-shotçš„demonstrations
- Sentï¼šä½¿ç”¨SimCSE
- RE_SimCSE: æ–¹æ¡ˆ1
- RE_FTï¼šæ–¹æ¡ˆ2

å¯ä»¥è§‚å¯Ÿå¾—åˆ°ç»“è®ºï¼š

- è™½ç„¶æ€»ä½“è¡¨ç°å‡ºäº†ä¸é”™çš„æ•ˆæœï¼Œä½†æ˜¯å¯ä»¥çœ‹åˆ°éœ€è¦æ ·ä¾‹æ•°æ¯”è¾ƒå¤§ï¼ˆæœ€å°‘ä¹Ÿåœ¨15ä¸ªæ ·ä¾‹ä»¥ä¸Šï¼‰æ‰èƒ½è¾¾åˆ°SOTAï¼Œè€Œä¸”è°ƒç”¨GPTçš„ä»£ä»·æ¯”è¾ƒå¤§ï¼ˆèŠ±é’±ï¼Œä»¥è‡³äºä½œè€…åœ¨TACREDå’ŒACE05è¿™ä¸¤ä¸ªæ¯”è¾ƒå¤§testæ•°æ®é›†ä¸‹åªé€‰æ‹©äº†10%çš„æ ·ä¾‹ï¼‰ã€‚
- å®Œå…¨æ— è®­ç»ƒæ— æ¢¯åº¦æ›´æ–°çš„æ–¹æ¡ˆä¸€ï¼Œä»ç„¶æ²¡æœ‰è¾¾åˆ°SOTAã€‚åªæœ‰ä½¿ç”¨è®­ç»ƒåçš„è¡¨å¾æ¥æ£€ç´¢ï¼Œæ‰èƒ½è¾¾åˆ°SOTAï¼Œå¹¶ä¸”æå‡å¹…åº¦å¾ˆå¤§ã€‚
- æ²¡æœ‰æ¯”è¾ƒæ¨ç†é€Ÿåº¦ï¼Œä¸ªäººè®¤ä¸ºæ¨ç†é€Ÿåº¦ä¸ä¼šå¿«ï¼ˆæ£€ç´¢+å¤§æ¨¡å‹ï¼‰
- åŠ å…¥CoTçš„æ•ˆæœæå‡å¹…åº¦ä¸æ˜¯ç‰¹åˆ«å¤§ï¼Œå¹¶ä¸”è¦æ±‚äº†é¢å¤–çš„GPTè¯·æ±‚ï¼Œæ›´åŠ èŠ±é’±ï¼ˆä½œè€…åœ¨å®éªŒéƒ¨åˆ†å¯¹CoTçš„å¯¹æ¯”ä»…ä»…é€šè¿‡15ä¸ªæ ·ä¾‹ï¼Œè€Œä¸æ˜¯æœ€å¥½çš„æ ·ä¾‹æ•°é‡ï¼Œè¿™æ˜¯å› ä¸ºè¾“å…¥é•¿åº¦çš„é™åˆ¶ï¼‰

ä¸‹é¢æ˜¯ä½œè€…å¯¹äºéšç€shotæ•°é‡å˜åŒ–ï¼Œæ¨¡å‹æ€§èƒ½çš„å˜åŒ–ï¼Œå¯ä»¥çœ‹åˆ°æå‡è¿˜æ˜¯å¾ˆå¤§çš„ï¼ˆæœ€å¤šæœ‰åå‡ ä¸ªç‚¹çš„æå‡ï¼‰ã€‚åŒæ—¶ä»æ¶ˆèæ‰CoTï¼ˆå³reasoningï¼‰çš„æ•ˆæœæ¥çœ‹ï¼ŒåŠ å…¥CoTï¼ˆè§£é‡Šï¼‰çš„æƒ…å†µä¸‹ï¼Œå¯¹äºæ›´å°‘demonstrationsçš„æƒ…å†µæå‡æ›´æ˜æ˜¾ï¼ˆå›¾ä¸­shot=30çš„æ—¶å€™æ²¡æœ‰å¯¹åº”çš„æ¶ˆèå®éªŒï¼Œç”±äºè¾“å…¥é•¿åº¦é™åˆ¶ï¼‰ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527231519715.png"  style="zoom:35%;" />

## AutoKG

LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities

arXiv 2023.05ï¼Œæµ™å¤§ZJUNLPï¼Œ[ä»£ç ](https://github .com/zjunlp/AutoKG)ã€‚

> This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We employ eight distinct datasets that encompass aspects including entity, relation and event extraction, link prediction, and question answering. Empirically, our findings suggest that GPT-4 outperforms ChatGPT in the majority of tasks and even surpasses fine-tuned models in certain reasoning and question-answering datasets. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, which culminates in the presentation of the Virtual Knowledge Extraction task and the development of the VINE dataset. Drawing on these empirical findings, we further propose AutoKG, a multiagent-based approach employing LLMs for KG construction and reasoning, which aims to chart the future of this field and offer exciting opportunities for advancement. We anticipate that our research can provide invaluable 1 insights for future undertakings of KG.

è°ƒç ”æ—¶çœ‹åˆ°çš„é¦–ä¸ªä½¿ç”¨GPT-4è¿›è¡ŒçŸ¥è¯†å›¾è°±ç›¸å…³ä»»åŠ¡çš„paperï¼Œå¯æƒœå—é™äºGPT-4çš„è®¿é—®ä»£ä»·ï¼Œä½œè€…ä»…ä»…æ˜¯å¯¹æ¯ä¸ªä»»åŠ¡éƒ½è¿›è¡Œäº†20ä¸ªå·¦å³çš„æµ‹è¯•æ ·ä¾‹çš„è¯„ä¼°ã€‚å‘ç°GPT-4å¯¹äºIEä»»åŠ¡æ•ˆæœæ¯”ChatGPTè¦å¥½ï¼Œä½†æ˜¯ä»ç„¶å’ŒSOTAæœ‰å·®è·ï¼ŒåŒæ—¶GPT-4æ›´åŠ æ“…é•¿KG reasoningï¼ˆlinking predictionï¼‰å’ŒQAä»»åŠ¡ã€‚

ç„¶åä½œè€…è‡ªå·±ä»RE-TACREDæ•°æ®é›†ä¸­é€‰æ‹©å¥å­ï¼Œä½¿ç”¨éšæœºåˆ›å»ºçš„æ–°è¯æ›¿æ¢å…¶ä¸­çš„å®ä½“å’Œå…³ç³»ï¼Œæ„é€ äº†ä¸€ä¸ªGPT-4åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰è§è¿‡çš„è™šå‡æ•°æ®é›†VINEï¼Œå‘ç°GPT-4ç¡®å®æ˜¯èƒ½å¤Ÿå¿«é€Ÿç†è§£instructionå»è¿›è¡Œä¿¡æ¯æŠ½å–ã€‚æœ€åæ˜¯ä½œè€…å€ŸåŠ©CAMELæ–¹æ³•ä¸­æå‡ºçš„role-playingæ–¹æ³•ï¼Œæå‡ºäº†ä¸€ä¸ªAutoKGçš„æ¦‚å¿µã€‚

![image-20230529000001137](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230529000001137.png)

## structured prompting

Prompting Language Models for Linguistic Structure

ACL 2023ï¼Œåç››é¡¿å¤§å­¦

> Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, **it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns.** To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases. We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pre-training corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.

ä½œè€…æå‡ºäº†ä¸€ç§ç®€å•çš„åºåˆ—æ ‡æ³¨promptæ–¹æ³•ï¼Œå°±æ˜¯åœ¨è¾“å‡ºçš„æ¯ä¸ªword tokenä¹‹ååŠ å…¥è¦æ ‡æ³¨çš„labelã€‚ä½œè€…æåˆ°äº†ï¼Œåœ¨è¾“å‡ºçš„æ—¶å€™ä¸æ˜¯ç›´æ¥è¾“å‡ºæ‰€æœ‰çš„tagåºåˆ—ï¼Œè€Œæ˜¯åŒæ—¶è¦è¾“å‡ºåŸæœ‰çš„word+tagã€‚å¦‚æœä¸é‡å¤è¾“å‡ºwordçš„è¯ï¼Œæ•ˆæœç”šè‡³ä¼šä¸‹é™70%-80%ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531113232237.png"   style="zoom:40%;" />

åŸºäºGPT-NeoXã€GPT-Curieã€GPT-Davinciè¿›è¡Œäº†å®éªŒã€‚ä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œä»æ•°æ®é›†ä¸­éšæœºæ‰¾$k$ä¸ªæ ·ä¾‹ï¼Œåªè¦ä¿è¯è¿™äº›æ ·ä¾‹èƒ½å¤Ÿè¦†ç›–æ‰€æœ‰çš„labelå³å¯ã€‚

æœ‰ä¸€ç‚¹å®éªŒå¯å‘çš„æ˜¯ï¼Œä½œè€…å‘ç°åœ¨NERä»»åŠ¡ä¸‹ï¼ŒLLMä¹Ÿå¸¸å¸¸ä¼šé”™è¯¯çš„åˆ†ç±»`O` labelï¼Œå’Œå…¶å®ƒçš„ç ”ç©¶å‘ç°REä»»åŠ¡å¸¸å¸¸é”™è¯¯åˆ†ç±»`None`ä¸€æ ·ã€‚è¿™è¯´æ˜äº†è¿™äº›æ¯”è¾ƒæ¨¡ç³Šã€æˆ–è€…å†…éƒ¨è¯­ä¹‰åˆ†å¸ƒæ¯”è¾ƒå¤šæ ·çš„labelï¼Œè®©LLMç›´æ¥å»åšå¾ˆå¯èƒ½å‡†ç¡®åº¦ä¸é«˜ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531153548171.png"   style="zoom:40%;" />

ä½œè€…è¿˜åŸºäºGPT-Neoçš„é¢„è®­ç»ƒæ•°æ®Pileä¸­ï¼Œå»æŸ¥æ‰¾æœ‰æ²¡æœ‰labelæ•°æ®ï¼Œç»“æœå‘ç°æ˜¯æœ‰çš„ï¼š

![image-20230531153914033](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531153914033.png)

## GPT-NER

GPT-NER: Named Entity Recognition via Large Language Models

åŒ—å¤§ï¼ŒarXivï¼Œ[ä»£ç ](https://github.com/ShuheWang1998/GPT-NER)ã€‚

> Despite the fact that large-scale Language Models (LLM) have achieved SOTA performances on a variety of NLP tasks, its performance on NER is still significantly below supervised baselines. This is due to the gap between the two tasks the NER and LLMs: the former is a sequence labeling task in nature while the latter is a text-generation model.
>
> In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the gap by transforming the sequence labeling task to a generation task that can be easily adapted by LLMs e.g., the task of finding location entities in the input text Columbus is a city is transformed to generate the text sequence @@Columbus## is a city, where special tokens @@## marks the entity to extract. To efficiently address the hallucination issue of LLMs, where LLMs have a strong inclination to over-confidently label NULL inputs as entities, we propose a self-verification strategy by prompting LLMs to ask itself whether the extracted entities belong to a labeled entity tag.
>
> We conduct experiments on five widely adopted NER datasets, and GPT-NER achieves comparable performances to fully supervised baselines, which is the first time as far as we are concerned. More importantly, we find that GPT-NER exhibits a greater ability in the low-resource and few-shot setups, when the amount of training data is extremely scarce, GPT-NER performs significantly better than supervised models. This demonstrates the capabilities of GPT-NER in real-world NER applications where the number of labeled examples is limited.

æ–¹æ³•å›¾ï¼š

![image-20230627153804979](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627153804979.png)

ä½œè€…è®¤ä¸ºNER focuses more on local evidence rather than a sentence-level taskã€‚æ¯”å¦‚è¦æŸ¥è¯¢å¥å­â€œJohn is a soldierâ€ï¼Œä»sentence-levelç›¸ä¼¼æ€§æ¥çœ‹ï¼Œâ€œhe is a soldierâ€æ˜¯ç›¸ä¼¼çš„ã€‚ä½†æ˜¯â€œhe is a soldierâ€ä¸­éƒ½æ²¡äº‹å®ä½“ï¼Œå¯èƒ½å¯»æ‰¾å…¶å®ƒå±äºPERSONçš„å®ä½“åº”è¯¥åˆç†ã€‚

![image-20230627154141754](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627154141754.png)

ä½œè€…è¿˜é¢å¤–è¿›è¡Œäº†ç»“æœçš„éªŒè¯ï¼š

![image-20230627154210391](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627154210391.png)

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627154237264.png"   style="zoom:40%;" />

ä»å®éªŒç»“æœæ¥çœ‹ï¼Œä¸åŒæ£€ç´¢æ–¹æ¡ˆä¹‹é—´çš„å·®å¼‚å¾ˆå¤§ã€‚è€Œè‡ªæˆ‘éªŒè¯ç­”æ¡ˆæ­£ç¡®ä¸å¦çš„å®éªŒç»“æœï¼Œå‘ç°ä¹Ÿå°±æ˜¯æå‡äº†å¤§æ¦‚1ä¸ªç‚¹å·¦å³ã€‚

## BertNet

BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models

ACL 2023 Findings, [ä»£ç ](https://github.com/tanyuqian/knowledge-harvest-from-lms)ã€‚

> It is crucial to automatically construct knowledge graphs (KGs) of diverse new relations to support knowledge discovery and broad applications. Previous KG construction methods, based on either crowdsourcing or text mining, are often limited to a small predefined set of relations due to manual cost or restrictions in text corpus. Recent research proposed to use pretrained language models (LMs) as implicit knowledge bases that accept knowledge queries with prompts. Yet, the implicit knowledge lacks many desirable properties of a full-scale symbolic KG, such as easy access, navigation, editing, and quality assurance. In this paper, we propose a new approach of harvesting massive KGs of arbitrary relations from pretrained LMs. With minimal input of a relation definition (a prompt and a few shot of example entity pairs), the approach efficiently searches in the vast entity pair space to extract diverse accurate knowledge of the desired relation. We develop an effective search-and-rescore mechanism for improved efficiency and accuracy. We deploy the approach to harvest KGs of over 400 new relations from different LMs. Extensive human and automatic evaluations show our approach manages to extract diverse accurate knowledge, including tuples of complex relations (e.g., "A is capable of but not good at B"). The resulting KGs as a symbolic interpretation of the source LMs also reveal new insights into the LMsâ€™ knowledge capacities.

ç›´æ¥ä»LLMæŠ½å–ä¿¡æ¯ï¼Œæ–¹æ³•å›¾ï¼š

![image-20230627154802433](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627154802433.png)

è¯„ä¼°ä¸åŒpromptçš„å…¬å¼ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627154830846.png"   style="zoom:40%;" />

$p$ä»£ç promptï¼Œ$h,t$ä»£è¡¨å¤´å°¾å®ä½“å¯¹ã€‚æ ¹æ®ä¸åŒpromptç”Ÿæˆçš„æ–°çš„å¤´å°¾å®ä½“ï¼Œå’Œæ¯ä¸€ä¸ªpromptåŒ¹é…åï¼Œè®¡ç®—ä¸Šé¢çš„å…¬å¼è·å¾—æ‰“åˆ†ï¼Œå†è¿›è¡Œæ’åºã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627155033043.png"   style="zoom:50%;" />

è¡¨æ ¼ä¸­çš„accuracyæ˜¯äººå·¥åˆ¤æ–­ç”Ÿæˆçš„ä¿¡æ¯ä¸‰å…ƒç»„æ˜¯å¦æ­£ç¡®ã€‚relation setæ˜¯æŒ‡ä½œè€…åˆå§‹é˜¶æ®µä½¿ç”¨çš„relation seté›†åˆæ¥æºã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230627155208099.png"   style="zoom:35%;" />

æ¨¡å‹è¶Šå¤§ï¼ŒæŠ½å–å‡ºæ¥çš„ä¿¡æ¯æ­£ç¡®ç¨‹åº¦è¶Šé«˜ã€‚

## CoT-MIE

Chain-of-Thought Prompt Distillation for Multimodal Named Entity Recognition and Multimodal Relation Extraction

é˜¿é‡ŒAnt groupï¼Œ2023-08 arXiv

> Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction (MRE) necessitate the fundamental reasoning capacity for intricate linguistic and multimodal comprehension. In this study, we explore distilling the reasoning ability of large language models (LLMs) into a more compact student model by generating a chain of thought (CoT) â€“ a sequence of intermediate reasoning steps. Specifically, we commence by exemplifying the elicitation of such reasoning ability from LLMs through CoT prompts covering multi-grain (noun, sentence, multimodality) and data-augmentation (style, entity, image) dimensions. Subsequently, we present a novel conditional prompt distillation method to assimilate the commonsense reasoning ability from LLMs, thereby enhancing the utility of the student model in addressing text-only inputs without the requisite addition of image and CoT knowledge. Extensive experiments reveal that our approach attains state-of-the-art accuracy and manifests a plethora of advantages concerning interpretability, data efficiency, and cross-domain generalization on MNER and MRE datasets.

ä½œè€…å£°ç§°æ˜¯å¸Œæœ›èƒ½å¤Ÿå°†LLMçš„æ¨ç†èƒ½åŠ›äº¤ç»™å°æ¨¡å‹ï¼Œä½†æ˜¯ä¸ªäººé˜…è¯»ä¸‹æ¥æ„Ÿè§‰å°æ¨¡å‹ä¹Ÿæ²¡æœ‰å­¦ä¼šæ¨ç†èƒ½åŠ›ã€‚å¹¶ä¸”è¿™é‡Œä¸€ç›´åœ¨å¼ºè°ƒCoTï¼Œäº‹å®ä¸Šè¿™ç¯‡è®ºæ–‡ä¸ªäººæ›´æ„¿æ„çœ‹åšæ˜¯ä¸€ç§æ•°æ®å¢å¼º/çŸ¥è¯†æ£€ç´¢çš„æ–¹æ³•ï¼Œæ¯•ç«ŸLLMæœ¬èº«æ²¡æœ‰é’ˆå¯¹ä¿¡æ¯æŠ½å–ç»™å‡ºä¸­é—´çš„æ¨ç†æ­¥éª¤ã€‚

ä½œè€…çš„åšæ³•å‡ºå‘ç‚¹æ˜¯ï¼š

- ä¹‹å‰çš„åŸºäºæ£€ç´¢çš„æ¨¡å‹ï¼Œéš¾ä»¥ä¿è¯æ£€ç´¢åˆ°çš„ç»“æœå’ŒæŸ¥è¯¢çš„å¥å­æ˜¯åŒ¹é…çš„ï¼Œæ¯”å¦‚ä¸‹å›¾ï¼š

  <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824231237542.png"   style="zoom:40%;" />

- å¤§æ¨¡å‹çš„æ¨ç†æˆæœ¬æ¯”è¾ƒé«˜ï¼Œä½†æ˜¯å®ƒçš„æ¨ç†èƒ½åŠ›æ¯”è¾ƒå¥½ã€‚å¸Œæœ›èƒ½å¤Ÿç”¨ä¸ªå°æ¨¡å‹å­¦ä¼šå¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸”æœ‰è¾ƒä½çš„æ¨ç†æˆæœ¬ã€‚

ä½œè€…çš„æ–¹æ³•ï¼š

![image-20230824231405165](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824231405165.png)

é¦–å…ˆï¼Œä½œè€…ç”¨BLIP2æŠŠå¤šæ¨¡æ€ä¿¡æ¯æŠ½å–ä¸­çš„å›¾ç‰‡è½¬åŒ–ä¸ºæ–‡æœ¬captionã€‚

ç„¶ååˆ©ç”¨LLMç”Ÿæˆä¸‹é¢å‡ ç§é¢å¤–çš„çŸ¥è¯†ï¼š

- Nounï¼šå¯¹äºå¥å­ä¸­çš„potential entities, slang, and terminologyç­‰åè¯è¿›è¡ŒæŸ¥è¯¢ï¼Œå¯¹åº”çš„promptæ˜¯ï¼š`Help me explain the meaning of special words for understanding. + x`
- Sentenceï¼šå¯¹äºæ•´ä¸ªå¥å­è¿›è¡Œç†è§£ï¼ŒIt can explain the sentiment, cause, and subject of users. å¯¹åº”çš„promptæ˜¯`Explain the sentence to me with necessary background. + x`
- Multimodalityï¼šè®©LLMè§£é‡Šæ½œåœ¨çš„imageå’Œtextä¹‹é—´çš„å…³ç³»ï¼Œè¿™ä¸€æ­¥å¯ä»¥ç”¨æ¥å»å™ªã€æ½œåœ¨çš„å¯¹é½visual objectå’Œtextual entityï¼Œå¯¹åº”çš„promptæ˜¯ï¼š`What is the relation between the text and the attached image? + x + I`

ä½œè€…è¿˜åˆ©ç”¨LLMè¿›è¡Œäº†æ•°æ®å¢å¼ºï¼š

- Styleï¼šåˆ©ç”¨LLMè½¬æ¢è¾“å…¥å¥å­çš„é£æ ¼ï¼Œè®©æ–‡æœ¬çš„æè¿°ä¿æŒä¸€è‡´çš„é£æ ¼ï¼Œå¯¹åº”çš„promptæ˜¯`Transform the sentence in Twitter style without changing the meaning. + x`
- Entityï¼šç”¨åŒç±»å‹çš„entityæ›¿æ¢å€™é€‰çš„entityï¼Œç„¶åç”¨LLMåˆ¤æ–­æ›¿æ¢åçš„ä¼ªæ ·æœ¬æ˜¯å¦æˆç«‹ï¼Œåˆ¤æ–­çš„promptæ˜¯`Whether the sentence is possible in fact, answer yes or no. + x`
- Imageï¼šè®©LLMçŒœæµ‹èƒ½å¤Ÿå’Œæ–‡æœ¬æè¿°å¯¹åº”çš„imageé•¿ä»€ä¹ˆæ ·å­ï¼Œå¯¹åº”çš„promptæ˜¯`What is a possible image with the text in a tweet? + x`

æ•°æ®å¢å¼ºåçš„æ ·æœ¬è¢«çœ‹åšæ˜¯æ–°çš„æ ·æœ¬ã€‚

ç„¶åé—®é¢˜çš„å…³é”®æ˜¯æ€ä¹ˆæ ·èƒ½å¤Ÿè®©å°æ¨¡å‹å­¦ä¼šLLMçš„æ¨ç†ï¼Œä½œè€…å£°ç§°æå‡ºäº†Conditional Prompt Distillationçš„æ–¹æ³•ã€‚å…·ä½“åšæ³•æ˜¯é¦–å…ˆä½œè€…æŠŠåŸå§‹çš„text $x$ã€å›¾åƒçš„caption $I$ä»¥åŠLLMç”Ÿæˆçš„çŸ¥è¯†$c$æ‹¼æ¥åˆ°ä¸€èµ·ï¼Œç»è¿‡text encoderè·å¾—è¾“å‡ºåˆ†å¸ƒ$H_k$ï¼›ç„¶åï¼Œä½œè€…å®šä¹‰äº†å¯å­¦ä¹ çš„soft promptæ¥ä½œä¸ºconditional promptèšåˆtextï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824232713196.png"   style="zoom:40%;" />

è¿™é‡Œç”Ÿæˆçš„$p$å’ŒåŸå§‹çš„text $x$æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œç»è¿‡text encoderè·å¾—è¾“å‡ºåˆ†å¸ƒ$H_t$ï¼›æœ€åï¼Œä½œè€…æœŸæœ›è¿™ä¸¤ç§åˆ†å¸ƒæ˜¯ç›¸è¿‘çš„ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824232832068.png"   style="zoom:40%;" />

ä¸ªäººå¯¹äºè¿™ä¸ªå…¬å¼æœ‰ç‚¹ç–‘æƒ‘ï¼Œè¿™é‡Œçš„åˆ†å¸ƒåˆ°åº•æ˜¯ä¿¡æ¯æŠ½å–çš„classification distributionè¿˜æ˜¯token distributionï¼Ÿ

æ›´ç–‘æƒ‘çš„æ˜¯ï¼Œæœ€åé¢„æµ‹ç»“æœä»ç„¶æ˜¯åŠ å…¥äº†LLMç”ŸæˆçŸ¥è¯†$c$çš„ç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233139004.png"   style="zoom:40%;" />

éš¾é“æ˜¯åœ¨æµ‹è¯•é˜¶æ®µä»…ä»…ç”¨å°æ¨¡å‹ï¼Œä¸éœ€è¦LLMæå‰å¤„ç†ï¼Ÿ

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233204415.png"   style="zoom:30%;" />

å’Œç›®å‰çš„SOTAç›¸æ¯”ï¼ŒMNREæ•°æ®é›†ä¸Šè¿˜æœ‰10%çš„å·®è·ï¼›è€ŒTwitter15å’Œ17æ•°æ®é›†å¯ä»¥è®¤ä¸ºæ˜¯è¾¾åˆ°äº†SOTAã€‚

å¦å¤–ä»æ¶ˆèçš„ç»“æœæ¥çœ‹ï¼Œå¯¹äºåè¯çš„è§£é‡Šï¼Œå¯èƒ½ä½œç”¨ç›¸å¯¹æ¯”è¾ƒå¤§ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233303269.png"   style="zoom:30%;" />

è®ºæ–‡çš„case studyå¯ä»¥çœ‹ä¸‹ï¼Œæ„Ÿè§‰è¿™äº›LLMç”Ÿæˆçš„knowledgeè¿˜æ˜¯æ¯”è¾ƒæœ‰æ„ä¹‰çš„ï¼Œé—®é¢˜åœ¨äºæ²¡æœ‰CoT..ä¹Ÿä¸ç¡®å®šå°æ¨¡å‹æ˜¯å¦å­¦ä¹ åˆ°äº†æ¨ç†èƒ½åŠ›ï¼š

![image-20230824233447694](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233447694.png)

## PGIM

Prompt ChatGPT In MNER: Improved multimodal named entity recognition method based on auxiliary refining knowledge from ChatGPT

å¤©æ´¥å¤§å­¦ï¼Œ2023-05ï¼ŒarXiv

> Multimodal Named Entity Recognition (MNER) on social media aims to enhance textual entity prediction by incorporating image-based clues. Existing research in this domain has primarily focused on maximizing the utilization of potentially relevant information in images or incorporating external knowledge from explicit knowledge bases (KBs). However, **these methods either neglect the necessity of providing the model with relevant external knowledge, or the retrieved external knowledge suffers from high redundancy.** To address these problems, **we propose a conceptually simple two-stage framework called Prompt ChatGPT In MNER (PGIM) in this paper.** We leverage ChatGPT as an implicit knowledge engine to acquire auxiliary refined knowledge, thereby bolstering the modelâ€™s performance in MNER tasks. Specifically, we first utilize a Multimodal Similar Example Awareness module to select suitable examples from a small number of manually annotated samples. These examples are then integrated into a formatted prompt template tailored to the MNER task, guiding ChatGPT to generate auxiliary refined knowledge. Finally, the acquired knowledge is integrated with the raw text and inputted into the downstream model for further processing. Extensive experiments show that our PGIM significantly outperforms all existing state-of-the-art methods on two classic MNER datasets.

ä½œè€…æ˜¯æœŸæœ›åˆ©ç”¨LLMæ¥è§£å†³ï¼š

- ä¸€èˆ¬çš„text+imageçš„å¤šæ¨¡æ€å°æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦å¤–éƒ¨çš„çŸ¥è¯†æ¥è¿›è¡Œè¯†åˆ«

- è€ŒåŸºäºå¤–éƒ¨knowledgeçš„ä¿¡æ¯æŠ½å–æ–¹æ³•æ£€ç´¢åˆ°çš„å¤–éƒ¨çŸ¥è¯†å¯èƒ½ç›¸å…³æ€§ç¨‹è¾ƒä½ï¼Œæˆ–è€…æ˜¯å†—ä½™

ä½œè€…åŒæ ·æŠŠLLMçœ‹åšæ˜¯ä¸€ä¸ªå¯ä»¥æä¾›high-quality auxiliary knowledgeçš„baseã€‚

æ–¹æ³•ï¼š

![image-20230825160004278](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825160004278.png)

é¦–å…ˆï¼Œä½œè€…åœ¨è¿™é‡Œä½¿ç”¨LLMå¯¼å‡ºçš„å¤–éƒ¨knowledgeåŒ…æ‹¬äº†LLMæŠ½å–å‡ºçš„å®ä½“ï¼Œä»¥åŠæ¨ç†çš„åŸå› ã€‚

é‚£ä¹ˆæ€ä¹ˆæ ·è®©LLMèƒ½å¤Ÿç”Ÿæˆè¿™æ ·çš„knowledgeå‘¢ï¼Ÿ

ä½œè€…éšæœºä»æ•°æ®é›†ä¸­é€‰æ‹©äº†ä¸€å°éƒ¨åˆ†æ ·ä¾‹ï¼Œç„¶åäººå·¥å†™äº†æ¨ç†åŸå› ï¼Œè¿™ä¸€å°éƒ¨åˆ†æ ·ä¾‹ä¼šä½œä¸ºå¾…æŠ½å–çš„å¥å­çš„ä¸Šä¸‹æ–‡æ¥è·å–LLMçš„knowledgeã€‚

ä½œè€…ä½¿ç”¨cosineç›¸ä¼¼åº¦ï¼Œä»è¿™å°éƒ¨åˆ†äººå·¥æ ‡æ³¨çš„æ ·ä¾‹ä¸­é€‰æ‹©åˆé€‚çš„æ ·ä¾‹ä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆå®ç°ä¸­é€‰æ‹©$5$ä¸ªæ ·ä¾‹åšä¸Šä¸‹æ–‡ï¼‰ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825160618895.png"   style="zoom:40%;" />

å…¬å¼é‡Œçš„$H$ä»£è¡¨ç€multimodal representationsï¼Œä½œè€…ä½¿ç”¨UMTæ–¹æ³•å¯¼å‡ºmultimodal representationsæ¥è®¡ç®—æ ·ä¾‹ç›¸ä¼¼åº¦ã€‚ï¼ˆä½†ä¸æ¸…æ¥šè¿™é‡Œçš„$H$å…·ä½“æ˜¯æŒ‡åºåˆ—ä¸­å“ªä¸ªembeddingï¼Ÿï¼‰

æ‹¿åˆ°ä¸Šä¸‹æ–‡ä¹‹åï¼Œä½œè€…ç”¨æ¥æŸ¥è¯¢çš„promptï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825161714124.png"   style="zoom:40%;" />

æ³¨æ„ä¸€ä¸‹ï¼Œåªæ˜¯ä½¿ç”¨äº†çº¯æ–‡æœ¬çš„ChatGPTï¼Œå› æ­¤ä½œè€…æ˜¯ä½¿ç”¨BLIP2æŠŠimageè½¬åŒ–ä¸ºtext captionå»æŸ¥è¯¢çš„ã€‚å¹¶ä¸”åœ¨prompté‡Œï¼Œä½œè€…æç¤ºLLMå¯ä»¥é€‰æ‹©æ˜¯å¦é‡‡ç”¨æ¥è‡ªimageçš„ä¿¡æ¯ã€‚

åœ¨æ‹¿åˆ°äº†LLMè¾“å‡ºçš„auxiliary knowledge $z$ä¹‹åï¼Œä¸åŸæœ‰çš„textæ‹¼æ¥ï¼Œç»è¿‡ä¸€ä¸ªTransformer encoderï¼ˆå®éªŒä¸­æ˜¯XLM-RoBERTa-largeï¼‰ï¼Œæœ€åè¿‡CRFè·å–å®ä½“çš„BIOé¢„æµ‹æ ‡æ³¨ã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825161339967.png"  style="zoom:40%;" />

Twitter2015æ•°æ®é›†ç›¸æ¯”è¾ƒMoReæ–¹æ³•æå‡ä¸å¤ªæ˜æ˜¾ã€‚ï¼ˆimageåœ¨è¿™ä¸¤ä¸ªTwitteræ•°æ®é›†ä¸Šåˆ°åº•æœ‰å¤šå¤§ä½œç”¨ï¼Œä¸ªäººç°åœ¨å¾ˆæ€€ç–‘ï¼Œå¹¶ä¸”æ ‡æ³¨ä¹Ÿä¸å¤Ÿå¥½ï¼Œæœ‰å¾ˆå¤šçš„å™ªéŸ³â€¦ï¼‰

case studyï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825161447842.png"   style="zoom:40%;" />

èƒ½å¤Ÿçœ‹å‡ºæ¥ï¼Œä½œè€…å€¾å‘äºåœ¨LLMçš„è¾“å‡ºæ¨ç†è¿‡ç¨‹ä¸­ï¼Œç›´æ¥å¯¹spanè¿›è¡Œè§£é‡Šï¼Œå› æ­¤è“è‰²çš„å¥å­é‡Œä¼šå¾ˆæ˜æ˜¾çš„çº¿ç´¢æ¥çŸ¥é“æœ€åè¯†åˆ«å®ä½“ã€‚

## CollabKG

CollabKG: A Learnable Human-Machine-Cooperative Information Extraction Toolkit for (Event) Knowledge Graph Construction

åŒ—äº¤ï¼ŒarXiv 2023-07ï¼ŒChatIEä½œè€…ï¼Œ[ä»“åº“](https://github.com/cocacola-lab/CollabKG)ã€‚

> In order to construct or extend entity-centric and event-centric knowledge graphs (KG and EKG), the information extraction (IE) annotation toolkit is essential. However, existing IE toolkits have several non-trivial problems, such as not supporting multi-tasks, not supporting automatic updates. In this work, **we present CollabKG, a learnable human-machine-cooperative IE toolkit for KG and EKG construction.** Specifically, for the multitask issue, CollabKG unifies different IE subtasks, including named entity recognition (NER), entity-relation triple extraction (RE), and event extraction (EE), and supports both KG and EKG. Then, combining advanced prompting-based IE technology, the human-machine-cooperation mechanism with LLMs as the assistant machine is presented which can provide a lower cost as well as a higher performance. Lastly, owing to the two-way interaction between the human and machine, CollabKG with learning ability allows self-renewal. Besides, CollabKG has several appealing features (e.g., customization, trainingfree, propagation, etc.) that make the system powerful, easy-to-use, and high-productivity. We holistically compare our toolkit with other existing tools on these features. Human evaluation quantitatively illustrates that CollabKG significantly improves annotation quality, efficiency, and stability simultaneously.

ä½œè€…åœ¨ChatIEçš„çš„åŸºç¡€ä¸Šï¼Œæ„é€ äº†ä¸€ä¸ªå¯ä»¥äººæœºååŒçš„IEæŠ½å–å·¥å…·ã€‚æœ€å¤§çš„ç‰¹ç‚¹ä¸ªäººè®¤ä¸ºæ˜¯ï¼Œå®ƒä¼šä¸æ–­æŠŠäººå·¥æ ‡æ³¨çš„ç»“æœï¼Œæœ‰é€‰æ‹©çš„å­˜å…¥åˆ°ä¸€ä¸ªæ•°æ®åº“å½“ä¸­ï¼Œè¿™ä¸ªæ•°æ®åº“ä¼šè¢«ç”¨æ¥æ„é€ promptï¼Œæ–¹ä¾¿ChatIEè¿›è¡Œä¿¡æ¯æŠ½å–ã€‚è¿™æ ·å°±ä½¿å¾—CollabKGä¸€æ–¹é¢å¯ä»¥å­¦ä¹ åˆ°æ–°çš„æ¦‚å¿µ/çŸ¥è¯†ï¼ŒåŒæ—¶è¿˜ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒã€‚æ”¯æŒä¸­è‹±æ–‡ï¼Œæ”¯æŒå®ä½“æŠ½å–ã€ä¸‰å…ƒç»„æŠ½å–ã€äº‹ä»¶è§¦å‘è¯æ£€æµ‹ä»¥åŠäº‹ä»¶è®ºå…ƒæŠ½å–ç­‰ã€‚

ä¸ç°æœ‰çš„å…¶å®ƒIE toolkitçš„å¯¹æ¯”ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825221723968.png"   style="zoom:25%;" />

ä½œè€…å®šä¹‰çš„å·¥ä½œæµç¨‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825221819267.png"   style="zoom:35%;" />

é¦–å…ˆï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©è‡ªåŠ¨åŸºäºLLMè¿›è¡Œä¿¡æ¯æŠ½å–ï¼Œä¼šé¦–å…ˆåŸºäºå¾…æŠ½å–çš„textå»ä¸€ä¸ªçŸ¥è¯†åº“ä¸­è¿›è¡Œæ£€ç´¢ï¼ˆå…·ä½“æ€ä¹ˆæ ·è¿›è¡Œæ£€ç´¢ï¼Œè®ºæ–‡ä¸­æ²¡æœ‰è¯´æ˜ï¼‰ï¼Œç„¶åé€‰æ‹©åˆ°æ‰¾åˆ°ç›¸ä¼¼çš„å·²æœ‰æ ‡æ³¨æ ·ä¾‹ï¼Œæ„é€ promptï¼Œè°ƒç”¨ChatGPTè¿›è¡Œè‡ªåŠ¨æŠ½å–ï¼ˆå…·ä½“æ„é€ å‡ºæ¥çš„promptæ˜¯ä»€ä¹ˆæ ·å­æ²¡æœ‰åœ¨è®ºæ–‡ä¸­ç»™å‡ºï¼‰ã€‚

ç„¶åï¼Œè‡ªåŠ¨æŠ½å–çš„ç»“æœä¼šè¿”å›ç»™ç”¨æˆ·ï¼Œç”¨æˆ·å¯ä»¥ä½¿ç”¨å·¥å…·é‡Œå®šä¹‰çš„å„ç§æ ‡æ³¨æ¥ä¿®æ”¹è‡ªåŠ¨æŠ½å–çš„ç»“æœï¼Œå¯ä»¥é€‰æ‹©æ˜¯å¦æ¥å—acceptã€åˆ é™¤deleteæˆ–è€…å¾…å®šsuggestedçŠ¶æ€ã€‚

æœ€åï¼Œäººå·¥ä¿®è®¢åçš„ç»“æœä¼šè¿”å›ï¼ŒCollabKGä¼šå°†æ ‡æ³¨è¿›è¡Œè½¬åŒ–ï¼Œå˜ä¸ºç»Ÿä¸€çš„æ ¼å¼ï¼Œé€‰æ‹©æœ€è¿‘çš„/é«˜é¢‘çš„æ ‡æ³¨æ”¾å…¥åˆ°çŸ¥è¯†åº“å½“ä¸­ã€‚

å¦å¤–ï¼Œä½œè€…å®šä¹‰ç»Ÿä¸€çš„ä¿¡æ¯æŠ½å–æ ·å¼/æ ¼å¼ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825222520746.png"   style="zoom:30%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825222733141.png"   style="zoom:25%;" />

å…·ä½“çš„æ ‡æ³¨ç•Œé¢ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825222926358.png"   style="zoom:25%;" />

## UniversalNER

UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition

2023-08ï¼ŒICLR 2024ï¼Œå—åŠ å·å¤§å­¦ï¼Œ[é¡¹ç›®](universal-ner.github.io)

> Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. **In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction.** Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average. With a tiny fraction of parameters, UniversalNER not only acquires ChatGPTâ€™s capability in recognizing arbitrary entity types, but also outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably, UniversalNER even outperforms by a large margin state-of-the-art multi-task instruction-tuned systems such as InstructUIE, which uses supervised NER examples. We also conduct thorough ablation studies to assess the impact of various components in our distillation approach. We will release the distillation recipe, data, and UniversalNER models to facilitate future research on targeted distillation.

ä¸€ç¯‡å’ŒInstructIEå’ŒInstructUIEç›¸ä¼¼æ€æƒ³çš„å·¥ä½œï¼Œéƒ½æ˜¯è®­ç»ƒIE LLMã€‚è¿™ç¯‡è®ºæ–‡åŒæ—¶ç»“åˆäº†ç°æœ‰çš„NERæ•°æ®é›†å’Œåˆ©ç”¨ChatGPTä»raw textä¸­è¿›è¡Œopen NERæ ‡æ³¨åçš„æ–°æ„é€ çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚foundation modelæ˜¯LLaMA 7B/13Bã€‚

ä½œè€…åœ¨è®ºæ–‡å¼ºè°ƒçš„è§‚ç‚¹æ˜¯ï¼Œå¾ˆå¤šç°æœ‰çš„instruction-tuningå·¥ä½œæ˜¯åˆ©ç”¨äº†ChatGPTç­‰æ›´å¤§sizeçš„LLMæ¥æ„é€ æŒ‡ä»¤ï¼Œè¿™å¯ä»¥çœ‹åšæ˜¯ä¸€ç§è’¸é¦æŠ€æœ¯ã€‚ä½†æ˜¯å¾ˆå¤šinstruction-tuningå·¥ä½œæ˜¯å…³æ³¨è®©student LLMå­¦ä¼šåœ¨ä¸åŒä»»åŠ¡ä¸Šéµå¾ªæŒ‡ä»¤ï¼Œè¿™ç§åšæ³•æ˜¯ä¸å¯èƒ½è¶…è¶Šteacher LLMå¦‚ChatGPTçš„ã€‚

å› æ­¤ä½œè€…è§‰å¾—åº”è¯¥è®©LLMæ›´åŠ å…³æ³¨æŸä¸€ç±»ä»»åŠ¡ï¼Œä½œè€…é€‰æ‹©äº†NERä»»åŠ¡ä½œä¸ºæ¢ç©¶ä»»åŠ¡ã€‚ä½œè€…çš„æŒ‡ä»¤é‡ç‚¹ä¸åœ¨äºä¸ºä¸åŒçš„taskæ„é€ ä¸åŒçš„æè¿°ï¼Œè€Œæ˜¯æƒ³åŠæ³•èƒ½å¤Ÿæè¿°æ¸…æ¥šä¸åŒæ•°æ®é›†ã€ä¸åŒé¢†åŸŸçš„NER labelçš„å«ä¹‰ã€‚

ä½œè€…åˆ©ç”¨ChatGPTä»Pile corpusä¸­è¿›è¡Œsentence-level open NERæ ‡æ³¨ï¼Œä¸é™åˆ¶entityç±»å‹ã€‚åªè¦æ˜¯GPTè®¤ä¸ºæ˜¯entityçš„mentionéƒ½è¢«å¯¼å‡ºã€‚ä¸‹é¢æ˜¯è¿›è¡Œæ ‡æ³¨çš„promptï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829155757746.png"   style="zoom:30%;" />

ç»è¿‡æ¸…æ´—åï¼Œä½œè€…è·å¾—äº†240,725å®ä½“ï¼Œ13,020å®ä½“ç±»å‹ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829155933160.png"   style="zoom:30%;" />

ç„¶åæ˜¯å¦‚ä½•æ„é€ instructionï¼Œä»¥åŠå¦‚ä½•è®­ç»ƒã€‚

- ä½œè€…æ ¹æ®ChatGPTçš„æ ‡æ³¨ï¼Œç›´æ¥è¯¢é—®æŸä¸€ç±»entityåœ¨textä¸­çš„mentionï¼Œç›¸å½“äºChatIEæ–¹æ³•çš„ç¬¬äºŒæ­¥ã€‚ä¸‹é¢æ˜¯instructionï¼š

  <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829160050553.png"   style="zoom:30%;" />

- Negative samplingï¼Œä½œè€…å‘ç°éœ€è¦è®©LLMå­¦ä¼šå›ç­”ä»€ä¹ˆentity typeæ²¡æœ‰åœ¨textä¸­å‡ºç°èƒ½å¤Ÿæå¤§çš„æé«˜æ¨¡å‹å­¦ä¹ æ•ˆæœï¼ˆå®éªŒä¸­æœ‰20%ä»¥ä¸Šçš„æ•ˆæœæå‡ï¼‰ã€‚è¿›è¡Œä¾æ®entity type frequencyçš„é‡‡æ ·ï¼Œæ„é€ è´Ÿæ ·æœ¬ã€‚

- é™¤å»äº†åˆ©ç”¨ChatGPTæ ‡æ³¨çš„æ–°æ•°æ®å¤–ï¼Œä½œè€…ä¹Ÿç”¨åˆ°äº†ç°æœ‰çš„å„ç±»NER datasetsã€‚ä¸ºäº†è§£å†³ä¸åŒæ•°æ®é›†ä¹‹é—´label definitionsçš„å·®å¼‚é—®é¢˜ï¼ˆå¦‚PERSON entityåœ¨ACLæ•°æ®é›†ä¸­åŒ…æ‹¬äº†she, heè¿™äº›äººç§°ä»£è¯ï¼Œè€Œåœ¨multiNERDå°±æ²¡æœ‰åŒ…æ‹¬äººç§°ä»£è¯ï¼‰ï¼Œå› æ­¤labeléœ€è¦å’Œdatasetç›¸å…³è”ï¼Œä½œè€…é¢å¤–çš„åœ¨promptå·¦ä¾§åŠ å…¥datasetçš„nameæ¥è¿›è¡Œè¾¨åˆ«ï¼š

  <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829160538488.png"   style="zoom:30%;" />

ä½œè€…æ”¶é›†äº†ç°æœ‰çš„43ä¸ªNERæ•°æ®é›†ï¼Œæ¶‰åŠ9ä¸ªdomainï¼ŒåŒ…æ‹¬general, biomedical, clinical, STEM, programming, social media, law, finance, and transportation domainsã€‚

è®­ç»ƒéµå¾ªå’ŒVicunaä¸€æ ·çš„è®­ç»ƒè§„åˆ’ã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829160752996.png"  style="zoom:25%;" /><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829160826877.png"   style="zoom:25%;" />

ä¸‹é¢æ˜¯å¯¹è´Ÿé‡‡æ ·çš„æ¶ˆèå®éªŒï¼Œå¯ä»¥çœ‹åˆ°è®©LLMå­¦ä¼šå›ç­”è‡ªå·±ä¸çŸ¥é“ä»€ä¹ˆ/ä»€ä¹ˆä¸œè¥¿ä¸å­˜åœ¨æ˜¯å¾ˆå…³é”®çš„ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829161000484.png"   style="zoom:30%;" />



## SUMASK

Revisiting Large Language Models as Zero-shot Relation Extractors. ä¸œå—å¤§å­¦. EMNLP 2023

> Relation extraction (RE) consistently involves a certain degree of labeled or unlabeled data even if under zero-shot setting. Recent studies have shown that large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt, which provides the possibility of extracting relations from text without any data and parameter tuning. This work focuses on the study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors. On the one hand, **we analyze the drawbacks of existing RE prompts and attempt to incorporate recent prompt techniques such as chain-of-thought (CoT) to improve zeroshot RE. We propose the summarize-and-ask (SUMASK) prompting, a simple prompt recursively using LLMs to transform RE inputs to the effective question answering (QA) format.** On the other hand, we conduct comprehensive experiments on various benchmarks and settings to investigate the capabilities of LLMs on zero-shot RE. Specifically, we have the following findings: (i) SUMASK consistently and significantly improves LLMs performance on different model sizes, benchmarks and settings; (ii) Zero-shot prompting with ChatGPT achieves competitive or superior results compared with zero-shot and fully supervised methods; (iii) LLMs deliver promising performance in extracting overlapping relations; (iv) The performance varies greatly regarding different relations. Different from small language models, LLMs are effective in handling challenge none-of-the-above (NoTA) relation.

è®¾è®¡æ›´å¥½çš„promptï¼Œå¤šè½®æé—®LLMæ¥å®ç°æ›´å¥½çš„zero-shot relation extractionï¼ˆç»™å®šå¤´å°¾entityï¼‰ã€‚åœ¨zero-shotåœºæ™¯ä¸‹ï¼Œæ•ˆæœæ˜¯ç›®å‰çš„sotaï¼›åœ¨å…¨ç›‘ç£è®¾ç½®ä¸‹ï¼Œä½¿ç”¨zero-shot promptingçš„æ–¹å¼ï¼Œåœ¨TACREDã€TACREVå’ŒRe-TACREDä¸‰ä¸ªæ•°æ®é›†ä¸‹é è¿‘äº†sotaæˆ–è€…è¾¾åˆ°äº†æ–°sotaã€‚

é¦–å…ˆï¼Œä½œè€…å‘ç°å’Œä»¥å‰çš„ç»“æœä¸€è‡´ï¼Œå¦‚æœæ˜¯é‡‡ç”¨æœ€vanillaçš„promptï¼Œæ•ˆæœè·ç¦»ä»¥å‰çš„sotaæ–¹æ³•æ•ˆæœå¾ˆè¿œï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016145531310.png"  style="zoom:40%;" />

ä½œè€…æ¨æµ‹åŸå› æ˜¯ä¸Šé¢çš„promptè¦æ±‚ä»¥ä¸‹æ­¥éª¤åœ¨ä¸€æ­¥å†…å®Œæˆï¼š

- ç†è§£å¥å­ä¸­å¤´å°¾å®ä½“çš„relation semanticsï¼›
- ç†è§£relation label semanticï¼›
- ç„¶åèƒ½å¤ŸæŠŠä¸¤ç§semanticè¿›è¡ŒåŒ¹é…ï¼›

è¿™äº›æ­¥éª¤åœ¨ä¸€æ­¥å®Œæˆï¼Œè®©LLMå¯¹äºREä»»åŠ¡è¡¨ç°ä¸å¥½ã€‚å› æ­¤ï¼Œä½œè€…å€ŸåŠ©CoTçš„æ€æƒ³ï¼Œå°†REä»»åŠ¡æ‹†åˆ†ä¸ºä¸åŒçš„æ¨ç†æ­¥éª¤ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016145721912.png"  style="zoom:50%;" />

å…·ä½“æ­¥éª¤ï¼š

1. ç»™å®šsentenceï¼Œè®©LLMæ¨æµ‹å¥å­ä¸­å¤´å°¾å®ä½“å¯èƒ½çš„è¯­ä¹‰è”ç³»ï¼Œä½œè€…ç§°ä¸ºè¾“å‡ºsummarizationï¼Œé‡å¤$k$æ¬¡ï¼›
2. è¾“å…¥å€™é€‰relationï¼Œæ„é€ å€™é€‰ä¸‰å…ƒç»„ï¼Œè®©LLMæ ¹æ®ä¸‰å…ƒç»„åˆ›å»ºå‡ºå¯¹åº”çš„å›ç­”yes/noçš„é—®é¢˜questionï¼Œé‡å¤$k$æ¬¡ï¼›
3. å¯¹äºå‰é¢çš„$k$ä¸ªsummarizationå’Œquestionï¼Œè®©LLMå›ç­”æ˜¯å¦èƒ½å¤Ÿæ ¹æ®summarizationå›ç­”questionï¼Œé€šè¿‡æŠ•ç¥¨é€‰æ‹©æœ€ç»ˆLLMè®¤ä¸ºå¤´å°¾å®ä½“é—´çš„å€™é€‰å…³ç³»æ˜¯å¦æˆç«‹ï¼›

å¯¹äºæ¯ç§å€™é€‰å…³ç³»$r$ï¼Œéƒ½è¦è¿›è¡Œ$k^3$çš„æé—®ï¼ˆå®éªŒä¸­$k=5$ï¼‰ï¼Œèµ„æºæ¶ˆè€—å’Œæ—¶é—´æˆæœ¬éå¸¸å¤§ã€‚ä¸‹é¢æ˜¯å‡ ä¸ªä¾‹å­ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016151659972.png"  style="zoom:50%;" />

ç»è¿‡ä¸Šé¢3æ­¥ï¼Œä¼šè·å¾—å¤šä¸ªæœ€ç»ˆLLMè®¤ä¸ºæˆç«‹çš„å€™é€‰relationï¼Œå› æ­¤éœ€è¦è®¾è®¡æŸç§æœºåˆ¶è¿›è¡Œé€‰æ‹©ï¼Œæœ€ç›´æ¥çš„æƒ³æ³•æ˜¯é€‰æ‹©3ä¸ªæ­¥éª¤è¾“å‡ºç­”æ¡ˆæ¦‚ç‡æœ€å¤§çš„å¯¹åº”çš„relationï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016150313425.png" style="zoom:40%;" />

ä½†æ˜¯ï¼Œä¸æ˜¯æ‰€æœ‰LLMéƒ½èƒ½å¤Ÿè¾“å‡ºæ¦‚ç‡çš„ï¼Œå› æ­¤ï¼Œä½¿ç”¨ä¸ç¡®å®šæ€§è¿›è¡Œä¼°è®¡ï¼Œé€‰æ‹©ä¸ç¡®å®šæ€§æœ€å°çš„å›ç­”ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016150449686.png"  style="zoom:40%;" />

ä¸ç¡®å®šæ€§ä¼°è®¡çš„æ–¹æ³•å€Ÿé‰´äº†å‰äººçš„æ–¹æ³•[*Active prompting with chain-ofthought for large language models. 2023*]ï¼Œå°†$k$ä¸ªå›ç­”è¾“å…¥åˆ°Sentence-BERTä¸­ï¼Œè·å¾—ç¼–ç ï¼Œç„¶åè®¡ç®—æ¯ä¸ªå›ç­”è¡¨å¾å’Œå¹³å‡è¡¨å¾çš„è·ç¦»ä½œä¸ºdispersion degreeï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016150606944.png"  style="zoom:40%;" />

æœ€åé€‰æ‹©ä¾æ®ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016150705709.png" style="zoom:40%;" />

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä½œè€…é‡‡ç”¨äº†Entity-Relation Mappingæœºåˆ¶[*Fastre: Towards fast relation extraction with convolutional encoder and improved cascade binary tagging framework. IJCAI 2022*]ï¼Œæå‰æ’é™¤äº†å¾ˆå¤šrelationï¼Œå¦‚æœå·²çŸ¥äº†entity typeï¼Œå°±æå‰æ’é™¤æ‰ä¸€äº›ä¸å¯èƒ½æˆç«‹çš„relationã€‚

ä½œè€…å®éªŒé‡‡ç”¨äº†`GPT-J-6B`ã€`BLOOM-7.1B`ã€`T0pp-11B`å’Œ`gpt-3.5-turbo-0301`ï¼Œæœ€ç»ˆæ˜¯gpt-3.5-turbo-0301æ•ˆæœæœ€å¥½ï¼Œä¸‹é¢å®éªŒé‡Œçš„SUMASKå°±æ˜¯å¯¹åº”çš„é‡‡ç”¨gpt-3.5çš„ç»“æœã€‚

Zero-shot relation classificationå®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016151026213.png" style="zoom:30%;" />

å’Œå…¨ç›‘ç£çš„REæ–¹æ³•å¯¹æ¯”ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016151114659.png" style="zoom:30%;" />

å’Œå…¨ç›‘ç£çš„æ–¹æ³•ç›¸æ¯”ï¼Œzero-shotçš„LLMæœ‰æ½œåŠ›é è¿‘sotaï¼Œä½†æ˜¯ä¸ªäººä»ç„¶æœ‰ä»¥ä¸‹çš„ç–‘é—®ï¼š
1. èµ„æºæ¶ˆè€—ï¼Ÿ
2. æ—¶é—´ï¼Ÿ
3. è¿™äº›æ•°æ®é›†è¡¨ç°æ¯”è¾ƒå¥½ï¼Œæ˜¯å¦æ˜¯å› ä¸ºLLMåœ¨é¢„è®­ç»ƒé˜¶æ®µå·²ç»ç†è§£äº†å¯¹åº”çš„labelï¼Œå¦‚æœæ˜¯æ–°çš„datasetï¼ŒLLMæ˜¯å¦ä»ç„¶èƒ½å¤Ÿè¡¨ç°å¥½ï¼Ÿ

ä½œè€…è®ºæ–‡ä¸­Table4è¿˜è¿›è¡Œäº†å…¶å®ƒå®éªŒï¼Œå‘ç°ä¸åŒrelationä¹‹é—´çš„æ€§èƒ½å·®è·éå¸¸å¤§ï¼Œæœ€å¥½çš„æœ‰90%ä»¥ä¸Šå‡†ç¡®ç‡ï¼Œæœ€å·®çš„10%-20%å‡†ç¡®ç‡ã€‚

å¯¹äºOverlapping REä»»åŠ¡çš„å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016151345868.png"  style="zoom:30%;" />

## Guideline Learning

Guideline Learning for In-Context Information Extraction. EMNLP 2023. ä¸­ç§‘é™¢

> Large language models (LLMs) can perform a new task by merely conditioning on task instructions and a few input-output examples, without optimizing any parameters. This is called In-Context Learning (ICL). In-context Information Extraction has recently garnered attention in the research community. However, current experiment results are generally suboptimal. **We attribute this primarily to the fact that the complex task settings and a variety of edge cases are hard to be fully expressed in the length-limited context.** In this paper, **we propose a Guideline Learning (GL) framework for In-context IE which learns to generate and follow guidelines.** During the learning phrase, GL automatically synthesizes a set of guidelines from a few annotations, and during inference, helpful guidelines are retrieved for better ICL. Experiments on event extraction and relation extraction show that guideline learning can improve the performance of in-context IE.

**Issue**ï¼šä½œè€…è®¤ä¸ºIEä»»åŠ¡æ˜¯ä¸€ä¸ªå¤æ‚çš„ä»»åŠ¡ï¼Œä¸ºäº†å‡†ç¡®å…¨é¢çš„å®šä¹‰å¥½taskçš„*target concept*éœ€è¦å¾ˆå¤šçš„exampleså’Œrulesè¿›è¡Œå®šä¹‰ã€‚ä¾‹å¦‚åœ¨ACMå…³ç³»æŠ½å–ä¸­çš„guidelinesè¶…è¿‡33é¡µå†…å®¹ã€‚

ä¼ ç»Ÿçš„æ–¹æ³•éœ€è¦æå‰æœ‰å¾ˆå¤šçš„è®­ç»ƒæ ·æœ¬+å¤§é‡çš„è®­ç»ƒå‚æ•°ï¼›è€ŒLLM+ICLæ˜¯ä¸€ç§èƒ½å¤Ÿæ— æ¢¯åº¦æ›´æ–°çš„èŒƒå¼ï¼Œç„¶è€Œè¿™ç§èŒƒå¼åœ¨ä»¥å‰çš„è®ºæ–‡é‡Œæ•ˆæœè¿˜ä¸å¤Ÿå¥½ã€‚

ä½œè€…è®¤ä¸ºåŸå› æ˜¯ï¼ŒLLMå¯¹äºIEä»»åŠ¡ç†è§£çš„*comprehended concept*å’Œ*target concept*ä¹‹é—´å­˜åœ¨*conceptual bias*ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016191744066.png" style="zoom:35%;" />

**Solution**: å› æ­¤ï¼Œä½œè€…å¸Œæœ›èƒ½å¤Ÿè®©LLMè‡ªå·±å­¦ä¹ guidelinesï¼Œè¿™ç§guidelinesï¼Œå®é™…ä¸Šï¼Œå°±æ˜¯å¯¹äºlabel semanticçš„æè¿°ã€‚ä½œè€…æå‡ºæ–¹æ³•çš„å›¾ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016192009243.png" style="zoom:30%;" />

æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œä»é¢„æµ‹é”™è¯¯çš„æ ·ä¾‹ä¸­å­¦ä¹ åé¦ˆï¼Œæ€æƒ³followäº†å‰äººçš„å·¥ä½œ[*Memory-assisted prompt editing to improve GPT-3 after deployment. EMNLP 2022*]ã€‚

ä¼ªä»£ç ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016192126083.png"  style="zoom:35%;" />

ä½œè€…å®šä¹‰çš„guidelineså°±æ˜¯ä¸€ç³»åˆ—çš„è‡ªç„¶è¯­è¨€æè¿°çš„rulesé›†åˆï¼š

> Suppose we have collected the Guidelines $\mathcal{G} = \{ r_i \}|_{i=1}^{|\mathcal{G}|}$ which is a set of rules that supports read, write, and retrieve operations. Each rule, expressed as a natural language sentence, defines an aspect of the task. The guidelines illustrate how to perform the task.

é¦–å…ˆæ˜¯ä¼ªä»£ç ä¸­çš„`Retrieve`ï¼šä»å·²æœ‰çš„guidelinesé›†åˆé‡Œï¼Œå¯»æ‰¾å’Œå½“å‰æ ·ä¾‹æœ€ç›¸è¿‘çš„guidelinesã€‚å…·ä½“åšæ³•æ˜¯åˆ©ç”¨LLMå»æŠ½è±¡å‡ºsentence $x$çš„general form $\tilde{x}$ï¼Œå¯¹äºREä»»åŠ¡ï¼Œä½œè€…ç”¨äº†ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯ç®€åŒ–å…·ä½“çš„æè¿°ï¼Œåªä¿ç•™textä¸­å¿…è¦çš„tokensï¼Œä¸€ç§æ˜¯è®©LLMçŒœæµ‹å®ä½“çš„typeã€‚ä¸¤ç§å½¢å¼çš„general formsæ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸ºREä»»åŠ¡å¯¹äºsentence semanticçš„æŠ½è±¡$\tilde{x}$ï¼Œè¾“å…¥åˆ°OpenAIçš„`text-embedding-ada-002` APIï¼Œè·å¾—embeddingï¼Œç„¶ååŸºäºä½™å¼¦ç›¸ä¼¼åº¦é€‰æ‹©æœ€ç›¸ä¼¼çš„rulesã€‚åŒæ—¶éšæœºä»è®­ç»ƒé›†ä¸­æ‰¾æ ·ä¾‹ä½œä¸ºdemonstrationsï¼Œåœ¨æ•´ä¸ªæ•°æ®é›†ä¸‹æ˜¯å›ºå®šçš„ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016192458557.png" style="zoom:50%;" />

ç„¶å`Reason`ï¼šè¾“å…¥task instructionã€query instanceã€few-shot exampleså’Œrulesï¼Œè®©LLMè¾“å‡ºæŠ½å–ç»“æœå’ŒLLMè®¤ä¸ºæœ‰ç”¨çš„rulesã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016193053838.png"  style="zoom:50%;" />

æ ¹æ®æŠ½å–ç»“æœï¼Œæ›´æ–°rulesçš„scoresï¼Œæ¥åˆ¤æ–­æŸä¸ªruleçš„æœ‰ç”¨ç¨‹åº¦(æŸä¸ªruleè¢«ä½¿ç”¨çš„æ¬¡æ•°ä¸­ï¼Œèƒ½å¤Ÿå¸®åŠ©é¢„æµ‹æ­£ç¡®çš„æ¬¡æ•°è¶Šå¤šè¶Šå¥½)ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016193218204.png"  style="zoom:40%;" />

å¦‚æœæŠ½å–relationæ˜¯é”™è¯¯çš„ï¼Œé‚£ä¹ˆè¦è¿›è¡Œåé¦ˆ`Reflect`ï¼šä½¿ç”¨general formå’Œtrue labelç›´æ¥æ‹¼æ¥ä½œä¸ºæ–°çš„ruleã€‚ä»ä½œè€…çš„è¯´æ˜æ¥çœ‹ï¼š

> In this paper, we simply concatenate the general form $\tilde{x}$ of the instance $i$ and the golden label to generate a rule. Figure 3 presents an example of this process in EE.

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240408155256384.png"  style="zoom:50%;" />

ä½œè€…å¦å¤–çš„è´¡çŒ®æ˜¯ï¼Œæå‡ºäº†ä¸€ç§Active Instance Selectionçš„ç­–ç•¥ï¼Œé€‰æ‹©é€‚åˆä½œä¸ºä¸Šé¢çš„guidelines learningçš„æ–¹æ³•ã€‚å¦‚æœæ˜¯éšæœºé€‰æ‹©ä¸‹ä¸€æ¬¡é€‚åˆæ ‡æ³¨çš„æ ·æœ¬çš„è¯ï¼Œæ•ˆç‡å¯èƒ½æ¯”è¾ƒä½ï¼Œå› ä¸ºå¯èƒ½ä¼šé€‰å‡ºLLMå·²ç»èƒ½å¤Ÿæ­£ç¡®é¢„æµ‹çš„æ ·æœ¬ã€‚å› æ­¤ä½œè€…é€‰æ‹©é‚£äº›LLMæœ€ä¸confidenceçš„dataã€‚

å…·ä½“çš„é€‰æ‹©æ–¹æ³•æ˜¯ï¼Œåˆ©ç”¨self-consistency CoTï¼Œè®©LLMç”Ÿæˆå¤šä¸ªæ¨ç†è·¯å¾„å’Œå¯¹åº”çš„ç­”æ¡ˆã€‚ç„¶åæ ¹æ®ç­”æ¡ˆçš„åˆ†å¸ƒï¼Œç»Ÿè®¡ä¸åŒç±»å‹relationçš„åˆ†å¸ƒï¼Œç„¶åä½¿ç”¨ç†µçš„è´Ÿå€¼ä½œä¸ºconfidenceã€‚æœ€åé€‰æ‹©è´Ÿç†µæœ€å°çš„dataï¼Œä¹Ÿå°±æ˜¯LLMé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒæœ€å¹³æ»‘çš„dataã€‚

æœ€åå®ç°ä½¿ç”¨`gpt-3.5-turbo`ï¼Œå®éªŒäº†Event Extractionå’Œrelation extractionï¼ˆç»™å®šå¤´å°¾å®ä½“ï¼‰ä¸¤ç±»ä»»åŠ¡ã€‚äº‹ä»¶æŠ½å–ä½¿ç”¨äº†ChFinAnnæ•°æ®é›†ï¼›REä»»åŠ¡ä½¿ç”¨äº†SemEval 2010 task 8æ•°æ®é›†ï¼ˆæœ‰9ç§relationï¼‰ï¼Œæµ‹è¯•é›†éšæœºé‡‡æ ·1000ä¸ªã€‚ä»REä»»åŠ¡ç»“æœæ¥çœ‹ï¼Œå’ŒSOTAè¿˜æœ‰å·®è·ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016194434785.png"  style="zoom:40%;" />

ä¸Šé¢ä½œè€…çš„baselineï¼š

- RE-ICLï¼šç›´æ¥è®©LLMåŸºäºICLè¾“å‡ºrelation label
- RE-GL-bï¼šä½œè€…çš„æ–¹æ³•ï¼Œwithout guidelines
- RE-GL-rï¼šä»è®­ç»ƒé›†ä¸­ï¼Œéšæœºé€‰æ‹©500ä¸ªinstancesä½œä¸ºguidelines learningï¼ˆå¹³å‡æ¯ä¸ªrelation 50ä¸ªinstancesï¼‰
- RE-GL-aï¼šä»è®­ç»ƒé›†ä¸­ï¼Œä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œä»éšæœºçš„1000ä¸ªinstancesä¸­ï¼Œé€‰å‡º500ä¸ªinstancesè¿›è¡Œguidelines learning

case studyï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240408155338816.png"  style="zoom:40%;" />

## RationalCL

Rationale-Enhanced Language Models are Better Continual Relation Learners. EMNLP 2023. åŒ—å¤§. [ä»£ç ](https://github.com/WeiminXiong/RationaleCL)ã€‚

> Continual relation extraction (CRE) aims to solve the problem of catastrophic forgetting when learning a sequence of newly emerging relations. Recent CRE studies have found that catastrophic forgetting arises from the modelâ€™s lack of robustness against future analogous relations. To address the issue, **we introduce rationale, i.e., the explanations of relation classification results generated by large language models (LLM), into CRE task.** Specifically, we design the multi-task rationale tuning strategy to help the model learn current relations robustly. We also conduct contrastive rationale replay to further distinguish analogous relations. Experimental results on two standard benchmarks demonstrate that our method outperforms the state-of-the-art CRE models. Our code is available at https://github.com/WeiminXiong/RationaleCL

ä½œè€…æœŸæœ›è§£å†³çš„ä»»åŠ¡æ˜¯Continual Relation Extractionï¼Œä¸‹é¢æ˜¯ä»»åŠ¡å®šä¹‰ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016222421718.png"  style="zoom:30%;" />

è¿™ä¸€ä»»åŠ¡ä¹‹å‰çš„æ–¹æ³•æ˜¯ä¸“æ³¨äºåˆ©ç”¨çŸ¥è¯†è’¸é¦ç­‰æŠ€æœ¯ç¼“è§£ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚æœ€è¿‘æœ‰å·¥ä½œå‘ç°ï¼Œæ¨¡å‹åœ¨é­é‡å’Œå·²ç»è§è¿‡çš„relationç›¸ä¼¼çš„æ–°relationæƒ…å†µä¸‹ï¼Œä¸èƒ½å¤Ÿå¾ˆå¥½çš„ææ¸…æ¥šç›¸ä¼¼relationä¹‹é—´çš„å…³ç³»ã€‚

ä½œè€…è®¤ä¸ºï¼Œå¯ä»¥é€šè¿‡å¼•å…¥rationalesæ¥ç¼“è§£è¿™ä¸€é—®é¢˜ã€‚è¿™æ˜¯å› ä¸ºä¸€æ–¹é¢This is inspired by the intuition that, training models with explicit rationale supervision can provide greater robustness (Chen et al., 2022).ã€‚å¦å¤–ï¼Œè®©å°æ¨¡å‹å­¦ä¼šè¾“å‡ºrationalesï¼Œèƒ½å¤Ÿè®©ç¼“è§£å°æ¨¡å‹å¯èƒ½çš„shortcut learningçš„é—®é¢˜ã€‚

ä½†æ˜¯ç›®å‰æ•°æ®é›†é‡Œå¹¶æ²¡æœ‰rationalesã€‚å› æ­¤ä½œè€…æœŸæœ›è®©LLMæ¥è¾“å‡ºrationalesã€‚è™½ç„¶GPTå¯¹äºç›´æ¥è¿›è¡ŒREä»»åŠ¡æ•ˆæœè¿˜ä¸å¤Ÿå¥½ï¼Œä½†æ˜¯å¦‚æœç»™å®šrelationï¼Œè®©GPTç»™å‡ºåŸå› æ¥ï¼Œæ•ˆæœè¿˜æ˜¯å¯ä»¥çš„ã€‚å³

> According to their studies, ChatGPT is limited by the output format requirements in accomplishing fine-grained relation extraction tasks, and it is difficult to directly generate the target relation label within the defined range. However, ChatGPTâ€™s semantic understanding is sufficient, and when we provide chatgpt with correct relation labels, ChatGPT can understand the meaning of the relation according to the context and give reasonable rationales. According to the human-check results (Li et al., 2023), domain experts highly approve of the reasons given by ChatGPT.

ä½œè€…åˆ©ç”¨`gpt-3.5-turbo`è¾“å‡ºçš„rationalesï¼Œfinetuneä¸€ä¸ªT5-baseï¼Œä½¿ç”¨å¤šä»»åŠ¡çš„æ¶æ„ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016221257901.png" style="zoom:50%;" />

ç¬¬ä¸€é˜¶æ®µè®­ç»ƒä¸‰ä¸ªä»»åŠ¡çš„lossï¼š

- ä¸»ä»»åŠ¡ï¼Œè¾“å…¥æ–‡æœ¬$X$ï¼Œè¾“å‡ºrelation $Y$
- è¾…åŠ©ä»»åŠ¡1ï¼Œè¾“å…¥æ–‡æœ¬$X$ï¼Œè®©å°æ¨¡å‹è¾“å‡ºrelation $Y$å’Œrationale $R$
- è¾…åŠ©ä»»åŠ¡2ï¼Œè¾“å…¥æ–‡æœ¬$X$å’Œrationale $R$ï¼Œè®©å°æ¨¡å‹è¾“å‡ºrelation $Y$

ç¬¬ä¸€é˜¶æ®µç»“æŸåï¼Œä¸ºäº†ç¼“è§£ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œä½œè€…followå‰äººçš„å·¥ä½œ[*Continual relation learning via episodic memory activation and reconsolidation. ACL 2020*]ï¼Œç»´æŠ¤ä¸€ä¸ªepisodic memory moduleï¼Œé‡Œé¢ä¿å­˜ä¸åŒrelationä¸‹ä»£è¡¨æ€§çš„dataï¼ˆå®ç°ä¸­æ¯ä¸ªrelationä¿ç•™10ä¸ªdataï¼‰ã€‚è¿™ä¸ªmemoryé‡Œé¢çš„dataï¼Œä¼šåœ¨ä¹‹åç»§ç»­è¢«è¿›è¡Œå­¦ä¹ ã€‚

ç¬¬äºŒé˜¶æ®µæ˜¯ä¸ºäº†è§£å†³æ–°relationå’Œå·²æœ‰çš„ç›¸ä¼¼relationå®¹æ˜“æ··æ·†çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†contrastive rationalesçš„æ¦‚å¿µï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016222112205.png"  style="zoom:35%;" />

é€šè¿‡embeddingè®¡ç®—ä¸¤ä¸ªrelationä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæ‰¾åˆ°ç›¸ä¼¼relationï¼›ç„¶åè®©LLMå»ç»™å‡ºè¾“å‡ºä¸€ä¸ªrelationï¼Œè€Œä¸è¾“å‡ºå¦ä¸€ä¸ªrelationçš„rationalesã€‚ç”¨æ–°çš„contrastive rationalesæ›¿æ¢memory moduleé‡Œé¢çš„å·²æœ‰rationalesï¼Œç„¶åè®­ç»ƒã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231016222501679.png" style="zoom:30%;" />

## Text2KGBench

Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text. ISWC 2023. IBM. [ä»£ç ](https://github.com/cenguix/Text2KGBench).

> The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. **In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology.** Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact extraction performance, ontology conformance, and hallucinations by LLMs. Furthermore, **we provide results for two baseline models, Vicuna-13B and Alpaca-LoRA-13B using automatic prompt generation from test cases.** The baseline results show that there is room for improvement using both Semantic Web and Natural Language Processing techniques.

KGçš„æ„å»ºå¯ä»¥é€šè¿‡RDB2RDF[*A survey of current approaches for mapping of relational databases to rdf.*]è¿™ç§æ–¹æ³•ä»relational dataä¸­æ„å»ºï¼›å¯ä»¥ç”¨RMLè¿™ç§æ–¹æ³•[*Rml: A generic language for integrated rdf mappings of heterogeneous data.*]ï¼Œä»åŠç»“æ„åŒ–çš„æ•°æ®ä¸­æ„å»ºï¼›è¿˜å¯ä»¥è€ƒè™‘ç”¨ä¼—åŒ…çš„å½¢å¼æ„å»ºï¼Œä¾‹å¦‚Wikidataã€‚

ä½†æ˜¯ä»ç„¶å­˜åœ¨å¾ˆå¤šéç»“æ„åŒ–çš„æ–‡æœ¬ï¼Œå¹¶ä¸”å—é™äºè§„æ¨¡å’Œéšç§è€ƒè™‘ç­‰å› ç´ ï¼Œæ— æ³•ä½¿ç”¨ä¼—åŒ…ã€‚ä¹Ÿå› æ­¤ï¼Œä¸€ç§æ„å»ºKGçš„æ€è·¯å°±æ˜¯åˆ©ç”¨NLPæŠ€æœ¯ï¼Œæ¯”å¦‚NERã€REã€entity linkingç­‰æ–¹æ³•ï¼Œä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æŠ½å–ç»“æ„åŒ–ä¿¡æ¯ã€‚ç›®å‰æœ‰ä¸¤ä¸ªç›¸å…³çš„workshopï¼š

> There is a growing interest in the Semantic Web community to explore such approaches as seen from the workshops such as Text2KG [Tiwari et al., 2022, 2023] and NLP4KGC [Vakaj et al., 2023].

ä½œè€…æ„å»ºäº†Text2KGBenchæ¥è¯„ä¼°ä½¿ç”¨LLMï¼Œåœ¨ç»™å®šontologyçš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿç”ŸæˆKGçš„èƒ½åŠ›ã€‚ä½œè€…çš„benchmarké‡ŒKGä¸æ˜¯ç”¨RDF/OWLçš„å½¢å¼æè¿°çš„ï¼Œè€Œæ˜¯ä½¿ç”¨relationä¸‰å…ƒç»„çš„å½¢å¼ã€‚

åŒ…æ‹¬äº†ä¸¤ä¸ªæ•°æ®é›†ï¼š

- Wikidata-TekGenï¼šåŒ…æ‹¬10ç§ä»Wikidataä¸­å¯¼å‡ºçš„ontologiesï¼Œç„¶åä½¿ç”¨TekGenè¯­æ–™åº“æ‰¾åˆ°å¯¹åº”çš„ä¸‰å…ƒç»„å’Œå¥å­
- DBpedia-WebNLGï¼šåŒ…æ‹¬19ç§æœ¬ä½“

ä¸‹é¢æ˜¯Wikidata-TekGenæ•°æ®é›†musicæœ¬ä½“ç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017152255979.png" style="zoom:40%;" />

åŸºäºä½œè€…çš„Text2KGBenchï¼Œä½œè€…å°è¯•äº†Vicuna-13Bå’ŒAlpaca-LoRA-13Båœ¨ç»™å®šæœ¬ä½“çš„æƒ…å†µä¸‹ï¼ŒåŸºäºkNN ICLè¿›è¡Œä¿¡æ¯æŠ½å–çš„æ•ˆæœã€‚ä¸‹é¢æ˜¯ä½¿ç”¨çš„promptï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017152527701.png"  style="zoom:30%;" />

ä½œè€…æå‡ºï¼Œè¦ä½¿ç”¨ä¸‰ç±»æŒ‡æ ‡æ¥è¯„ä¼°ï¼š

- Fact Extraction Accuracy: Precision (P), Recall (R), and F1
- Ontology Conformance: Ontology Conformance (OC) metric, a triple is considered to be conforming to the ontology if the relation is one of the canonical relations listed in the ontology.
- Hallucinations: subject hallucination (SH), relation hallucination (RH), and object hallucination (OH). For each triple, SH and OH check if the subject and object are present in either the sentence or the ontology concepts, and RH checks if the relation is present in the ontology relations.

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017153036430.png"  style="zoom:50%;" />

å¯ä»¥çœ‹åˆ°ï¼Œæ€»ä½“æ•ˆæœè¿˜æœ‰å¾ˆå¤§çš„è¿›æ­¥ç©ºé—´ï¼ŒåŒæ—¶æ˜¯å­˜åœ¨ä¸€å®šç¨‹åº¦çš„å¹»è§‰çš„ã€‚

