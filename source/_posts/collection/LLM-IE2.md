---
title: LLM-IE2
published: false
date: 2023-10-23 16:48:52
categories:
  - Paper
  - LLM
  - IE
tags:
  - LLM
  - IE
  - Collection
---

# 基于LLM的Information Extraction 2

基于LLM的信息抽取工作总结合集2。

<!--more-->

## Paraphrase NER

When and how to paraphrase for named entity recognition?

ACL 2023，{% post_link nlp/when-how-paraphrase-NER  [详细博客] %}。

> While paraphrasing is a promising approach for data augmentation in classification tasks, its effect on named entity recognition (NER) is not investigated systematically due to the difficulty of **span-level label preservation**. In this paper, **we utilize simple strategies to annotate entity spans in generations and compare established and novel methods of paraphrasing in NLP such as back translation, specialized encoder-decoder models such as Pegasus, and GPT-3 variants for their effectiveness in improving downstream performance for NER** across different levels of gold annotations and paraphrasing strength on 5 datasets. We thoroughly explore the influence of paraphrasers, dynamics between paraphrasing strength and gold dataset size on the NER performance with visualizations and statistical testing. We find that the choice of the paraphraser greatly impacts NER performance, with one of the **larger GPT-3 variants exceedingly capable of generating high quality paraphrases, yielding statistically significant improvements in NER performance with increasing paraphrasing strength,** while other paraphrasers show more mixed results. Additionally, inline auto annotations generated by larger GPT-3 are strictly better than heuristic based annotations. We also find diminishing benefits of paraphrasing as gold annotations increase for most datasets. Furthermore, while most paraphrasers promote entity memorization in NER, the proposed GPT-3 configuration performs most favorably among the compared paraphrasers when tested on unseen entities, with memorization reducing further with paraphrasing strength. Finally, we explore mention replacement using GPT-3, which provides additional benefits over base paraphrasing for specific datasets.

作者选择了5个不同领域的NER数据集。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221.png"   style="zoom:40%;" />

作者先对比两个已有的Paraphrasers工具：

- 基于Back-translation（BT）：For our experiments we use pre-trained English-German and German-English models (∼738M parameters) available from Huggingface model hub via Tiedemann and Thottingal (2020) and the model architecture used is BART (Lewis et al., 2019).
- 基于PEGASUS：We use an off-the-shelf version of PEGASUS fine-tuned for paraphrasing released on Huggingface model hub. 3

然后，作者利用两个GPT-3模型：`text-ada-001` (∼350M parameters), and `text-davinci-002` (∼175B parameters)。使用的temperature为0.8。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214754741-20231023165922734.png"   style="zoom:40%;" />

作者关注数据增强可能带来的一个问题Entity Memorization。即目前基于改写的数据增强方法，没有改变entity mention，生成的data中出现了entity的重复。因此作者想检查模型是不是直接记住了entity和它对应的label，而不是学会从feature推测label。

如果是记忆，那么model意味着模型走了捷径shortcut learning [*Shortcut learning in deep neural networks. Nature 2020*]，那么此时model应该无法准确处理没有见过的entity。

因此，作者又进行了在test set中，不同entity type里，没有在训练集里出现过的entity作为新的测试集unseen entity (UE) test sets。

为了缓解entity memorization问题，作者提出了一种解决方法Mention replacement（MR）。那就是不要重复entity mention，用GPT生成新的entity mention，然后去替换生成句子中的entity mention：

> In particular, for every entity mention in the gold set, we prompt GPT-3 DaVinci model to generate entity mentions that are similar to the gold entity mention, while also providing a phrase level definition of the entity type being replaced.

使用到的prompt：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223735026.png"  style="zoom:50%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223753805.png"   style="zoom:50%;" />

作者选择了5个不同领域的NER数据集，微调distilbert-base-cased作为NER model。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221-20230917171137150.png"   style="zoom:40%;" />

## UnleashLLM

How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?

浙大zjunlp，SustaiNLP 2023，[代码](https://github.com/zjunlp/DeepKE/tree/main/example/llm)。

> Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, **we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments.** To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction.

作者探究了如何利用LLM模型去执行few shot RE任务，主要是两个不同的角度：

- 使用in-context learning让LLM直接进行RE
- 利用LLM生成训练数据，提升之前基于SLM的few-shot方法性能

下面是方法图：

![image-20230518225716044](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518225716044-20231023165922925.png)

作者实现是基于`text-davinci-003`，有以下细节：

- prompt时加入实体类型和任务描述一般会提升LLM的RE效果。受限于输入长度限制，作者主要是进行one-shot的任务。
- ICL的demonstrations是针对每种relation type，随机的从训练集中找样例。
- 进行数据生成时，作者是以few-shot的样例作为demos输入来获得更多的数据，然后与原来的训练数据一起训练基于SLM的之前模型。

![image-20230518230345906](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518230345906-20231023165923047.png)

## Is GPT-3 good data annotator 

Is GPT-3 a Good Data Annotator?. 南洋理工与阿里达摩，ACL 2023，[代码](https://github.com/DAMO-NLP-SG/LLM-Data-Annotator)。

{% post_link llm/is-gpt3-good-data-annotator  [详细博客] %}。

> Data annotation is the process of labeling data that could be used to train machine learning models. Having high-quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output. GPT-3, a large-scale language model developed by OpenAI, has demonstrated impressive zero- and few-shot performance on a wide range of NLP tasks. It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks. **In this paper, we evaluate the performance of GPT-3 as a data annotator by comparing it with traditional data annotation methods and analyzing its output on a range of tasks.** Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP.

为什么要讨论数据标注问题？因为从大的方面讲，AI技术应该面向社会各界提供服务（论文中称为The democratization of artificial intelligence）。但是一个AI model往往需要大量的标注数据。

> The democratization of artificial intelligence (AI) (Garvey, 2018; Rubeis et al., 2022) aims to provide access to AI technologies to all members of society, including individuals, small- and medium-sized enterprises (SMEs), academic research labs, and nonprofit organizations.

标注数据的获得需要很高成本：

- labor costs associated with the labeling process
- the time and resources required to hire, train and manage annotators. 
- Additionally, there may be costs associated with the annotation tools and infrastructure needed to support the annotation process.

对于个人和小公司来说这种成本往往是不可接受的。

另一方面，GPT-3等大模型有很多knowledge，可以执行广泛的NLP任务；但是在production环境中，使用BERT-base等small的model可能是更加合理的（个人认为这种small model在极端情况下，需要高响应的场景中也不实用）。

所以，论文作者就关注利用GPT-3生成/标注训练数据，去更好的训练small model以降低标注数据获取成本。

作者的标注数据获取方法有三种：

- prompt-guided unlabeled data annotation (PGDA)：**tagging-based** approach，让LLM直接对in-domain unlabelled data进行标注
- prompt-guided training data generation (PGDG)：**generation-based** approach，让LLM生成带有label的数据
- dictionary-assisted training data generation (DADG)：**generation-based** approach，利用external knowledge source去辅助生成带有label的数据。先在Wikidata中查询相关的样例，然后让GPT模仿生成数据。这样做的好处是对于一些LLM的预训练数据没有包括/占比较少，学习效果不好的domain，更能够生成可信的结果。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905163214676-20231018161200247.png"   style="zoom:40%;" />

三种思路对于不同的任务有不同的prompt，但是都采用了in-context learning的形式。

一些实验设置：

- GPT-3使用`text-davinci-003`，使用其生成的data去训练small model
- small model是`BERT-base`
- DADG利用到的外部知识源是Wikidata

下面是记录的利用GPT生成NER数据和RE数据的PGDG方法的prompt，其它prompt参见论文：

RE任务：第一步让GPT生成特定relation的head/tail entity；第二步让GPT根据head/tail entity去创造包含这两个实体的sentence；从论文描述中看，应该是随机找的demonstrations。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905164544743-20231018161200293.png"   style="zoom:30%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905164602059-20231018161200344.png"   style="zoom:30%;" />

NER任务：第一步让GPT生成不同entity type下的可能entity；第二步让GPT利用生成的entity去生成对应的sentence：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905165740644-20231018161200393.png"   style="zoom:30%;" />

## Data Generation for clinical NER and RE

Does Synthetic Data Generation of LLMs Help Clinical Text Mining?

arXiv 2023-04

> Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI’s ChatGPT. These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation. However, their effectiveness in the healthcare sector remains uncertain. **In this study, we seek to investigate the potential of LLMs to aid in clinical text mining by examining their ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction.** However, our preliminary results indicate that employing LLMs directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients’ information to the LLM API. To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing LLMs and fine-tuning a local model for the downstream task. Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task. Furthermore, **generating data using LLMs can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns.** In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining.

作者先是尝试了ChatGPT在clinical NER和RE任务上，zero-shot ICL设置下和目前SOTA的差距：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925170021648-20230925171040987.png"   style="zoom:50%;" />

在clinical NER和RE上，作者发现效果并不好，这当然很正常，ChatGPT并不是专门为clinical domain训练的，而执行这一domain肯定需要大量的domain knowledge；同时直接调用LLM的API存在隐私泄露问题。因此作者尝试利用LLM去生成一系列的训练数据，而不是直接进行任务。用LLM生成数据去训练一个小模型，小模型可以直接本地部署，避免了隐私泄露问题。

作者用prompt engineering创造合适的prompt：

- 询问GPT “Provide five concise prompts or templates that can be used to generate data samples of [Task Descriptions].”
- 用每个prompt生成10个句子，然后人工检查下句子质量，选择效果最好的prompt
- 然后让GPT基于前面选择的最好的prompt，继续提供新的prompt。这一过程持续3遍

作者找到的最合适的prompt（没有demonstrations）：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925170508864-20230925171041027.png"   style="zoom:50%;" />

NER任务是根据entity直接生成句子；RE任务是输入头尾实体，判断某个relation是否存在

可视化结果显示，不控制的情况下，GPT自己发挥生成的句子和原来的sentence肯定有分布上的差别：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925170635577-20231023170047082.png"   style="zoom:50%;" />

## SynthIE

Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction. EMNLP 2023，[代码](https://github.com/epfl-dlab/SynthIE)。

使用LLM模型生成更多的IE任务训练数据，从而进一步提升模型性能。

> Large language models (LLMs) show great potential for synthetic data generation. This work shows that useful data can be synthetically generated even for tasks that cannot be solved directly by the LLM: we show that, for problems with structured outputs, it is possible to prompt an LLM to perform the task in the opposite direction, to generate plausible text for the target structure. Leveraging the asymmetry in task difficulty makes it possible to produce large-scale, high-quality data for complex tasks. We demonstrate the effectiveness of this approach on closed information extraction, where collecting ground-truth data is challenging, and no satisfactory dataset exists to date. We synthetically generate a dataset of 1.8M data points, demonstrate its superior quality compared to existing datasets in a human evaluation and use it to finetune small models (220M and 770M parameters). The models we introduce, SynthIE, outperform existing baselines of comparable size with a substantial gap of 57 and 79 absolute points in micro and macro F1, respectively. Code, data, and models are available at https://github.com/epfl-dlab/SynthIE.

motivation:

对于LLM模型来说，存在一些比较hard的task，直接利用LLM模型可能无法很好的直接解决，很多这样的NLP任务是要求输入自然语言的文本，输出格式化结果。作者认为，对于LLM模型来说，输入自然语言，获得结构化输出比较难，但是反过来输入结构化输入，输出对应的自然语言描述相对简单。这就是本文讨论的LLM的不对称性：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230517173725283.png"   style="zoom:30%;" />

作者认为IE任务对于LLM来说就是这样的hard task，IE任务数据构造需要大量的人工，另外构建的质量也不一定很高。比如根据评估，IE任务下最大的数据集REBEL文本中70%的信息没有被抽取到，45%的三元组实际上没有在文本中出现。因此，作者就尝试利用LLM模型生成训练数据，而不是直接执行训练任务，下面是流程图：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230517173826523.png" style="zoom:40%;" />

核心是两步，第一步是采样用来生成文本的三元组集合，在这一步作者核心考虑是怎么样保证三元组是连续的，也就是怎么样让三元组集合是常常在文本中一起出现的。作者通过在Wikidata knowledge graph上进行随机游走采样保证三元组之间存在关联。

其次还要考虑均匀度和覆盖度，让很少出现的实体或关系也能够被采样到。作者在随机游走K轮后，给从未被采样的entity更高的概率，已经被采样过的entity更低的概率。

第二步是根据三元组集合生成对应的文本。下面是一个示例：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518173205557.png"   style="zoom:50%;" />

作者使用的是text-davinci-003和code-davinci-002，生成了两个对应的数据集SynthIE-Text和SynthIE-Code。一个示例如下：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518173251020.png"   style="zoom:20%;" />

为了评估生成数据的结果，作者除了人工评估外，还使用人工生成的训练数据加入到原来的数据集中提升之前方法的效果：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518171257333.png"  style="zoom:30%;" />

不过个人感觉作者的实现提升效果不明显，而且随机偏差太大。

## DeepTagger

DeepTagger: Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries

arXiv 2023-06

> Named entity recognition (NER) is a crucial task for online advertisement. State-of-the-art solutions leverage pre-trained language models for this task. However, three major challenges remain unresolved: **web queries differ from natural language, on which pre-trained models are trained; web queries are short and lack contextual information; and labeled data for NER is scarce.** We propose DeepTagger, a knowledge-enhanced NER model for web-based ads queries. The proposed knowledge enhancement framework leverages both model-free and model-based approaches. For model-free enhancement, we collect unlabeled web queries to augment domain knowledge; and we collect web search results to enrich the information of ads queries. **We further leverage effective prompting methods to automatically generate labels using large language models such as ChatGPT.** Additionally, we adopt a model-based knowledge enhancement method based on adversarial data augmentation. We employ a three-stage training framework to train DeepTagger models. Empirical results in various NER tasks demonstrate the effectiveness of the proposed framework.

这篇文章集中在对Web queries进行NER场景上。这种任务通常发生在广告领域，对于用户输入的查询，需要识别实体，然后打广告。

Web queries与一般的完整natural language的区别：

- First, there is a domain shift between web queries and natural language. 大部分的web查询文本不是完整的句子，没有动词/形容词；同时会包含产品、品牌等在一般领域内不常见的实体
- Second, web queries are short and lack information. web查询文本很短，可能只有4-5个单词，没有很多的semantic components
- The third problem is label scarcity. 没有足够的针对web查询文本的标签数据

作者先是利用web search的结果的title来增加query的语义：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911223831963.png"   style="zoom:30%;" />

然后作者想办法获取不够准确的weakly-labeled data：

- 人类标注的也有可能有很多错误，作者把人类标注的data也作为一类weakly-labeled data

- 利用ChatGPT这类大模型进行初步NER标注，作者使用fixed CoT prompting方法；基于web query的返回结果的title来人工构造CoT：

  <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911224040473.png"   style="zoom:30%;" />

作者的strong-labeled data是指一小部分的人类专家标注的数据；为了增强利用这部分数据，作者使用了对抗数据增强的方法。原理是对某个data的微小的改动，不应该改变它对应的预测结果，也就是说对于数据点的邻居，模型应该给出一样的预测结果。这样增大最靠近决策边界的data point和决策边界的距离，让决策边界更加平滑，提升模型的鲁棒性[*Learning from rules generalizing labeled exemplars. ICLR 2020*]：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911224452680.png"   style="zoom:30%;" />

对于每个labeled data，生成它最难以被准确预测的邻居点：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911224159401.png"   style="zoom:30%;" />

最后，作者的NER model的训练流程：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911225016455.png"   style="zoom:50%;" />

UnleashLLM

How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?

浙大zjunlp，SustaiNLP 2023，[代码](https://github.com/zjunlp/DeepKE/tree/main/example/llm)。

> Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, **we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments.** To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction.

作者探究了如何利用LLM模型去执行few shot RE任务，主要是两个不同的角度：

- 使用in-context learning让LLM直接进行RE
- 利用LLM生成训练数据，提升之前基于SLM的few-shot方法性能

下面是方法图：

![image-20230518225716044](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518225716044.png)

作者实现是基于`text-davinci-003`，有以下细节：

- prompt时加入实体类型和任务描述一般会提升LLM的RE效果。受限于输入长度限制，作者主要是进行one-shot的任务。
- ICL的demonstrations是针对每种relation type，随机的从训练集中找样例。
- 进行数据生成时，作者是以few-shot的样例作为demos输入来获得更多的数据，然后与原来的训练数据一起训练基于SLM的之前模型。

![image-20230518230345906](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518230345906.png)

## Paraphrase NER

When and how to paraphrase for named entity recognition?

ACL 2023，{% post_link nlp/when-how-paraphrase-NER  [详细博客] %}。

> While paraphrasing is a promising approach for data augmentation in classification tasks, its effect on named entity recognition (NER) is not investigated systematically due to the difficulty of **span-level label preservation**. In this paper, **we utilize simple strategies to annotate entity spans in generations and compare established and novel methods of paraphrasing in NLP such as back translation, specialized encoder-decoder models such as Pegasus, and GPT-3 variants for their effectiveness in improving downstream performance for NER** across different levels of gold annotations and paraphrasing strength on 5 datasets. We thoroughly explore the influence of paraphrasers, dynamics between paraphrasing strength and gold dataset size on the NER performance with visualizations and statistical testing. We find that the choice of the paraphraser greatly impacts NER performance, with one of the **larger GPT-3 variants exceedingly capable of generating high quality paraphrases, yielding statistically significant improvements in NER performance with increasing paraphrasing strength,** while other paraphrasers show more mixed results. Additionally, inline auto annotations generated by larger GPT-3 are strictly better than heuristic based annotations. We also find diminishing benefits of paraphrasing as gold annotations increase for most datasets. Furthermore, while most paraphrasers promote entity memorization in NER, the proposed GPT-3 configuration performs most favorably among the compared paraphrasers when tested on unseen entities, with memorization reducing further with paraphrasing strength. Finally, we explore mention replacement using GPT-3, which provides additional benefits over base paraphrasing for specific datasets.

作者选择了5个不同领域的NER数据集。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221-20230917171504576.png"   style="zoom:40%;" />

作者先对比两个已有的Paraphrasers工具：

- 基于Back-translation（BT）：For our experiments we use pre-trained English-German and German-English models (∼738M parameters) available from Huggingface model hub via Tiedemann and Thottingal (2020) and the model architecture used is BART (Lewis et al., 2019).
- 基于PEGASUS：We use an off-the-shelf version of PEGASUS fine-tuned for paraphrasing released on Huggingface model hub. 

然后，作者利用两个GPT-3模型：`text-ada-001` (∼350M parameters), and `text-davinci-002` (∼175B parameters)。使用的temperature为0.8，进行one-shot ICL。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214754741.png"   style="zoom:40%;" />

作者关注数据增强可能带来的一个问题Entity Memorization。即目前基于改写的数据增强方法，没有改变entity mention，生成的data中出现了entity的重复。因此作者想检查模型是不是直接记住了entity和它对应的label，而不是学会从feature推测label。

如果是记忆，那么model意味着模型走了捷径shortcut learning [*Shortcut learning in deep neural networks. Nature 2020*]，那么此时model应该无法准确处理没有见过的entity。

因此，作者又进行了在test set中，不同entity type里，没有在训练集里出现过的entity作为新的测试集unseen entity (UE) test sets。

为了缓解entity memorization问题，作者提出了一种解决方法Mention replacement（MR）。那就是不要重复entity mention，用GPT生成新的entity mention，然后去替换生成句子中的entity mention：

> In particular, for every entity mention in the gold set, we prompt GPT-3 DaVinci model to generate entity mentions that are similar to the gold entity mention, while also providing a phrase level definition of the entity type being replaced.

使用到的prompt：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223735026-20230917171504656.png"  style="zoom:40%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223753805-20230917171504707.png"   style="zoom:40%;" />

作者选择了5个不同领域的NER数据集，微调`distilbert-base-cased`作为NER model。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221-20230917171137150-20230917171504792.png"   style="zoom:40%;" />

## $\mbox{S}^2$ynRE

S2ynRE: Two-stage Self-training with Synthetic data for Low-resource Relation Extraction. 中科大，ACL 2023，[代码](https://github.com/BenfengXu/S2ynRE)。

> Current relation extraction methods suffer from the inadequacy of large-scale annotated data. While distant supervision alleviates the problem of data quantities, there still exists domain disparity in data qualities due to its reliance on domain-restrained knowledge bases. In this work, **we propose S2ynRE, a framework of two-stage Self-training with Synthetic data for Relation Extraction.** We first leverage the capability of large language models to adapt to the target domain and automatically synthesize large quantities of coherent, realistic training data. We then propose an accompanied two-stage self-training algorithm that iteratively and alternately learns from synthetic and golden data together. We conduct comprehensive experiments and detailed ablations on popular relation extraction datasets to demonstrate the effectiveness of the proposed framework. Code is available at https://github.com/BenfengXu/S2ynRE.

对于RE任务来说，高质量有标注的data获取很难，之前一种解决这个问题的思路是远监督distant supervision，尽管远监督获得了效果的提升，但是远监督的数据不能够保证和下游任务的schema、context分布特征等是相符的：

> Although this line of methods have seen certain improvements, they still inevitably raise the concern that the distantly annotated data can vary considerably from downstream tasks both in target schema and in context distributions, thus may not be able to offer optimal transferability.

换句话说，要获得理想的领域特征一致的远监督数据本身也可能是比较难的。

因此，作者顺着最近的一些利用LLM生成text data的工作的思路，考虑使用LM来生成数据。作者的贡献主要有两点：

- 利用GPT-3.5和finetuned GPT-2 Large去适应target domain distribution，然后生成无label的RE data
- 提出了a two-stage self-training训练策略，更好的利用生成的无标注数据和原有标注数据

作者的RE任务是给定头尾实体，预测relation。

利用GPT-2 Large生成数据，首先按照language modeling的loss在训练集上微调；然后在推理阶段，输入`<bos>`开始进行采样生成new data。

利用GPT-3生成数据，采用5-shot ICL，随机找demonstrations的策略：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926161739020.png"  style="zoom:50%;" />

注意这里prompt对于结果的可控，只是通过一些指令性的表述，如`similar topic, domain and the same sub-obj format`。

然后是如何利用生成的无标注data，一般的策略是self-training，即给无标注data伪标注然后和原有data混合，训练小模型，训练好的小模型再重新标注无标注data。

作者认为这种直接将生成的数据加入到原有的数据方法前提是，要求生成的数据需要和原来的数据有一样的分布。

相反，作者将无标注数据和有标注数据分开，先使用gold data训练多个teacher model，然后标注生成的data，注意是soft label；然后用一个新初始化的student model在带有soft label的生成数据上训练，更新参数；之后继续在gold data上训练，更新后的model重新标注生成的data；这样迭代式的训练：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926162246951.png"   style="zoom:50%;" />

对于实验结果具体可以参考原paper，这里提供几个值得记录的结果：

作者使用BERT+Linear作为RE model。

直接用GPT不一定能够超过finetuned LM来生成data，下面的结果没有找到是具体哪个dataset上的测试结果：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926162817492.png"  style="zoom:50%;" />

作者使用type-token ratio ([*Evaluating story generation systems using automated linguistic analyses. 2017*]; *Data augmentation using pre-trained transformer models. 2020*)来评估diversity。

## Synthetic data: subjectivity

Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations

Purdue University, 作者评论接收至EMNLP 2023。{% post_link llm/synthetic-data-llm-sub [详细博客] %}。

> The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment. Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, **the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks.** To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the subjectivity of classification. Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data. We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM for synthetic data generation.

**Issue**: 目前在不同的task里，对于使用LLM生成的data是否能够和真实人工标注的data相比，没有定论。

**Solution**: 作者认为出现这种现象的原因之一和具体text classification任务的主观程度subjectivity有关，实验发现主观性越强的分类任务，LLM生成数据的效果也会越差。

作者采用了zero-shot和few-shot ICL两种设置。

对于zero-shot ICL prompt：

- “context prompt” relevant to the targeted domain of interest is used to set the context. 与具体task context相关的prompt
- the “data generation prompt”, is provided to the LLM, instructing the model to generate texts with a specific style, label (with respect to the classification task of interest), and word limit. 提供具体的label、生成字数限制等要求的prompt
- a “diversity prompt” to the LLM—“Can you provide something more diverse compared to the previously generated data?”—aiming to increase the diversity of the synthetic data generated. 生成具体的几个text data后，提示LLM生成更多不同的text data

对于few-shot ICL prompt：

- “context prompt”与前面zero-shot ICL一样
- 随机采样的几个demonstrations，其中说明了对应的label
- 还强制限制了不允许仅仅是修改原来的句子，而是期望生成更多的具体data，比如`You should imitate the example I have provided, but you cannot simply modify or rewrite the example I have given`

下面是不同task用到的具体prompt：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021233456402-20231023165740875.png"  style="zoom:50%;" />

分别独立的在真实数据、生成数据上进行训练的实验结果（对于关系分类任务，只讨论了FewRel 2.0数据集中`country`, `league`,`screenwriter`, and `tributary`的$4$种relation。每种relation生成$3000$条数据）：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021230350077-20231021233707905-20231023165740953.png"  style="zoom:50%;" />

观察：

- 直接使用真实数据训练的效果最好
- few-shot ICL生成数据效果比zero-shot ICL效果好
- LLM在生成带有更多人类主观性的数据上，效果更差

为什么任务的主观程度会增大LLM生成数据的效果？作者提供了两个解释：

1. highly subjective tasks often require a deep understanding of nuanced human emotions and contextual subtleties, as well as the ability to discern and accurately interpret different perspectives. 越主观，越要求对于人类情感等有非常微妙的理解
2. it may be challenging for LLMs to generate synthetic data to recover such potentially biased “majority view,” especially if the LLMs are trained to maintain neutrality. 大多数的任务实例是利用众包标注的，也就是说在数据集里的gold label可能只反映了多个人的主要投票意见。对于LLM来说，要生成反映这种majority view的句子可能比较难。

使用一小部分真实数据进行训练，然后拿这一小部分真实数据作为demonstrations进行数据增强的实验结果：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021230653949-20231021233708003-20231023165741015.png" style="zoom:50%;" />

观察：

- 在关系抽取任务上，作者的这种比较简单的生成数据的方法，没有明显提升效果

## STAR

STAR: Improving Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models. NeurIPS 2023 Workshop. University of California

> Information extraction tasks such as event extraction require an in-depth understanding of the output structure and subtask dependencies. They heavily rely on task-specific training data in the form of (passage, target structure) pairs to obtain reasonable performance. However, obtaining such data through human annotation is costly, leading to a pressing need for low-resource information extraction approaches that require minimal human labeling for real-world applications. Fine-tuning supervised models with synthesized training data would be a generalizable method, but **the existing data generation methods either still rely on large-scale ground-truth data or cannot be applied to complicated IE tasks due to their poor performance. **To address these challenges, we propose STAR, a data generation method that leverages Large Language Models (LLMs) to synthesize data instances given limited seed demonstrations, thereby boosting low-resource information extraction performance. **Our approach involves generating target structures (Y) followed by generating passages (X), all accomplished with the aid of LLMs.** We design fine-grained step-by-step instructions to obtain the initial data instances. We further reduce errors and improve data quality through self-reflection error identification and self-refinement with iterative revision. Our experiments show that the data generated by STAR significantly improves the performance of low-resource event extraction and relation extraction tasks, even surpassing the effectiveness of human-curated data. Human assessment of the data quality shows STAR-generated data exhibits higher passage quality and better align with the task definitions compared with the human-curated data.

**Issue**: 现有的解决低资源IE任务两种思路：

1. 迁移学习的方法
2. 将IE任务转化为另一种data-rich task的形式

但是这两种思路都要求有source task的训练数据，并且要求source task和IE task之间是相容的。

另外的一种思路是数据增强，包括：

- $X_{gold}\rightarrow Y$: annotate unlabeled examples with existing models as weak annotators
- $X_{gold}\rightarrow X^\prime$: produce analogous input
- $Y_{gold}\rightarrow X$: generate input assuming the labels are available

但是现有的数据增强IE方法只适用于简单的基于分类的IE任务，如RE。不适用于EE这样包含了不同子任务，并且子任务之间存在依赖的复杂IE任务。

**Soluation**: 作者提出利用LLM来生成IE任务训练数据的流程，STAR（Structure-to-Text DatA GeneRation），执行$Y\rightarrow X$生成，也就是从非已有的真实label到数据text的生成。

作者的方法流程：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023160605019.png" style="zoom:50%;" />

下面描述作者3个主要流程，以事件抽取EE为例：

Target Structure Generation：生成target structure $Y$

1. Trigger candidate generation. 生成触发词，prompt构成：

   - a definition of the selected event type
   - a few $k$ passages that contain event triggers of the selected event type as demonstrations

2. Argument candidate generation. 生成论元，prompt构成：

   - definition of the argument role under this specific event type
   - the entity type we are looking for (e.g. a vehicle)
   - 没有对应的demonstrations

3. Creating target structure and distribution control. 随机采样触发词和对应的论元，生成target structure，特别注意控制比例：

   - 每个event type生成相同数量例子，并且生成的触发词数量到100个，是现有ACE05数据集里不同event type对应的触发词数量的1.4x-50x倍大。

   - argument hallucination ratio: 按照不同概率，随机的移除一部分argument values，保证最后生成数据里，某个event type既有many arguments的例子，也有只有few arguments的例子

   - event density: 从$0$-$5$，让target structure包含不同event数量。

Instruction-Guided Passage Generation：根据target structure $Y$，生成initial passage $X_0$。具体的prompt包括下面几部分：

- Task-level instruction. 任务相关semantic，具体包括
  - a definition of “event”, “trigger”, “participant arguments” and “attribute arguments”;
  - an overall task requirement that the goal is to generate a sentence containing the event trigger words and arguments; 
  - hallucination clarification that instructs the model not to generate arguments of certain roles if we explicitly provide that “the argument is None”;
  - multiple event clarification that information from multiple events should be contained in a single passage.
- Event type-level instruction. label相关semantic，具体包括
  - the name and definition of the event type
  - the name and definition of each possible argument roles
- Instance-level verbalizer. demonstrations的format，具体包括
  - the number of events in the passage;
  - the content of the event target structure; 
  - the passage $X$ with tags wrapping triggers and arguments to explicit hint the LLM about the roles and positions of the keywords，如`<Plaintiff>He</Plaintiff> threatened to <Trigger>sue</Trigger> the company if the company did not refund his money.`。

Self-refinement by Self-reflection：improves the initial generation results through iterative updates (Madaan et al. 2023; Wang et al. 2022; Liu, Sferrazza, and Abbeel 2023)

作者针对EE任务，设计了一系列评估dimension：

- whether the trigger/argument mention is a subsequence of the passage; 
- whether a trigger is used to initiate an occurrence; 
- whether an argument is used as an event participant or attribute of the specific event; 
- whether the argument is serving the required argument role; 
- whether the passage contains information that could be served as an argument that should not appear; 
- whether POS tags of the argument mentions in the passage context match the provided ones.

对于每个评估角度，都query LLM去检查生成的passage $X$，如`Is ‘Syria’ a DESTINATION argument describing the event triggered by ‘flee’?`。LLM的回答，利用一个外部的NLI model MultiNLI [*BroadCoverage Challenge Corpus for Sentence Understanding through Inference. 2018*]去判断LLM的回复是否包含了含义`Yes, it is.`。

如果发现了问题，就采用对应的intervention templates去修正Passage $X$，如`The passage contains a hallucinated argument CRIME incorrectly, remove CRIME information for event triggered by ‘jailed’`。

上面的过程是针对EE任务，下面是作者在RE任务上的尝试：

1. target structure generation: we generate entity candidates using seed data instances’ entities as incontext examples. We then randomly pair entity candidates and assign a relation between the two entities. 对于每种relation type，给定包含头尾实体和例子，让LLM生成更多的相似实体
2. initial passage generation: we use relation type definition instead. 给定relation type的定义
3. self-refinement: 
   - whether the given entities are contained in the generated passage. 生成的句子是否包括了目标entity
   - whether there is a relation between them 头尾实体是否存在某种relation
   - whether they hold the certain relation provided in $Y$. 头尾实体是否描述了具体的target relation type

作者的实验基于`gpt-3.5-turbo-0301`和`gpt-4-0314`。$k$表示每种label使用的demonstrations数量，$N$表示生成的数据，最终在不同label包括$k+N$数据量的数据上进行训练。

在事件抽取ACE05数据集上的表现：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023164040881.png"  style="zoom:50%;" />

观察：

- 每个label生成50条数据用于训练，LLM生成的数据训练小模型的效果，超越了人类标注的real data。（但如果是使用全部的训练数据呢？）
- 使用上下文学习，模拟demonstrations是有意义的。如果只是提供task/label instruction，则很难生成合适的数据

在RE任务TACRED数据集上的表现：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023164319493.png" style="zoom:40%;" />

## GoLLMIE

GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. ICLR 2024. University of the Basque Country. [代码](https://github.com/hitz-zentroa/GoLLIE).

> Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines that describe the task and give examples to humans. **Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out of the box.** In this paper, we propose GoLLIE (Guideline following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines are key for good results. Code, data, and models are publicly available: https://github.com/hitz-zentroa/GoLLIE.

**Issue**: IE任务的困难之一是存在detailed  guidelines：

> This challenge is evident in the detailed guidelines, which feature granular definitions and numerous exceptions, that human annotators must follow to perform the task.

LLM能够执行instruction，但是不一定能够很好执行annotation guidelines，而简单的使用label name是不能够充分的描述这样的guidelines的，举例在NER任务中，person label和person label是不一样的，如在ACE05数据集中person包括了代词，而CoNLL03中person不包括代词。

**Solution**: 作者期望训练处能够学会follow guidelines的LLM。

作者提出的GoLLIE方法采用了code-style的input和output：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240308201714331.png"  style="zoom:50%;" />

原因是：

- This approach not only offers a clear and human-readable structure
- The inputs can be automatically standardized using Python code formatters such as Black. The output is well structured and parsing it is trivial.

特点：

1. label使用python class表示
2. label对应的arguments使用class内的属性表示
3. 待抽取的文本使用python string类型局部变量表示
4. 抽取结果使用python list类型局部变量表示
5. （创新点）guidelines利用python的class docstring和comment注释表示，在构造comment的时候，可能举几个具体的例子，如下图：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240308202448829.png"  style="zoom:50%;" />

最后训练的时候，为了让LLM学会跟随输入的guidelines，而不是学到某种特定的模式，因此作者使用了多种加入噪音的策略，例如Class order shuffling（打乱输入LLM的label python class的顺序）、Class dropout（随机移除一些class）、Guideline paraphrasing（改写guidelines）等。

在实现的时候，作者使用的训练数据集主要是目前已有的在News and Biomedical领域的IE数据集，而评估时还使用了更多的其它领域的数据集：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240308202856265.png" style="zoom:50%;" />

guidelines来源于数据集中本来就有的，或者是作者自行编写的。

训练细节：

- foundation LLM：使用了`Code-LLaMA 7/13/34B`。作者的前期实验发现Code-LLaMA比LLaMA2这些text LLM效果好

- 微调策略：使用QLoRA算法

- 资源：训练7B使用了80G的单个A100

  <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240308203238187.png"  style="zoom:50%;" />

作者的实验结果，在对应相关训练集上监督训练过的评估结果：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240308203414223.png"  style="zoom:50%;" />

表格中的baseline是指没有加入guidelines的作者方法的对应版本。可以看出，在有对应训练样本的情况下，加入guidelines并不会造成性能的下降。

在没有对应领域训练样本的情况下的实验结果：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240308203348446.png"  style="zoom:50%;" />

能够看出作者的方法很明显的提高了zero-shot的效果。

guideline举例：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240308203814357.png"  style="zoom:40%;" />

对于TACRED数据集，作者将其原本的RE任务，转化为了slot filling任务：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240408170404224.png"  style="zoom:50%;" />

## Code4UIE

Retrieval-Augmented Code Generation for Universal Information Extraction. arXiv 2023.11. 中科院

> Information Extraction (IE) aims to extract structural knowledge (e.g., entities, relations, events) from natural language texts, which brings challenges to existing methods due to task-specific schemas and complex text expressions. Code, as a typical kind of formalized language, is capable of describing structural knowledge under various schemas in a universal way. On the other hand, Large Language Models (LLMs) trained on both codes and texts have demonstrated powerful capabilities of transforming texts into codes, which provides a feasible solution to IE tasks. Therefore, in this paper, we propose a universal retrieval-augmented code generation framework based on LLMs, called Code4UIE, for IE tasks. Specifically, **Code4UIE adopts Python classes to define task-specific schemas of various structural knowledge in a universal way.** By so doing, extracting knowledge under these schemas can be transformed into generating codes that instantiate the predefined Python classes with the information in texts. To generate these codes more precisely, Code4UIE adopts the in-context learning mechanism to instruct LLMs with examples. In order to obtain appropriate examples for different tasks, Code4UIE explores several example retrieval strategies, which can retrieve examples semantically similar to the given texts. Extensive experiments on five representative IE tasks across nine datasets demonstrate the effectiveness of the Code4UIE framework.

类似于CodeIE，作者利用python code来统一表示各类IE任务。entity的python class表示：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240309111451115.png"  style="zoom:40%;" />

relation的表示：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240309111600522.png"  style="zoom:40%;" />

event的表示：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240309111629835.png"  style="zoom:40%;" />

在定义好了这些python class之后，作者提出了两种prompt进行IE任务，一种是one step就抽取出目标信息：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240309111805781.png"  style="zoom:40%;" />

另一种是two step抽取信息，stage 1只是判断是否存在某种entity type，stage 2只输入stage 1判断的entity type的定义，找出对应的entity，和ChatIE类似：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240309111854499.png"  style="zoom:50%;" />

在找上下文demonstrations的时候，作者除了直接使用`MPNet`方法学习sentence embedding，然后计算相似度外，还提出了一种Anonymous Sentence Embedding检索的策略，简单说就是用entity type替换了sentence中的entity mention，再计算相似度。目的在于让模型更加关注句子上下文和label之间的对应关系，而不是整个句子的text相似度。

实验使用了`text-davinci-002`, `text-davinci-003`和`gpt-3.5-turbo-16k`。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240309112219979.png"  style="zoom:40%;" />

作者没有复现CodeIE方法（基于Codex），没有使用一样的LLM，对比感觉不公平。

## c-ICL

c-ICL: Contrastive In-context Learning for Information Extraction. 北航. arXiv 2024

> Recently, there has been increasing interest in exploring the capabilities of advanced large language models (LLMs) in the field of information extraction (IE), specifically focusing on tasks related to named entity recognition (NER) and relation extraction (RE). Although researchers are exploring the use of few-shot information extraction through in-context learning with LLMs, **they tend to focus only on using correct or positive examples for demonstration, neglecting the potential value of incorporating incorrect or negative examples into the learning process.** In this paper, we present C -ICL, a novel few-shot technique that leverages both correct and incorrect sample constructions to create in-context learning demonstrations. This approach enhances the ability of LLMs to extract entities and relations by utilizing prompts that incorporate not only the positive samples but also the reasoning behind them. This method allows for the identification and correction of potential interface errors. Specifically, our proposed method taps into the inherent contextual information and **valuable information in hard negative samples and the nearest positive neighbors** to the test and then applies the in-context learning demonstrations based on LLMs. Our experiments on various datasets indicate that C -ICL outperforms previous few-shot in-context learning methods, delivering substantial enhancements in performance across a broad spectrum of related tasks. These improvements are noteworthy, showcasing the versatility of our approach in miscellaneous scenarios.

**Issue**：作者认为之前LLM的IE方法忽略了对于负样例/错误样例的利用，从负样例中可以学习到为什么会出现这样的错误的相关信息。

**Solution**：作者认为应该同时利用positive和hard negative samples作为demonstrations。在论文中，作者主要使用了code-style的prompt，但是没有特别解释到底为什么要使用这样形式的prompt，仅仅是简单提到了考虑到IE任务的结构？

对于label的定义，使用python comment中列举所有的label：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240310215315475.png"  style="zoom:40%;" />

对于正负样例，最后加入一行特殊的comment，表示其正负：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240310215412477.png"  style="zoom:40%;" />

正样例的检索，是通过计算sentence embedding的相似度，然后选择最相似的前k个示例。

对于负样例，特别的操作是同时会提供对应的正确结果：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240310215505286.png"  style="zoom:40%;" />

负样例的检索是通过一方面，作者利用self-consistency的策略，让LLM标注训练样本，然后计算预测结果的F1值选择hard negative samples（作者论文中没有提到是选择是设置一个阈值，大于这个阈值的认为是hard sample？还是小于的作为hard sample？）。

最后模型的输出是通过生成对应的IE任务函数，每个label对应的是python dictionary中的某个元素（list类型），可以添加对应的entity或者triple：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240310215716340.png"  style="zoom:40%;" />

实验结果，作者基于`CodeLLaMA 7/13/34B`。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240310215809608.png"  style="zoom:50%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240310215828704.png"  style="zoom:50%;" />

加入负样例的结果，效果提升：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240310220206852.png"  style="zoom:50%;" />

需要注意的是，加入负样例的数量不能太多（作者默认是2？还是3？论文里有些地方说法有冲突），否则会造成效果下降，具体参考论文。

作者具体还基于`CodeLLaMA`重新实现了CodeIE的效果：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240408150620391.png"  style="zoom:50%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240408150642317.png" style="zoom:50%;" />

## EventRL

EventRL: Enhancing Event Extraction with Outcome Supervision for Large Language Models. arXiv 2024. 清华

> In this study, we present EventRL, a reinforcement learning approach developed to enhance event extraction for large language models (LLMs). **EventRL utilizes outcome supervision with specific reward functions to tackle prevalent challenges in LLMs, such as instruction following and hallucination, manifested as the mismatch of event structure and the generation of undefined event types.** We evaluate EventRL against existing methods like FewShot Prompting (FSP) (based on GPT4) and Supervised Fine-Tuning (SFT) across various LLMs, including GPT-4, LLaMa, and CodeLLaMa models. Our findings show that EventRL significantly outperforms these conventional approaches by improving the performance in identifying and structuring events, particularly in handling novel event types. The study emphasizes the critical role of reward function selection and demonstrates the benefits of  incorporating code data for better event extraction. While increasing model size leads to higher accuracy, maintaining the ability to generalize is essential to avoid overfitting.

**Issue**: 利用LLM来直接解决事件抽取会遇到mismatches in event structure and the generation of undefined event types (Gao et al., 2023a)，最近有研究期望利用监督微调SFT的方法来解决这个问题，但是效果仍然不好。作者认为这是因为如果SFT仅仅是采用LLM的language modeling loss，不能够精细的、较好的强调分类事件相关信息错误/出现未定义事件类型的后果。原因是不同样例预测答案的错误和正确可能仅仅只有一两个word不一样，而language modeling loss是反映总体loss的，会忽略这种错误的重要影响。

**Solution**：作者提出了采用强化学习的方法，使用性能的F1指标作为奖励，让模型能够更加关注对于事件抽取预测错误的情况。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240312172557884.png"  style="zoom:50%;" />

作者对于输入是采用了类似markdown的形式：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240312172641825.png"  style="zoom:40%;" />

使用python `@dataclass`来定义label，与GoLLIE一样。

作者的奖励函数通过计算F1值来定义：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240312172750286.png"  style="zoom:40%;" />

然后，作者计算了一个advantage value，用来identifying actions that yield above-average benefits：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240312172914086.png"  style="zoom:50%;" />

其中，$Y$是指LLM通过nucleus sampling得到的预测输出，$\hat{Y}$是指greedy decoding得到的输出。最后梯度下降的定义：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240312173041374.png"  style="zoom:50%;" />

为了让模型训练稳定，作者采用了两种策略：

- Teacher-Force Threshold (Bengio et al., 2015) ：如果某个样例计算出来的F1 performance小于了阈值，就直接使用teacher的输出，也就是真实的输出
- Advantage Clipping (Schulman et al., 2017)：设置一个advantage value下界，任何比这个下界小的样例，都会直接使用这个下界作为advantage value

作者基于`LLaMA2 7B/13B`和`CodeLLaMA 7B/13B`，用两个A100 GPU，基于ColossalAI框架进行训练。在ACE 05数据集上的训练结果，作者选择了7个事件类型用于训练和验证，以及作为Held-in test测试集；另外19个事件类型作为unseen的Held-out测试集：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240312173221567.png"  style="zoom:50%;" />

观察：

- LLaMA 7B到13B效果提升很明显，相对的，codeLLaMA 7B到13B提升没有那么明显（尽管同样有提升）
- 相对来说，在codeLLaMA上用作者定义的代码形式的prompt微调效果提升更加一致
- 选择合适的奖励函数很重要，但是到底哪种会好，看起来似乎没有统一定论

## CoT-ER

Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction. EMNLP 2023 Findings. 哈工大深圳

> Few-shot relation extraction involves identifying the type of relationship between two specific entities within a text, using a limited number of annotated samples. A variety of solutions to this problem have emerged by applying meta-learning and neural graph techniques which typically necessitate a training process for adaptation. Recently, the strategy of incontext learning has been demonstrating notable results without training. Few studies have already utilized in-context learning for zeroshot information extraction. **Unfortunately, the evidence for inference is either not considered or implicitly modeled during the construction of chain-of-thought prompts.** In this paper, we propose a novel approach for few-shot relation extraction using large language models, named CoT-ER, chain-of-thought with explicit evidence reasoning. In particular, CoT-ER first induces large language models to generate evidence using task-specific and concept-level knowledge. Then this evidence is explicitly incorporated into chain-of-thought prompting for relation extraction. Experimental results demonstrate that our CoT-ER approach (with 0% training data) achieves competitive performance compared to the fully-supervised (with 100% training data) state-of-the-art approach on the FewRel1.0 and FewRel2.0 datasets.

**Issue**: 在RE任务上对于如何使用LLM的CoT推理能力，还没有过多的探究。最近的GPT-RE方法是通过给定样例及其label，让LLM归纳推理过程。但是这种方法存在问题：

- 其无法强调entity types，Previous studies and our experiments indicate that the one-step auto-generated reasoning process by LLM does not emphasize the higher-level abstraction of entity types, specifically the concept-level entities, which has been proven to be beneficial for FSRE task
2. ICL对于标签很敏感，单纯的label word可能无法准确的描述label semantic。The quality of semantic representation of the relation label is not crucial in the fully-supervised setting, but in-context learning is sensitive to the relation label.

**Solution**：作者为RE任务下的CoT推理进行了定制，三步推理过程，先推理head/tail entity type相关信息，寻找context text中的evidence；然后推理relation，寻找evidence。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240318171155266.png" style="zoom:50%;" />

首先，作者针对的是true few-shot设置下的RE任务。

> Perez et al. (2021) argues that prior research has achieved promising results by choosing prompts or tuning other hyperparameters using a large development set, such as selecting few-shot demonstrations from a large training set, which does not truly demonstrate the few-shot learning capability of LLMs.

对于每一类label，作者人工给1个sample构造推理过程；然后以这个seed example，让LLM为其它的训练样本生成对应的推理过程。

检索样例基于`text-embedding-ada-002`计算欧式距离，每个demonstration格式为：`Context: [text] Given the context, what is the relation between “[head entity]” and “[tail entity]”?`，强调头尾实体的存在。

最后推理用的template示例：

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240318170815510.png"  style="zoom:40%;" />

实验过程中，LLM使用`text-davinci-003`，数据集FewRel 1.0和2.0。2.0版本在1.0的验证集和测试集中加入了medical domain的新label。作者每个label都是只使用了label word，没有使用FewRel 1.0中包括的对于label的语义描述句子。

特别注意的是，由于LLM不擅长输出`NULL`关系，作者直接排除了数据集中的`None-of-the-Above`关系（个人认为不合理）。

由于FewRel不提供公开的test set label，因此作者从validation set中每个label采样100个样本作为测试集，即query set。

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240318171434959.png"  style="zoom:50%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240318171501184.png"  style="zoom:50%;" />

表格中的Auto-CoT（每个demonstration有对应的CoT）+reasoning表示，是否要求LLM对于query也要生成对应的CoT。

观察：

- 加入推理是否能够带来效果的提升不确定，在FewRel 1.0中有提升，但是在FewRel 2.0中就没有效果了
- 需要为RE任务定制CoT prompting方法

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240318171556087.png"  style="zoom:50%;" />

观察：

- auto-CoT缺少对于entity的reason，导致推理错误

- “crosses” and “located in or next to body of water”两个label有点相似，存在ambiguity。把entity和relation label都描述在一个完整的表达中，能够强调完整的语义，让最终推理过程输出正确

错例分析

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240318201038086.png"  style="zoom:40%;" />

观察：

- 第二个错误原因：CoT的推理过程虽然符合第一二步的推理过程，但是忽略了context信息
- 第三个错误原因：被相似relation label干扰
