---
title: MMKG-survey-list
notshow: false
date: 2022-06-19 16:07:15
categories:
- Reading-list
- MMKG
tags:
- Collection
- MMKG
- Reading-list
---

# Multimodal knowledge graph paper list

对目前的多模态知识图谱相关文献进行的调研list。

<!--more-->

Tutorial and Course:

| 标题                                                         | 地址                                                         | 内容                                                         | 评价                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **T**utorial on **M**ulti**M**odal **M**achine **L**earning  | [课程地址](https://cmu-multicomp-lab.github.io/mmml-tutorial/schedule/) | CMU 2022年最新的MMML tutorial，包括了slides和videos，主要介绍多模态机器学习相关概念和关键挑战；值得新人阅读。 | 内容较为全面，并且从专业的角度看到MMML的发展现状和挑战。作者说了很快会有一个600+引用文献的survey出现，值得期待。 |
| **A**dvanced **T**opics in **M**ulti**M**odal **M**achine **L**earning | [课程地址](https://cmu-multicomp-lab.github.io/adv-mmml-course/spring2022/) | CMU 2022春季的MMML各个领域最新的研究挑战；没有视频，但是提供了讲义。 | 还未阅读，目前看到讲义内容不多。                             |
|                                                              |                                                              |                                                              |                                                              |

Paper:

| 标题                                                         | 任务                                                         | 解决问题                                                     | 主要技术                                                   | 数据集                                                       | 参考价值                                                     |
| ------------------------------------------------------------ | :----------------------------------------------------------- | ------------------------------------------------------------ | ---------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System (ACL 22) | 对话                                                         | 之前的方法不能够充分学习不同模态之间的交互特征               | Transformer                                                | MMD                                                          | 并未利用MMKG，但是可以借鉴建模跨模态特征的方法               |
| Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine Comprehension (ACL 22) | Procedural MultiModal Machine Comprehension （多模态过程机器理解 | 之前的方法对于PMM中的实体建模粒度粗                          | GAT                                                        | RecipeQA、CraftQA                                            | 在PMM中同时建模一个描述实体跨模态和不同时间下的关系，可以借鉴 |
| Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network (ACL 22) | Sarcasm Detection                                            |                                                              | GCN                                                        | Cai et al.                                                   | 通过用户在网络上的发言构建一个多模态图，然后利用GCN进行信息捕获 |
| WIKIDiverse: A Multimodal Entity Linking Dataset with Diversified Contextual Topics and Entity Types (ACL 22) | Multimodal Entity Linking                                    | 为了解决现有的MEL数据集中出现的类型有效、可用性较差等问题    |                                                            | 提出新的数据集WIKIDiverse。Wikipedia作为使用的knowledge base | 人工设计了质量较高的MM实体链接数据集                         |
| Multimodal Sentiment Detection Based on Multi-channel Graph Neural Networks （ACL 21） | Sentiment Detection                                          | 之前探究多模态下的post的方法忽略了全局特征的提取             | GAT                                                        | MVSA-S、MVSA-M、TumEmo                                       | 利用GNN建模多模态信息                                        |
| MMGCN: Multimodal Fusion via Deep Graph Convolution Network for Emotion Recognition in Conversation (ACL 21) | Emotion Recognition                                          | 之前利用多模态信息的方法，仅仅是简单的不同模态特征的拼接     | GCN                                                        | IEMOCAP、MELD                                                | 利用GNN建模多模态信息                                        |
| LayoutLMv2: Multi-modal Pre-training for Visually-rich Document Understanding（ACL 21） | Document understanding                                       | 通过加入text-image对齐和text-image匹配的任务，进一步捕获不同模态的特征交互 | Transformer                                                |                                                              | 通过新的预测目标，隐式地增加不同模态间的交互                 |
| Integrating Multimodal Information in Large Pretrained Transformers （ACL 20） | Language model                                               | 通过加入一个额外的组件MAG（Multimodal Adaptation Gate），让BERT和XLNET能够在fine-tuning阶段接受文本外的其它信息 | Transformer                                                | CMU-MOSI                                                     | 多模态信息作为原来文本信息的补充                             |
| Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer （ACL 20） | Named Entity Recognition                                     | 设计了transformer-style的跨模态注意力模块                    | Transformer                                                | TWITTER-2015、TWITTER-2017                                   | 基于注意力的多模态特征交互                                   |
| Multimodal Transformer for Multimodal Machine Translation （ACL 20） | Multimodal Machine Translation                               | 基于text信息，利用注意力机制提取image上的信息                | Transformer                                                | Multi30k                                                     | 基于注意力的多模态特征交互                                   |
| Fatality Killed the Cat or: BabelPic, a Multimodal Dataset for Non-Concrete Concepts （ACL 20） |                                                              | 对于无法准确描述的概念，作者提供了文本和图像对于的一个数据集，BabelPic |                                                            | BabelPic                                                     | 一个多模态的知识库                                           |
| Multimodal Neural Graph Memory Networks for Visual Question Answering （ACL 20） | Visual Question Answering                                    | 以前的VQA会把一个image的描述，看做是线性的序列，作者将image的描述看做是一个图 | GNN                                                        | CLEVR                                                        | GNN用于多模态                                                |
| A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation（ACL 20） | Machine Translation                                          | 以前的多模态方法没有能够建模不同模态间细粒度的语义对应关系   | GNN                                                        | Multi30K、WMT17                                              | GNN用于多模态                                                |
| Multimodal Continual Graph Learning with Neural Architecture Search (WWW 22) | Continual Graph Learning                                     | 之前的方法无法很好的解决在持续图学习中的多模态问题           | GNN、NAS                                                   | Amazon、Articles                                             | GNN同时处理多模态和时序问题                                  |
| Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion （SIGIR 22） | Multimodal Knowledge Graph Completion                        | 作者认为之前的方法对于不同的知识图谱补全任务需要不同的模型结构并且无法选择不重要的模态特征 | Transformer                                                | FB15k-237-IMG、WN18-IMG、MNRE、 Twitter-2017                 | Transformer用于多模态知识图谱补全，并且涉及了不同的任务，参考价值大 |
| WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning (SIGIR 21) | 数据集                                                       | 作者创建了一个大规模、多语言、多模态的新数据集WIT            | -                                                          | WIT                                                          | -                                                            |
| Visual Pivoting for (Unsupervised) Entity Alignment (AAAI 21) | Entity Alignment                                             | 作者尝试利用引入图像提升实体对齐任务的性能                   | GCN、CNN                                                   | DBP15k、DWY15k                                               | 了解在不同KG上的多模态信息如何比较                           |
| RpBERT: A Text-image Relation Propagation-based BERT Model for Multimodal NER （AAAI 21） | Multimodal NER                                               | 之前的方法无法估计不相关的视觉线索，从而限制效果             | BERT                                                       | TRC、Fudan University、 Snap Research                        | 多模态命名实体识别                                           |
| Is Visual Context Really Helpful for Knowledge Graph? A Representation Learning Perspective （ACM-MM 21） | KGE                                                          | 目前，对于在KG中，加入视觉信息是不是能够真的对KG的任务有帮助？是否会带来更多不相关的特征？这一问题还未探究过 | Gate-based                                                 | WN18-IMG、FB15K-IMG、WN18-IMG-S、FB15K-IMG-S、FBX%           | 多模态知识图谱KGE                                            |
| Knowledge Perceived Multi-modal Pretraining in E-commerce （ACM-MM 21） | Multi-modal Pretraining                                      | 作者把KG和商品的图片信息融合，然后进行预训练，最后同时在masked object modeling (MOM), masked language modeling (MLM), 和link prediction modeling (LPM)任务上进行预训练 | Transformer                                                | TaoBao                                                       | KG预训练，然后服务于不同的多模态任务可行吗？                 |
| Graph Neural Networks for Knowledge Enhanced Visual Representation of Paintings (ACM-MM 21) | Fine art analysis                                            | 作者在艺术品和艺术家组成的多模态graph上使用GNN进行学习       | GNN                                                        | WikiArt                                                      | 图神经网络用于多模态图                                       |
| Multimodal Entity Linking: A New Dataset and A Baseline (ACM-MM 21) | Multimodal Entity Linking                                    | 作者针对MEL任务发布了一个新的MEL数据集-M3EL（MultiModal Movie Entity Linking），并且提出了一个新的baseline方法 | -                                                          | M3EL、AIDA、UIUC、WNED                                       | 对MEL任务最新的研究进展                                      |
| Multimodal Relation Extraction with Efficient Graph Alignment (ACM-MM 21) | Multimodal Relation Extraction                               | 视觉的信息可以补充关系抽取中缺失的语义联系，提升准确性。作者提出了MRE任务，大规模数据集MNRE。并且提出了一个利用图对齐的方法 | -                                                          | MNRE                                                         | 多模态关系抽取的新进展                                       |
| MultiModal Language Modelling on Knowledge Graphs for Deep Video Understanding （ACM-MM 21） | Deep Video Understanding                                     | 作者把多模态建模方法和知识图谱进行了融合                     | -                                                          | 作者自己提出了一个新的数据集                                 | KG和其它模态信息的融合                                       |
| Towards Using Semantic-Web Technologies for Multi-Modal Knowledge Graph Construction （ACM-MM 20） | 知识图谱构建                                                 | 作者基于目前已有的几种多模态建模方法，进行知识图谱构建。主要目的是探究目前可用方法的限制以及可能的研究方向 | -                                                          | -                                                            | -                                                            |
| Multimodal Representation with Embedded Visual Guiding Objects for Named Entity Recognition in Social Media Posts (ACM-MM 20) | Named Entity Recognition                                     | 作者认为之前的多模态命名实体识别方法忽略了视觉目标和实体之间的对应关系 | LSTM                                                       | Twitters                                                     | 多模态命名实体识别                                           |
| Multi-modal Multi-relational Feature Aggregation Network for Medical Knowledge Representation Learning (ACM-MM 20) | Medical KGE                                                  | 作者认为很多的KGE方法无法处理medical KG的三种性质：multimodal， unbalanced和heterogeneous | GNN                                                        | FB15k-237、Symptoms-in-Chinese、IMDb                         | 多模态多关系KGE                                              |
| UniMF: A Unified Framework to Incorporate Multimodal Knowledge Bases into End-to-End Task-Oriented Dialogue Systems (IJCAI 21) | 对话系统                                                     | 首个企图将多模态KG用于对话系统的方法                         | 多模态KG中对于图像信息和文本信息的抽取分别设计了不同的模块 | SMD、MultiWOZ、MMDialKB                                      | 多模态KG用于对话                                             |
| Modeling Dense Cross-Modal Interactions for Joint Entity-Relation Extraction (IJCAI 20) | 联合实体关系抽取                                             | 作者认为之前的方法没有能够实现对不同模态的特征进行细粒度的交互 |                                                            | CoNLL04、ADE                                                 | 多模态实体关系抽取                                           |
| ITA: Image-Text Alignments for Multi-Modal Named Entity Recognition （NAACL 22） | 命名实体识别                                                 | 作者认为之前的多模态命名实体识别方法，在建模文本和图像的交互时，由于没有在同一空间下进行学习，因此学习跨模态的交互不充分。作者在文本空间下同时学习文本和图像的表示，提出了ITA方法 | transformer                                                | Twitter-15、Twitter-17、SNAP                                 | 多模态KG的命名实体识别最新进展                               |
| Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction (NAACL 22) |                                                              |                                                              |                                                            |                                                              |                                                              |
|                                                              |                                                              |                                                              |                                                            |                                                              |                                                              |

