---
title: LLM-IE
published: false
date: 2023-05-15 23:24:09
categories:
- Paper
- LLM
- IE
tags:
- LLM
- IE
---

# åŸºäºLLMçš„Information Extraction

åŸºäºLLMçš„ä¿¡æ¯æŠ½å–å·¥ä½œæ€»ç»“ã€‚

<!--more-->

## filter-then-rerank

Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!

arXiv 2023.03ï¼Œå—æ´‹ç†å·¥

> Large Language Models (LLMs) have made remarkable strides in various tasks. However, whether they are competitive few-shot solvers for information extraction (IE) tasks and surpass fine-tuned small Pre-trained Language Models (SLMs) remains an open problem. This paper aims to provide a thorough answer to this problem, and moreover, to explore an approach towards effective and economical IE systems that combine the strengths of LLMs and SLMs. Through extensive experiments on eight datasets across three IE tasks, **we show that LLMs are not effective few-shot information extractors in general, given their unsatisfactory performance in most settings and the high latency and budget requirements.** However, we demonstrate that LLMs can well complement SLMs and effectively solve hard samples that SLMs struggle with. Building on these findings, **we propose an adaptive filter-then-rerank paradigm, in which SLMs act as filters and LLMs act as rerankers.** By utilizing LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.1% F1-gain on average) on various IE tasks, with acceptable cost of time and money.

ä½œè€…è¯„ä¼°äº†ä»¥Codexï¼ˆcode-davinci-002ï¼Œ2023/03/03ä¹‹å‰ï¼‰ä¸ºåŸºå‡†çš„LLM+in-context learningæ–¹æ³•åœ¨ä¿¡æ¯æŠ½å–ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¯¹æ¯”äº†åŸºäºRoBERTaå’ŒT5å°å‹è¯­è¨€æ¨¡å‹çš„ç°æœ‰IE SOTAæ–¹æ³•ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼š

![image-20230515233558514](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515233558514.png)

ä½œè€…å‘ç°å½“æ‰§è¡Œone-shotä»»åŠ¡æ—¶ï¼ŒLLMæ€§èƒ½è¿˜å¯ä»¥ï¼›å½“è®­ç»ƒæ ·æœ¬æ•°é€æ¸å¢åŠ æ—¶ï¼ŒåŸºäºLLMçš„æ–¹æ³•å—é™äºè¾“å…¥é•¿åº¦é™åˆ¶ä»¥åŠé¢„è®­ç»ƒè¿‡ç¨‹ç­‰å› ç´ ï¼Œæ²¡æœ‰åŠæ³•è¾¾åˆ°SOTAçš„IEæ€§èƒ½ã€‚

ä¸‹é¢æ˜¯ä½œè€…çš„å®éªŒç»“æœï¼š

![image-20230515233212836](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515233212836.png)

ä¸Šå›¾æœ‰ä¸¤ä¸ªå‘ç°ï¼š

- å½“è¾“å…¥çš„labelç±»å‹å°‘çš„æ—¶å€™ï¼Œå¦‚åœ¨CONLL03æ•°æ®é›†åªæœ‰4ç§labelè¡¨ç°æ•ˆæœä¸é”™ï¼›è€Œåœ¨æ›´å¤šçš„labelæ•°æ®é›†ï¼Œæ¯”å¦‚MAVENæœ‰168ä¸­event typeï¼Œå®é™…ä¸ŠLLMæ¨¡å‹ä¸èƒ½å¤Ÿå¾ˆå¥½çš„ç†è§£ä¸åŒlabelçš„å†…åœ¨å«ä¹‰[*Large language models still canâ€™t plan (a benchmark for llms on planning and reasoning about change. 2022*]ã€‚å¹¶ä¸”è¶Šå¤šçš„labelæ„å‘³ç€éœ€è¦è¶Šå¤šè¶Šå¤æ‚çš„è¾“å…¥demosã€‚
- ä¸‰ç§ä»»åŠ¡æ¯”è¾ƒèµ·æ¥ï¼Œåœ¨REä»»åŠ¡ä¸Šè¡¨ç°è¿˜å¯ä»¥ã€‚

åŸºäºLLMçš„IEæ–¹æ³•è¿˜æœ‰å¦ä¸€ä¸ªé‡è¦é—®é¢˜æ˜¯æ¥å£è¿”å›å€¼å¾ˆæ…¢ï¼Œç‰¹åˆ«æ˜¯è¾“å…¥ç‰¹åˆ«å¤§çš„æƒ…å†µä¸‹éœ€è¦çš„å¤„ç†æ—¶é—´å°±æ›´é•¿äº†ï¼›è€Œå°çš„æ¨¡å‹æ¨ç†é€Ÿåº¦å¾ˆå¿«ï¼Œå…·ä½“å¯ä»¥å‚è€ƒè®ºæ–‡ä¸­çš„Table 1ã€‚

ä½œè€…æå‡ºï¼ŒLLMæ¨¡å‹å¯ä»¥ç”¨æ¥è§£å†³æ›´åŠ hardçš„æ ·æœ¬ï¼Œå»è§£å†³é‚£äº›å°çš„åŸºäºç›‘ç£è®­ç»ƒçš„æ¨¡å‹æ— æ³•å¾ˆå¥½é¢„æµ‹çš„æ ·æœ¬ï¼Œè¿™äº›hard sampleå¯èƒ½éœ€è¦external knowledgeæˆ–è€…æ›´å¤æ‚çš„reasoningèƒ½åŠ›ï¼Œè¿™äº›æ­£å¥½æ˜¯LLMæ¨¡å‹çš„é•¿å¤„ã€‚å› æ­¤ä½œè€…æå‡ºäº†ä½¿ç”¨å°çš„æ¨¡å‹Small Language Modelï¼ˆSLMï¼‰å…ˆè¿›è¡Œè®­ç»ƒåé¢„æµ‹ï¼Œå¯¹äºæ¯”è¾ƒç®€å•çš„æ ·æœ¬ï¼Œç›´æ¥ä½¿ç”¨SLMçš„è¾“å‡ºç»“æœï¼›å¯¹äºæ¯”è¾ƒéš¾é¢„æµ‹çš„æ ·æœ¬ï¼Œè¾“å‡ºå‡ ä¸ªé¢„æµ‹å¾—åˆ†åœ¨top-nçš„labelï¼Œè®©LLMè¿›è¡Œrerankï¼Œæœ€åè¿›è¡Œè¾“å‡ºã€‚

ä½œè€…åˆ¤æ–­ä¸€ä¸ªæ ·æœ¬æ˜¯å¦éš¾ä»¥è¢«åŸºäºSLMçš„æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„ä¾æ®å°±æ˜¯ä¸åŒlabel scoreä¸­æœ€å¤§scoreè¶Šå°ï¼Œè¡¨ç¤ºè¶Šéš¾åˆ¤æ–­è¿™ä¸ªæ ·æœ¬ã€‚

ä¸‹é¢æ˜¯æ¨¡å‹å›¾ï¼Œä½œè€…åœ¨å®ç°è‡ªå·±çš„æ¨¡å‹ä½¿ç”¨äº†InstructGPTï¼ˆtext-davinci-003ï¼‰ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515234734532.png"   style="zoom:50%;" />

æ–¹æ³•çœ‹èµ·æ¥æ¯”è¾ƒç®€å•ï¼Œæœ‰ä¸€ç‚¹å¯ä»¥æ³¨æ„ä¸‹ï¼Œä½œè€…æŠŠIEä»»åŠ¡ä¸‹å¯èƒ½è¦æ±‚çš„æ ¼å¼åŒ–çš„è¾“å‡ºï¼ˆæ¯”å¦‚ä¸‰å…ƒç»„ï¼‰è½¬æ¢ä¸ºå¥å­çš„å½¢å¼ï¼Œè®©LLMè¡Œå»åšmulti-choice questionï¼Œè¿™æ ·LLMæ¨¡å‹å¯èƒ½å¯ä»¥æ›´å¥½çš„ç†è§£demosä¸­çš„å®ä¾‹ã€‚

![image-20230515235129692](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515235129692.png)

åœ¨few-shotçš„IEä»»åŠ¡ä¸‹å¹³å‡F1æå‡äº†2.1%ã€‚

## CheatGPT IE

Evaluating ChatGPTâ€™s Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness

åŒ—å¤§ï¼ŒarXiv 2023.04

> The capability of Large Language Models (LLMs) like ChatGPT to comprehend user intent and provide reasonable responses has made them extremely popular lately. In this paper, we focus on assessing the overall ability of ChatGPT using 7 fine-grained information extraction (IE) tasks. Specially, we present the systematically analysis by measuring ChatGPTâ€™s performance, explainability, calibration, and faithfulness, and resulting in 15 keys from either the ChatGPT or domain experts. **Our findings reveal that ChatGPTâ€™s performance in Standard-IE setting is poor, but it surprisingly exhibits excellent performance in the OpenIE setting, as evidenced by human evaluation.** In addition, our research indicates that ChatGPT provides high-quality and trustworthy explanations for its decisions. However, there is an issue of ChatGPT being overconfident in its predictions, which resulting in low calibration. Furthermore, ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. We manually annotate and release the test sets of 7 finegrained IE tasks contains 14 datasets to further promote the research. The datasets and code are available at this url.

è¿™ç¯‡è®ºæ–‡åŒæ ·æ˜¯è®¨è®ºåŸºäºLLMçš„IEï¼Œåªä¸è¿‡ä½œè€…æ˜¯åŸºäºChatGPTï¼Œä¹Ÿæ²¡æœ‰ä½¿ç”¨æ›´å¤šçš„æŠ€æœ¯ï¼Œæ¯”å¦‚ä¸Šé¢è®ºæ–‡çš„in-context learningã€‚ä½œè€…ä»Performanceï¼ŒExplainabilityï¼ŒCalibrationï¼ˆæ¨¡å‹å¯¹äºè¾“å‡ºç»“æœçš„è‡ªä¿¡ç¨‹åº¦ï¼‰å’ŒFaithfulnessï¼ˆè¾“å‡ºç»“æœæ˜¯å¦ä¸è¾“å…¥å†…å®¹ä¸€è‡´ï¼‰å››ä¸ªå¤§çš„æ–¹é¢ï¼Œç”¨15ä¸ªæŒ‡æ ‡ï¼ˆäººå·¥+è‡ªåŠ¨ï¼‰è¿›è¡Œäº†è¯„ä¼°ï¼š

![](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230515235818750.png)

ä½œè€…ä½¿ç”¨äº†ä¸¤ç§åœºæ™¯ä¸‹çš„IEï¼š

- Standard IEï¼šç»™å®šlabel set
- Open IEï¼šä¸ç»™å®šlabel setï¼Œè®©ChatGPTè‡ªå·±å›ç­”ï¼Œäººå·¥åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ­£ç¡®

ä¸ºäº†é¿å…å†å²å›ç­”è®°å½•çš„å½±å“ï¼Œæ¯æ¬¡å›ç­”éƒ½ä¼šæ¸…ç©ºä¸Šä¸€æ¬¡å›ç­”çš„è®°å½•ï¼Œä¸‹é¢æ˜¯ä½œè€…è¿›è¡Œäº‹ä»¶æ£€æµ‹ä»»åŠ¡æ—¶è¾“å…¥çš„æ ·ä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000754165.png"   style="zoom:20%;" />

æœ€ç»ˆå®éªŒç»“æœå¦‚ä¸‹ï¼š

![image-20230516000110009](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000110009.png)

åœ¨entity typingä»»åŠ¡ä¸‹è¡¨ç°ä¸é”™ã€‚æ³¨æ„ä¸€ä¸‹ï¼Œé‡Œé¢çš„relation extractionä»»åŠ¡å®é™…ä¸Šæ˜¯å®ä½“-å…³ç³»è”åˆæŠ½å–ä»»åŠ¡ï¼Œrelation classificationä»»åŠ¡æ˜¯åªé¢„æµ‹relationçš„ä»»åŠ¡ã€‚æ€»ä½“ä¸ŠLLMå’ŒSOTAè¿˜æœ‰è¾ƒå¤§å·®è·ï¼Œä½†æ˜¯ä½œè€…è¿›ä¸€æ­¥å‘ç°å¦‚æœæ˜¯è®¡ç®—top-kæŒ‡æ ‡çš„è¯ï¼Œæ•ˆæœè¿˜ä¸é”™ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000316332.png"   style="zoom:40%;" />

è€Œå¦‚æœåœ¨open IEåœºæ™¯ä¸‹ï¼ŒChatGPTæ•ˆæœä¼šæ›´å¥½ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000408562.png"   style="zoom:40%;" />

å¯¹äºå¯è§£é‡Šæ€§ï¼Œä½œè€…å‘ç°ChatGPTèƒ½å¤Ÿç»™å‡ºä¸é”™çš„è§£é‡Šï¼ˆå…·ä½“ç»“æœå‚è€ƒè®ºæ–‡çš„Table 4ï¼‰ã€‚

å¯¹äºCalibrationï¼Œå‘ç°ChatGPTä¸è®ºæ˜¯å¦åˆ†ç±»æ­£ç¡®ï¼Œæ€»æ˜¯å¯¹è‡ªå·±çš„ç»“æœå¾ˆè‡ªä¿¡ï¼Œç»™å‡ºå¾ˆé«˜çš„å¾—åˆ†ã€‚

æœ€åï¼Œä½œè€…å‘ç°ChatGPTè¾“å‡ºç»“æœåŸºæœ¬ä¸Šå’Œè¾“å…¥æ˜¯ç›¸ç¬¦çš„ã€‚

## ChatIE

Zero-Shot Information Extraction via Chatting with ChatGPT

åŒ—äº¤ï¼ŒarXiv 2023.02ï¼Œ[ä»£ç ](https://github.com/cocacola-lab/ChatIE)ã€‚

> Zero-shot information extraction (IE) aims to build IE systems from the unannotated text. It is challenging due to involving little human intervention. Challenging but worthwhile, zero-shot IE reduces the time and effort that data labeling takes. Recent efforts on large language models (LLMs, e.g., GPT3, ChatGPT) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this work, we ask whether strong IE models can be constructed by directly prompting LLMs. Specifically, we transform the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework (ChatIE). With the power of ChatGPT, we extensively evaluate our framework on three IE tasks: entity-relation triple extract, named entity recognition, and event extraction. Empirical results on six datasets across two languages show that ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL). We believe that our work could shed light on building IE models with limited resources.

ä½œè€…å‘ç°ç›´æ¥è®©ChatGPTé—®ç­”IEä»»åŠ¡æ•ˆæœä¸å¥½ï¼Œå› æ­¤æå‡ºäº†ä¸¤æ­¥çš„å¤šè½®é—®ç­”æ–¹å¼çš„æ–¹æ³•chatIEï¼Œç›®æ ‡æ˜¯zero-shot IEä»»åŠ¡ï¼Œä¸‹é¢æ˜¯æ¨¡å‹å›¾ï¼š

![image-20230516000929739](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516000929739.png)

ç¬¬ä¸€æ­¥æé—®è¾“å…¥æ–‡æœ¬ä¸­æœ‰å“ªäº›ç±»çš„æ€§èƒ½ï¼Œæ¯”å¦‚æœ‰å“ªäº›ç±»å®ä½“ï¼›

ç¬¬äºŒæ­¥è¿›ä¸€æ­¥æé—®æ¯ä¸€ç±»ä¸‹çš„å…·ä½“ç»“æœï¼Œè¿™ä¸€æ­¥å¯èƒ½æœ‰å¤šè½®é—®ç­”ã€‚

ä¸‹é¢æ˜¯NERä»»åŠ¡çš„å®ä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516001252515.png"  style="zoom:25%;" />

å®éªŒç»“æœï¼š

![image-20230516001208421](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516001208421.png)

## CodeIE

CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors

å¤æ—¦ï¼Œarxiv 2023.05ï¼Œä½œè€…è¯„è®ºè¯´æ¥æ”¶è‡³ACL 2023ï¼Œ[ä»£ç ](https://github.com/dasepli/CodeIE)ã€‚

> Large language models (LLMs) pre-trained on massive corpora have demonstrated impressive few-shot learning ability on many NLP tasks. A common practice is to recast the task into a text-to-text format such that generative LLMs of natural language (NL-LLMs) like GPT-3 can be prompted to solve it. However, it is non-trivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text. In this paper, we propose to recast the structured output in the form of code instead of natural language and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, in particular, named entity recognition and relation extraction. In contrast to NL-LLMs, **we show that Code-LLMs can be well-aligned with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks.** Experiment results on seven benchmarks show that our method consistently outperforms fine-tuning moderate-size pre-trained models specially designed for IE tasks (e.g., UIE) and prompting NL-LLMs under few-shot settings. We further conduct a series of in-depth analyses to demonstrate the merits of leveraging Code-LLMs for IE tasks.

ä½œè€…æå‡ºï¼ŒåŸºäºLLMæ¨¡å‹å»åšIEä»»åŠ¡æ—¶ï¼ŒæŠŠè¾“å…¥å’Œè¾“å‡ºéƒ½è½¬åŒ–ä¸ºä»£ç çš„å½¢å¼æ›´å¥½ï¼Œå› ä¸ºä¸€èˆ¬IEä»»åŠ¡çš„è¾“å‡ºæ˜¯æ ¼å¼åŒ–çš„ï¼Œè€Œé¢„è®­ç»ƒæ¨¡å‹å¾ˆå¤šæ˜¯åœ¨è‡ªç„¶è¯­è¨€ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼›å¦å¤–ä½œè€…å‘ç°ä½¿ç”¨ä¸»è¦åˆ†æä»£ç çš„LLMä¾‹å¦‚Codexæ•ˆæœæ¯”ä¸€èˆ¬çš„LLMæ¨¡å‹æ›´å¥½ï¼ˆä½œè€…å®éªŒä¸­ä½¿ç”¨çš„è¿˜æ˜¯code-davinci-002å’Œtext-davinci-002ï¼Œä¸æ¸…æ¥šä¸Šè¿°ç»“è®ºå¯¹äº003ç‰ˆæœ¬ä»¥åŠGPT-4æ˜¯å¦æˆç«‹ï¼‰ã€‚

motivationï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516223705834.png"   style="zoom:30%;" />

ä½œè€…æå‡ºçš„æ–¹æ³•ï¼š

![image-20230516223400913](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516223400913.png)

ä¸»è¦æ˜¯é’ˆå¯¹few-shot IEä»»åŠ¡ï¼ŒåŠ å…¥äº†å‡ ä¸ªdemonstrationã€‚å®šä¹‰çš„promptæ˜¯pythonçš„functionæ ¼å¼ï¼Œè®©Codexå»è¡¥å…¨å‰©ä¸‹çš„ä»£ç ã€‚ä½œè€…ä¹Ÿè¯•éªŒäº†å…¶å®ƒå‡ ä¸ªæ¯”å¦‚ä½¿ç”¨class initå‡½æ•°ç­‰ï¼Œå‘ç°è¿™æ ·å­æ•ˆæœæœ€å¥½ã€‚

ä½œè€…çš„å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230516223639496.png"   style="zoom:30%;" />

## SynthIE

Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction

arXiv 2023.03ï¼Œ[ä»£ç ](https://github.com/epfl-dlab/SynthIE)ã€‚

ä½¿ç”¨LLMæ¨¡å‹ç”Ÿæˆæ›´å¤šçš„IEä»»åŠ¡è®­ç»ƒæ•°æ®ï¼Œä»è€Œè¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚

> Large language models (LLMs) show great potential for synthetic data generation. This work shows that useful data can be synthetically generated even for tasks that cannot be solved directly by the LLM: we show that, for problems with structured outputs, it is possible to prompt an LLM to perform the task in the opposite direction, to generate plausible text for the target structure. Leveraging the asymmetry in task difficulty makes it possible to produce large-scale, high-quality data for complex tasks. We demonstrate the effectiveness of this approach on closed information extraction, where collecting groundtruth data is challenging, and no satisfactory dataset exists to date. We synthetically generate a dataset of 1.8M data points, demonstrate its superior quality compared to existing datasets in a human evaluation and use it to finetune small models (220M and 770M parameters). The models we introduce, SynthIE, outperform existing baselines of comparable size with a substantial gap of 57 and 79 absolute points in micro and macro F1, respectively. Code, data, and models are available at https://github.com/epfl-dlab/SynthIE.

motivation:

å¯¹äºLLMæ¨¡å‹æ¥è¯´ï¼Œå­˜åœ¨ä¸€äº›æ¯”è¾ƒhardçš„taskï¼Œç›´æ¥åˆ©ç”¨LLMæ¨¡å‹å¯èƒ½æ— æ³•å¾ˆå¥½çš„ç›´æ¥è§£å†³ï¼Œå¾ˆå¤šè¿™æ ·çš„NLPä»»åŠ¡æ˜¯è¦æ±‚è¾“å…¥è‡ªç„¶è¯­è¨€çš„æ–‡æœ¬ï¼Œè¾“å‡ºæ ¼å¼åŒ–ç»“æœã€‚ä½œè€…è®¤ä¸ºï¼Œå¯¹äºLLMæ¨¡å‹æ¥è¯´ï¼Œè¾“å…¥è‡ªç„¶è¯­è¨€ï¼Œè·å¾—ç»“æ„åŒ–è¾“å‡ºæ¯”è¾ƒéš¾ï¼Œä½†æ˜¯åè¿‡æ¥è¾“å…¥ç»“æ„åŒ–è¾“å…¥ï¼Œè¾“å‡ºå¯¹åº”çš„è‡ªç„¶è¯­è¨€æè¿°ç›¸å¯¹ç®€å•ã€‚è¿™å°±æ˜¯æœ¬æ–‡è®¨è®ºçš„LLMçš„ä¸å¯¹ç§°æ€§ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230517173725283.png"   style="zoom:30%;" />

ä½œè€…è®¤ä¸ºIEä»»åŠ¡å¯¹äºLLMæ¥è¯´å°±æ˜¯è¿™æ ·çš„hard taskï¼ŒIEä»»åŠ¡æ•°æ®æ„é€ éœ€è¦å¤§é‡çš„äººå·¥ï¼Œå¦å¤–æ„å»ºçš„è´¨é‡ä¹Ÿä¸ä¸€å®šå¾ˆé«˜ã€‚æ¯”å¦‚æ ¹æ®è¯„ä¼°ï¼ŒIEä»»åŠ¡ä¸‹æœ€å¤§çš„æ•°æ®é›†REBELæ–‡æœ¬ä¸­70%çš„ä¿¡æ¯æ²¡æœ‰è¢«æŠ½å–åˆ°ï¼Œ45%çš„ä¸‰å…ƒç»„å®é™…ä¸Šæ²¡æœ‰åœ¨æ–‡æœ¬ä¸­å‡ºç°ã€‚å› æ­¤ï¼Œä½œè€…å°±å°è¯•åˆ©ç”¨LLMæ¨¡å‹ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œè€Œä¸æ˜¯ç›´æ¥æ‰§è¡Œè®­ç»ƒä»»åŠ¡ï¼Œä¸‹é¢æ˜¯æµç¨‹å›¾ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230517173826523.png" style="zoom:40%;" />

æ ¸å¿ƒæ˜¯ä¸¤æ­¥ï¼Œç¬¬ä¸€æ­¥æ˜¯é‡‡æ ·ç”¨æ¥ç”Ÿæˆæ–‡æœ¬çš„ä¸‰å…ƒç»„é›†åˆï¼Œåœ¨è¿™ä¸€æ­¥ä½œè€…æ ¸å¿ƒè€ƒè™‘æ˜¯æ€ä¹ˆæ ·ä¿è¯ä¸‰å…ƒç»„æ˜¯è¿ç»­çš„ï¼Œä¹Ÿå°±æ˜¯æ€ä¹ˆæ ·è®©ä¸‰å…ƒç»„é›†åˆæ˜¯å¸¸å¸¸åœ¨æ–‡æœ¬ä¸­ä¸€èµ·å‡ºç°çš„ã€‚ä½œè€…é€šè¿‡åœ¨Wikidata knowledge graphä¸Šè¿›è¡Œéšæœºæ¸¸èµ°é‡‡æ ·ä¿è¯ä¸‰å…ƒç»„ä¹‹é—´å­˜åœ¨å…³è”ã€‚

å…¶æ¬¡è¿˜è¦è€ƒè™‘å‡åŒ€åº¦å’Œè¦†ç›–åº¦ï¼Œè®©å¾ˆå°‘å‡ºç°çš„å®ä½“æˆ–å…³ç³»ä¹Ÿèƒ½å¤Ÿè¢«é‡‡æ ·åˆ°ã€‚ä½œè€…åœ¨éšæœºæ¸¸èµ°Kè½®åï¼Œç»™ä»æœªè¢«é‡‡æ ·çš„entityæ›´é«˜çš„æ¦‚ç‡ï¼Œå·²ç»è¢«é‡‡æ ·è¿‡çš„entityæ›´ä½çš„æ¦‚ç‡ã€‚

ç¬¬äºŒæ­¥æ˜¯æ ¹æ®ä¸‰å…ƒç»„é›†åˆç”Ÿæˆå¯¹åº”çš„æ–‡æœ¬ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518173205557.png"   style="zoom:50%;" />

ä½œè€…ä½¿ç”¨çš„æ˜¯text-davinci-003å’Œcode-davinci-002ï¼Œç”Ÿæˆäº†ä¸¤ä¸ªå¯¹åº”çš„æ•°æ®é›†SynthIE-Textå’ŒSynthIE-Codeã€‚ä¸€ä¸ªç¤ºä¾‹å¦‚ä¸‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518173251020.png"   style="zoom:20%;" />

ä¸ºäº†è¯„ä¼°ç”Ÿæˆæ•°æ®çš„ç»“æœï¼Œä½œè€…é™¤äº†äººå·¥è¯„ä¼°å¤–ï¼Œè¿˜ä½¿ç”¨äººå·¥ç”Ÿæˆçš„è®­ç»ƒæ•°æ®åŠ å…¥åˆ°åŸæ¥çš„æ•°æ®é›†ä¸­æå‡ä¹‹å‰æ–¹æ³•çš„æ•ˆæœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518171257333.png"  style="zoom:30%;" />

ä¸è¿‡ä¸ªäººæ„Ÿè§‰ä½œè€…çš„å®ç°æå‡æ•ˆæœä¸æ˜æ˜¾ï¼Œè€Œä¸”éšæœºåå·®å¤ªå¤§ã€‚

## ChatGPT for KG

Enhancing Knowledge Graph Construction Using Large Language Models.

arXiv 2023

> The growing trend of Large Language Models (LLM) development has attracted significant attention, with models for various applications emerging consistently. However, the combined application of Large Language Models with semantic technologies for reasoning and inference is still a challenging task. This paper analyzes how the current advances in foundational LLM, like ChatGPT, can be compared with the specialized pretrained models, like REBEL, for joint entity and relation extraction. To evaluate this approach, we conducted several experiments using sustainability-related text as our use case. We created pipelines for the automatic creation of Knowledge Graphs from raw texts, and our findings indicate that using advanced LLM models can improve the accuracy of the process of creating these graphs from unstructured text. Furthermore, we explored the potential of automatic ontology creation using foundation LLM models, which resulted in even more relevant and accurate knowledge graphs.

ä½œè€…ä½¿ç”¨ChatGPTå»å®Œæ•´çš„æ„é€ ä¸€ä¸ªä¸å¯æŒç»­ç›¸å…³çš„çŸ¥è¯†å›¾è°±ï¼ŒåŒ…æ‹¬å®ä½“å…³ç³»æŠ½å–ä¸æœ¬ä½“åˆ›å»ºç­‰ï¼Œä½œè€…å‘ç°è®©ChatGPTå»å…³è”æŠ½å–å‡ºçš„å®ä½“å…³ç³»ä¸æœ¬ä½“ï¼Œæ•ˆæœä¸å¥½ã€‚è®©ChatGPTç›´æ¥ç”Ÿæˆæœ¬ä½“å¯èƒ½æ˜¯æ›´åˆé€‚çš„æ–¹å¼ã€‚

è®ºæ–‡ä¸­æ²¡æœ‰æä¾›å…·ä½“çš„promptè®¾è®¡æ–¹æ³•ï¼Œå‚è€ƒä»·å€¼ä¸å¤§ã€‚

## VicunaNER

arXiv 2023.05ï¼Œæ–°åŠ å¡å›½ç«‹å¤§å­¦ï¼ˆæˆªæ­¢05/18æ—¥è¿˜åªèƒ½çœ‹åˆ°ä¸å¤ªå®Œæ•´çš„è®ºæ–‡ï¼Œæ²¡æœ‰å®éªŒç»“æœï¼‰

> Large Language Models (LLMs, e.g., ChatGPT) have shown impressive zero- and fewshot capabilities in Named Entity Recognition (NER). However, these models can only be accessed via online APIs, which may cause data leak and non-reproducible problems. In this paper, we propose VicunaNER, a zero/fewshot NER framework based on the newly released open-source LLM â€“ Vicuna. VicunaNER is a two-phase framework, where each phase leverages multi-turn dialogues with Vicuna to recognize entities from texts. We name the second phase as Re-Recognition, which recognizes those entities not recognized in the first phase (a.k.a. Recongition). Moreover, we set entity correctness check dialogues in each phase to filter out wrong entities. We evaluate VicunaNERâ€™s zero-shot capacity on 10 datasets crossing 5 domains and few-shot capacity on Few-NERD. Experimental results demonstrate that VicunaNER achieves superior performance in both shot settings. Additionally, we conduct comprehensive investigations on Vicuna from multiple perspectives.

ä½œè€…åŸºäºç¾Šé©¼æ¨¡å‹è¿›è¡ŒNERä»»åŠ¡ï¼Œä½œè€…é€‰æ‹©open LLMçš„ç†ç”±å¦‚ä¸‹ï¼š

- æ•°æ®é›†æ³„éœ²é—®é¢˜ï¼Œæ¯”å¦‚ä¸‰æ˜Ÿçš„æ•æ„Ÿæ•°æ®è¢«æ³„éœ²åˆ°äº†ChatGPT
- ä¸å¯å¤ç°é—®é¢˜ï¼Œåœ¨çº¿é—­æºçš„LLMéƒ½åœ¨æŒç»­æ›´æ–°ï¼Œå¾ˆéš¾é‡å¤å‰äººçš„ç ”ç©¶ç»“æœ

æ–¹æ³•ä¸»è¦æ˜¯åŸºäºå¤šè½®é—®ç­”çš„NERï¼Œå…·ä½“è€Œè¨€æ˜¯æœ‰å››æ­¥ï¼š

1. è®©VicunaæŠ½å–entity
2. è¯¢é—®VicunaæŠ½å–å‡ºçš„entityæ˜¯å¦æ­£ç¡®ï¼Œè¿‡æ»¤æ‰ä¸æ­£ç¡®çš„å®ä½“ï¼ˆç¬¬ä¸€é˜¶æ®µç»“æŸï¼‰
3. ç»™å®šä¸Šä¸€é˜¶æ®µæŠ½å–åˆ°çš„å®ä½“ï¼Œè®©Vicunaç»§ç»­è¯†åˆ«æœªè¯†åˆ«å‡ºçš„å®ä½“
4. è¯¢é—®VicunaæŠ½å–å‡ºçš„entityæ˜¯å¦æ­£ç¡®ï¼Œè¿‡æ»¤æ‰ä¸æ­£ç¡®çš„å®ä½“ï¼ˆç¬¬äºŒé˜¶æ®µç»“æŸï¼‰

å†åŠ å…¥æ›´å¤šè½®çš„é—®ç­”ä½œè€…å‘ç°å¹¶æ²¡æœ‰æ˜æ˜¾æå‡æ€§èƒ½ã€‚

ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

![image-20230518111407753](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518111407753.png)

ä»è¿™é‡Œå¯ä»¥ä½“ä¼šä¸‹LLMçš„ä¼˜ç‚¹ï¼Œä½œè€…çš„ä¸¤ä¸ªé˜¶æ®µç›¸å½“äºæ˜¯è¾“å…¥ä¸åŒçš„å°ä»»åŠ¡ï¼Œå¯¹äºLLMæ¨¡å‹æ¥è¯´æ²¡æœ‰åŒºåˆ«ï¼Œå®ƒå¯ä»¥ç›´æ¥æ‰§è¡Œè¿™ä¸¤ä¸ªä»»åŠ¡ã€‚ç›¸æ¯”èµ·æ¥ï¼Œä¼ ç»Ÿçš„æ¨¡å‹æ›´åŠ specificï¼Œå¾ˆéš¾è¾¾åˆ°è¿™æ ·çš„æ³›åŒ–æ€§ï¼Œé€šè¿‡é›†æˆå‡ ä¸ªä¸åŒçš„å°ä»»åŠ¡æå‡å¤§ä»»åŠ¡çš„æ•ˆæœï¼Œè€Œä¸”ä¸éœ€è¦åˆ†åˆ«è®­ç»ƒæ¨¡å‹ã€‚ï¼ˆä¸Šé¢çš„å·¥ä½œæ€æƒ³æ ¸å¿ƒåº”è¯¥è¯´å‡ºæ˜¯boostï¼Ÿï¼‰ã€‚

## UnleashLLM

How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?

æµ™å¤§zjunlpï¼ŒarXiv 2023.05ï¼Œ[ä»£ç ](https://github.com/zjunlp/ DeepKE/tree/main/example/llm)ã€‚

> Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, incontext learning and data generation, for fewshot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction.

ä½œè€…æ¢ç©¶äº†å¦‚ä½•åˆ©ç”¨LLMæ¨¡å‹å»æ‰§è¡Œfew shot REä»»åŠ¡ï¼Œä¸»è¦æ˜¯ä¸¤ä¸ªä¸åŒçš„è§’åº¦ï¼š

- ä½¿ç”¨in-context learningè®©LLMç›´æ¥è¿›è¡ŒRE
- åˆ©ç”¨LLMç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œæå‡ä¹‹å‰åŸºäºSLMçš„few-shotæ–¹æ³•æ€§èƒ½

ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

![image-20230518225716044](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518225716044.png)

ä½œè€…å®ç°æ˜¯åŸºäºtext-davinci-003ï¼Œæœ‰ä»¥ä¸‹ç»†èŠ‚ï¼š

- promptæ—¶åŠ å…¥å®ä½“ç±»å‹å’Œä»»åŠ¡æè¿°ä¸€èˆ¬ä¼šæå‡LLMçš„REæ•ˆæœã€‚å—é™äºè¾“å…¥é•¿åº¦é™åˆ¶ï¼Œä½œè€…ä¸»è¦æ˜¯è¿›è¡Œone-shotçš„ä»»åŠ¡ã€‚
- è¿›è¡Œæ•°æ®ç”Ÿæˆæ—¶ï¼Œä½œè€…æ˜¯ä»¥few-shotçš„æ ·ä¾‹ä½œä¸ºdemosè¾“å…¥æ¥è·å¾—æ›´å¤šçš„æ•°æ®ï¼Œç„¶åä¸åŸæ¥çš„è®­ç»ƒæ•°æ®ä¸€èµ·è®­ç»ƒåŸºäºSLMçš„ä¹‹å‰æ¨¡å‹ã€‚

![image-20230518230345906](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230518230345906.png)

## CodeKGC

CodeKGC: Code Language Model for Generative Knowledge Graph Construction

æµ™å¤§zjunlpï¼ŒarXiv 2023.04ï¼Œ[ä»£ç ](https://github.com/zjunlp/DeepKE/tree/main/example/llm)ã€‚

> Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, **we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph.** As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provide intermediate steps, thereby improving knowledge extraction abilities. Experimental results indicate that the proposed approach can obtain better performance on benchmark datasets compared with baselines.

motivationï¼š

ä½œè€…è®¤ä¸ºå¯¹äºçŸ¥è¯†å›¾è°±æ„å»ºè¿™æ ·çš„ä»»åŠ¡æ¥è¯´ï¼Œç”±äºä¸‰å…ƒç»„ä¹‹é—´å­˜åœ¨ä¾èµ–ï¼Œäº’ç›¸å…³è”ï¼Œè®©è¯­è¨€æ¨¡å‹ç›´æ¥ç”Ÿæˆç»“æ„åŒ–çš„è¾“å‡ºæ¯”è¾ƒéš¾ï¼Œå› æ­¤ä½œè€…å°†çŸ¥è¯†å›¾è°±ä¿¡æ¯æŠ½å–ä»»åŠ¡çœ‹åšæ˜¯ä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œä½¿ç”¨ç¼–ç¨‹è¯­è¨€æ¥æè¿°è¾“å…¥çš„æ–‡æœ¬å’Œè¾“å‡ºï¼Œè€Œä¸æ˜¯ä½¿ç”¨è‡ªç„¶è¯­è¨€ã€‚

methodï¼š

![image-20230519154317958](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519154317958.png)

ä½œè€…åˆ©ç”¨pythonè¯­è¨€æè¿°promptã€‚è¾“å…¥çš„æ–‡æœ¬æ˜¯ä½œä¸ºpythonä¸­çš„`Docstrings`ã€‚

schemaçš„å®šä¹‰æ˜¯é€šè¿‡pythonçš„`class`ï¼Œä½œè€…å®šä¹‰äº†åŸºç¡€çš„ç±»`Entity`ï¼Œ`Rel`å’Œ`Triple`ã€‚å…¶å®ƒçš„å®ä½“å’Œå…³ç³»ç±»ä¼šç»§æ‰¿`Entity`å’Œ`Rel`ã€‚æ¯ä¸€ä¸ªä¸‰å…ƒç»„è¢«å®šä¹‰ä¸ºå¯¹åº”çš„`Triple`ç±»ï¼Œæ¯”å¦‚`(ğ¿ğ‘œğ‘›ğ‘‘ğ‘œğ‘›,ğ‘™ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ‘–ğ‘›,ğ‘ˆğ¾)`å¯¹åº”`Triple(LOC("London"), Rel("located in"), LOC("London"))`ã€‚

ä½œè€…è¿˜å¦å¤–æå‡ºäº†ä¸€ä¸ªå¯é€‰çš„Rationale-enhancedç”Ÿæˆæ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯å…ˆæŠ½å–å‡ºå…³ç³»ï¼Œå†æŠ½å–å®ä½“ï¼Œæœ€åæŠ½å–ä¸‰å…ƒç»„ã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519155533998.png"   style="zoom:40%;" />

åœ¨å®éªŒéƒ¨åˆ†ä½œè€…å®é™…ä¹Ÿä½¿ç”¨äº†code-davinci-002ï¼Œä½†æ˜¯ä½œè€…æåˆ°ç”±äºCodexä½¿ç”¨èŒƒå›´æœ‰é™ï¼ˆOpenAIåœ¨3æœˆ23æ—¥åœæ­¢äº†å¯¹Codex APIçš„æŒç»­æ”¯æŒï¼‰ï¼Œå› æ­¤ä½œè€…ä»…ä»…åœ¨æ¶ˆèå®éªŒéƒ¨åˆ†ä½¿ç”¨äº†Codexã€‚

## InstructUIE

InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction

å¤æ—¦ï¼ŒarXiv 2023.04ï¼Œ[ä»£ç ](https://github.com/BeyonderXX/InstructUIE)ã€‚

>  Large language models have unlocked strong multi-task capabilities from reading instructive prompts. However, recent studies have shown that existing large models still have difficulty with information extraction tasks. For example, gpt-3.5-turbo achieved an F1 score of 18.22 on the Ontonotes dataset, which is significantly lower than the state-of-the-art performance. **In this paper, we propose InstructUIE, a unified information extraction framework based on instruction tuning, which can uniformly model various information extraction tasks and capture the inter-task dependency.** To validate the proposed method, we introduce IE INSTRUCTIONS, a benchmark of 32 diverse information extraction datasets in a unified text-to-text format with expert-written instructions. Experimental results demonstrate that our method achieves comparable performance to Bert in supervised settings and significantly outperforms the state-of-the-art and gpt3.5 in zero-shot settings.

åœ¨ä¹‹å‰çš„ä¸€äº›ç ”ç©¶ä¸­å‘ç°LLMæ¨¡å‹åœ¨IEä»»åŠ¡ä¸Šè¡¨ç°å¹¶ä¸å¥½ï¼Œå› æ­¤ä½œè€…å¸Œæœ›èƒ½å¤Ÿå®ç°ä¸€ä¸ªåŸºäºLLMçš„unified information extraction (UIE) modelã€‚ä½œè€…é›†åˆäº†ç°æœ‰çš„NERï¼ŒREå’ŒEEæ•°æ®é›†ï¼Œæ„é€ äº†ä¸€ä¸ªåŠ å…¥instructionçš„benchmarkâ€”â€”IE INSTRUCTIONï¼Œç”¨å…¶æ¥instruction-tuning LLMç”¨äºIEä»»åŠ¡ã€‚

ä½œè€…æŠŠIEä»»åŠ¡çœ‹åšæ˜¯è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ï¼Œä¸€ä¸ªtext-to-textçš„ä»»åŠ¡ã€‚è¾“å…¥æ˜¯å¸¦æœ‰instructionçš„promptï¼Œè¾“å‡ºæ˜¯æ–‡æœ¬ã€‚ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

![image-20230519170242805](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519170242805.png)

æ–¹æ³•æ¯”è¾ƒç®€å•ï¼Œè¾“å…¥çš„promptåŒ…æ‹¬ä¸‹é¢å‡ éƒ¨åˆ†ï¼š

- Task Instructionï¼štype of information to be extracted, the format of the output structure, and any additional constraints or rules that need to be followed during the extraction process.
- Optionsï¼šthe set of possible outputs that can be generated by the model for a given input.
- Textï¼šinput sentence.

ä½œè€…å¦å¤–æ„å»ºäº†ä¸€ä¸ªåŸºäºä¿¡æ¯æŠ½å–å…¬å¼€æ•°æ®é›†çš„benchmarkâ€”â€”IE INSTRUCTIONSï¼ŒåŒ…æ‹¬32ä¸ªå°çš„æ•°æ®é›†ï¼Œæ•°æ®åˆ†å¸ƒå¦‚ä¸‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230519170702469.png"  style="zoom:30%;" />

ä½œè€…å¯¹æ”¶é›†çš„æ•°æ®é›†è¿›è¡Œäº†ä»¥ä¸‹å¤„ç†ï¼š

- ç»Ÿä¸€ä¸åŒæ•°æ®é›†çš„labelæè¿°
- æŠŠä¸€äº›ç¼©å†™æˆ–ç®€å†™çš„æ ‡ç­¾è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€ï¼Œæ¯”å¦‚`place_of_birth`è½¬åŒ–ä¸º`place of birth`ã€‚
- æŠŠæ‰€æœ‰æ•°æ®é›†éƒ½è½¬åŒ–ä¸ºtext-to-textçš„å½¢å¼

ä½œè€…çš„å®éªŒåŸºäº11B FlanT5ï¼Œä½œè€…è¿›è¡Œäº†ä¸¤ç§æœ‰ç›‘ç£çš„åœ¨IE INSTRUCTIONSä¸Šå¾®è°ƒLLMå’Œæ— ç›‘ç£çš„zero-shotä¸¤ç§å®éªŒ:

- Supervised Settings: 10,000 examples for each dataset
- Zero-shot Settings:
  - Train: 18 NER datasets and 6 RE datasets
  - Test: 7 NER datasets and 2 RE datasets

å…·ä½“å®éªŒç»“æœå‚çœ‹è®ºæ–‡ã€‚

## GPT-3 for Clinical IE

Large Language Models are Few-Shot Clinical Information Extractors

EMNLP 2022ï¼ŒMITï¼Œ[ä»£ç ](https://huggingface.co/datasets/mitclinicalml/clinical-ie)ã€‚

> A long-running goal of the clinical NLP community is the extraction of important variables trapped in clinical notes. However, roadblocks have included dataset shift from the general domain and a lack of public clinical corpora and annotations. **In this work, we show that large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain.** Whereas text classification and generation performance have already been studied extensively in such models, here we additionally demonstrate how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs, including span identification, token-level sequence classification, and relation extraction. Further, due to the dearth of available data to evaluate these systems, we introduce new datasets for benchmarking fewshot clinical information extraction based on a manual re-annotation of the CASI dataset (Moon et al., 2014) for new tasks 1 . On the clinical extraction tasks we studied, the GPT-3 systems significantly outperform existing zero- and few-shot baselines.

ä¸´åºŠåŒ»å­¦å¯èƒ½æ˜¯ä¸€ä¸ªèƒ½å¤Ÿä½“ç°LLMåœ¨IEä»»åŠ¡ä¸­ç‰¹æœ‰ä»·å€¼çš„å…·ä½“åœºæ™¯ã€‚ä¸´åºŠä¿¡æ¯æŠ½å–ä»»åŠ¡ä¸€ç›´é¢ä¸´ä¸‹é¢çš„é—®é¢˜ï¼š

1. æ–‡æœ¬ä¸­åŒ…æ‹¬å¾ˆå¤šçš„ä¸“ä¸šæœ¯è¯­å’Œæ¨¡ç³Šçš„æè¿°
2. å¤§å¤šä¸´åºŠæ•°æ®é›†ä¸å…¬å¼€ï¼Œå³ä½¿å…¬å¼€äº†ä¹Ÿæœ‰ä¸¥æ ¼çš„ä½¿ç”¨é™åˆ¶ï¼Œæ— æ³•ç”¨äºåœ¨çº¿çš„OpenAIçš„LLM API

ä¸Šé¢çš„é—®é¢˜åœ¨å¾ˆå¤šæ•°æ®æ•æ„Ÿçš„ä¸“ä¸šé¢†åŸŸåº”è¯¥éƒ½æ˜¯å­˜åœ¨çš„ã€‚ä½¿ç”¨LLMçš„å¥½å¤„ä¹‹ä¸€å°±æ˜¯å®ƒå¯ä»¥ä¸ç»è¿‡è®­ç»ƒï¼Œåœ¨éœ€è¦å¤–éƒ¨çŸ¥è¯†æˆ–è€…å¤æ‚æ¨ç†èƒ½åŠ›çš„åœºæ™¯ä¸‹è¾¾åˆ°è¿˜ä¸é”™çš„æ•ˆæœã€‚

ä½œè€…æ¢ç©¶äº†åˆ©ç”¨GPT-3è¿›è¡Œä¸´åºŠæ•°æ®çš„ä¿¡æ¯æŠ½å–çš„æ•ˆæœï¼ŒåŒæ—¶é‡æ–°æ ‡æ³¨äº†ä¸‰ä¸ªæ•°æ®é›†ä»¥è¯„ä¼°å°‘æ¬¡æŠ½å–æ€§èƒ½ã€‚ä¸‹é¢æ˜¯æ–¹æ³•ï¼ŒåŸºæœ¬å°±æ˜¯ç®€å•çš„ICLï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230520154610827.png"   style="zoom:30%;" />

## GPT-3 for Biomedical IE

Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again

EMNLP 2022 Findingsï¼Œä¿„äº¥ä¿„å·ç«‹å¤§å­¦ï¼Œ[ä»£ç ](https://github. com/dki-lab/few-shot-bioIE)ã€‚

> Large pre-trained language models (PLMs) such as GPT-3 have shown strong in-context learning capabilities, which are highly appealing for domains such as biomedicine that feature high and diverse demands of language technologies but also high data annotation costs. In this paper, **we present the first systematic and comprehensive study to compare the few-shot performance of GPT-3 in-context learning with fine-tuning smaller (i.e., BERT-sized) PLMs on two representative biomedical information extraction (IE) tasks: named entity recognition and relation extraction.** We follow the true few-shot setting (Perez et al., 2021) to avoid overestimating modelsâ€™ few-shot performance by model selection over a large validation set. We also optimize GPT-3â€™s performance with known techniques such as contextual calibration and dynamic in-context example retrieval. However, **our results show that GPT-3 still significantly underperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3 in-context learning also yields smaller gains in accuracy when more training data becomes available.** More in-depth analyses further reveal issues of in-context learning that may be detrimental to IE tasks in general. Given the high cost of experimenting with GPT-3, we hope our study provides helpful guidance for biomedical researchers and practitioners towards more practical solutions such as fine-tuning small PLMs before better in-context learning is available for biomedical IE.

ä½œè€…ä½¿ç”¨GPT-3è¿›è¡Œç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„IEä»»åŠ¡ï¼Œä¸»è¦ä½¿ç”¨ICLæŠ€æœ¯ï¼Œå‘ç°GPT-3è¿˜ä¸èƒ½å¤Ÿè¶…è¶Šç›®å‰åŸºäºSLMçš„SOTAæ–¹æ³•ï¼ŒåŒæ—¶å¾€ICLä¸­åŠ å…¥æ›´å¤šçš„demoså¹¶æ²¡æœ‰èƒ½å¤ŸæŒç»­æå‡æ•ˆæœã€‚

æ–¹æ³•ï¼š

![image-20230520164636198](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230520164636198.png)

ä½œè€…çš„æ–¹æ³•ä¸»è¦æ˜¯ä½¿ç”¨ICLæŠ€æœ¯ï¼Œä¸ºäº†èƒ½å¤Ÿé€‰æ‹©å’Œå½“å‰æ ·ä¾‹ç›¸è¿‘çš„demosï¼Œä½œè€…åŸºäºRoBERTa-largeä½œä¸ºç¼–ç å™¨ï¼Œä½¿ç”¨kNNæ–¹æ³•ä»100ä¸ªå›ºå®šçš„è®­ç»ƒé›†æ ·ä¾‹é›†åˆä¸­åŠ¨æ€é€‰æ‹©ã€‚NERæœ€å¤šé€‰æ‹©10ä¸ªæ ·ä¾‹ï¼ŒREæœ€å¤šé€‰æ‹©5ä¸ªæ ·ä¾‹ã€‚

å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230520164836464.png"   style="zoom:40%;" />

å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ä½œè€…çš„å®éªŒç¯å¢ƒä¸‹ï¼Œä½¿ç”¨GPT-3å’Œå½“å‰çš„SOTAæ–¹æ³•è¿˜æ˜¯æœ‰å·®è·ã€‚

## ChatGPT for ED

Exploring the Feasibility of ChatGPT for Event Extraction

arXiv 2023.03ï¼Œå“ˆå·¥å¤§-æ·±åœ³ã€‚

> Event extraction is a fundamental task in natural language processing that involves identifying and extracting information about events mentioned in text. However, it is a challenging task due to the lack of annotated data, which is expensive and time-consuming to obtain. The emergence of large language models (LLMs) such as ChatGPT provides an opportunity to solve language tasks with simple prompts without the need for task-specific datasets and fine-tuning. While ChatGPT has demonstrated impressive results in tasks like machine translation, text summarization, and question answering, it presents challenges when used for complex tasks like event extraction. **Unlike other tasks, event extraction requires the model to be provided with a complex set of instructions defining all event types and their schemas.** To explore the feasibility of ChatGPT for event extraction and the challenges it poses, we conducted a series of experiments. **Our results show that ChatGPT has, on average, only 51.04% of the performance of a task-specific model such as EEQA in long-tail and complex scenarios.** Our usability testing experiments indicate that ChatGPT is not robust enough, and continuous refinement of the prompt does not lead to stable performance improvements, which can result in a poor user experience. Besides, ChatGPT is highly sensitive to different prompt styles.

å±äºå¯¹LLMçš„capacity evaluationï¼Œä½œè€…ä½¿ç”¨ChatGPTè¿›è¡Œzero-shotçš„event detectionä»»åŠ¡ã€‚ä¸»è¦ç”¨çš„æ–¹æ³•æ˜¯ICLï¼Œä¸‹é¢æ˜¯ç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230521231825422.png"   style="zoom:30%;" />

æ€»ä½“æ•ˆæœå’ŒSOTAè¿˜æ˜¯æœ‰å·®è·ï¼Œä¸‹é¢æ˜¯åœ¨ACE 2005æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230521231945056.png"   style="zoom:30%;" />

ä¸è¿‡ä½œè€…åœ¨è®ºæ–‡ä¸­æåˆ°äº†ä»…ä»…æ˜¯ä½¿ç”¨äº†æµ‹è¯•é›†ä¸­çš„20ä¸ªsampleè¿›è¡Œäº†æµ‹è¯•ï¼Œè¿™ä¸ªç»“æœå¯èƒ½ä¸å¤Ÿå‡†ç¡®ã€‚

ä¸è¿‡ä¸€ä¸ªæœ‰æ„æ€çš„æ˜¯ä½œè€…æ‰¾äº†å››NLPé¢†åŸŸçš„ç ”ç©¶ç”Ÿï¼Œè®©ä»–ä»¬å»5æ¬¡æ”¹å˜promptæ¥è·å¾—æ›´å¥½çš„æ•ˆæœæœºä¼šï¼Œæµ‹è¯•æ ·ä¾‹ä¸€å…±æœ‰10ä¸ªï¼Œä¸‹é¢æ˜¯å®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230521232252014.png"   style="zoom:30%;" />

åŒæ ·ï¼Œä¸ªäººè®¤ä¸ºè¿™ä¸ªç»“æœä¹Ÿä¸å¤Ÿé²æ£’ï¼Œæ¯”è¾ƒæµ‹è¯•æ ·ä¾‹åªæœ‰10ä¸ªï¼Œé”™1ä¸ªæ ·ä¾‹å°±æ˜¯10%çš„å·®è·äº†ã€‚

## Wadhwa et al.

Revisiting Relation Extraction in the era of Large Language Models

Northeastern Universityï¼ŒarXiv 2023.05ï¼ˆä½œè€…è¯„è®ºæ˜¯æ¥æ”¶è‡³ACL 2023ï¼‰ã€‚

> Relation extraction (RE) is the core NLP task of inferring semantic relationships between entities from text. Standard supervised RE techniques entail training modules to tag tokens comprising entity spans and then predict the relationship between them. Recent work has instead treated the problem as a sequence-tosequence task, linearizing relations between entities as target strings to be generated conditioned on the input. Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision. We address issues inherent to evaluating generative approaches to RE by doing human evaluations, in lieu of relying on exact matching. Under this refined evaluation, we find that: (1) Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly equivalent to existing fully supervised models; (2) Flan-T5 is not as capable in the few-shot setting, but supervising and fine-tuning it with Chain-of-Thought (CoT) style explanations (generated via GPT3) yields SOTA results. We release this model as a new baseline for RE tasks.

ä½œè€…è¿™ç¯‡è®ºæ–‡ä¸»è¦åšäº†ä¸¤ä¸ªå·¥ä½œï¼š

1. æµ‹è¯•å¹¶è¯„ä¼°GPT-3å¯¹äºREä»»åŠ¡çš„æ€§èƒ½ã€‚ç”±äºä½œè€…å‘ç°GPT-3å¸¸å¸¸ä¼šäº§ç”Ÿå’Œè¾“å…¥è¦æ±‚ä¸ä¸€è‡´çš„å…³ç³»ï¼Œå› æ­¤ä½œè€…è¿˜é‡æ–°äººå·¥è¯„ä¼°äº†æ•ˆæœGPT-3å¯¹REä»»åŠ¡çš„æ€§èƒ½ã€‚ä½œè€…å‘ç°åœ¨CONLL04å’ŒADEæ•°æ®é›†ä¸Šå¯ä»¥è¾¾åˆ°æ¥è¿‘SOTAçš„ç»“æœã€‚
2. ä½œè€…é€šè¿‡ä½¿ç”¨GPT-3è‡ªåŠ¨ç”Ÿæˆçš„explanationsä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡å¾®è°ƒFlanT5-largeè¾¾åˆ°äº†æ–°çš„SOTAã€‚

ä½œè€…æµ‹è¯•GPT-3çš„è¾“å…¥å¦‚å›¾ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524194415967.png"    style="zoom:40%;" />

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524194429292.png"   style="zoom:40%;" />

åœ¨æµ‹è¯•çš„æ—¶å€™ä¼šéšæœºé‡‡æ ·12ä¸ªexamplesä½œä¸ºdemonstrationsã€‚ç„¶åä½œè€…å‘ç°GPT-3ä¼šäº§ç”Ÿå’Œè¾“å…¥ä¸ä¸€è‡´çš„è¾“å‡ºrelationï¼Œä½†æ˜¯è¿™äº›relationè®©äººå·¥å»è¯„ä¼°çš„è¯åˆä¼šæ„Ÿè§‰åœ¨è¯­ä¹‰ä¸Šæ˜¯ä¸€è‡´çš„ã€‚å› æ­¤ä½œè€…åˆäººå·¥é‡æ–°è¯„ä¼°äº†æ‰€æœ‰çš„è¾“å‡ºç»“æœï¼ˆé€šè¿‡åœ¨Amazon Mechanical Turkå¹³å°ä¸Šä¼—åŒ…ï¼‰ã€‚æ•°æ®é›†çš„åˆ†å¸ƒå¦‚ä¸‹æ‰€ç¤ºï¼ŒADEè¿™ä¸ªæ•°æ®é›†æ˜¯ç”¨10-foldäº¤å‰éªŒè¯æ¥è¿›è¡Œè¯„ä¼°ã€‚é™¤NYTå¤–ï¼Œå…¶å®ƒä¸¤ä¸ªæ•°æ®é›†æµ‹è¯•é‡æŒºå°çš„ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524194748501.png"   style="zoom:40%;" />

ä¸‹é¢æ˜¯ä½œè€…çš„GPT-3å®éªŒç»“æœï¼ˆè®°ä½è¿™é‡Œçš„GPT-3è¯„ä¼°ç»“æœæ˜¯ç”±äººå·¥é‡æ–°è¯„ä¼°ä¹‹åçš„ï¼‰ï¼š

![image-20230524195229694](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524195229694.png)

ä¸Šé¢çš„ç»“æœæ˜¾ç¤ºï¼ŒGPT-3åœ¨NYTæ•°æ®é›†ä¸Šè¡¨ç°æ•ˆæœä¸å¥½ï¼Œè¿™æ˜¯å› ä¸ºNYTçš„å…³ç³»ç±»å‹å¤ªå¤šï¼Œå¯¼è‡´æ— æ³•å‡†ç¡®çš„æè¿°NYTä¸­ä¸åŒå…³ç³»ç±»å‹ã€‚

ä½œè€…è¿›ä¸€æ­¥æå‡ºï¼Œå¯ä»¥ä½¿ç”¨GPT-3è‡ªåŠ¨ç”Ÿæˆçš„è§£é‡Šä½œä¸ºCoTæ¥è¿›ä¸€æ­¥å¼•å¯¼æ¨¡å‹å¾®è°ƒã€‚ä½œè€…å…ˆè®©GPT-3ç”Ÿæˆè§£é‡Šï¼Œç„¶åç”¨è¿™äº›ç”Ÿæˆçš„è§£é‡Šè¾“å…¥åˆ°Flan-T5-largeï¼ˆ760Mï¼‰ï¼Œéšåè¿›è¡Œå¾®è°ƒè¿›ä¸€æ­¥å¯ä»¥æå‡Flan-T5-largeçš„æ€§èƒ½ã€‚ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524200126966.png"   style="zoom:30%;" />

ä½œè€…åœ¨è®ºæ–‡é‡ŒæŠŠFlan-T5-largeä¹Ÿå«åšæ˜¯LLMï¼Œä¸ªäººè®¤ä¸ºä¸åˆé€‚ã€‚

## QA4RE

ä¿„äº¥ä¿„å·ç«‹å¤§å­¦ï¼ŒarXiv 2023.05ï¼Œä½œè€…è¯„è®ºæ˜¯æ¥æ”¶è‡³ACL 2023 findingsã€‚[ä»£ç ](https://github.com/OSU-NLP-Group/QA4RE)ã€‚

> Recent work has shown that fine-tuning large language models (LLMs) on large-scale instruction-following datasets substantially improves their performance on a wide range of NLP tasks, especially in the zero-shot setting. However, even advanced instructiontuned LLMs still fail to outperform small LMs on relation extraction (RE), a fundamental information extraction task. We hypothesize that instruction-tuning has been unable to elicit strong RE capabilities in LLMs due to REâ€™s low incidence in instruction-tuning datasets, making up less than 1% of all tasks (Wang et al., 2022). To address this limitation, **we propose QA4RE, a framework that aligns RE with question answering (QA), a predominant task in instruction-tuning datasets.** Comprehensive zero-shot RE experiments over four datasets with two series of instruction-tuned LLMs (six LLMs in total) demonstrate that our QA4RE framework consistently improves LLM performance, strongly verifying our hypothesis and enabling LLMs to outperform strong zero-shot baselines by a large margin. Additionally, we provide thorough experiments and discussions to show the robustness, few-shot effectiveness, and strong transferability of our QA4RE framework. This work illustrates a promising way of adapting LLMs to challenging and underrepresented tasks by aligning these tasks with more common instruction-tuning tasks like QA.

ä½œè€…è¿™ç¯‡å·¥ä½œçš„æ€æƒ³å¾ˆç®€å•ï¼Œå°±æ˜¯æŠŠrelationé€‰æ‹©è½¬åŒ–ä¸ºmulti-choice optionsé€‰æ‹©çš„QAé—®é¢˜ã€‚ç±»ä¼¼çš„åšæ³•åœ¨filter-then-reranké‡Œæœ‰å®ç°ã€‚

ä½œè€…è¿™ä¹ˆåšçš„å‡ºå‘ç‚¹æ˜¯ä¹‹å‰çš„ç ”ç©¶å‘ç°LLMå¯¹äºREçš„æ•ˆæœä¸å¥½ï¼Œä½œè€…è‡ªå·±ä½¿ç”¨GPT-3.5å’ŒFlanT5è¿›è¡Œäº†å°è¯•å‘ç°åŒæ ·æ•ˆæœä¸å¥½ã€‚ä½œè€…è®¤ä¸ºè¿™æ ·çš„åŸå› æ˜¯LLMæ¨¡å‹åœ¨è¿›è¡Œinstruction tuningè¿‡ç¨‹ä¸­ï¼Œåªæœ‰æå°‘çš„æ ·æœ¬å¯èƒ½æ¶‰åŠäº†REä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç»Ÿè®¡ç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230528105537993.png"   style="zoom:50%;" />

å› æ­¤ä½œè€…å°†REä»»åŠ¡çš„å½¢å¼å’Œåœ¨instruction tuningæ•°æ®é›†ä¸­æ›´å¸¸å‡ºç°çš„QAä»»åŠ¡å½¢å¼å¯¹é½ã€‚ä¸‹é¢æ˜¯æ–¹æ³•å›¾ï¼š

![image-20230524234509972](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524234509972.png)

ä½œè€…å®ç°çš„éƒ¨åˆ†ç»†èŠ‚ï¼š

- ä½¿ç”¨SuREæ–¹æ³•[*Summarization as indirect supervision for relation extraction*]ä¸­æå‡ºçš„relation templateæ¥æ„é€ æ¨¡æ¿

- ä½¿ç”¨text-davinci-003å’ŒFLAN-T5-XXLargeä½œä¸ºåŸºåº§LLM

- å¯¹äºprompt engineeringï¼Œä½œè€…ä½¿ç”¨text-davinci-002åœ¨TACREDçš„dev setä¸Šé€‰æ‹©250ä¸ªæ ·ä¾‹è¿›è¡Œè¯„ä¼°ã€‚ç„¶åå¯¹æ‰€æœ‰çš„æµ‹è¯•æ•°æ®é›†ä½¿ç”¨ç›¸åŒçš„promptæ ¼å¼ã€‚ä»¥å…³ç³»$org:top\_members/employees$ä¸ºä¾‹ï¼Œä½œè€…è¿›è¡Œäº†å››ç§æ¨¡æ¿çš„å°è¯•ï¼ˆè¿™å››ç§æ¨¡æ¿ä¹Ÿæ˜¯å‰äººçš„å·¥ä½œï¼‰ï¼š

  <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235128751.png"   style="zoom:35%;" />

ä½œè€…çš„zero-shot REå®éªŒç»“æœï¼š

![image-20230524235216668](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235216668.png)

ä¸ºäº†é™åˆ¶OpenAIçš„èŠ±è´¹ï¼Œä½œè€…ä»æµ‹è¯•é›†é‡‡æ ·äº†1000ä¸ªä¾‹å­è¯„ä¼°åŸºäºtext-davinci-003çš„æ•ˆæœã€‚é€šè¿‡ä½œè€…æå‡ºçš„ç®€å•promptæ”¹åŠ¨ï¼Œå°±è·å¾—äº†å¹³å‡8%å·¦å³çš„æå‡â€¦

ä¸è¿‡ä½œè€…è¿›ä¸€æ­¥åœ¨é™„å½•é‡Œæä¾›äº†å¯¹äºFlan-T5åœ¨æ•´ä¸ªæµ‹è¯•é›†ä¸‹çš„æµ‹è¯•ç»“æœï¼š

![image-20230528105952811](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230528105952811.png)

åŒæ ·èƒ½å¤Ÿçœ‹åˆ°ç®€å•çš„æ”¹åŠ¨å¸¦æ¥äº†éå¸¸æ˜æ˜¾çš„æç¤ºã€‚

ä¸‹é¢æ˜¯ä½œè€…åšçš„æ›´å¤šçš„æ¢ç©¶å®éªŒï¼Œä¸ªäººè®¤ä¸ºæœ‰ä¸€å®šå‚è€ƒä»·å€¼ã€‚

å¯¹äº4ç§promptæ ¼å¼çš„å®éªŒï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235402066.png"   style="zoom:35%;" />

å¯ä»¥çœ‹åˆ°promptçš„è®¾è®¡è¿˜æ˜¯å¾ˆå…³é”®çš„ï¼Œæ€ä¹ˆæ ·æ‰¾åˆ°åˆé€‚çš„promptå¼•èµ·äº†10%å·¦å³çš„åå·®ï¼ˆå³ä½¿åœ¨äººç±»çœ‹æ¥ä¸åŒçš„relation optionæ¨¡æ¿éƒ½æ˜¯æ­£ç¡®çš„ï¼‰ã€‚

ä½œè€…è¿˜é¢å¤–åšäº†few-shotå®éªŒï¼Œfew-shotä¸Šè¡¨ç°çš„æ•ˆæœä¸å¥½ï¼Œç‰¹åˆ«æ˜¯å—åˆ°è¾“å…¥é•¿åº¦çš„é™åˆ¶ä¸èƒ½æŒç»­çš„è¾“å…¥shotæ ·ä¾‹ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235554154.png"  style="zoom:35%;" />

å¦ä¸€ä¸ªæœ‰å‚è€ƒæ„ä¹‰çš„å®éªŒæ˜¯ä½œè€…åœ¨task instructionä¸­åŠ å…¥äº†å¯¹äºlabelçš„æè¿°ï¼Œè€Œä¿æŒoptionè¿˜æ˜¯ç¼©ç•¥çš„relationï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235720898.png"  style="zoom:35%;" />

å®éªŒç»“æœå‘ç°ä»…ä»…é€šè¿‡å¯¹labelè¿›è¡ŒæŠ½è±¡çš„è§£é‡Šï¼Œä¸èƒ½å¤Ÿå¾ˆå¥½çš„æå‡LLMçš„å›ç­”ã€‚åè€Œå¦‚æœ¬æ–‡æå‡ºçš„QA4REä¸€æ ·æŠŠä¸åŒlabelçš„è¾“å‡ºç›´æ¥è½¬åŒ–ä¸ºå…·ä½“çš„å¥å­ï¼ŒLLMæ›´å®¹æ˜“ç†è§£ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235816398.png"  style="zoom:35%;" />

ä½œè€…è¿˜æ¯”è¾ƒäº†åŸºäºLLMçš„æ–¹æ³•éšç€model sizeå˜åŒ–çš„æ€§èƒ½å˜åŒ–ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230524235859346.png"   style="zoom:35%;" />

å¯ä»¥çœ‹åˆ°éšç€æ¨¡å‹sizeçš„å¢å¤§ï¼Œæ•ˆæœè¶Šæ¥è¶Šå¥½ã€‚ä½†æ˜¯æå‡çš„å¹…åº¦å’Œsizeå¤§å°å¹¶ä¸æ˜¯æˆæ¯”ä¾‹çš„

ï¼ˆæ•´ç¯‡è®ºæ–‡æ–¹æ³•éƒ¨åˆ†åªè®¨è®ºäº†1é¡µå·¦å³ï¼Œå®éªŒéƒ¨åˆ†è®¨è®ºäº†4é¡µå¤šï¼‰

## GPT-RE

GPT-RE: In-context Learning for Relation Extraction using Large Language Models

äº¬éƒ½å¤§å­¦ï¼ŒarXiv 2023.05ã€‚

> In spite of the potential for ground-breaking achievements offered by large language models (LLMs) (e.g., GPT-3), they still lag significantly behind fully-supervised baselines (e.g., fine-tuned BERT) in relation extraction (RE). This is due to the two major shortcomings of LLMs in RE: (1) **low relevance regarding entity and relation in retrieved demonstrations for in-context learning;** and (2) **the strong inclination to wrongly classify NULL examples into other pre-defined labels**.
>
> In this paper, we propose GPT-RE to bridge the gap between LLMs and fully-supervised baselines. GPT-RE successfully addresses the aforementioned issues by (1) incorporating task-specific entity representations in demonstration retrieval; and (2) enriching the demonstrations with gold label-induced reasoning logic. We evaluate GPT-RE on four widelyused RE datasets, and observe that GPT-RE achieves improvements over not only existing GPT-3 baselines, but also fully-supervised baselines. Specifically, GPT-RE achieves SOTA performances on the Semeval and SciERC datasets, and competitive performances on the TACRED and ACE05 datasets.

ä½œè€…è¿™ç¯‡å·¥ä½œæ˜¯å¯¹äº[*Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again*]å·¥ä½œçš„æ”¹è¿›ï¼Œä¸»è¦æ˜¯é’ˆå¯¹å…¶ä¸¤ä¸ªé—®é¢˜è¿›è¡Œæ”¹è¿›ï¼š

- åœ¨ICLä¸­çš„demonstrationsçš„é€‰æ‹©åªæ˜¯ä»sentence-levelè¿›è¡Œæ¯”è¾ƒï¼Œå¿½ç•¥äº†å®ä½“å’Œå…³ç³»çš„è¯­ä¹‰
- LLMå¾ˆéš¾å‡†ç¡®åœ°åˆ†ç±»NULLå…³ç³»

ä¸‹é¢æ˜¯ç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527155614789.png"   style="zoom:35%;" />

ä½œè€…æäº†ä¸¤ç‚¹æ”¹è¿›ï¼š

- é€šè¿‡ä¿®æ”¹promptæ ¼å¼ï¼Œè®©promptæ›´åŠ å¼ºè°ƒå¥å­ä¸­çš„å®ä½“ä¿¡æ¯ï¼›æˆ–è€…ç›´æ¥ä½¿ç”¨ä¸€ä¸ªåœ¨REä»»åŠ¡ä¸Šfine-tunedå¥½çš„BERTæ¨¡å‹æ¥è·å–å¤´å°¾å®ä½“çš„embeddingï¼›ä¹‹åå†è¿›è¡ŒåŸºäºkNNçš„demonstrationsæ£€ç´¢
- åŠ å…¥äº†CoTï¼Œä¹Ÿå°±æ˜¯è®©GPTè‡ªå·±ç”Ÿæˆä¸€ä¸ªè§£é‡Šï¼ŒåŠ å…¥åˆ°ICLçš„demonstrationsä¸­ã€‚

æ–¹æ³•å›¾ï¼š

![image-20230527160412848](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527160412848.png)

demonstrationsæ£€ç´¢æ–¹æ³•çš„æ”¹è¿›ï¼š

- æ–¹æ¡ˆ1ï¼šä¿®æ”¹contextæ ¼å¼ï¼Œä¾‹å¦‚â€™He has a sister Lisaâ€˜ä¿®æ”¹ä¸ºâ€™The relation between â€˜Heâ€™ and â€˜Lisaâ€™ in the context: He has a sister Lisa.â€˜
- æ–¹æ¡ˆ2ï¼šæ›´åŠ ç›´æ¥ï¼Œä½¿ç”¨fine-tunedå¤´å°¾å®ä½“è¡¨å¾æ¥è¿›è¡ŒkNNæ£€ç´¢ã€‚ä½œè€…è‡ªå·±å¾®è°ƒäº†ä¸€ä¸ªé’ˆå¯¹REä»»åŠ¡çš„BERTæ¥è·å–å¤´å°¾å®ä½“è¡¨å¾ã€‚ï¼ˆä¸€ä¸ªç®€å•ç²—æš´ï¼Œæ³›åŒ–æ€§å¼±çš„æ–¹æ³•ï¼Œä½†æ˜¯æ•ˆæœæœ€å¥½ï¼‰

CoTä¸­çš„explanationsæ˜¯ä½¿ç”¨GPTè‡ªåŠ¨ç”Ÿæˆçš„ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230528111844081.png"   style="zoom:40%;" />

ä½œè€…ä½¿ç”¨SimCSEæ–¹æ³•æ¥è¡¡é‡ç›¸ä¼¼åº¦ã€‚ä¸‹é¢æ˜¯å®éªŒç”¨çš„æ•°æ®é›†å’Œå®éªŒç»“æœï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527214328082.png"   style="zoom:40%;" />

![image-20230527214353436](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527214353436.png)

å®éªŒç»“æœä¸­ï¼ˆåŸºäºtext-davinci-003ï¼‰ï¼Œ

- Randomï¼šéšæœºæ‰¾few-shotçš„demonstrations
- Sentï¼šä½¿ç”¨SimCSE
- RE_SimCSE: æ–¹æ¡ˆ1
- RE_FTï¼šæ–¹æ¡ˆ2

å¯ä»¥è§‚å¯Ÿå¾—åˆ°ç»“è®ºï¼š

- è™½ç„¶æ€»ä½“è¡¨ç°å‡ºäº†ä¸é”™çš„æ•ˆæœï¼Œä½†æ˜¯å¯ä»¥çœ‹åˆ°éœ€è¦æ ·ä¾‹æ•°æ¯”è¾ƒå¤§ï¼ˆæœ€å°‘ä¹Ÿåœ¨15ä¸ªæ ·ä¾‹ä»¥ä¸Šï¼‰æ‰èƒ½è¾¾åˆ°SOTAï¼Œè€Œä¸”è°ƒç”¨GPTçš„ä»£ä»·æ¯”è¾ƒå¤§ï¼ˆèŠ±é’±ï¼Œä»¥è‡³äºä½œè€…åœ¨TACREDå’ŒACE05è¿™ä¸¤ä¸ªæ¯”è¾ƒå¤§testæ•°æ®é›†ä¸‹åªé€‰æ‹©äº†10%çš„æ ·ä¾‹ï¼‰ã€‚
- å®Œå…¨æ— è®­ç»ƒæ— æ¢¯åº¦æ›´æ–°çš„æ–¹æ¡ˆä¸€ï¼Œä»ç„¶æ²¡æœ‰è¾¾åˆ°SOTAã€‚åªæœ‰ä½¿ç”¨è®­ç»ƒåçš„è¡¨å¾æ¥æ£€ç´¢ï¼Œæ‰èƒ½è¾¾åˆ°SOTAï¼Œå¹¶ä¸”æå‡å¹…åº¦å¾ˆå¤§ã€‚
- æ²¡æœ‰æ¯”è¾ƒæ¨ç†é€Ÿåº¦ï¼Œä¸ªäººè®¤ä¸ºæ¨ç†é€Ÿåº¦ä¸ä¼šå¿«ï¼ˆæ£€ç´¢+å¤§æ¨¡å‹ï¼‰
- åŠ å…¥CoTçš„æ•ˆæœæå‡å¹…åº¦ä¸æ˜¯ç‰¹åˆ«å¤§ï¼Œå¹¶ä¸”è¦æ±‚äº†é¢å¤–çš„GPTè¯·æ±‚ï¼Œæ›´åŠ èŠ±é’±ï¼ˆä½œè€…åœ¨å®éªŒéƒ¨åˆ†å¯¹CoTçš„å¯¹æ¯”ä»…ä»…é€šè¿‡15ä¸ªæ ·ä¾‹ï¼Œè€Œä¸æ˜¯æœ€å¥½çš„æ ·ä¾‹æ•°é‡ï¼Œè¿™æ˜¯å› ä¸ºè¾“å…¥é•¿åº¦çš„é™åˆ¶ï¼‰

ä¸‹é¢æ˜¯ä½œè€…å¯¹äºéšç€shotæ•°é‡å˜åŒ–ï¼Œæ¨¡å‹æ€§èƒ½çš„å˜åŒ–ï¼Œå¯ä»¥çœ‹åˆ°æå‡è¿˜æ˜¯å¾ˆå¤§çš„ï¼ˆæœ€å¤šæœ‰åå‡ ä¸ªç‚¹çš„æå‡ï¼‰ã€‚åŒæ—¶ä»æ¶ˆèæ‰CoTï¼ˆå³reasoningï¼‰çš„æ•ˆæœæ¥çœ‹ï¼ŒåŠ å…¥CoTï¼ˆè§£é‡Šï¼‰çš„æƒ…å†µä¸‹ï¼Œå¯¹äºæ›´å°‘demonstrationsçš„æƒ…å†µæå‡æ›´æ˜æ˜¾ï¼ˆå›¾ä¸­shot=30çš„æ—¶å€™æ²¡æœ‰å¯¹åº”çš„æ¶ˆèå®éªŒï¼Œç”±äºè¾“å…¥é•¿åº¦é™åˆ¶ï¼‰ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230527231519715.png"  style="zoom:35%;" />

## AutoKG

LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities

arXiv 2023.05ï¼Œæµ™å¤§ZJUNLPï¼Œ[ä»£ç ](https://github .com/zjunlp/AutoKG)ã€‚

> This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We employ eight distinct datasets that encompass aspects including entity, relation and event extraction, link prediction, and question answering. Empirically, our ï¬ndings suggest that GPT-4 outperforms ChatGPT in the majority of tasks and even surpasses ï¬ne-tuned models in certain reasoning and question-answering datasets. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, which culminates in the presentation of the Virtual Knowledge Extraction task and the development of the VINE dataset. Drawing on these empirical ï¬ndings, we further propose AutoKG, a multiagent-based approach employing LLMs for KG construction and reasoning, which aims to chart the future of this ï¬eld and offer exciting opportunities for advancement. We anticipate that our research can provide invaluable 1 insights for future undertakings of KG.

è°ƒç ”æ—¶çœ‹åˆ°çš„é¦–ä¸ªä½¿ç”¨GPT-4è¿›è¡ŒçŸ¥è¯†å›¾è°±ç›¸å…³ä»»åŠ¡çš„paperï¼Œå¯æƒœå—é™äºGPT-4çš„è®¿é—®ä»£ä»·ï¼Œä½œè€…ä»…ä»…æ˜¯å¯¹æ¯ä¸ªä»»åŠ¡éƒ½è¿›è¡Œäº†20ä¸ªå·¦å³çš„æµ‹è¯•æ ·ä¾‹çš„è¯„ä¼°ã€‚å‘ç°GPT-4å¯¹äºIEä»»åŠ¡æ•ˆæœæ¯”ChatGPTè¦å¥½ï¼Œä½†æ˜¯ä»ç„¶å’ŒSOTAæœ‰å·®è·ï¼ŒåŒæ—¶GPT-4æ›´åŠ æ“…é•¿KG reasoningï¼ˆlinking predictionï¼‰å’ŒQAä»»åŠ¡ã€‚

ç„¶åä½œè€…è‡ªå·±ä»RE-TACREDæ•°æ®é›†ä¸­é€‰æ‹©å¥å­ï¼Œä½¿ç”¨éšæœºåˆ›å»ºçš„æ–°è¯æ›¿æ¢å…¶ä¸­çš„å®ä½“å’Œå…³ç³»ï¼Œæ„é€ äº†ä¸€ä¸ªGPT-4åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰è§è¿‡çš„è™šå‡æ•°æ®é›†VINEï¼Œå‘ç°GPT-4ç¡®å®æ˜¯èƒ½å¤Ÿå¿«é€Ÿç†è§£instructionå»è¿›è¡Œä¿¡æ¯æŠ½å–ã€‚æœ€åæ˜¯ä½œè€…å€ŸåŠ©CAMELæ–¹æ³•ä¸­æå‡ºçš„role-playingæ–¹æ³•ï¼Œæå‡ºäº†ä¸€ä¸ªAutoKGçš„æ¦‚å¿µã€‚

![image-20230529000001137](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230529000001137.png)

## structured prompting

Prompting Language Models for Linguistic Structure

ACL 2023ï¼Œåç››é¡¿å¤§å­¦

> Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns. To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases. We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pre-training corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.

ä½œè€…æå‡ºäº†ä¸€ç§ç®€å•çš„åºåˆ—æ ‡æ³¨promptæ–¹æ³•ï¼Œå°±æ˜¯åœ¨è¾“å‡ºçš„æ¯ä¸ªword tokenä¹‹ååŠ å…¥è¦æ ‡æ³¨çš„labelã€‚ä½œè€…æåˆ°äº†ï¼Œåœ¨è¾“å‡ºçš„æ—¶å€™ä¸æ˜¯ç›´æ¥è¾“å‡ºæ‰€æœ‰çš„tagåºåˆ—ï¼Œè€Œæ˜¯åŒæ—¶è¦è¾“å‡ºåŸæœ‰çš„word+tagã€‚å¦‚æœä¸é‡å¤è¾“å‡ºwordçš„è¯ï¼Œæ•ˆæœç”šè‡³ä¼šä¸‹é™70%-80%ã€‚

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531113232237.png"   style="zoom:40%;" />

åŸºäºGPT-NeoXã€GPT-Curieã€GPT-Davinciè¿›è¡Œäº†å®éªŒã€‚

æœ‰ä¸€ç‚¹å®éªŒå¯å‘çš„æ˜¯ï¼Œä½œè€…å‘ç°åœ¨NERä»»åŠ¡ä¸‹ï¼ŒLLMä¹Ÿå¸¸å¸¸ä¼šé”™è¯¯çš„åˆ†ç±»`O` labelï¼Œå’Œå…¶å®ƒçš„ç ”ç©¶å‘ç°REä»»åŠ¡å¸¸å¸¸é”™è¯¯åˆ†ç±»`None`ä¸€æ ·ã€‚è¿™è¯´æ˜äº†è¿™äº›æ¯”è¾ƒæ¨¡ç³Šã€æˆ–è€…å†…éƒ¨è¯­ä¹‰åˆ†å¸ƒæ¯”è¾ƒå¤šæ ·çš„labelï¼Œè®©LLMç›´æ¥å»åšå¾ˆå¯èƒ½å‡†ç¡®åº¦ä¸é«˜ï¼š

<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531153548171.png"   style="zoom:40%;" />

ä½œè€…è¿˜åŸºäºGPT-Neoçš„é¢„è®­ç»ƒæ•°æ®Pileä¸­ï¼Œå»æŸ¥æ‰¾æœ‰æ²¡æœ‰labelæ•°æ®ï¼Œç»“æœå‘ç°æ˜¯æœ‰çš„ï¼š

![image-20230531153914033](https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531153914033.png)
