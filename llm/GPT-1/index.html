<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0">

<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/lxy-apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/lxy-favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/lxy-favicon-16x16.png">
  <link rel="mask-icon" href="/images/lxy-favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liuxiyang641.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"width":300},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":true,"preload":false}}</script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/config.min.js"></script>

    <meta name="description" content="Improving Language Understanding by Generative Pre-Training 2018-06年，OpenAI，GPT-1  Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering">
<meta property="og:type" content="blog">
<meta property="og:title" content="GPT-1">
<meta property="og:url" content="https://liuxiyang641.github.io/llm/GPT-1/index.html">
<meta property="og:site_name" content="Liu Xiyang">
<meta property="og:description" content="Improving Language Understanding by Generative Pre-Training 2018-06年，OpenAI，GPT-1  Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220513101404397.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154323724.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154617674.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154934018.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510155720266.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510155835380.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160042465.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160500198.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160616495.png">
<meta property="article:published_time" content="2022-05-10T07:25:23.000Z">
<meta property="article:modified_time" content="2022-05-13T02:54:46.797Z">
<meta property="article:author" content="Liu Xiyang">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220513101404397.png">


<link rel="canonical" href="https://liuxiyang641.github.io/llm/GPT-1/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://liuxiyang641.github.io/llm/GPT-1/","path":"llm/GPT-1/","title":"GPT-1"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>GPT-1 | Liu Xiyang</title>
  




<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Liu Xiyang</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">50</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">72</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">157</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#improving-language-understanding-by-generative-pre-training"><span class="nav-number">1.</span> <span class="nav-text">Improving Language Understanding by Generative Pre-Training</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction"><span class="nav-number">1.1.</span> <span class="nav-text">1 Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#framework"><span class="nav-number">1.2.</span> <span class="nav-text">2 Framework</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#unsupervised-pre-training"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 Unsupervised pre-training</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#supervised-%EF%AC%81ne-tuning"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 Supervised ﬁne-tuning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#experiments"><span class="nav-number">1.3.</span> <span class="nav-text">3 Experiments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conclusion"><span class="nav-number">1.4.</span> <span class="nav-text">Conclusion</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Liu Xiyang"
      src="/images/lxy-avatar.jpg">
  <p class="site-author-name" itemprop="name">Liu Xiyang</p>
  <div class="site-description" itemprop="description">Try your best to be an ordinary man.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">157</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/liuxiyang641" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;liuxiyang641" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liuxiyang@buaa.edu.cn" title="E-Mail → mailto:liuxiyang@buaa.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liuxiyang641.github.io/llm/GPT-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lxy-avatar.jpg">
      <meta itemprop="name" content="Liu Xiyang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liu Xiyang">
      <meta itemprop="description" content="Try your best to be an ordinary man.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="GPT-1 | Liu Xiyang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          GPT-1<a href="https://github.com/liuxiyang641/liuxiyang641.github.io/edit/hexo/source/_posts/llm/GPT-1.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pen-nib"></i></a>
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-10 15:25:23" itemprop="dateCreated datePublished" datetime="2022-05-10T15:25:23+08:00">2022-05-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-05-13 10:54:46" itemprop="dateModified" datetime="2022-05-13T10:54:46+08:00">2022-05-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/Pretrain/" itemprop="url" rel="index"><span itemprop="name">Pretrain</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="improving-language-understanding-by-generative-pre-training">Improving Language Understanding by Generative Pre-Training</h1>
<p>2018-06年，OpenAI，GPT-1</p>
<blockquote>
<p>Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. <strong>We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task.</strong> In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).</p>
</blockquote>
<span id="more"></span>
<p>参考：</p>
<ul>
<li>原论文《<em>Improving Language Understanding by Generative Pre-Training</em>》</li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1AF411b7xQ/?spm_id_from=333.788">沐神的GPT讲解视频</a></li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220513101404397.png" style="zoom:25%;" /></p>
<p>GPT把Transformer的解码器拿出来在大规模数据集上进行预训练；BERT把transformer的编码器拿过来。BERT-base维度和结构层数和GPT-1是一样的，并且也使用了BooksCorpus数据集进行预训练。</p>
<h2 id="introduction">1 Introduction</h2>
<p>作者希望解决什么问题？</p>
<p>深度学习的模型往往需要足够的标注数据进行训练，但是这往往代表着高昂的人工代价和成本。同时在很多领域没有这么多的标注数据。但是直接利用无标签数据进行信息捕获的方法，是一直以来期望能够实现的方向。即便是有足够标注数据的领域，如果引入通过无监督方式学习到的表示，也可能进一步提升模型效果，比如使用预训练好的word embedding来提升NLP任务结果。</p>
<p>但是目前在如何利用无标签数据这个方向上的方法存在两个问题：</p>
<ol type="1">
<li>从无标签文本当中学习什么样的优化目标是最适合之后进行task transfer的，没有明确的答案。</li>
<li>对如何把学习到的表示转化到特定的任务，没有统一的方法/共识，很多方法往往会针对特定任务进一步改造模型架构，引入更多的参数。</li>
</ol>
<p>作者是用什么方法/思路解决上面的问题的？</p>
<p><strong>思路</strong>：半监督预训练+有监督的任务相关的微调，unsupervised pre-training+supervised ﬁne-tuning</p>
<blockquote>
<p>In this paper, we explore a semi-supervised approach for language understanding tasks using a combination of unsupervised pre-training and supervised ﬁne-tuning.</p>
</blockquote>
<p>最终期望能够在大规模语料上训练好，对于不同的任务（甚至是和语料表示的领域不相关的任务）只需要很小的改动即可。</p>
<blockquote>
<p>Our goal is to learn a universal representation that transfers with little adaptation to a wide range of tasks.</p>
</blockquote>
<p><strong>设计</strong>：预训练（Transformer decoder）+微调（把输入采用traversal-style approaches，变为序列化token的输入，输出在Transformer后加一个线性层和softmax）</p>
<p>使用transformer作为总体的架构，因为它更能够处理长期依赖（想想它是所有token都一起经过attention的），因此在不同的task之间，提供了较好的鲁棒性（设想下不同的task需要的信息是不同的，可能存在于语料的不同地方，那么当然需要预训练的模型尽量把所有的信息都能够记住）。</p>
<p><em>有研究者认为预训练实际上是一个regularization scheme，因此能够让深度学习有更好的泛化性</em>，这里如有兴趣，可以参考paper《Why does unsupervised pre-training help deep learning?》</p>
<h2 id="framework">2 Framework</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154323724.png" style="zoom:50%;" /></p>
<p>从上图可以看到，GPT会把各个子任务变为序列的形式，在开始加入一个<span class="math inline">\(Start\)</span>词元，在最后加入一个抽取<span class="math inline">\(Extract\)</span>词元。整个序列输入transformer解码器，然后使用抽取词元的表示经过线性层，作为具体的预测目标。</p>
<ul>
<li>Entailment：指在premise中是不是支持hypothesis，三分类问题</li>
<li>Similarity：两段文本是不是相似，构造两个序列</li>
<li>Multiple Choice：n个答案，构造n个序列输入</li>
</ul>
<h3 id="unsupervised-pre-training">2.1 Unsupervised pre-training</h3>
<p>优化目标，标准的语言模型优化目标，已知前<span class="math inline">\(k\)</span>个token，尝试预测当前token <span class="math inline">\(i\)</span>，<span class="math inline">\(k\)</span>就是窗口大小：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154617674.png" style="zoom:50%;" /></p>
<p>已知前面几个token的情况下，预测第i个token出现的概率；这点和BERT中的不太一样；BERT的预训练是采用了带掩码的语言模型，会mask掉任意的word然后进行了预测，做完形填空，这样来看BERT的预训练的语义方向是双向的。</p>
<p>优化目标<span class="math inline">\(L_1\)</span>是整个语料<span class="math inline">\(U\)</span>各个token出现的概率，一般情况下概率之间应该是相乘的，这里使用<span class="math inline">\(log\)</span>之后，就变成了多个概率相加。相加的操作比相乘更容易并行，计算也更简单。<span class="math inline">\(k\)</span>越大的话，整个模型会月倾向于使用更长的文本中寻找信息。</p>
<p>输入是context token（不太清楚具体指什么vector，难道就是简单的token编码，比如one-hot？）。</p>
<p>使用的模型是transformer的解码器，因为transformer的编码器是可以看到整个文本的，而解码器是只会看到前面的词，因此在GPT里还是使用了transformer的解码器。结构是12层+768 dimensional states+12 attention heads，输出是预测是哪个token的概率：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154934018.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(W_e\)</span>是指token embedding组成的矩阵。</p>
<h3 id="supervised-ﬁne-tuning">2.2 Supervised ﬁne-tuning</h3>
<p>输入是token，对于某些任务，比如问题-回答等，需要把原来结构化的输入变为与序列化的输入。</p>
<p>对于输入<span class="math inline">\(&lt;x^1,\cdots,x^m&gt;\)</span>，放入transformer里，获得最后一层的位置<span class="math inline">\(m\)</span>输出的表示。</p>
<p>参数就是前一步train好的Transformer，后面再加一线性层，最后经过softmax获得预测的标签<span class="math inline">\(y\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510155720266.png"  style="zoom:50%;" /></p>
<p>优化的目标函数：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510155835380.png"  style="zoom:50%;" /></p>
<p>作者同样是有了辅助目标函数来增加有监督模型泛化性（让有监督模型不仅仅是只看重一个优化目标），加速收敛（不仅仅依赖于微调对于pre-train model的updating）。但是作者在后面的实验部分发现，辅助函数主要是对规模比较大的有监督的数据集效果比较好，而对于规模比较小的数据集效果不如移除辅助目标函数。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160042465.png" style="zoom:50%;" /></p>
<p>在优化task相关的目标loss的同时，也进一步优化之前pretrain的目标loss。</p>
<h2 id="experiments">3 Experiments</h2>
<p>在BooksCorpus数据集上进行了预训练，7000篇没有被发表的书。</p>
<p>作者用到了大量的训练上的trick，这里不提。有一部分是我不了解的，也没有使用过。</p>
<p>总的来说，在4个任务atural language inference，question answering，semantic similarity， text classiﬁcation，一共12个数据集上的9个数据集取得了最好的结果。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160500198.png" style="zoom:50%;" /></p>
<p>具体的结果也不粘贴了，参考论文。</p>
<p>主要看一下消融实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160616495.png" style="zoom:50%;" /></p>
<p>证明了：</p>
<ul>
<li>加入辅助目标函数，帮助模型在规模更大的数据集上取得了更好的效果</li>
<li>使用Transformer而不是LSTM，帮助模型取得了更好的效果（除了在MRPC数据集上）</li>
<li>如果不使用预训练，在所有数据集下都出现了严重的效果下降</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p><strong>Our work suggests that achieving signiﬁcant performance gains is indeed possible, and offers hints as to what models (Transformers) and data sets (text with long range dependencies) work best with this approach.</strong> We hope that this will help enable new research into unsupervised learning, for both natural language understanding and other domains, further improving our understanding of how and when unsupervised learning works</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Liu Xiyang
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://liuxiyang641.github.io/llm/GPT-1/" title="GPT-1">https://liuxiyang641.github.io/llm/GPT-1/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/ml/NN-extrapolate/" rel="prev" title="NN-extrapolate">
                  <i class="fa fa-chevron-left"></i> NN-extrapolate
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/llm/GPT-2/" rel="next" title="GPT-2">
                  GPT-2 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-flag"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liu Xiyang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">900k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">13:38</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="//cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/comments.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/motion.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/next-boot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/pjax.min.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.8/pdfobject.min.js","integrity":"sha256-tu9j5pBilBQrWSDePOOajCUdz6hWsid/lBNzK4KgEPM="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/tags/pdf.min.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/fancybox.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"//cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"}}</script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/math/mathjax.min.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"liuxiyang641","repo":"liuxiyang_blog_comment","client_id":"b800b344e096846a4608","client_secret":"45ac194feea7e642c29f8e13180184cc98afb3e6","admin_user":"liuxiyang641","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"668f396056b6f35549e120421308e564"}</script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/comments/gitalk.min.js"></script>
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>
