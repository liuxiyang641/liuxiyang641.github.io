<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>10-graph</title>
    <url>/algorithm-note/10-graph/</url>
    <content><![CDATA[<h1 id="第10章-图算法专题">第10章 图算法专题</h1>
<p>《算法笔记》第10章。</p>
<span id="more"></span>
<h2 id="图的基本定义">图的基本定义</h2>
<p>顶点（vertex）、边（edge）、出度、入度等不再赘述。</p>
<h2 id="图的存储">图的存储</h2>
<p>这里从传统算法的角度讨论图的存储，两个基本办法：邻接矩阵和邻接表</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 邻接矩阵</span></span><br><span class="line"><span class="keyword">int</span> maxv = <span class="number">1000</span>;</span><br><span class="line"><span class="keyword">int</span> G[maxv][maxv]; <span class="comment">// 可使用1表示连通，适用于顶点数量较少，一般少于1000顶点的情况</span></span><br><span class="line"><span class="comment">// 邻接表</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; G[n]; <span class="comment">// n是顶点数量，每个数组元素是一个vector</span></span><br><span class="line"><span class="comment">// 如果要储存边权</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> v, dis;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">vector</span>&lt;Node&gt; G[n];</span><br></pre></td></tr></table></figure>
<h2 id="图的遍历">图的遍历</h2>
<p>和前面在tree中讨论了很多次的一样，图的遍历同样是DFS和BFS，最大的区别在于</p>
<ul>
<li>图不一定是连通的，可能存在多个连通分量，因此需要从每个顶点出发尝试遍历，并且不断记录已经访问过的顶点</li>
<li>遍历了所有顶点，不代表已经遍历了所有边。这一点需要特别注意</li>
</ul>
<p>下面写出BFS和DFS的代码，以邻接表为例</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DFS遍历grpah</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DFS</span><span class="params">(<span class="keyword">int</span> u, <span class="keyword">int</span> &amp;stat_res)</span> </span>&#123;</span><br><span class="line">  vis[u] = ture; <span class="comment">// 记当前顶点已访问</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;G[u].size(); ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span>(vis[G[u][i]]==<span class="literal">false</span>) &#123;</span><br><span class="line">      <span class="comment">// 如果新的下一级顶点还未访问，则DFS</span></span><br><span class="line">      DFS(G[u][i], stat_res);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DFSGraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> u = <span class="number">0</span>; u&lt;n; ++u) &#123;</span><br><span class="line">    <span class="keyword">if</span>(vis[u]==<span class="literal">false</span>) &#123;</span><br><span class="line">      <span class="keyword">int</span> stat_res = <span class="number">0</span>; <span class="comment">// 某些可能的统计数据</span></span><br><span class="line">      DFS(u, stat_res);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// BFS遍历graph</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BFS</span><span class="params">(<span class="keyword">int</span> u)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">  vis[u] = ture;</span><br><span class="line">  q.push(q);</span><br><span class="line">  <span class="keyword">while</span>(!q.empty()) &#123;</span><br><span class="line">    <span class="keyword">int</span> u = q.top();</span><br><span class="line">    q.pop();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;G[u].size();++i) &#123;</span><br><span class="line">      <span class="keyword">if</span>(vis[G[u][i]]==<span class="literal">false</span>)</span><br><span class="line">      	q.push(G[u][i]);</span><br><span class="line">      	vis[G[u][i]] = ture;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BFSGraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> u = <span class="number">0</span>; u&lt;n; ++u) &#123;</span><br><span class="line">    <span class="keyword">if</span>(vis[u]==<span class="literal">false</span>) &#123;</span><br><span class="line">      BFS(u);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最短路径">最短路径</h2>
<h3 id="dijkstra算法">Dijkstra算法</h3>
<p>求最短路径的经典算法，该算法能够从某个起点出发，寻找到其它所有顶点的最短路径。</p>
<p>基本思想：从还没有到达的剩余顶点中，选择一个最短距离的顶点，访问它；然后检查如果从这个新访问的顶点出发，看能否让剩余未到达的顶点的最短距离变小，如果可以就更新剩余顶点的最短距离；持续执行上一步，知道所有顶点都访问完毕。</p>
<p>实现时候的几个核心思路：</p>
<ul>
<li>一个检查是否已经访问过的数组<code>bool vis[maxv]</code>，初始化时<code>false</code></li>
<li>一个存储到不同顶点最短路径的数据<code>int d[maxv]</code>，初始化为<code>INF</code>，一个巨大的数字，可以是<code>e9</code>；结合<code>vis[maxv]</code>和<code>d[maxv]</code>就可以选出所有未到达顶点中具有最短路径的那个顶点</li>
</ul>
<p>邻接矩阵版本的dijkstra算法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> INF = <span class="number">1000000000</span>;</span><br><span class="line"><span class="comment">// s是开始的起点编号</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Disjkstra</span><span class="params">(<span class="keyword">int</span> s)</span> </span>&#123;</span><br><span class="line">  fill(d, d+n, INF);</span><br><span class="line">  fill(vis, vis+n, <span class="literal">false</span>);</span><br><span class="line">  d[s] = <span class="number">0</span>; <span class="comment">// 开始顶点距离为0</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;n; ++i) &#123; <span class="comment">// 开始访问n个顶点</span></span><br><span class="line">    <span class="keyword">int</span> u = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> MIN = INF;</span><br><span class="line">    <span class="comment">// 寻找还未访问的顶点中有最短路径的顶点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">      <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; d[v]&lt;MIN) &#123;</span><br><span class="line">        u = v;</span><br><span class="line">        MIN = d[v];</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(u==<span class="number">-1</span>) <span class="keyword">return</span>; <span class="comment">// 已经没有可以访问的顶点了，返回</span></span><br><span class="line">    vis[u] = ture; <span class="comment">// 访问节点u</span></span><br><span class="line">    <span class="comment">// 开始检查从u出发，能否让还未访问的顶点最短路径减小</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">      <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; G[u][v]!=<span class="number">-1</span> &amp;&amp; d[v]&gt;d[u] + G[u][v]) &#123;</span><br><span class="line">        d[v] = d[u] + G[u][v]; <span class="comment">// 更新最短路径</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的函数执行完毕后，<code>d[maxv]</code>中将保存所有最短路径距离。</p>
<p>接下来讨论，如何输出最短路径？</p>
<p>解决方法是记录每个顶点最短路径的前驱结点即可，开始结点的最短路径是自身</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> pre[maxv]; <span class="comment">// 记录前驱</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Disjkstra</span><span class="params">(<span class="keyword">int</span> s)</span> </span>&#123;</span><br><span class="line">  fill(d, d+n, INF);</span><br><span class="line">  fill(vis, vis+n, <span class="literal">false</span>);</span><br><span class="line">  d[s] = <span class="number">0</span>; <span class="comment">// 开始顶点距离为0</span></span><br><span class="line">  pre[s] = s; <span class="comment">// 开始结点的前驱是自身</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;n; ++i) &#123; <span class="comment">// 开始访问n个顶点</span></span><br><span class="line">    <span class="keyword">int</span> u = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> MIN = INF;</span><br><span class="line">    <span class="comment">// 寻找还未访问的顶点中有最短路径的顶点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">      <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; d[v]&lt;MIN) &#123;</span><br><span class="line">        u = v;</span><br><span class="line">        MIN = d[v];</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(u==<span class="number">-1</span>) <span class="keyword">return</span>; <span class="comment">// 已经没有可以访问的顶点了，返回</span></span><br><span class="line">    vis[u] = ture; <span class="comment">// 访问节点u</span></span><br><span class="line">    <span class="comment">// 开始检查从u出发，能否让还未访问的顶点最短路径减小</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">      <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; G[u][v]!=<span class="number">-1</span> &amp;&amp; d[v]&gt;d[u] + G[u][v]) &#123;</span><br><span class="line">        d[v] = d[u] + G[u][v]; <span class="comment">// 更新最短路径</span></span><br><span class="line">        pre[v] = u; <span class="comment">// 更新前驱</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后通过递归就可以输出最短路径</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DFSPath</span><span class="params">(<span class="keyword">int</span> s, <span class="keyword">int</span> u)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(s==u) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, s);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  DFSPath(s, pre[u]);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, u);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当然在做题的时候，不会只有这么简单的要求，通常会有更多的要求，比如要求选择在最短路径中花费最少的一条，要求输出最短路径的数量等等。</p>
<p>下面是三种常见的应对策略：</p>
<ul>
<li>给每条边新增边权，然后要求在多个最短路径中选择新增边权最好的情况</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 新增的边权就类似于graph进行存储，同时用另一个新数组记录第二边权访问各个顶点时的情况</span></span><br><span class="line"><span class="comment">// 下面是核心代码</span></span><br><span class="line"><span class="comment">// 开始检查从u出发，能否让还未访问的顶点最短路径减小</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">  <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; G[u][v]!=<span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (d[v]&gt;d[u] + G[u][v]) &#123;</span><br><span class="line">      d[v] = d[u] + G[u][v]; <span class="comment">// 更新最短路径</span></span><br><span class="line">      pre[v] = u;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (d[v] == d[u] + G[u]) &#123;</span><br><span class="line">      <span class="comment">// 第二边权的更新，在最短路径不变的情况下选择最好的第二边权</span></span><br><span class="line">      <span class="comment">// 这里的cost代表路径的花费</span></span><br><span class="line">      <span class="keyword">if</span>(c[v] &gt; cost[u][v] + c[u]) &#123;</span><br><span class="line">				c[v] = cost[u][v] + c[u];</span><br><span class="line">        pre[v] = u;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>每个点新增了点权，要求在最短路径中，寻找点权最优的情况，类似于上面的方法</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">  <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; G[u][v]!=<span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (d[v] &gt; d[u] + G[u][v]) &#123;</span><br><span class="line">      d[v] = d[u] + G[u][v]; <span class="comment">// 更新最短路径</span></span><br><span class="line">      pre[v] = u;</span><br><span class="line">      w[v] = w[u] + weight[v];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (d[v] == d[u] + G[u]) &#123;</span><br><span class="line">      <span class="comment">// 点权的更新，在最短路径不变的情况下选择最好的点权</span></span><br><span class="line">      <span class="comment">// 这里希望点权w[v]越大越好</span></span><br><span class="line">      <span class="keyword">if</span>(w[v] &lt; w[u] + weight[v]) &#123;</span><br><span class="line">				w[v] = w[u] + weight[v];</span><br><span class="line">        pre[v] = u;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>求最短路径的数量，使用一个数组，记录最短路径数量即可</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">  <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; G[u][v]!=<span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (d[v] &gt; d[u] + G[u][v]) &#123;</span><br><span class="line">      d[v] = d[u] + G[u][v]; <span class="comment">// 更新最短路径</span></span><br><span class="line">      pre[v] = u;</span><br><span class="line">      nums[v] = nums[u] <span class="comment">// 到达顶点v的最短路径数量与达到顶点u一样</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (d[v] == d[u] + G[u]) &#123;</span><br><span class="line">      <span class="comment">// 说明此时从顶点u出发也可以最短路径的到达顶点v</span></span><br><span class="line">      nums[v] += nums[u];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面的方法中，总是只保留最优的最短路径，这种情况不一定适用于所有的情形。下面介绍一种方法，总是先保留所有的最短路径，然后再从所有的最短路径中进行选择。</p>
<p>核心方法是，不再只保留一个前驱结点，而是保留所有的最短路径的前驱结点</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; pre[maxv];</span><br></pre></td></tr></table></figure>
<p>新的方法</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Disjkstra</span><span class="params">(<span class="keyword">int</span> s)</span> </span>&#123;</span><br><span class="line">  fill(d, d+n, INF);</span><br><span class="line">  fill(vis, vis+n, <span class="literal">false</span>);</span><br><span class="line">  d[s] = <span class="number">0</span>; <span class="comment">// 开始顶点距离为0</span></span><br><span class="line">  pre[s].clear();</span><br><span class="line">  pre[s].push_back(s); <span class="comment">// 开始顶点的前驱是自身</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;n; ++i) &#123; <span class="comment">// 开始访问n个顶点</span></span><br><span class="line">    <span class="keyword">int</span> u = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> MIN = INF;</span><br><span class="line">    <span class="comment">// 寻找还未访问的顶点中有最短路径的顶点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">      <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; d[v]&lt;MIN) &#123;</span><br><span class="line">        u = v;</span><br><span class="line">        MIN = d[v];</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(u==<span class="number">-1</span>) <span class="keyword">return</span>; <span class="comment">// 已经没有可以访问的顶点了，返回</span></span><br><span class="line">    vis[u] = ture; <span class="comment">// 访问节点u</span></span><br><span class="line">    <span class="comment">// 开始检查从u出发，能否让还未访问的顶点最短路径减小</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">      <span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; G[u][v]!=<span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span>(d[v]&gt;d[u] + G[u][v]) &#123;</span><br><span class="line">          d[v] = d[u] + G[u][v]; <span class="comment">// 更新最短路径</span></span><br><span class="line">          <span class="comment">// 更新前驱</span></span><br><span class="line">          pre[v].clear();</span><br><span class="line">          pre[v].push_back(u);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span>(d[v]&gt;d[u] + G[u][v]) &#123;</span><br><span class="line">          pre[v].push_back(u); <span class="comment">// 记录新的可能的最短路径的前驱</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>遍历所有的最短路径：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DFSPath</span><span class="params">(<span class="keyword">int</span> s, <span class="keyword">int</span> u, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;tmpPath, <span class="keyword">int</span> &amp;optValue, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;optPath)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(u==s) &#123;</span><br><span class="line">    tmpPath.push_back(u);</span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">if</span>(当前最短路径的value优于optvalue) &#123;</span><br><span class="line">      optValue = value;</span><br><span class="line">      optPath = tmpPath;</span><br><span class="line">    &#125;</span><br><span class="line">    tmpPath.pop_back();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  tmpPath.push_back(u); <span class="comment">// 当前路径加入新的结点</span></span><br><span class="line">  <span class="comment">// 开始遍历所有的前驱结点</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;pre[u].size();++i) &#123;</span><br><span class="line">    DFSPath(s, pre[i], tmpPath, optValue, optPath);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 退出当前结点，返回上一级</span></span><br><span class="line">  tmpPath.pop_back();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="bellman-ford算法和spfa算法">Bellman-Ford算法和SPFA算法</h3>
<p>在dijkstra算法中，如果遇到图有负权边，由于该算法会直接选择该负边，而忽略了其它可能的路径，可能造成某些通过非负权边可以访问到的顶点没有被访问到。它无法较好的处理负权边。</p>
<p>对于以上问题，同样是针对单源最短路径问题，有bellman-ford算法，以及其改进版本SPFA算法可以解决。</p>
<p>Bellman-ford算法的基本思想：</p>
<ul>
<li>对图中的每个边进行<code>V-1</code>轮的检查。在每一轮的检查中，如果发现通过边<code>[u][v]</code>，可以让顶点<code>v</code>的最短路径缩短，就进行替换，这一点类似于Dijkstra算法，区别在于Bellman算法是遍历每条边，保证所有的边都会参与判定过程。进行<code>V-1</code>轮检查的原因是，某个结点到开始顶点的最短路径长度不会超过<code>V</code>（包括开始顶点），如果不考虑都有的开始顶点，只需要最多<code>V-1</code>步就可以到达任意连通的结点。</li>
<li>之后，再进行一轮检查，如果发现还有某个边，可以更新当前的最短路径，可以判定图中存在源点可达的负环（也就是循环一轮后，发现总的边权减少了）。请注意，这样无法判定图中是否有源点不可达的负环。</li>
</ul>
<p>以邻接表为例的代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 返回ture表示无源点s可达的负环</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">bellman</span><span class="params">(<span class="keyword">int</span> s)</span> </span>&#123;</span><br><span class="line">  d[s] = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 开始n-1轮检查</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n<span class="number">-1</span>; ++i) &#123;</span><br><span class="line">    <span class="comment">// 开始遍历所有边</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> u = <span class="number">0</span>; u &lt; n; ++u) &#123;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; Adj[u].size(); ++j) &#123;</span><br><span class="line">        <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">        <span class="keyword">int</span> dis = Adj[u][j].dis;</span><br><span class="line">        <span class="keyword">if</span>(d[v] &gt; d[u] + dis) &#123;</span><br><span class="line">          d[v] = d[u] + dis;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 开始判断是否有源点可达的负环</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> u = <span class="number">0</span>; u &lt; n; ++u) &#123;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; Adj[u].size(); ++j) &#123;</span><br><span class="line">        <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">        <span class="keyword">int</span> dis = Adj[u][j].dis;</span><br><span class="line">        <span class="keyword">if</span>(d[v] &gt; d[u] + dis) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">	<span class="keyword">return</span> ture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述算法每次要遍历所有的边，实际上只有最短路径<code>d</code>发生变化的顶点出发的边才需要进行判断，因此可以使用一个队列存储所有最短路径发生变化的顶点，出队后，再把发生最短路径变化且不再队列中的顶点入队。如果发现队空了，可以判断没有可达的负环；如果有某个顶点入队次数超过了<code>V</code>（也就是最短路径发生变化超过了<code>V</code>次），可以判断存在可达的负环。</p>
<p>经过上述改进后的算法就叫做SPFA算法（Shortest Path Faster Algorithm），该算法在大多数的图中都非常高效。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 返回ture表示无源点s可达的负环</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">SPFA</span><span class="params">(<span class="keyword">int</span> s)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">  q.push(s);</span><br><span class="line">  <span class="keyword">bool</span> inqueue[n]=&#123;<span class="literal">false</span>&#125;;</span><br><span class="line">  <span class="keyword">int</span> inqueueNum[n]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">  inqueue[s] = <span class="literal">true</span>;</span><br><span class="line">  d[s] = <span class="number">0</span>;</span><br><span class="line">  inqueueNum[s] = <span class="number">1</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">while</span>(!q.empty()) &#123;</span><br><span class="line">    <span class="keyword">int</span> u = q.top();</span><br><span class="line">    q.pop();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; Adj[u].size(); ++j) &#123;</span><br><span class="line">        <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">        <span class="keyword">int</span> dis = Adj[u][j].dis;</span><br><span class="line">        <span class="keyword">if</span>(d[v] &gt; d[u] + dis) &#123;</span><br><span class="line">          d[v] = d[u] + dis;</span><br><span class="line">          <span class="comment">// 顶点v的最短路径发生变化</span></span><br><span class="line">          <span class="keyword">if</span>(inqueue[v]==<span class="literal">false</span>) &#123;</span><br><span class="line">            q.push(v);</span><br><span class="line">            inqueue[v] = <span class="literal">true</span>;</span><br><span class="line">            inqueueNum[v]++;</span><br><span class="line">            <span class="keyword">if</span>(inqueueNum[v]&gt;=n) <span class="comment">// 入队次数超过或者达到了n</span></span><br><span class="line">              <span class="keyword">return</span> <span class="literal">false</span>; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="floyd算法">Floyd算法</h3>
<p>Floyd可以解决全源最短路径的问题，也就是说询问任意两个点之间的最短距离，该问题就限制了问题可以查询的顶点数量在200以内，所以总是可以使用邻接矩阵的方法解决。核心思想是，如果顶点<code>k</code>为中介时，可以使得顶点<code>i</code>到顶点<code>j</code>的距离缩短，就使用顶点<code>k</code>为中介。</p>
<p>代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Floyd</span><span class="params">(<span class="keyword">int</span> s)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> k =<span class="number">0</span>; k&lt;n; ++k) &#123;</span><br><span class="line">    <span class="comment">// 开始遍历所有顶点组合</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>; i&lt;n; ++i) &#123;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;n; ++j) &#123;</span><br><span class="line">        <span class="keyword">if</span>(dis[i][k]!=INF &amp;&amp; dis[k][j]!=INF &amp;&amp; dis[i][k]+dis[k][j]&lt;dis[i][j]) &#123;</span><br><span class="line">          dis[i][j] = dis[i][k]+dis[k][j];</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最小生成树">最小生成树</h2>
<p>最小生成树是从一个无向图当中，获取一课树，这棵树满足</p>
<ul>
<li>包括了所有的图顶点</li>
<li>所有的边都是图中原有的边</li>
<li>该树的边权和最小</li>
</ul>
<p>由于是一棵树，所以最小生成树一定有<code>V-1</code>条边。最小生成树的根结点可以是任意的结点（试想下一棵树，如果没有特殊的性质，我们当然可以把任意一个数结点当做是根结点，然后重新排列成树的层级形状）。当然在题目中，一般会指定要从哪个结点出发生成最小生成树。</p>
<h3 id="prime算法">Prime算法</h3>
<p>prime算法和dijkstra算法很相似，区别在于prime选择下一步访问的图顶点时不是考虑到起源结点最短距离，而是到整个已访问结点集合的最短距离（具体的说，访问新顶点，检查下新访问顶点到未访问顶点的距离，看能否让距离减小，不需要考虑之前新访问顶点的最短距离）。</p>
<p>下面写一下邻接表版本的prime算法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> INF = <span class="number">1000000000</span>;</span><br><span class="line"><span class="keyword">bool</span> vis[maxn];</span><br><span class="line"><span class="keyword">int</span> dis[maxn];</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">prime</span><span class="params">(<span class="keyword">int</span> s)</span> </span>&#123;</span><br><span class="line">  fill(vis, vis+n, <span class="literal">false</span>);</span><br><span class="line">  fill(dis, dis+n, INF);</span><br><span class="line">  dis[s] = <span class="number">0</span>; <span class="comment">// 起源顶点的最短距离设置为1</span></span><br><span class="line">  <span class="keyword">int</span> ans = <span class="number">0</span>; <span class="comment">// 记录生成树的边权和</span></span><br><span class="line">  <span class="comment">// 开始访问所有顶点，总共访问n次</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    <span class="keyword">int</span> MINDIS = INF;</span><br><span class="line">    <span class="keyword">int</span> u = <span class="number">-1</span>;</span><br><span class="line">    <span class="comment">// 下面这段代码可以使用小顶堆或者优先队列维护，就无须总是遍历所有的顶点了</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v = <span class="number">0</span>; v&lt;n; ++v) &#123;</span><br><span class="line">			<span class="keyword">if</span>(vis[v]==<span class="literal">false</span> &amp;&amp; dis[v]&lt;MINDIS) &#123;</span><br><span class="line">        <span class="comment">// 寻找当前最短距离最小的顶点</span></span><br><span class="line">        MINDIS = dis[v];</span><br><span class="line">        u = v;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(u==<span class="number">-1</span>) <span class="keyword">return</span> ans;</span><br><span class="line">    vis[u] = <span class="literal">true</span>; <span class="comment">// 访问顶点u</span></span><br><span class="line">    ans += dis[u]; <span class="comment">// 累积边权和</span></span><br><span class="line">    <span class="comment">// 开始更新未访问顶点的最短距离</span></span><br><span class="line">    <span class="comment">// 检查顶点u的相连顶点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j&lt;Adj[u].size(); ++j) &#123;</span><br><span class="line">      <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">      <span class="keyword">int</span> dis_uv = Adj[u][j].dis;</span><br><span class="line">      <span class="comment">// 如果顶点v未访问，并且距离顶点u的边权更小</span></span><br><span class="line">      <span class="comment">// 这一行是prime区别于dijkstra的核心，不考虑之前顶点u的最短距离</span></span><br><span class="line">			<span class="keyword">if</span>(vis[v] == <span class="literal">false</span> &amp;&amp; dis[v] &gt; dis_uv) &#123;</span><br><span class="line">        dis[v] = dis_uv;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="kruskal算法">kruskal算法</h3>
<p>Kruskal算法（克鲁斯卡尔算法）的思想很简单，使用边贪心的思路：</p>
<ul>
<li>按照边权从小到大排序所有边</li>
<li>认为所有图顶点一开始是独立不连通的块（并查集的初始状态）</li>
<li>遍历所有排好序的边，如果一条边的两个顶点不在同一个连通块（并查集寻找集合根结点），就加入这个边，连通两个连通块（并查集合并）；如果两个顶点已经处于同一个连通块，就略过该边</li>
<li>重复上一步直至所有边遍历完毕或者已经选择了<code>V-1</code>个边</li>
</ul>
<p>代码示意：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">edge</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> u, v;</span><br><span class="line">  <span class="keyword">int</span> dis;</span><br><span class="line">&#125; E [maxe];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cmp</span><span class="params">(edge e1, edge e2)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> e1.dis &lt; e2.dis;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> father[maxn]; <span class="comment">// 记录顶点所属的连通块/集合</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findFather</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> tmp_i = i;</span><br><span class="line">  <span class="keyword">while</span>(father[i]!=i) &#123;</span><br><span class="line">    i = father[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 压缩并查集路径</span></span><br><span class="line">  <span class="keyword">while</span>(i!=father[tmp_i]) &#123;</span><br><span class="line">    <span class="keyword">int</span> tmp_z = tmp_i;</span><br><span class="line">    tmp_i=father[tmp_i];</span><br><span class="line">    father[tmp_z] = i; <span class="comment">// 直接指向集合的根结点</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kruskal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;n; ++i) &#123;</span><br><span class="line">		father[i] = i; <span class="comment">// n个不连通块</span></span><br><span class="line">  &#125;</span><br><span class="line">  sort(E, E+edge_num, cmp);</span><br><span class="line">  <span class="keyword">int</span> u, v;</span><br><span class="line">  <span class="keyword">int</span> tree_count = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;edge_num; ++i) &#123;</span><br><span class="line">    u = E[i].u;</span><br><span class="line">    fatherU = findFather(u);</span><br><span class="line">    v = E[i].v;</span><br><span class="line">    fatherV = findFather(v);</span><br><span class="line">    dis = E[i].dis;</span><br><span class="line">	  <span class="keyword">if</span>(fatherU!=fatherV) &#123;</span><br><span class="line">      father[fatherU] = father[fatherV]; <span class="comment">// 合并两个并查集，根结点合并</span></span><br><span class="line">      ans += dis; <span class="comment">// 边加入生成树</span></span><br><span class="line">      tree_count++;</span><br><span class="line">      <span class="keyword">if</span>(tree_count==n<span class="number">-1</span>) <span class="keyword">break</span>; <span class="comment">// 如果已经找到足够的生成树边</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(tree_count!=n<span class="number">-1</span>) <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// 有顶点无法连通</span></span><br><span class="line">  <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="拓扑排序">拓扑排序</h2>
<p>一个有向图的任意顶点都不可能通过一些有向边返回，这样的有向图叫做有向无环图。</p>
<p>检查一个有向无环图的办法可以通过检查图的拓扑排序能否包括所有的图顶点。拓扑排序是指如果在图中存在<code>u-&gt;v</code>，则<code>u</code>在拓扑排序中一定在<code>v</code>前，<code>u</code>是<code>v</code>的先导元素。</p>
<p>解决思路是，使用一个队列存储所有入度为0的顶点，出队队首元素，访问该顶点，然后删除所有以该顶点为起点的边，如果有顶点入度变为了0，就入队。重复上述过程直到队列为空。检查此时访问的元素，如果存在部分顶点为访问，则说明有向图中存在环。</p>
<p>邻接表版本的代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> inDegree[maxn]; <span class="comment">// 记录所有顶点的入度</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">topologicalSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">  <span class="comment">// 所有入度是0的顶点入队</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++) &#123;</span><br><span class="line">    <span class="keyword">if</span>(inDegree[i]==<span class="number">0</span>) &#123;</span><br><span class="line">      q.push(i);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">int</span> zeroDegreeCount = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(!q.empty()) &#123;</span><br><span class="line">    <span class="keyword">int</span> u = q.front();</span><br><span class="line">    q.pop();</span><br><span class="line">    zeroDegreeCount++;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, u); <span class="comment">// 访问队顶元素，输出拓扑排序</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; Adj[u].size(); ++j) &#123;</span><br><span class="line">      <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">      inDegree[v]--;</span><br><span class="line">      <span class="keyword">if</span>(inDegree[v]==<span class="number">0</span>) &#123;</span><br><span class="line">        q.push(v);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(zeroDegreeCount==n) <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">// 返回true，没有环</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 有环</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="关键路径">关键路径</h2>
<p>AOV（Activity On Vertex）网络是顶点表示活动，顶点可以有点权，边没有边权，代表优先级。上一节的拓扑排序就是用来寻找AOV网络上的一种活动排序。</p>
<p>AOE（Activity On Edge）网络是边表示活动，顶点表示事件，顶点没有点权，边有边权。AOE通常用在工程场景中，边表示从一个事件到另一事件需要的时间/代价等。</p>
<p>AOV和AOE网络的边都表示某种优先级，因此不会存在环，都是有向无环图。</p>
<p>AOV网络总是可以转换为AOE网络，试想下只需要把AOV中的顶点拆分为两个顶点作为事件开始与结束，这两个顶点中的有向边边权就是原顶点的点权，剩下的AOV原有边边权设置为0。</p>
<p>AOE网络总是可以通过添加额外的起点和汇点，形成只有一个起点，一个汇点的图。</p>
<p>关键路径：对于AOE网络中的最长路径，叫做关键路径；关键路径上的所有活动叫做关键活动；关键路径表示要完成AOE网络中的所有活动所需要的最少时间，关键活动是无法拖延完成的活动。</p>
<p>关键路径的寻找方法，核心在于寻找顶点<code>i</code>（事件）的最早开始时间和最晚开始时间，最早开始时间是从起点开始就马不停蹄的完成所有事件，只要顶点<code>i</code>的所有先导顶点完成了，就立刻开始完成顶点<code>i</code>。顶点<code>i</code>的最晚开始时间，是从终点开始反向计算，只要不延误后续顶点的最晚开始时间就可以。</p>
<p>实现的时候，对于每个顶点，维护数组<code>ve[maxn]</code>保存顶点的最早开始时间；数组<code>vl[maxn]</code>保存顶点的最迟开始时间。计算好这两个数组之后，遍历所有的边<code>u-&gt;v</code>，计算<code>u-&gt;v</code>的最早开始时间<code>ve[u]</code>和最晚开始时间<code>vl[v]-dis[u-&gt;v]</code>。</p>
<p>按照拓扑排序，可以计算出各个顶点的最早开始时间<code>max</code>（所有先导顶点的最早时间+先导边时间）；然后按照拓扑排序的反向顺序，计算各个顶点的最晚开始时间<code>min</code>（所有后续顶点的最晚开始时间-后续边时间）。</p>
<p>代码实现：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; topoloStack; <span class="comment">// 保存拓扑排序序列</span></span><br><span class="line"><span class="keyword">int</span> ve[maxn];</span><br><span class="line"><span class="keyword">int</span> vl[maxn];</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> inDegree[maxn];</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">topologicalSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  fill(ve, ve+n, <span class="number">0</span>);</span><br><span class="line">  <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">  <span class="comment">// 所有入度是0的顶点入队</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++) &#123;</span><br><span class="line">    <span class="keyword">if</span>(inDegree[i]==<span class="number">0</span>) &#123;</span><br><span class="line">      q.push(i);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">int</span> zeroDegreeCount = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(!q.empty()) &#123;</span><br><span class="line">    <span class="keyword">int</span> u = q.front();</span><br><span class="line">    q.pop();</span><br><span class="line">    zeroDegreeCount++;</span><br><span class="line">    topoloStack.push(u);  <span class="comment">// 加入拓扑排序</span></span><br><span class="line">    <span class="comment">// 对于顶点u的所有后续结点，顶点u都是先导顶点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; Adj[u].size(); ++j) &#123;</span><br><span class="line">      <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">      <span class="keyword">int</span> dis = Adj[u][j].dis;</span><br><span class="line">      inDegree[v]--;</span><br><span class="line">      <span class="keyword">if</span>(inDegree[v]==<span class="number">0</span>) &#123;</span><br><span class="line">        q.push(v);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 如果以顶点u为先导，完成活动后到达顶点v的最早开始时间更长</span></span><br><span class="line">      <span class="keyword">if</span>(ve[v] &lt; ve[u] + dis) &#123;</span><br><span class="line">        ve[v] = ve[u] + dis;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(zeroDegreeCount==n) <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">// 返回true，没有环</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 有环</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">criticalPath</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(!topologicalSort()) <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// 有环</span></span><br><span class="line">  <span class="comment">// 开始计算vl[n]</span></span><br><span class="line">  fill(vl, vl+n, ve[n<span class="number">-1</span>]); <span class="comment">// 初始化vl值为汇点的最晚开始时间（等于汇点的最早开始时间），也就是关键路径长度</span></span><br><span class="line">  <span class="keyword">while</span>(!topoloStack.empty()) &#123;</span><br><span class="line">    <span class="keyword">int</span> u = topoloStack.top();</span><br><span class="line">    topoloStack.pop();</span><br><span class="line">    <span class="comment">// 对于顶点u的所有后续结点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; Adj[u].size(); ++j) &#123;</span><br><span class="line">      <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">      <span class="keyword">int</span> dis = Adj[u][j].dis;</span><br><span class="line">      <span class="comment">// 如果到达顶点v的最晚开始时间更小</span></span><br><span class="line">      <span class="keyword">if</span>(vl[u] &gt; vl[v] - dis) &#123;</span><br><span class="line">        vl[u] = vl[v] - dis;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 开始遍历所有边，寻找关键活动，也就是不能延误开始的边</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> u = <span class="number">0</span>; u &lt; n; ++u) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; Adj[u].size(); ++j) &#123;</span><br><span class="line">      <span class="keyword">int</span> v = Adj[u][j].v;</span><br><span class="line">      <span class="keyword">int</span> dis = Adj[u][j].dis;</span><br><span class="line">      <span class="keyword">int</span> e_edge = ve[u]; <span class="comment">// 边的最早开始时间</span></span><br><span class="line">      <span class="keyword">int</span> l_edge = vl[v] - dis; <span class="comment">// 边的最迟开始时间</span></span><br><span class="line">      <span class="keyword">if</span>(e_dege == l_edge) &#123;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;%d-&gt;%d\n&quot;</span>, u, v);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ve[n<span class="number">-1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>11-dynamic-programming</title>
    <url>/algorithm-note/11-dynamic-programming/</url>
    <content><![CDATA[<h1 id="动态规划">动态规划</h1>
<p>《算法笔记》第11章，动态规划</p>
<span id="more"></span>
<h2 id="动态规划基本介绍">动态规划基本介绍</h2>
<p>动态规划（Dynamic Programming, DP）是很精妙的算法，没有固定的写法。基本思想是把一个复杂问题拆分为几个不同的子问题，通过综合子问题的最优解来获得复杂问题的最优解。理解动态规划有以下几点需要注意：</p>
<ul>
<li>应用动态规划的前提是复杂问题的最优解可以通过其子问题的最优解来获得，如果一个问题满足这样的性质，就称该问题具有最优子结构（Optimal Substructure）。</li>
<li>动态规划与分治法的区别是：分治法划分子问题没有重叠，一个子问题不会再重复的出现；动态规划划分出的子问题会重复的出现，因此<em>动态规划通常会记录子问题的解</em>，当再次遇到子问题时直接给出解。另外，分治法不一定是在解决最优问题，动态规划则总是在找最优解。</li>
<li>动态规划与贪心法的区别是：贪心算法会依赖于当前状态，在多个子问题中直接选择当前最优的子问题，而不再考虑其它子问题，因此贪心算法能否真的找到最优解还依赖于分析证明；<em>动态规划会考虑所有子问题</em>，在后续的步骤中可能会重新考虑之前的子问题，不断综合子问题的最优解，保证最后能够找到最优结果。</li>
</ul>
<p>接下来考虑几个经典的动态规划算法</p>
<h2 id="最大连续子序列和">最大连续子序列和</h2>
<p>给定一个数字序列<code>A</code>，求最大的连续数字序列的和。</p>
<p>思路：对于<code>i</code>位的数字，规定以<code>i</code>位数字结尾的最大连续序列和为<code>dp[i]</code>，那么<code>dp[i]=max(A[i], dp[i-1]+A[i])</code>，最大的子序列和就是所有<code>dp[]</code>的最大值。核心就是这个状态转移方程，可以看到当前状态仅仅依赖于已有的状态，一旦当前状态确定后，不会在后续的步骤中改变。动态规划的核心难点就是这一点。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> dp[n];</span><br><span class="line">  dp[<span class="number">0</span>] = A[<span class="number">0</span>]; <span class="comment">// 初始化首位</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; ++i) &#123;</span><br><span class="line">		dp[i] = max(dp[i<span class="number">-1</span>]+A[i], A[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 检查最大值</span></span><br><span class="line">  <span class="keyword">int</span> MAX = dp[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span>(dp[i]&gt;MAX) &#123;</span><br><span class="line">      MAX = dp[i];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, MAX);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最长不下降子序列lis">最长不下降子序列（LIS）</h2>
<p>给定一个序列，求最长的可不连续、非递降子序列（Longest Increasing Sequence, LIS）。</p>
<p>思路：对于<code>A[i]</code>，遍历所有的<code>A[0]-A[i-1]</code>，如果存在一个元素<code>A[k]</code>比<code>A[i]</code>小或者相等，那么计算下<code>dp[k]+1</code>，选择最大值保存为<code>dp[i]</code>。同样，无论<code>dp[i]</code>之后出现什么新元素，不会改变<code>dp[i]</code>，<code>dp[i]</code>也只依赖于之前已有的结果。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> dp[n];</span><br><span class="line">  dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    dp[i] = <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// 遍历以前所有的元素，保存LIS值</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; ++j) &#123;</span><br><span class="line">      <span class="keyword">if</span>(A[j]&lt;=A[i] &amp;&amp; dp[j] + <span class="number">1</span> &gt; dp[i]) &#123;</span><br><span class="line">        dp[i] = dp[j] + <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 检查最大不下降序列</span></span><br><span class="line">  <span class="keyword">int</span> MAX = dp[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">		<span class="keyword">if</span>(MAX&lt;dp[i]) MAX = dp[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, MAX);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最长公共子序列lcs">最长公共子序列（LCS）</h2>
<p>给定两个序列<code>A</code>和<code>B</code>，求最长的公共可不连续子序列（Longest Common Seqence, LCS）</p>
<p>思路：对于<code>A[i]</code>和<code>B[j]</code>，如果<code>A[i]==B[j]</code>，那么<code>LCS+1</code>；如果<code>A[i]!=B[j]</code>，那么<code>LCS=max(dp[i][j-1], dp[i-1][j])</code>。初始化的边界是<code>dp[0][j]=0</code>和<code>dp[i][0]=0</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> m,n; <span class="comment">// m是序列A的长度，n是序列B的长度</span></span><br><span class="line">  <span class="keyword">int</span> dp[m+<span class="number">1</span>][n+<span class="number">1</span>];</span><br><span class="line">  <span class="comment">// 初始化</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;m;++i) &#123;</span><br><span class="line">    dp[i][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;++j) &#123;</span><br><span class="line">    dp[<span class="number">0</span>][j] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 从下标1开始，避免i-1小于0</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=m;i++) &#123;</span><br><span class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=n;j++) &#123;</span><br><span class="line">      <span class="keyword">if</span>(A[i]==B[j]) &#123;</span><br><span class="line">        dp[i][j] = dp[i<span class="number">-1</span>][j<span class="number">-1</span>] + <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">        dp[i][j] = max(dp[i<span class="number">-1</span>][j], dp[i][j<span class="number">-1</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, dp[m][n]); <span class="comment">// 此时，dp[m][n]就是最大公共子序列</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最长回文子串">最长回文子串</h2>
<p>回文是指从左向右和从右到左读的结果都一样的序列。检验回文只需要两个指针从两端分别检查是否元素相等，直至相遇即可。</p>
<p>给定序列<code>A</code>，要求输出最长的回文串。</p>
<p>思路：如果<code>dp[i][j]</code>中，如果<code>A[i]==A[j]</code>，并且<code>dp[i+1][j-1]</code>是回文串，那么<code>dp[i][j]</code>也是回文串；如果<code>A[i]!=A[j]</code>，那么<code>dp[i][j]</code>不是回文串。这里在实现的时候，问题在于不能直接按照<code>i</code>，<code>j</code>的循环遍历，因为这样会造成<code>dp[i+1]</code>在<code>dp[i]</code>之后出现。因此需要想办法先计算好<code>dp[i+1][j-1]</code>，考虑到长度问题，使用长度来作为循环。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> dp[n][n]; <span class="comment">// n是序列A长度，dp[i][j]=1表示序列i-&gt;j是回文子串</span></span><br><span class="line">  <span class="keyword">int</span> ans = <span class="number">1</span>; <span class="comment">// 初始化的最大回文子串长度</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; ++i) &#123;</span><br><span class="line">    dp[i][i] = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 子问题的长度从2-n</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> L=<span class="number">2</span>; L&lt;=n; L++) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i + L - <span class="number">1</span>&lt;n; i++) &#123;</span><br><span class="line">      <span class="keyword">int</span> j = i + L - <span class="number">1</span>;</span><br><span class="line">      <span class="keyword">if</span>(A[i] == A[j] &amp;&amp; dp[i+<span class="number">1</span>][j<span class="number">-1</span>] == <span class="number">1</span>) &#123;</span><br><span class="line">        dp[i][j] = <span class="number">1</span>;</span><br><span class="line">        ans = L;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, ans);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="dag最长路径">DAG最长路径</h2>
<p>这里使用DP的思想解决有向无环图DAG的最长/最短路径问题，思想实际比dijkstra等算法更加简单易理解。</p>
<p>求一个DAG中的最长路径，不规定起点和终点</p>
<p>思想：令<code>dp[i]</code>表示从顶点<code>i</code>出发能够到达的最长路径，那么<code>dp[i]=max&#123;dp[j]+G[i][j]&#125;</code>，顶点<code>j</code>是顶点<code>i</code>的后继顶点。很明显这是一个逆拓扑排序的顺序，使用递归的方法可以简单实现。最后只需要在所有的<code>dp[i]</code>中搜索最大值即可。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> choice[maxn]; <span class="comment">// 记录选择的后继结点，初始化为-1</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">DP</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// dp初始化全为0</span></span><br><span class="line">  <span class="keyword">if</span>(dp[i]&gt;<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;++j) &#123;</span><br><span class="line">		<span class="keyword">if</span>(G[i][j]!=INF &amp;&amp; dp[i]&lt;DP(j)+G[i][j]) &#123;</span><br><span class="line">      dp[i] = dp[j]+G[i][j]; <span class="comment">// 更新</span></span><br><span class="line">      choice[i] = j;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> dp[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printPath</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(choice[i]!=<span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, i);</span><br><span class="line">    i = choice[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>求一个DAG中，固定重点T的最长路径</p>
<p>思想：令<code>dp[i]</code>表示从顶点<code>i</code>出发能够到达终点<code>T</code>的最长路径，那么<code>dp[i]=max&#123;dp[j]+G[i][j]&#125;</code>，顶点<code>j</code>是顶点<code>i</code>的后继顶点。和上面的问题最大区别是如何体现能够到达终点<code>T</code>？前面使用<code>dp[i]==0</code>代表已经到了终点，如果还是使用0表示到达终点<code>T</code>，这会导致无法区分出不能到达<code>T</code>的顶点，那些无法到达终点<code>T</code>的路径也被考虑，最后输出错误结果。因此，考虑让<code>dp[i]</code>初始化为<code>-INF</code>，这样不能到达<code>T</code>的路径都会取到很小的值，从而被排除。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">DP</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// dp初始化全为-INF</span></span><br><span class="line">  <span class="keyword">if</span>(vis[i]==<span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">return</span> dp[i];</span><br><span class="line">  vis[i] = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;n; ++j) &#123;</span><br><span class="line">		<span class="keyword">if</span>(G[i][j]!=INF &amp;&amp; dp[i]&lt;DP(j)+G[i][j]) &#123;</span><br><span class="line">      dp[i] = dp[j]+G[i][j]; <span class="comment">// 更新</span></span><br><span class="line">      choice[i] = j;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> dp[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="背包问题">背包问题</h2>
<h3 id="背包">01背包</h3>
<p>n种物品，价值和重量分别为<code>c[i]</code>和<code>w[i]</code>，每种物品只有1件，要求总背包承重是<code>V</code>的情况下，总价值最大。</p>
<p>思路：第<code>i</code>种物品是否放入背包容积<code>v</code>的最大值由前<code>i-1</code>种物品完全决定。<code>dp[i][v]=max(dp[i-1][v], dp[i-1][v-w[i]])</code>。为了减小二维数组的开销，可以使用滚动数组的方法，只使用一个动态改变值的一维数组来实现。注意到计算<code>i</code>的时候，<code>i-1</code>是固定值，完全可以把<code>i-1</code>看做是上一轮数组的结果，同样还是两层循环，<code>i:1-&gt;n, v:V-&gt;w[i]</code>。</p>
<p>代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> dp[V+<span class="number">1</span>];</span><br><span class="line">  <span class="comment">// 初始化</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>;v&lt;V+<span class="number">1</span>;++v) &#123;</span><br><span class="line">    dp[v] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=n; ++i) &#123;</span><br><span class="line">    <span class="comment">// 这里必须是逆序排列，第i轮计算要用到第i-1轮的新结果</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=V; v&gt;=w[i]; --v) &#123;</span><br><span class="line">      dp[v] = max(dp[v], dp[v-w[i]] + c[i]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 寻找最大值</span></span><br><span class="line">  <span class="keyword">int</span> max = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>;v&lt;V+<span class="number">1</span>;++v) &#123;</span><br><span class="line">    <span class="comment">// pass</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="完全背包">完全背包</h3>
<p>n种物品，价值和重量分别为<code>c[i]</code>和<code>w[i]</code>，每种物品有任意件，要求总背包承重是<code>V</code>的情况下，总价值最大。</p>
<p>思路：第<code>i</code>种物品是否放入背包容积<code>v</code>的最大值由前<code>i-1</code>种物品完全决定。<code>dp[i][v]=max(dp[i-1][v], dp[i][v-w[i]])</code>。和01背包的区别就是放入<code>i</code>种物品后，还可以继续考虑放入第<code>i</code>种物品。</p>
<p>代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> dp[V+<span class="number">1</span>];</span><br><span class="line">  <span class="comment">// 初始化</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> v=<span class="number">0</span>;v&lt;V+<span class="number">1</span>;++v) &#123;</span><br><span class="line">    dp[v] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=n; ++i) &#123;</span><br><span class="line">    <span class="comment">// 这里必须是正序排列，第i轮计算要用到第i轮的新结果</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> v=w[i]; v&lt;=V; --v) &#123;</span><br><span class="line">      dp[v] = max(dp[v], dp[v-w[i]] + c[i]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>12-string</title>
    <url>/algorithm-note/12-string/</url>
    <content><![CDATA[<h1 id="字符串专题">字符串专题</h1>
<span id="more"></span>
<h2 id="字符串hash进阶">字符串hash进阶</h2>
<p>在前面第4章讨论过对只有大小写字母的字符串的hash办法，简单说就是把字母看出26进制，然后换算成10进制 <span class="math display">\[
H[i] = H[i-1]\times26 + index(str[i])
\]</span> 为了避免结果太大，取模 <span class="math display">\[
H[i] = \left(H[i-1]\times26 + index(str[i])\right)\ \%\ mod
\]</span> 当然这可能出现hash碰撞。幸运的是，在实践中发现，如果选择合适的进制和取模除数，可以很大程度避免这个问题，一般来讲，设置进制<code>p</code>为一个<span class="math inline">\(10^7\)</span>的素数（如10000019），<code>mod</code>为<span class="math inline">\(10^9\)</span>的素数（例如1000000007），冲突概率就非常小了。 <span class="math display">\[
H[i] = \left(H[i-1]\times p + index(str[i])\right)\ \%\ mod
\]</span> 字符串的子串hash问题：如何表示<code>H[i...j]</code>？</p>
<p>思路：我们当然可以对子串同样进行相同的hash操作，但是这样会造成大量的冗余计算。我们可以利用上面计算的结果来简化操作，<code>H[j]</code>可以由<code>H[i-1]</code>一路推导下来： <span class="math display">\[
H[j] = H[i-1]\times p^{j-i+1} + H[i...j] \\
H[i...j] = H[j] - H[i-1]\times p^{j-i+1}
\]</span> 如果加入取模操作，注意<code>H[j]</code>可能会小于<code>H[i-1]xp</code>，直接取模可能得到负值，因此为了得到非负结果，结果取模后再度加一次<code>mod</code>，然后再取模，保证能够得到正值。 <span class="math display">\[
H[i...j] = ((H[j] - H[i-1]\times p^{j-i+1})\%\ mod + mod)\%\ mod
\]</span> 因此，我们可以在计算获得<code>H[i]</code>之后，按照上面的式子方便的获得所有子串的hash值，用于之后的计算。</p>
<p>可以用于计算两个字符串的最大公共子串（注意不是子序列），只需要比较两个子字符串的所有子串hash是否相同，并取最大值即可；</p>
<p>也可以用于计算字符串的最大回文子串，把原来的字符串反转，然后比较最大的hash相同的公共子串。</p>
<p>最后，如果出现了hash冲突，只需要改变下<code>p</code>和<code>mod</code>即可。甚至还可以采用双hash，也就是计算两个不同的hash值一起表示字符串的办法。</p>
<h2 id="kmp算法">KMP算法</h2>
<p>接下来讨论字符串匹配问题，KMP算法是三个发明作者的首字母。</p>
<p>思想：核心是设计一个next数组，<code>next[i]=k</code>表示字符串<code>s[0..i]</code>的最长相等前缀<code>s[0...k]</code>和后缀<code>s[i-k...i]</code>。</p>
<p>获取next数组的代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getNext</span><span class="params">(<span class="keyword">char</span> s[], <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> j = <span class="number">-1</span>;</span><br><span class="line">  next[<span class="number">0</span>] = <span class="number">-1</span>; <span class="comment">// -1表示没有匹配的前后缀</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;len; ++i) &#123;</span><br><span class="line">    <span class="comment">// 后缀最后一位一定是s[i]，因此前缀最后一位必须匹配s[i]</span></span><br><span class="line">    <span class="keyword">while</span>(j!=<span class="number">-1</span> &amp;&amp; s[i]!=s[j+<span class="number">1</span>]) &#123;</span><br><span class="line">      j = next[j];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果成功匹配</span></span><br><span class="line">    <span class="keyword">if</span>(s[i]==s[j+<span class="number">1</span>]) &#123;</span><br><span class="line">      j++;</span><br><span class="line">    &#125;</span><br><span class="line">    next[i] = j; <span class="comment">// 设置最大匹配前后缀</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>KMP算法就是利用前面的next数组来实现，对于字符串<code>text</code>和模式串<code>pattern</code>。计算<code>pattern</code>的next数组，然后模仿next的计算过程不断去匹配<code>text</code>。实际上，<code>next</code>数组的求解过程，就是自身对自身的匹配。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 返回匹配的字符串个数</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">KMP</span><span class="params">(<span class="keyword">char</span> text[], <span class="keyword">char</span> pattern[])</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> n = <span class="built_in">strlen</span>(text), m = <span class="built_in">strlen</span>(pattern);</span><br><span class="line">  getNext(pattern, m);</span><br><span class="line">  <span class="keyword">int</span> j = <span class="number">-1</span>; <span class="comment">// 此时j表示在pattern上的位置</span></span><br><span class="line">  <span class="keyword">int</span> matchCount = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; ++i) &#123;</span><br><span class="line">    <span class="comment">// 没有办法继续匹配，就让pattern已匹配的前缀后退</span></span><br><span class="line">    <span class="keyword">while</span>(j!=<span class="number">-1</span> &amp;&amp; text[i]!=pattern[j+<span class="number">1</span>]) &#123;</span><br><span class="line">      j = next[j];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(text[i] == pattern[j+<span class="number">1</span>]) &#123;</span><br><span class="line">      j++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果已经全部匹配</span></span><br><span class="line">    <span class="keyword">if</span>(j==m<span class="number">-1</span>) &#123;</span><br><span class="line">      matchCount++;</span><br><span class="line">      j = next[j]; <span class="comment">// 回退，然后继续尝试匹配</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> matchCount;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>2-basic</title>
    <url>/algorithm-note/2-basic/</url>
    <content><![CDATA[<h1 id="c语言基础要点">C语言基础要点</h1>
<p>《算法笔记》第二章 C/C++快速入门。这里记录些要点。</p>
<p>C语言常包括头文件<code>&lt;stdio.h&gt;</code>，<code>stdio</code>是标准输入输出的意思。实际上，在c++标准中，推荐使用<code>&lt;cstdio&gt;</code>，<code>cmath</code>和<code>cstring</code>等头文件，和<code>.h</code>结尾的头文件是等价的。</p>
<span id="more"></span>
<h2 id="基本数据类型">基本数据类型</h2>
<p>int的取值范围在<span class="math inline">\(10^9\)</span>范围内，long long的范围在<span class="math inline">\(10^{18}\)</span>。如果要给int定义一个表示无穷大的数，推荐取值为<span class="math inline">\(2^{30}-1\)</span>，这样能够避免相加后超出int取值范围，一般定义是<code>int INF=(1&lt;&lt;30)-1</code>。</p>
<p>浮点数float的精度是6-7位，double是15-16位，推荐一般使用double。</p>
<p>单个char赋值的时候，字符常量只有单个字符，要使用<code>''</code>单引号。字符编码记住小写字母&gt;大写字母&gt;数字，大写字母+32就是对应的小写字母ASCII码。</p>
<p>字符串可以使用char数组，<code>char str[24]</code>，输入和输出可以直接使用<code>%s</code>。字符串一定不能赋值给char。</p>
<p>条件运算符是c语言中的唯一三母运算符，<code>int c = a&gt;b ? a : b;</code>。</p>
<h2 id="scanf与printf">scanf与printf</h2>
<p>scanf和printf比c++中的cin和cout要快，在某些要求时间约束的题目中好用。</p>
<p>输入和输出long long，都使用<code>%lld</code>。字符是<code>%c</code>，输入float是<code>%f</code>，输入double是<code>%lf</code>，输入字符串是<code>%s</code>。记住<code>%c</code>可以直接获得空格和换行符，<code>%s</code>遇到空格和换行符就会停止输入。</p>
<p>scanf的格式：<code>scanf(&quot;格式控制&quot;,  变量地址)</code>。注意除了<code>%s</code>由于是数组首元素地址，其它变量都需要使用<code>&amp;</code>获得变量地址。</p>
<p>printf的格式：<code>printf(&quot;格式控制&quot;，变量名)</code>。printf输出变量时，除了double和float一样都使用<code>%f</code>即可，其它都和scanf一样。几个特殊的控制输出的格式：</p>
<ul>
<li><code>%md</code>：<code>m</code>是控制输出整型以m位右对齐，如果整型变量本身超出m位，就保持原样。</li>
<li><code>%0md</code>：对于左边不够m位的，使用<code>0</code>补齐</li>
<li><code>%.mf</code>：浮点数保留m位，保留的规则不是简单的四舍五入，而是四舍六入五成双。</li>
<li><code>%%</code>和<code>//</code>：输出<code>%</code>和<code>/</code>。</li>
</ul>
<p><code>getchar()</code>和<code>putchar(char)</code>可以方便的获取单个字符。</p>
<h2 id="常用math函数">常用math函数</h2>
<p>下面提到的math函数，输入都是<code>double</code>。</p>
<ul>
<li><code>fabs(double x)</code>：double取绝对值</li>
<li><code>floor(double x)</code>和<code>ceil(double x)</code>：向下和向上取整，注意负数的向下取整是取更负的值。</li>
<li><code>pow(double r, double p)</code>：计算<span class="math inline">\(r^p\)</span>。</li>
<li><code>sqrt(double x)</code>：返回算术平方根</li>
<li><code>log(double x)</code>：返回<span class="math inline">\(e\)</span>为底的对数值，如果要计算非<span class="math inline">\(e\)</span>为底的对数，利用换底公式<span class="math inline">\(log_ab=log_eb/log_ea\)</span>。</li>
<li><code>sin(double x), cos(), tan()</code>：输入的<code>x</code>是弧度，不是角度，注意<code>弧度=角度 x pi/180</code>。</li>
<li><code>asin(double x), acos(), atan()</code>：反三角函数，返回弧度值</li>
<li><code>round(double x)</code>：四舍五入</li>
</ul>
<h2 id="数组">数组</h2>
<h3 id="一般数组">一般数组</h3>
<p>数组的一般定义形式</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">数据类型 数组名[数量]</span><br></pre></td></tr></table></figure>
<p><em>注意数组传入函数时，如果是二维数组，需要指定第二维的长度，如果是一维数组不要求指定；在函数中修改数组元素，会直接修改原数组的值</em>。</p>
<p>定义的时候初始化：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 一维数组</span></span><br><span class="line"><span class="keyword">int</span> a[<span class="number">45</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>&#125;;</span><br><span class="line"><span class="comment">// 二维数组</span></span><br><span class="line"><span class="keyword">int</span> b[<span class="number">2</span>][<span class="number">3</span>] = &#123;&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>&#125;, &#123;&#125;, &#123;<span class="number">2</span>, <span class="number">4</span>&#125;&#125;;</span><br><span class="line"><span class="comment">// 字符数组</span></span><br><span class="line"><span class="keyword">char</span> c[<span class="number">2</span>] = &#123;<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>&#125;;</span><br><span class="line"><span class="keyword">char</span> c[<span class="number">2</span>] = <span class="string">&quot;ac&quot;</span>; <span class="comment">// 注意只有定义的时候可以这样用&quot;&quot;定义</span></span><br></pre></td></tr></table></figure>
<p>注意，如果定义的数组较大（元素数量&gt;<span class="math inline">\(10^6\)</span>），由于函数内部的局部变量来自系统栈，允许的空间较小，需要移到函数外，函数外的全局变量来自静态存储区，允许申请的空间比较大。</p>
<p>利用函数初始化数组，有两种函数：</p>
<ul>
<li><code>memset(数组名, 值, sizeof(数组名)</code>：按照<em>字节</em>依据所给的值赋值给数组元素，因此为了避免错误，一般是使用<code>0</code>或者<code>-1</code>初始化。该函数执行速度较快。需要<code>#include&lt;string&gt;</code></li>
<li><code>fill(数组开始地址, 数组结束地址, 值)</code>：需要包括<code>#include&lt;algorithm&gt;</code>，便于利用其他值初始化数组，不会出错，执行速度更慢。</li>
</ul>
<h3 id="字符数组">字符数组</h3>
<p>字符数组的输入与输出：</p>
<ol type="1">
<li>使用<code>scanf</code>和<code>printf</code></li>
</ol>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, str); <span class="comment">// 遇到空格或者换行停止</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>, str);</span><br></pre></td></tr></table></figure>
<p>注意，使用scanf输入时，编译器会自动在字符串末尾添加<code>\0</code>，因此字符串数组大小至少要比规定的大小大1。使用printf输出时，识别<code>\0</code>作为中断输出，如果没有该字符，会输出乱码。</p>
<ol start="2" type="1">
<li>使用<code>getchar</code>和<code>putchar</code></li>
</ol>
<p>输入输出单个字符，注意该方法无法自动识别字符串尾端，需要人工增加<code>\0</code>避免出错。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> c = getchar();</span><br><span class="line"><span class="built_in">putchar</span>(c);</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>使用<code>gets</code>和<code>puts</code></li>
</ol>
<p>用来直接输入和输出字符串，记住<code>gets(str)</code>是以<code>\n</code>作为输入结束标志，因此<code>gets()</code>可以用来输入有空格的字符串，它也会自动添加<code>\0</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> str1[<span class="number">100</span>];</span><br><span class="line">gets(str1);</span><br><span class="line"><span class="built_in">puts</span>(str1);</span><br></pre></td></tr></table></figure>
<p><code>string.h</code>头文件包含了很多有用的处理字符串的函数：</p>
<ul>
<li><code>strlen(str)</code> ：返回字符个数，<code>int len=strlen(str);</code>。</li>
<li><p><code>strcmp(str1, str2)</code>：按照字典序比较字符串，<code>str1&lt;str2</code>返回负数，<code>str1==str2</code>返回<code>0</code>，<code>str1&gt;str2</code>返回正数。</p></li>
<li><code>strcpy(str1, str2)</code>：拷贝str1给str2。</li>
<li><p><code>strcat(str1, str2)</code>：把str2连接到str1后面，<code>strcat(str1, str2);</code>。</p></li>
</ul>
<p>介绍两个在<code>strio.h</code>中就包含的函数，<code>sscanf</code>和<code>sprintf</code>。<code>sscanf</code>用来把一个字符串按照要求的格式赋值给其它变量，<code>sprintf</code>用来把其它变量按照要求的格式赋值给字符串。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> str[<span class="number">50</span>]=<span class="string">&quot;12345&quot;</span>;</span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line"><span class="comment">// sscanf用法</span></span><br><span class="line"><span class="built_in">sscanf</span>(str, <span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line"><span class="keyword">char</span> str1[<span class="number">50</span>]=<span class="string">&quot;2048:3.14,hello&quot;</span>;</span><br><span class="line"><span class="keyword">double</span> b;</span><br><span class="line"><span class="keyword">char</span> s[<span class="number">10</span>];</span><br><span class="line"><span class="built_in">sscanf</span>(str1, <span class="string">&quot;%d:%lf,%s&quot;</span>, &amp;n, &amp;b, s);</span><br><span class="line"><span class="comment">// sprintf用法</span></span><br><span class="line"><span class="built_in">sprintf</span>(str, <span class="string">&quot;%d:%.1lf&quot;</span>, n, b); <span class="comment">// 此时str由12345变为2018:3.1</span></span><br></pre></td></tr></table></figure>
<h2 id="指针">指针</h2>
<p>在c语言中，指针是指向变量首个字节地址的变量，由于不同类型的变量有不同的字节，因此还需要确定变量的类型。<code>int *p = &amp;a;</code>。指针本身都是一个unsigned的int。</p>
<p>如果定义多个指针，都需要包括<code>*</code>，<code>int *p1, *p2, *p3;</code>。</p>
<p>指针变量支持自增和自减操作。</p>
<p>c语言中的数组名就代表首个数组元素的地址，也可以直接看做是个指针。因此</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> *p = a;</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, a); <span class="comment">// 会直接赋值给a[0]</span></span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, a+<span class="number">1</span>); <span class="comment">// 会直接赋值给a[1]</span></span><br></pre></td></tr></table></figure>
<p>指针作为函数参数传入时，指针参数本身是值传递，但是通过指针操作被指向的变量可以直接修改。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">change</span><span class="params">(<span class="keyword">int</span> *p)</span> </span>&#123;</span><br><span class="line">  *p = <span class="number">1</span>; <span class="comment">// 会修改被指向变量的值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>c++提供了引用的语法，用在函数的形式参数中，用来表示该形式参数只是传入变量的一个别名，不会拷贝和复制，这样不需要指针也能够直接修改传入的原参数。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> &amp;a, <span class="keyword">int</span> &amp;b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> c = a;</span><br><span class="line">  a = b;</span><br><span class="line">  b = c;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> x = <span class="number">0</span>, y = <span class="number">1</span>;</span><br><span class="line">swap(x, y); <span class="comment">// 注意，x和y不能再加&amp;</span></span><br></pre></td></tr></table></figure>
<h2 id="结构体的使用">结构体的使用</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">studentInfo</span> &#123;</span></span><br><span class="line">  <span class="comment">// 基本数据类型</span></span><br><span class="line">  <span class="keyword">int</span> age;</span><br><span class="line">  <span class="keyword">char</span> name[<span class="number">10</span>];</span><br><span class="line">  studentInfo * nextStu;</span><br><span class="line">&#125; stu, *stuP, students[<span class="number">20</span>];</span><br></pre></td></tr></table></figure>
<p>注意，定义的时候，结构体内不能有自身类型，但是可以有指向自身的指针。</p>
<p>访问结构体元素：</p>
<ul>
<li><p>非指针：<code>stu.age; stu.name</code></p></li>
<li><p>指针：<code>stuP-&gt;age; stuP-&gt;name</code></p></li>
</ul>
<p>构造函数，为了方便直接利用已有的基本数据类型变量生成一个结构体实例，c语言提供了结构体的构造函数，没有返回类型，构造函数命名就是本身。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">studentInfo</span> &#123;</span></span><br><span class="line">  <span class="comment">// 基本数据类型</span></span><br><span class="line">  <span class="keyword">int</span> age;</span><br><span class="line">  <span class="keyword">char</span> name[<span class="number">10</span>];</span><br><span class="line">  studentInfo * nextStu;</span><br><span class="line">  <span class="comment">// 构造函数</span></span><br><span class="line">  <span class="comment">// 默认构造函数，可以设计多个应用与不同场景，只要形参不同即可</span></span><br><span class="line">  studentInfo() &#123;&#125; <span class="comment">// 便于不初始化也能定义结构体变量</span></span><br><span class="line">  studentInfo(<span class="keyword">int</span> _age, <span class="keyword">char</span> _name[]) &#123;</span><br><span class="line">    age = _age;</span><br><span class="line">    <span class="built_in">strcpy</span>(name, _name);</span><br><span class="line">  &#125;</span><br><span class="line">  studentInfo(<span class="keyword">int</span> _age) &#123;</span><br><span class="line">    age = _age;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">studentInfo stu; <span class="comment">// 如果没有默认构造函数就无法这样定义</span></span><br><span class="line">studentInfo stu2 = studentInfo(<span class="number">18</span>, <span class="string">&quot;alexpp&quot;</span>);</span><br></pre></td></tr></table></figure>
<h2 id="补充">补充</h2>
<p>cin读入字符串数组的时候，直接<code>cin&gt;&gt;str</code>即可，但是如果希望读入一整行的话，使用<code>getline</code>，比如<code>getline(cin, str)</code>，这个方法对于STL中的string同样适用。</p>
<p>cout的输出，如果需要指定浮点数的精度，需要包括<code>&lt;iomanip&gt;</code>，</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cout</span>&lt;&lt;setiosflags(ios::fixed)&lt;&lt;setprecision(<span class="number">2</span>)&lt;&lt;<span class="number">123.456</span>&lt;&lt;<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure>
<p>浮点数的比较，在进行了可能影响小数点的精度的运算之后，本来两个从原理上应该相等的浮点数，结果由于舍弃了部分小数位，导致不相等，这时候需要考虑误差允许范围内的比较操作。</p>
<p>定义一个小数，<code>const double eps = 1e-8</code>，<code>1e</code>代表的是<code>10</code>。</p>
<p>重新定义<code>==, !=,&lt;,&gt;,&gt;=,&lt;=</code>。</p>
<p>举例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">equ</span><span class="params">(<span class="keyword">double</span> a, <span class="keyword">double</span> b)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">fabs</span>(a - b) &lt; eps;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">large</span><span class="params">(<span class="keyword">double</span> a, <span class="keyword">double</span> b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (a - b) &gt; eps;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">less</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (b - a) &gt; eps;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">largeEqu</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a &gt; (b - eps);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">lessEqu</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a &lt; (b + eps);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>计算<span class="math inline">\(\pi\)</span>，使用<code>const double pi = acos(-1.0);</code>即可。</p>
<h2 id="黑盒测试">黑盒测试</h2>
<p>单点测试就是OJ对于每组输入都重新启动文件，程序运行一次只需要处理一组测试数据，即程序只需要保证单次运行成功即可。</p>
<p>多点测试就是要求程序必须一次运行所有组测试数据，根据题目不同有不同写法。</p>
<p>由于OJ是把所有测试数据放在一个文件中，因此只要判断测试文件是否已经输入完毕即可。<code>scanf</code>函数会返回成功读入的参数的个数，如果读到文件末尾就会返回<code>-1</code>，在c语言中使用<code>EOF</code>代表-1。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">&quot;d&quot;</span>, &amp;n)!=EOF) &#123;</span><br><span class="line">  <span class="comment">// pass</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 如果是在读入字符串</span></span><br><span class="line"><span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">&quot;s&quot;</span>, str)!=EOF) &#123;</span><br><span class="line">  <span class="comment">// pass</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span>(gets(str)!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">    <span class="comment">// pass</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当然根据题目，可能还有其它合适的循环读入的方法。</p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>6-stl</title>
    <url>/algorithm-note/6-stl/</url>
    <content><![CDATA[<h1 id="c标准模板库">C++标准模板库</h1>
<p>本文来自于《算法笔记》第六章内容</p>
<p>STL：standard template library</p>
<span id="more"></span>
<h2 id="vector常见用法">vector常见用法</h2>
<p>可变长数组，使用前提</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br></pre></td></tr></table></figure>
<p>定义方法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vector</span> &lt;<span class="keyword">typename</span>&gt; name;</span><br><span class="line"><span class="comment">// 比如：</span></span><br><span class="line"><span class="built_in">vector</span> &lt;<span class="keyword">char</span>&gt; vec;</span><br><span class="line"><span class="built_in">vector</span> &lt;<span class="built_in">vector</span> &lt;<span class="keyword">int</span>&gt; &gt; twod_array <span class="comment">// 注意这里的&gt; &gt;之间的空格，防止部分编译器编译错误</span></span><br></pre></td></tr></table></figure>
<p>访问vector中的元素有两种方法，下标访问以及通过迭代器访问。</p>
<p>下标访问，和数组的正常访问一样，只要不越界即可：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vector</span> &lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line"><span class="comment">// pass</span></span><br><span class="line">a = vec[<span class="number">1</span>];</span><br></pre></td></tr></table></figure>
<p>迭代器访问，迭代器是一种类似于指针的东西，定义方法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vector</span> &lt;<span class="keyword">typename</span>&gt;::iterator it;</span><br><span class="line"><span class="comment">// 让it指向vector中的某个元素地址，然后直接使用*it就能取值，例如：</span></span><br><span class="line">it = vec.begin();</span><br><span class="line">val = *it;</span><br><span class="line">val = *(it+<span class="number">3</span>);</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">8</span>;</span><br><span class="line">val = *(it+i); <span class="comment">// 注意这种迭代器+整数的写法，只有在vector和string中有实现，其它stl容器无提供相关内容</span></span><br></pre></td></tr></table></figure>
<p>迭代器实现了自增和自减操作：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 可用于循环取vector中的元素</span></span><br><span class="line">it++;</span><br><span class="line">++it;</span><br><span class="line">--it;</span><br><span class="line">it--;</span><br></pre></td></tr></table></figure>
<p>可以用于遍历元素：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注意这里&lt;vec.end()的写法，只有在vector和string容器里可用</span></span><br><span class="line"><span class="keyword">for</span>(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator it = vec.begin(); it &lt; vec.end(); ++it) &#123;</span><br><span class="line">  <span class="comment">// pass</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>vector常用函数举例：</p>
<p><code>begin()</code>和<code>end()</code>，需要注意的是<code>end()</code>不指向实际的元素，这是因为在c语言中，习惯用左闭右开的区间写法。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 返回vector的首地址以及尾地址的后一位</span></span><br><span class="line">vec.begin();</span><br><span class="line">vec.end();</span><br><span class="line"><span class="comment">// 这两个函数可以和iterator结合起来进行元素遍历，也可以用在sort函数中</span></span><br><span class="line">sort(vec.begin(), vec.end());</span><br></pre></td></tr></table></figure>
<p><code>size()</code>返回元素个数，常用于遍历</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> total_num = vec.size();</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; total_num; ++i) &#123;</span><br><span class="line">  <span class="comment">// pass</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>push_back()</code>末尾增加元素</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;n;++i) &#123;</span><br><span class="line">	<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;temp);</span><br><span class="line">	vec.push_back(temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>pop_back()</code>删除末尾元素</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">vec.pop_back();</span><br></pre></td></tr></table></figure>
<p><code>clear()</code>清空所有元素</p>
<p><code>insert(it, x)</code>在特定位置插入新元素</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">vec.insert(vec.begin()+<span class="number">2</span>, <span class="number">-1</span>); <span class="comment">// 在第3个元素插入-1</span></span><br></pre></td></tr></table></figure>
<p><code>earse()</code>删除特定元素或者一个区间的元素（左闭右开）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 删除特定迭代器位置的元素</span></span><br><span class="line">vec.earse(vec.begin()+<span class="number">3</span>);</span><br><span class="line"><span class="comment">// 删除一个区间的元素</span></span><br><span class="line">vec.earse(vec.begin()+<span class="number">1</span>, vec.begin()+<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<h2 id="set常见用法">set常见用法</h2>
<p>在c语言中的<code>set</code>是一个<strong>自动排序且无重复元素</strong>的容器。</p>
<p>使用前提</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>定义方法，与vector一样</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">typename</span>&gt; name;</span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt; st;</span><br></pre></td></tr></table></figure>
<p>另外，set的排序是可以更改的，默认的是使用<code>less&lt;typename&gt;</code>的排序标准，可以改为从大到小的排序</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>, greater&lt;<span class="keyword">int</span>&gt;&gt; numbers;</span><br></pre></td></tr></table></figure>
<p>访问元素，只能使用迭代器，不能使用下标访问。遍历set中的元素：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注意这里，不能使用it&lt;st.end()来判断停止条件</span></span><br><span class="line"><span class="keyword">for</span>(<span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt;::iterator it = st.begin(); it!=st.end(); ++it) &#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, *it);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>set</code>的常用函数：</p>
<p><code>insert()</code>插入新元素，会去重并排序，记得没有<code>push_back()</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">st.insert(<span class="number">1</span>);</span><br><span class="line">st.insert(<span class="number">2</span>);</span><br><span class="line">st.insert(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<p><code>size()</code>返回元素个数；</p>
<p><code>find()</code>返回对应值的元素的迭代器：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">it = st.find(<span class="number">2</span>);</span><br><span class="line"><span class="comment">// 如果没有找到对应元素</span></span><br><span class="line"><span class="keyword">if</span> (st.find(<span class="number">-1000</span>) == st.end()) &#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;not found\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>earse()</code>删除元素：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 删除单个元素</span></span><br><span class="line">st.earse(<span class="number">2</span>); <span class="comment">// 直接删除对应值的元素</span></span><br><span class="line">st.earse(st.find(<span class="number">2</span>)); <span class="comment">// 删除对应迭代器位置的元素</span></span><br><span class="line"><span class="comment">// 删除一组元素，[)</span></span><br><span class="line">st.earse(it1, it2);</span><br></pre></td></tr></table></figure>
<p><code>clear()</code>清空元素。</p>
<p>还有其它类似的<code>set</code>容器，比如<code>multiset</code>和<code>unordered_set</code>。</p>
<p><code>multiset</code>不会去重，但是会排序，使用方法与set类似，同样是默认从小到大的排序。</p>
<p><code>unordered_set</code>不会排序但是会去重，速度更快，可以用来很方便的去重元素，使用方法与set类似。</p>
<h2 id="string常见用法">string常见用法</h2>
<p>c++在stl中提供了string类型用于实现对字符串的处理。</p>
<p>使用前提</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注意&lt;string.h&gt;是完全不同的头文件</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>定义：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">string</span> str = <span class="string">&quot;abcde&quot;</span>;</span><br></pre></td></tr></table></figure>
<p>输入与输出：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 只能使用cin和cout</span></span><br><span class="line"><span class="built_in">cin</span>&gt;&gt;str;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;str;</span><br><span class="line"><span class="comment">// 输出也可以使用printf</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>, str.c_str());</span><br></pre></td></tr></table></figure>
<p>元素访问：</p>
<p>单元素访问，类似于vector可以使用下标：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> = <span class="number">2</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, str[i]);</span><br></pre></td></tr></table></figure>
<p>通过迭代器访问：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">string</span>::iterator it = str.begin();</span><br><span class="line">it++;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, *it);</span><br><span class="line">it+=<span class="number">3</span>; <span class="comment">// 类似于vector，可以让迭代器加一个常量长度</span></span><br></pre></td></tr></table></figure>
<p>string常用函数：</p>
<p>操作符<code>+=</code>，直接拼接两个string，<code>str1+=str2</code>。</p>
<p>比较符<code>==,!=,&lt;,&lt;=,&gt;,&gt;=</code>，比较顺序是字典序。</p>
<p>元素个数查询<code>length()/size()</code>。</p>
<p>插入新字符<code>insert()</code>，举两个实例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在特定位置pos插入字符串str</span></span><br><span class="line">str.insert(<span class="number">3</span>, <span class="string">&quot;opt&quot;</span>);</span><br><span class="line"><span class="comment">// 在迭代器it，插入另一个字符串的[it1, it2)子串</span></span><br><span class="line">str.insert(it, str2.begin(), str2.end());</span><br></pre></td></tr></table></figure>
<p>删除元素<code>erase()</code>，举例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 删除迭代器位置it的单个元素</span></span><br><span class="line">str.erase(it);</span><br><span class="line"><span class="comment">// 删除一个区间的元素，两个迭代器中间的元素</span></span><br><span class="line">str.erase(first, last);</span><br><span class="line"><span class="comment">// 删除一个位置开始的一定长度的元素</span></span><br><span class="line">str.erase(pos, length);</span><br></pre></td></tr></table></figure>
<p>清空元素<code>clear()</code>。</p>
<p>截取子串，<code>substr(pos, len)</code>。</p>
<p>寻找子串<code>find()</code>，举例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 寻找一个子串，返回位置pos</span></span><br><span class="line"><span class="keyword">int</span> pos = str.find(<span class="string">&quot;ab&quot;</span>);</span><br><span class="line"><span class="comment">// 如果没有找到，返回没有找到的代码</span></span><br><span class="line"><span class="keyword">if</span> (pos == <span class="built_in">string</span>::npos) &#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;not found\n&quot;</span>);</span><br><span class="line">&#125; <span class="comment">// 记住，string::npos是一个常数，作为find函数匹配失败的返回值</span></span><br><span class="line"><span class="comment">// 还可以从某个位置开始匹配</span></span><br><span class="line">pos = str.find(<span class="string">&quot;ab&quot;</span>, <span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<p>替换子串<code>replace()</code>，举例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">str.replace(<span class="number">2</span>, <span class="number">4</span>, <span class="string">&quot;gggg&quot;</span>); <span class="comment">//把str中[2, 4)的子串替换为&quot;gggg&quot;</span></span><br><span class="line">str.replace(it1, it2, <span class="string">&quot;gggg&quot;</span>); <span class="comment">//把str中[it1, it2)的子串替换为&quot;gggg&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="map常见用法">map常见用法</h2>
<p>map可以将任何基本类型（包括容器）映射到任何基本类型（包括容器）。</p>
<p>使用map</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>map的定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">map</span>&lt;keytype, valtype&gt; mp;</span><br><span class="line"><span class="comment">// 如果使用字符串作为key，只能使用string</span></span><br><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt; mp;</span><br></pre></td></tr></table></figure>
<p>map元素的访问，通过下标key进行访问</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mp[&#x27;aa&#x27;] = 2;</span><br><span class="line">mp[&#x27;aa&#x27;] = 20;</span><br></pre></td></tr></table></figure>
<p>通过迭代器访问</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;::iterator it;</span><br><span class="line">it = mp.begin();</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;it-&gt;first; <span class="comment">// 通过it-&gt;first访问键, it-&gt;second访问值</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;it-&gt;second;</span><br></pre></td></tr></table></figure>
<p>map内部是使用红黑树实现的，因此会按照从小到大的顺序自动排列键。</p>
<p>map常用函数：</p>
<p>查找某个key是否存在<code>find()</code>，返回迭代器，<code>mp.find(&quot;aa&quot;)</code>；</p>
<p>插入元素<code>insert()</code></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">mp.insert(<span class="built_in">pair</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;(<span class="string">&quot;bbb&quot;</span>, <span class="number">7</span>)); <span class="comment">// 注意map都是以pair为操作对象，插入需要是一个pair对象</span></span><br></pre></td></tr></table></figure>
<p>删除元素<code>erase()</code>，</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">mp.erase(it); <span class="comment">// 删除迭代器位置的元素</span></span><br><span class="line">mp.erase(<span class="string">&quot;aa&quot;</span>); <span class="comment">// 删除key键的元素</span></span><br><span class="line">mp.erase(first_it, last_it); <span class="comment">// 删除[first_it, last_it)的元素</span></span><br></pre></td></tr></table></figure>
<p>元素个数<code>size()</code>；</p>
<p>清空<code>clear()</code>；</p>
<p>map中的键和值是唯一的，如果希望一个键对应多个值，可以使用<code>multimap</code>。</p>
<p>由于map会默认按照<code>less&lt;typename&gt;</code>进行排序，所以类似于set，c++11中提供了<code>unordered_map</code>。</p>
<p>map和set实际具有几乎完全相同的接口和函数名，set可以看做是一种特殊的map，即key=value。</p>
<h2 id="queue常见用法">queue常见用法</h2>
<p>queue是先进先出的限制性数据结构</p>
<p>使用queue</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;queue&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>定义queue</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">queue</span>&lt;<span class="keyword">typename</span>&gt; que;</span><br></pre></td></tr></table></figure>
<p>访问元素，queue只能访问队首或者队尾，不能像前面的stl一样通过下标任意访问</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">que.front(); <span class="comment">// 访问队首，在使用前记住要先判断que.empty()，避免队空而出错</span></span><br><span class="line">que.back(); <span class="comment">// 访问队尾</span></span><br></pre></td></tr></table></figure>
<p>queue常用函数</p>
<p>增加新元素<code>push()</code>。</p>
<p>队首元素出列<code>pop()</code>。</p>
<p>检测queue是否为空<code>empty()</code>，如果是空返回<code>true</code>。</p>
<p>元素个数<code>size()</code>。</p>
<h2 id="priority_queue常见用法">priority_queue常见用法</h2>
<p>priority_queue是优先队列，和queue的区别是它保证队列中优先级最高的总是在<em>队首</em>，queue不会自动排序。</p>
<p>priority_queue的定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="built_in">priority_queue</span>&lt;<span class="keyword">typename</span>&gt; pq;</span><br></pre></td></tr></table></figure>
<p>常用函数：</p>
<p>增加新元素<code>push()</code>。</p>
<p>查看队首元素<code>top()</code>，注意没有queue中的<code>front()</code>和<code>back()</code>。</p>
<p>弹出队首元素<code>pop()</code>，使用前记得使用<code>empty()</code>判断是否为空，防止报错。</p>
<p>检测空<code>empty()</code>。</p>
<p>元素个数<code>size()</code>。</p>
<p>如何设置priority_queue的优先级？</p>
<p>一般的，按照基本类型的从大到小排序，字符串按照字典序，int按照数值大小。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">priority_queue</span>&lt;<span class="keyword">int</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;, less&lt;<span class="keyword">int</span>&gt; &gt; pq; <span class="comment">// 优先级大的int元素在队首</span></span><br></pre></td></tr></table></figure>
<p>其中的<code>vector&lt;int&gt;</code>是priority_queue的底层数据结构堆的容器，类型需要和前面的元素type保持一致。<code>less&lt;int&gt;</code>是数值大的在队首，这一点和前面的set是相反的，<code>greater&lt;int&gt;</code>表示数值小的会在队首。</p>
<p>另外，对于结构体，可以通过下面重载比较符<code>&lt;</code>的方法定义优先级，注意只能重载<code>&lt;</code>不能重载<code>&gt;</code>，因为只要定义好了<code>&lt;</code>，<code>&gt;</code>和<code>==</code>也就都定义好了。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fruit</span> &#123;</span></span><br><span class="line">  <span class="built_in">string</span> name;</span><br><span class="line">  <span class="keyword">int</span> price;</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">bool</span> <span class="keyword">operator</span> &lt; (fruit f1, fruit f2) &#123;</span><br><span class="line">    <span class="keyword">return</span> f1.price &lt; f2.price; <span class="comment">// 让价格高的在队首，优先队列会选择f1和f2中比较出来大的对象放到前面</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="built_in">priority_queue</span>&lt;fruit&gt; fruits;</span><br></pre></td></tr></table></figure>
<p>这种定义方式有些类似于<code>sort()</code>函数中可以自定义的比较函数，但是如果上面的比较方法放在<code>sort</code>中，会让价格低的在前面，与priority_queue刚好相反。</p>
<h2 id="stack常见用法">stack常见用法</h2>
<p>stack是后进先出的限制性容器，定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="built_in">stack</span>&lt;<span class="keyword">typename</span>&gt; st;</span><br></pre></td></tr></table></figure>
<p>访问元素类似于priority_queue，只能通过<code>top()</code>访问栈顶元素。</p>
<p>常用函数：</p>
<p><code>push()</code>增加新元素</p>
<p><code>top()</code>获得栈顶元素</p>
<p><code>pop()</code>退栈</p>
<p><code>empty()</code>检测是否为空</p>
<p><code>size()</code>元素个数</p>
<h2 id="pair常见用法">pair常见用法</h2>
<p>pair可以将两个元素合并为一个元素，可以看做是一个包含两个元素的struct。</p>
<p>pair的定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="comment">// #include&lt;map&gt; // 由于map的内部使用了pair，所以map头文件中会自动添加utility，所以可以偷懒使用map头文件</span></span><br><span class="line"><span class="built_in">pair</span>&lt;typename1, typename2&gt; p;</span><br></pre></td></tr></table></figure>
<p>pair的初始化</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">pair&lt;string, int&gt; p (&quot;aaa&quot;, 9);</span><br></pre></td></tr></table></figure>
<p>pair临时构造</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">pair</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;(<span class="string">&quot;cccc&quot;</span>, <span class="number">11</span>);</span><br><span class="line"><span class="comment">// 或者使用make_pair函数</span></span><br><span class="line"><span class="built_in">make_pair</span>(<span class="string">&quot;cccc&quot;</span>, <span class="number">11</span>);</span><br></pre></td></tr></table></figure>
<p>pair元素访问，只有两个元素，分别是first和second</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">p.first;</span><br><span class="line">p.second;</span><br></pre></td></tr></table></figure>
<p>pair常用函数</p>
<p>支持比较操作符，<code>==</code>,<code>&lt;</code>,<code>&gt;</code>等，规则是先比较first，只有first相等之后才会比较second。</p>
<h2 id="algorithm头文件下的常用函数">algorithm头文件下的常用函数</h2>
<p>使用</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br></pre></td></tr></table></figure>
<p><code>max</code>,<code>min</code>和<code>abs</code>分别返回最大值、最小值以及<em>整数</em>的绝对值</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>, y = <span class="number">-1</span>, z = <span class="number">3</span>;</span><br><span class="line">max(x, y);</span><br><span class="line">min(x, y);</span><br><span class="line"><span class="built_in">abs</span>(y);</span><br><span class="line"><span class="comment">// 如果希望是浮点数的绝对值，使用&lt;math&gt;头文件下的fabs</span></span><br><span class="line"><span class="built_in">fabs</span>(<span class="number">-0.19</span>);</span><br></pre></td></tr></table></figure>
<p><code>swap()</code>交换x和y的值</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">swap(x, y);</span><br></pre></td></tr></table></figure>
<p><code>reverse()</code>反转一段数组或者一部分容器的元素</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a [<span class="number">3</span>] = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>&#125;;</span><br><span class="line">reverse(a, a+<span class="number">2</span>);</span><br><span class="line"><span class="built_in">string</span> b = <span class="string">&quot;abcdefg&quot;</span>;</span><br><span class="line">reverse(b.begin(), b.begin()+<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<p><code>next_permutation()</code>返回下一个排列</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d %d %d\n&quot;</span>, a[<span class="number">0</span>], a[<span class="number">1</span>], a[<span class="number">2</span>]);</span><br><span class="line">&#125; <span class="keyword">while</span> (next_permutation(a, a+<span class="number">3</span>));</span><br></pre></td></tr></table></figure>
<p><code>fill(it1, it2, val)</code>将数组或者容器的一部分连续元素赋值为相同值</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">fill(a, a+<span class="number">2</span>, <span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<p><code>sort(it1, it2, compare_func)</code>排序数组或容器，结构体等。可能是最常用的方法。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 默认从小到大排序</span></span><br><span class="line">sort(a, a+<span class="number">3</span>);</span><br><span class="line"><span class="comment">// 从大到小排序数组</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cmp</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> x &gt; y;</span><br><span class="line">&#125;</span><br><span class="line">sort(a, a+<span class="number">3</span>, cmp);</span><br><span class="line"><span class="comment">// 排序容器，只有vector，string，deque可用</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">vec.push_back(<span class="number">2</span>);</span><br><span class="line">vec.push_back(<span class="number">4</span>);</span><br><span class="line">vec.push_back(<span class="number">-1</span>);</span><br><span class="line">sort(vec.begin(), vec.end(), cmp);</span><br><span class="line"><span class="comment">// 排序结构体</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> x, y;</span><br><span class="line">&#125; ssd[<span class="number">10</span>];</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cmp_stru</span><span class="params">(node n1, node n2)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> n1.x &gt; n2.x;</span><br><span class="line">&#125;</span><br><span class="line">sort(ssd, ssd+<span class="number">4</span>, cmp_stru);</span><br></pre></td></tr></table></figure>
<p><code>lower_bound()</code>返回第一个<em>等于或者大于</em>目标元素的指针（数组）或者迭代器，如果没找到返回适合插入该元素的位置；</p>
<p><code>upper_bound()</code>返回第一个<em>大于</em>目标元素的指针（数组）或者迭代器，如果没找到返回适合插入该元素的位置；</p>
<p>因此，如果没有找到对应元素，两个函数会返回相同的值</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> * low_pos = lower_bound(a, a+<span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"><span class="keyword">int</span> * up_pos = upper_bound(a, a+<span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;lower_bound: %d\n&quot;</span>, low_pos - a); <span class="comment">// 返回下标</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>5-math</title>
    <url>/algorithm-note/5-math/</url>
    <content><![CDATA[<h1 id="数学问题">数学问题</h1>
<p>《算法笔记》第五章 数学问题</p>
<span id="more"></span>
<h2 id="最大公约数和最小公倍数">最大公约数和最小公倍数</h2>
<p>求解最大公约数的方法一般为欧几里得法，即辗转相除法。0和任意整数的最大公约数都是整数本身。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">gcd</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(y==<span class="number">0</span>) <span class="keyword">return</span> x; <span class="comment">// 保证除数不是0</span></span><br><span class="line">  <span class="keyword">return</span> gcd(y, x % y);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最小公倍数的求解方法是在求解最大公约数的基础上进行的，最小公倍数的求解方法未<code>a*b/d</code>，<code>d</code>就是最大公约数。为了避免超出类型范围，一般为<code>a / d * b</code>。</p>
<h2 id="素数">素数</h2>
<p>素数，也叫做质数是指除了1和本身之外，不能被任意的整数整除的数字。</p>
<p>合数是指可以被除了1和本身之外的数字整除的数字。</p>
<p>特殊的是1，<em>1既不是素数，也不是合数</em>。</p>
<h3 id="判断素数">判断素数</h3>
<p>假设数字n可以被k整除：<code>n % k == 0</code>，我们当然可以遍历从2开始到n-1的所有值检查是否可以整除。</p>
<p>实际上，可以缩小判断范围，考虑平方根，<code>sqrt(n)*sqrt(n) == n</code>，所有可以整除n的第一个数字，一定是<code>&lt;= sqrt(n)</code>，因此我们只需要遍历从2开始到sqrt(n)。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isPrime</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> sqr = <span class="built_in">sqrt</span>(x);</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= sqr; ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span>(n % i == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="获取素数表">获取素数表</h3>
<p>我们当然可以判断每一个数字是否是素数获得素数表，但是这样效率较低。</p>
<p>可以考虑使用埃式筛选法：</p>
<p>如果一个数字<code>i</code>是素数，就把它所有的后续整倍数筛选出去。如果一个数没有被筛选出去，那它就是素数。初始化默认2是素数。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> prime[maxn];</span><br><span class="line"><span class="keyword">int</span> pNum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">bool</span> isPrime[maxn] = &#123;<span class="literal">true</span>&#125;;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">findPrime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; maxn; ++i) &#123;</span><br><span class="line">		<span class="keyword">if</span>(isPrime[i]) &#123;</span><br><span class="line">      prime[pNum++] = i;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">2</span>; i * j &lt; maxn; ++j) &#123;</span><br><span class="line">				isPrime[i * j] = <span class="literal">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="质因子分解">质因子分解</h2>
<p>把一个数字<code>n</code>分解为多个质数的乘积形式。</p>
<p>首先通过获取质数表，我们可以获得所有的候选质数，然后判断各个质数是否是数字<code>n</code>的因子。</p>
<p>同样的，类似于判断质数的方法，数字<code>n</code>的<code>&gt;=sqrt(n)</code>的质因子至多有一个，<code>&lt;sqrt(n)</code>的质因子可以有多个，因此，我们可以先寻找所有<code>&lt;sqrt(n)</code>的质因子，之后如果发现乘积不为数字<code>n</code>，则继续计算。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">factor</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> x, cnt; <span class="comment">// 记录质因子和个数</span></span><br><span class="line">&#125; fac[<span class="number">10</span>]; <span class="comment">// 10个最多了</span></span><br><span class="line">findPrime();</span><br><span class="line"><span class="keyword">int</span> sqr = <span class="built_in">sqrt</span>(n);</span><br><span class="line"><span class="keyword">int</span> num; <span class="comment">// 记录所有质因子的数量</span></span><br><span class="line"><span class="comment">// 遍历素数表</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; pNum &amp;&amp; primes[i] &lt;= sqr; ++i) &#123;</span><br><span class="line">  <span class="keyword">if</span>(n % prime[i] == <span class="number">0</span>) &#123;</span><br><span class="line">    fac[num].x = prime[i];</span><br><span class="line">    fac[num].cnt = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(n % prime[i] ==<span class="number">0</span>) &#123;</span><br><span class="line">      n = n / prime[i];</span><br><span class="line">      fac[num].cnt++;</span><br><span class="line">    &#125;</span><br><span class="line">    num++;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(n==<span class="number">1</span>) <span class="keyword">break</span>; <span class="comment">// 已经找到所有的质因子</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(n != <span class="number">1</span>) &#123;</span><br><span class="line">  <span class="comment">// 如果还存在&gt;=sqrt(n)的质因子</span></span><br><span class="line">  fac[num].x = n;</span><br><span class="line">  fac[num].cnt = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="大整数运算">大整数运算</h2>
<h3 id="大整数的存储">大整数的存储</h3>
<p>对于过于大的整数，比如1000位的整数，不能再使用基本类型存储，因此考虑使用结构体进行存储。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bign</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> d[<span class="number">1000</span>]; <span class="comment">// 保存整数的各位数字，[0]是最低位</span></span><br><span class="line">  <span class="keyword">int</span> len; <span class="comment">// 保存位数</span></span><br><span class="line">  bign() &#123;</span><br><span class="line">    <span class="built_in">memset</span>(d, <span class="number">0</span>, <span class="keyword">sizeof</span>(d)); <span class="comment">// 使用0初始化所有位，方便四则运算</span></span><br><span class="line">    len = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>需要记住我们使用从低位到高位的存储办法。因此，在读入大整数的时候，对于读入的大整数可以先考虑使用<code>char[]</code>保存，然后逆位赋值给<code>bign</code>。同理，<code>bign</code>和<code>bign</code>的比较，同样是从<code>len-1</code>开始比较。</p>
<h3 id="大整数的四则运算">大整数的四则运算</h3>
<p>大整数的加法，从最低位开始相加，如果大于10就进位（除以10），余数在当前位。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">bign <span class="title">add</span><span class="params">(bign a, bign b)</span> </span>&#123;</span><br><span class="line">  bign c;</span><br><span class="line">  <span class="keyword">int</span> carry = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> tmp;</span><br><span class="line">  <span class="comment">// 从低位开始加起</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; a.len || i &lt; b.len; ++i) &#123;</span><br><span class="line">    tmp = a.d[i] + b.d[i] + carry;</span><br><span class="line">    c.d[i] = tmp % <span class="number">10</span>;</span><br><span class="line">    c.len++;</span><br><span class="line">    carry = tmp / <span class="number">10</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(carry != <span class="number">0</span>) &#123; <span class="comment">// 加法的最终进位最多1位</span></span><br><span class="line">    c.d[len++] = carry;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>大整数的减法，与加法的一个很大区别是，需要首先判断两个大整数的大小，总是使用大整数减去小整数，对于结果是负数的情况额外输出负号即可。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">bign <span class="title">sub</span><span class="params">(bign a, bign b)</span> </span>&#123;</span><br><span class="line">  bign c;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>; i &lt; a.len || i &lt; b.len; ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span>(a.d[i] - b.d[i] &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      a.d[i + <span class="number">1</span>]--;</span><br><span class="line">      a.d[i] += <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    c.d[len++] = a.d[i] - b.d[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 减去高位可能存在的多个0，但是至少保留1位，例如3333332-3333331=1</span></span><br><span class="line">  <span class="keyword">while</span>(c.len &gt; <span class="number">1</span> &amp;&amp; c.d[len - <span class="number">1</span>] == <span class="number">0</span>) &#123;</span><br><span class="line">    c.len--;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>大整数与int的乘法，类似于大整数的加法，从低位到高位，将int与大整数的某一位相乘，结果加上进位，然后个位保留作为该位结果，更高位作为进位。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">bign <span class="title">mult</span><span class="params">(bign a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">  bign c;</span><br><span class="line">  <span class="keyword">int</span> tmp, carry = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; a.len; ++i) &#123;</span><br><span class="line">    tmp = a.d[i] * b + carry;</span><br><span class="line">    c.d[len++] = tmp % <span class="number">10</span>;</span><br><span class="line">    carry = tmp / <span class="number">10</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span>(carry != <span class="number">0</span>) &#123;</span><br><span class="line">    c.d[len++] = carry % <span class="number">10</span>;</span><br><span class="line">    carry /= <span class="number">10</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>大整数与int的除法，每一步都是上一步的余数乘以10，加上当前位与除数相除，结果作为当前位，余数留到下一位。除法需要从高位开始操作。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">bign <span class="title">divide</span><span class="params">(bign a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">  bign c;</span><br><span class="line">  c.len = a.len; <span class="comment">// 余数的位数最多和被除数一样</span></span><br><span class="line">  <span class="keyword">int</span> tmp, carry = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = a.len - <span class="number">1</span>; i &gt;= <span class="number">0</span>; --i) &#123;</span><br><span class="line">		tmp = carry * <span class="number">10</span> + a.d[i];</span><br><span class="line">    a.d[i] = tmp % b;</span><br><span class="line">    carry = tmp / b;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 去除高位的0</span></span><br><span class="line">  <span class="keyword">while</span>(c.len &gt; <span class="number">1</span> &amp;&amp; c.d[len - <span class="number">1</span>] == <span class="number">0</span>) &#123;</span><br><span class="line">    c.len--;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="组合数">组合数</h2>
<p>关于问题，求<code>n!</code>有几个质因子<code>p</code>？</p>
<p>可以记住一个式子，<code>n!</code>中有<span class="math inline">\(\frac{n}{p}+\frac{n}{p^2}+\frac{n}{p^3}+\dots\)</span>的质因子<code>p</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">cal</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span> p)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(n) &#123;</span><br><span class="line">    ans += n / p;</span><br><span class="line">    n /= p;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面答案的一个变形是求解<code>n!</code>会有末尾0的个数，本质上等于求有多少个2和5的组合的个数，又因为质因子2的数量多于5，因此直接求解<code>n!</code>有多少个质因子5即可。</p>
<p>求解组合数<span class="math inline">\(C_{n}^{m}\)</span>，如果直接使用公式<span class="math inline">\(\frac{n!}{m!(n-m)!}\)</span>可能超界限，可以考虑使用公式<span class="math inline">\(C_{n}^{m}=C_{n-1}^{m-1}+C_{n-1}^{m}\)</span>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> res[<span class="number">67</span>][<span class="number">67</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">C</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> n, <span class="keyword">long</span> <span class="keyword">long</span> m)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(m==<span class="number">0</span> || n==m) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(res[n][m] != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> res[n][m];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> res[n][m] = C(n<span class="number">-1</span>, m) + C(n<span class="number">-1</span>, m<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>7-data-structure</title>
    <url>/algorithm-note/7-data-structure/</url>
    <content><![CDATA[<h1 id="第七章-数据结构专题">第七章 数据结构专题</h1>
<p>《算法笔记》笔记。</p>
<span id="more"></span>
<h2 id="栈的应用">栈的应用</h2>
<p>这里记录下使用数组实现栈的思路，核心是使用一个栈顶指针记录位置。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> s[<span class="number">100000</span>]; <span class="comment">// 栈的定义</span></span><br><span class="line"><span class="keyword">int</span> TOP = <span class="number">-1</span>; <span class="comment">// 栈顶指针</span></span><br><span class="line"><span class="comment">// 自定义的常用函数，可以看到实现非常简单，主要是直接对TOP指针的操作</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  TOP = <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> TOP + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  s[TOP++] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  TOP--;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">top</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> s[TOP];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">empty</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (TOP == <span class="number">-1</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="队列的应用">队列的应用</h2>
<p>这里同样使用数组实现队列，和实现栈不一样的是，这里维护两个指针<code>front</code>和<code>back</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> q[<span class="number">100000</span>];</span><br><span class="line"><span class="keyword">int</span> front = <span class="number">-1</span>, back = <span class="number">-1</span>; <span class="comment">// 队首与队尾指针，让队首始终指向首个元素的前一位，这样方便判断只有一个元素时，队列是否为空</span></span><br><span class="line"><span class="comment">// 常用函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  front = back = <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> back - front;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">empty</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (front == back) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  q[++back] = x;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  front++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get_front</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> q[front+<span class="number">1</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get_back</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> q[back];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="链表的处理">链表的处理</h2>
<p>这里讨论的链表，类似于vector，只不过是自己实现。</p>
<h3 id="动态链表">动态链表</h3>
<p>先讨论动态链表，即动态生成、删除、释放链表节点。</p>
<p>首先需要定义节点用来存储数据，</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">  <span class="keyword">typename</span> data;</span><br><span class="line">  Node * next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> data;</span><br><span class="line">  Node * next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来讨论如何动态生成新节点，在c语言和c++中都有不同的实现办法，c语言中使用<code>malloc()</code>函数，c++中使用<code>new</code>操作符。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 使用malloc函数，malloc函数会返回(void *)的指针，使用(typename*)进行类型转化</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="keyword">typename</span> * p = (<span class="keyword">typename</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">typename</span>));</span><br><span class="line"><span class="comment">// 举例</span></span><br><span class="line">Node * p = (Node *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(Node));</span><br><span class="line"><span class="comment">// 在c++中直接使用new</span></span><br><span class="line"><span class="keyword">typename</span> * p = <span class="keyword">new</span> <span class="keyword">typename</span>;</span><br><span class="line"><span class="comment">// 举例</span></span><br><span class="line">Node *p = <span class="keyword">new</span> Node;</span><br></pre></td></tr></table></figure>
<p>如何释放新节点？</p>
<p>为什么要释放新节点？</p>
<p><em>因为c语言的设计者认为程序员完全有能力自己控制内存的分配与释放</em>。</p>
<p>c语言中使用<code>free()</code>函数，c++中使用<code>delete()</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// c语言</span></span><br><span class="line"><span class="built_in">free</span>(p);</span><br><span class="line"><span class="comment">// c++</span></span><br><span class="line"><span class="keyword">delete</span>(p);</span><br></pre></td></tr></table></figure>
<p>链表的创建，首先第一个问题是是否拥有头结点（dummy node）？这里按照《算法笔记》上的内容，默认拥有头结点，头结点不是第一个节点，头结点的<code>next</code>指向第一个保存数据的结点，头结点本身不储存任何数据。这样的好处之一是无论链表是否有数据，总会有一个固定的头结点，方便判断链表是否为空，以及插入新的结点等。</p>
<p>尾结点的<code>next</code>应该设置为<code>NULL</code>。</p>
<p>对于动态链表的各项操作，这里不写出来。</p>
<h3 id="静态链表">静态链表</h3>
<p>静态链表和动态链表的区别是，静态链表是通过定义数组的方式提前开辟好的连续内存，<code>next</code>就是下一个结点在数组中的下标。</p>
<p>静态链表的适用范围是在需要的地址比较小的时候，比如<code>&lt;10^5</code>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 静态链表的定义</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> data;</span><br><span class="line">  <span class="keyword">int</span> next; <span class="comment">// next == -1时表示到了链表尾端</span></span><br><span class="line">  <span class="keyword">bool</span> is_node; <span class="comment">// 这里是用来记录当前的数组元素是否属于链表的一个节点，默认应该设置为false</span></span><br><span class="line">&#125;</span><br><span class="line">Node p[<span class="number">100010</span>];</span><br><span class="line"><span class="comment">// 访问下个结点</span></span><br><span class="line"><span class="keyword">int</span> begin_address = <span class="number">2210</span>;</span><br><span class="line"><span class="keyword">int</span> next_address = p[begin_address].next;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%d&quot;</span>, p[next_address].data);</span><br><span class="line"><span class="comment">// 静态链表的好处是，便于直接适用sort函数实现排序</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cmp</span> <span class="params">(Node n1, Node n2)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(!n1.is_node || !n2.is_node) &#123;</span><br><span class="line">    <span class="keyword">return</span> n1.is_node &gt; n2.is_node; <span class="comment">// 让是结点元素的在数组靠前的位置</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> n1.data &lt; n2.data; <span class="comment">// 让data小的在前</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>9-data-structure2</title>
    <url>/algorithm-note/9-data-structure2/</url>
    <content><![CDATA[<h1 id="数据结构专题2">数据结构专题2</h1>
<p>《算法笔记》第九章，数据结构专题2，主要涉及树、并查集、堆等。</p>
<span id="more"></span>
<h2 id="树和二叉树">树和二叉树</h2>
<p>树的基本定义：在数据结构中的树只有一个根结点，若干个节点和边，并且所有的节点是连通的且无闭环。</p>
<p>几个比较实用的性质：</p>
<ul>
<li>树可以是空的，此时连根结点都没有，叫做空树。</li>
<li>树的层次layer，是从根结点作为第一层开始计算的，依次递增。</li>
<li>结点的子树数量叫做度degree，注意不计算空树。结点的最大度数看做是树的度数，叫做宽度。</li>
<li>树中的边只能连接两个结点，因此，对于有<span class="math inline">\(n\)</span>个结点的树，一定有<span class="math inline">\(n-1\)</span>个边。如果有<span class="math inline">\(n\)</span>个相互连通的结点，并且有<span class="math inline">\(n-1\)</span>个边，那么一定是一棵树。</li>
<li>叶子结点是度为0的结点。</li>
<li>节点的深度是从根结点深度为1开始算起到该节点的层数；节点的高度是从最底层的叶子结点到该节点的层数。类似于树的宽度定义，树的深度是结点的最大深度，树的高度是根结点的高度。</li>
<li>多棵树组合在一起叫做森林forest。</li>
</ul>
<p>二叉树的递归定义：</p>
<ol type="1">
<li>二叉树可以是空树（没有根结点）；</li>
<li>二叉树由根结点、左子树、右子树组成。左右子树都是二叉树；</li>
</ol>
<p>二叉树一定是度为2的树，但是度为2的树不一定是二叉树，因为二叉树的左右子树是严格区分的，不能互换。</p>
<p>两种特殊的二叉树：</p>
<ol type="1">
<li>满二叉树：除去叶子结点外，所有的节点的左右子树都是满的（即树的每一层都是满的，包括最底层）</li>
<li>完全二叉树：除去最底层外，所有层都是满结点的；并且最底层的叶子结点从左到右是连续的。</li>
</ol>
<p>二叉树的存储，一般的二叉树使用链表来定义（对于完全二叉树可以使用数组来定义）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">	<span class="keyword">typename</span> data;</span><br><span class="line">  Node * lchild; <span class="comment">// lchild == NULL表示左子树为空</span></span><br><span class="line">  Node * rchild; <span class="comment">// rchild == NULL表示右子树为空</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 定义一棵空树</span></span><br><span class="line">Node * root = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure>
<p>新建一个结点，但是还未加入到树中，具体要增加到树的哪个地方依赖于之后的具体二叉树的性质。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Node * <span class="title">newNode</span> <span class="params">(<span class="keyword">int</span> data)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// c语言和c++两种创建方式</span></span><br><span class="line">  Node * node = <span class="keyword">new</span> Node;</span><br><span class="line">  Node * node = (Node*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(Node));</span><br><span class="line">  node-&gt;data = data;</span><br><span class="line">  node-&gt;lchild = node-&gt;rchild = <span class="literal">NULL</span>;</span><br><span class="line">  <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>二叉树的查找与修改：查找到所有满足查询条件的结点，并且可以修改数据</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 下面的代码是从左开始的DFS</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">search</span><span class="params">(Node* current_root, <span class="keyword">int</span> x, <span class="keyword">int</span> new_data)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (current_root==<span class="literal">NULL</span>) <span class="keyword">return</span>; <span class="comment">// 空树返回</span></span><br><span class="line">  <span class="keyword">if</span> (current_root-&gt;data == x)</span><br><span class="line">    current_root-&gt;data = new_data;</span><br><span class="line">  <span class="comment">// 继续查询左子树</span></span><br><span class="line">  search(current_root-&gt;lchild, x, new_data);</span><br><span class="line">  <span class="comment">// 查询右子树</span></span><br><span class="line">  search(current_root-&gt;rchild, x, new_data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>二叉树的插入依赖于具体二叉树的性质，但是一般来说，二叉树的插入就是在不满足某种条件的位置，并且这个位置一般是确定唯一的，否则就会有多个位置适合插入了。</p>
<p>下面是一个二叉树插入新结点的伪代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 下面的函数需要特殊注意，current_root是引用形式，这样方便直接修改传入的root值</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(Node* &amp;current_root, <span class="keyword">int</span> new_data)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(current_root==<span class="literal">NULL</span>) &#123;</span><br><span class="line">		root = newNode(new_data); <span class="comment">// 没有找到合适位置，就是目前的空树插入新结点</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (根据new_data和目前节点的数据判断发现应该插入到左子树) &#123;</span><br><span class="line">    insert(current_root-&gt;lchild, new_data);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123; <span class="comment">// 根据new_data和目前节点的数据判断发现应该插入到右子树</span></span><br><span class="line">    insert(current_root-&gt;rchild, new_data);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>二叉树的创建，就是重复上面的插入函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Node* <span class="title">create</span><span class="params">(<span class="keyword">int</span> data[], <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  Node* root = <span class="literal">NULL</span>; <span class="comment">// 注意不能new Node，这样就不是空树了</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n ; i++) &#123;</span><br><span class="line">    insert(root, data[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> root;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面是一般的二叉树存储，对于完全二叉树，在元素数量不多的情况下，可以直接使用数组存储。</p>
<p>将根结点放在数据的位置<span class="math inline">\(1\)</span>，不能从<span class="math inline">\(0\)</span>开始存放，否则会丧失下面的规律：</p>
<p>对于结点<span class="math inline">\(i\)</span>，它的左子树位置一定是<span class="math inline">\(2i\)</span>，右子树位置是<span class="math inline">\(2i+1\)</span>。</p>
<p>判断是否是叶子结点，该结点的左子树位置超过了树的结点数量<span class="math inline">\(n\)</span>。</p>
<h2 id="二叉树的遍历">二叉树的遍历</h2>
<p>这里讨论二叉树的四种遍历方法：</p>
<ul>
<li>先序遍历：根结点、左子树、右子树</li>
<li>中序遍历：左子树、根结点、右子树</li>
<li>后序遍历：左子树、右子树、根结点</li>
<li>层序遍历：BFS，访问同一层的结点结束后，再访问下一层</li>
</ul>
<p>在上面的遍历过程中，可以发现，总是先访问左子树，再访问右子树。</p>
<p>下面是先序遍历的函数</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">preSearch</span><span class="params">(Node* root)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(root==<span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, root-&gt;data);</span><br><span class="line">  preSearch(root-&gt;lchild);</span><br><span class="line">  preSearch(root-&gt;rchild);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 中序与后序遍历就是上面代码的顺序改变下即可</span></span><br></pre></td></tr></table></figure>
<p>层序遍历，利用到之前学的使用队列实现BFS</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">layerSearch</span><span class="params">(Node* root)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">queue</span>&lt;Node*&gt; q; <span class="comment">// 注意是结点指针的队列</span></span><br><span class="line">  q.push(root);</span><br><span class="line">  <span class="keyword">while</span>(!q.empty()) &#123;</span><br><span class="line">    Node* tmp_node = q.front();</span><br><span class="line">    q.pop();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, tmp_node-&gt;data);</span><br><span class="line">    <span class="comment">// 左右子树入队</span></span><br><span class="line">    q.push(tmp_node-&gt;lchild);</span><br><span class="line">    q.push(tmp_node-&gt;rchild);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先序、中序以及后序遍历的作用在于，可以根据先序+中序或者后序+中序的输出，来唯一的重建树。先序或者后序都可以确定当前序列的根结点（第一位或者最后一位），然后结合中序就可以找到左右子树。</p>
<p>利用先序+中序重建树，如果两者对应的序列数组是<span class="math inline">\([preL, preR]\)</span>和<span class="math inline">\([inL, inR]\)</span>，那么根结点是<span class="math inline">\(preL\)</span>位置的元素，根据根结点寻找根结点在中序中的位置假设为<span class="math inline">\(k\)</span>，那么对应的左子树的先序和中序序列是<span class="math inline">\([preL+1, preL+k-inL]\)</span>，<span class="math inline">\([inL, k-1]\)</span>；右子树的先序序列是<span class="math inline">\([preL+k-inL+1, preR]\)</span>，中序序列是<span class="math inline">\([k+1, inR]\)</span>。</p>
<p>使用递归的方式就可以实现重建树。</p>
<p>二叉树也可以使用数组的方式来实现，指针变为数组的下标，左右子树都指向数组的下标，同时，如果是空树就设为-1，这里不赘述具体实现。</p>
<h2 id="树的遍历">树的遍历</h2>
<p>一般的树有多个子结点，并且不限制左右树顺序。</p>
<p>对于多个子树，当然可以使用链表来保存，但是有些麻烦，这里按照书上的说明统一使用静态写法，</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">  <span class="keyword">typename</span> data;</span><br><span class="line">  <span class="built_in">vector</span> child;</span><br><span class="line">&#125; node[maxn];</span><br></pre></td></tr></table></figure>
<p>创建新结点的办法，类似与前面的静态二叉树：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> index = <span class="number">0</span>; <span class="comment">// 记录当前的新元素在tree数组中的位置，index下没有数据</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">newNode</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">	node[index].data = x;</span><br><span class="line">  node[index].child.clear();</span><br><span class="line">  <span class="keyword">return</span> index++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉查找树bst">二叉查找树（BST）</h2>
<p>二叉查找树就是满足左子树中的元素都<span class="math inline">\(&lt;=\)</span>根结点，右子树都<span class="math inline">\(&gt;\)</span>根结点的二叉树。当然，<span class="math inline">\(==\)</span>根结点的元素到底在哪颗子树存放可以看题目的具体要求。</p>
<p>bst的查找：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Node* <span class="title">search</span><span class="params">(Node* root, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(root==<span class="literal">NULL</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  <span class="keyword">if</span>(x==root-&gt;data) &#123;</span><br><span class="line">    <span class="keyword">return</span> root;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (x&lt;root-&gt;data) <span class="keyword">return</span> search(root-&gt;lchild, x);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> search(root-&gt;rchild, x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>bst的插入：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(Node* &amp;root, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(root==<span class="literal">NULL</span>) &#123;</span><br><span class="line">    node = <span class="keyword">new</span> Node;</span><br><span class="line">    node-&gt;data = x;</span><br><span class="line">    node-&gt;lchild = node-&gt;rchild = <span class="literal">NULL</span>;</span><br><span class="line">    root = node;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (x&lt;=root-&gt;data) insert(root-&gt;lchild, x);</span><br><span class="line">  <span class="keyword">else</span> insert(root-&gt;rchild, x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>bst的删除比较特殊，主要是涉及如何让结点被删除后，以该结点为根结点的整棵树还能够保证原来二叉查找树的性质。</p>
<p>有两种办法：用该结点的前驱或者后继来替换该结点。</p>
<ul>
<li>前驱：某个节点左子树中的最大结点，在树上表现为左子树的最右结点（可能有自己的左子树）</li>
<li>后继：某个结点右子树中的最小结点，在树上表现为右子树的最左结点（可能有自己的右子树）</li>
</ul>
<p>寻找前驱和后继：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 寻找某棵树的最大结点</span></span><br><span class="line"><span class="function">Node * <span class="title">findMax</span><span class="params">(Node* root)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(root!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">    root = root-&gt;rchild;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">Node* preMaxNode = findMax(root-&gt;lchild);</span><br><span class="line"><span class="comment">// 寻找某棵树的最小结点</span></span><br><span class="line"><span class="function">Node * <span class="title">findMin</span><span class="params">(Node* root)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(root!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">    root = root-&gt;lchild;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">Node* postMinNode = findMin(root-&gt;rchild);</span><br></pre></td></tr></table></figure>
<p>bst的删除操作：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteNode</span><span class="params">(Node* &amp;root, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(root==<span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">if</span>(root-&gt;data == x) &#123;</span><br><span class="line">    <span class="comment">// 如果要删除的结点是叶子结点</span></span><br><span class="line">    <span class="keyword">if</span>(root-&gt;lchild == <span class="literal">NULL</span> &amp;&amp; root-&gt;rchild==<span class="literal">NULL</span>) &#123;</span><br><span class="line">      <span class="keyword">delete</span>(root);</span><br><span class="line">      root=<span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 寻找前驱</span></span><br><span class="line">    <span class="keyword">if</span>(root-&gt;lchild != <span class="literal">NULL</span>) &#123;</span><br><span class="line">      Node* preMaxNode = findMax(root-&gt;lchild);</span><br><span class="line">      root-&gt;data = preMaxNode-&gt;data; <span class="comment">// 替换为前驱</span></span><br><span class="line">      deleteNode(preMaxNode, preMaxNode-&gt;data); <span class="comment">// 删除前驱</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      Node* postMinNode = findMin(root-&gt;rchild);</span><br><span class="line">      root-&gt;data = postMinNode-&gt;data; <span class="comment">// 替换为后继</span></span><br><span class="line">      deleteNode(postMinNode, postMinNode-&gt;data); <span class="comment">// 删除后继</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(root-&gt;data &lt; x) &#123;</span><br><span class="line">    deleteNode(root-&gt;rchild, x);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    deleteNode(root-&gt;lchild, x);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="平衡二叉树avl">平衡二叉树（AVL）</h2>
<p>平衡二叉树是对于前面二叉查找树的改进，“平衡“的意思是保证左右子树的高度差不超过1，这样总能够保证找寻所需元素时的搜索效率在<span class="math inline">\(O(log(n))\)</span>内。</p>
<p>平衡二叉树是两位前苏联的数学家提出来的，取他们名的大写字母命名为AVL树。在AVL树中的每个结点会额外记录一下当前结点的高度，同时利用左右子树的结点高度差<span class="math inline">\(左子树高度-右子树高度\)</span>，可以可以计算当前结点的<em>平衡因子</em>。</p>
<p>AVL树的难点在于插入与删除，一个结点的定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> data;</span><br><span class="line">  <span class="keyword">int</span> height; <span class="comment">// 默认为1</span></span><br><span class="line">  Node* lchild, rchild;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>新建结点</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Node* <span class="title">newNode</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  Node* node = <span class="keyword">new</span> Node;</span><br><span class="line">  node-&gt;data = x;</span><br><span class="line">  node-&gt;height = <span class="number">1</span>; <span class="comment">// 新增的定义</span></span><br><span class="line">  node-&gt;lchild = node-&gt;rchild = <span class="literal">NULL</span>;</span><br><span class="line">  <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>查询当前结点的高度与计算平衡因子</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getHight</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> node-&gt;height;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getBalanceFactor</span><span class="params">(Node * node)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> getHeight(node-&gt;lchild) - getHeight(node-&gt;rchild);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>更新节点高度</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">updateHeight</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  node-&gt;height = max(getHeight(node-&gt;lchild), getHeight(node-&gt;rchild)) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AVL树的查询操作，与一般的BST树一样，这里不重复叙述。</p>
<p>AVL树的插入操作，比较复杂，需要考虑在插入新结点后，如何保持”平衡“？这里有两种办法调整当前树的左右子树高度，<em>左旋</em>和<em>右旋</em>：</p>
<ul>
<li>左旋：通过旋转，让当前根结点变为原来右子树根结点的左结点，原来右子树根结点成为新根结点</li>
<li>右旋：通过旋转，让当前根结点变为原来左子树根结点的右结点，原来左子树根结点成为新根结点</li>
</ul>
<p>详细的旋转过程可以参考《算法笔记》上的图示，这里提供代码，核心思想在于：</p>
<ul>
<li>左旋：当前根结点变为新的左结点，当前根结点的右子树链接到右结点（新根结点）的左子树</li>
<li>右旋：当前根结点变为新的右结点，当前根结点的左子树链接到左结点（新根结点）的右子树</li>
</ul>
<p>代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 左旋</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">L</span><span class="params">(Node* &amp;root)</span> </span>&#123;</span><br><span class="line">  Node * tmp = root-&gt;rchild; <span class="comment">// 新根结点是原右子树</span></span><br><span class="line">  root-&gt;rchild = tmp-&gt;lchild; <span class="comment">// 当前根结点右子树变为原右子树的左子树</span></span><br><span class="line">  tmp-&gt;lchild = root; <span class="comment">// 新根结点的左子树是原根结点</span></span><br><span class="line">  updateHeight(root); <span class="comment">// 先更新新树的子树</span></span><br><span class="line">  updateHeight(tmp); <span class="comment">// 然后更新根结点</span></span><br><span class="line">  root = tmp; <span class="comment">// 将root改为新的根结点</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 右旋</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">R</span><span class="params">(Node* &amp;root)</span> </span>&#123;</span><br><span class="line">  Node * tmp = root-&gt;lchild; <span class="comment">// 新根结点是原左子树</span></span><br><span class="line">  root-&gt;lchild = tmp-&gt;rchild; <span class="comment">// 当前根结点左子树变为原左子树的右子树</span></span><br><span class="line">  tmp-&gt;rchild = root; <span class="comment">// 新根结点的右子树是原根结点</span></span><br><span class="line">  updateHeight(root); <span class="comment">// 先更新新树的子树</span></span><br><span class="line">  updateHeight(tmp); <span class="comment">// 然后更新根结点</span></span><br><span class="line">  root = tmp; <span class="comment">// 将root改为新的根结点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来可以讨论AVL树插入新元素的操作了。当AVL树插入新结点后，可能造成左子树比右子树高<span class="math inline">\(2\)</span>，或者是右子树比左子树高<span class="math inline">\(2\)</span>。一共有四种可能（更详细的讨论在书上）：</p>
<ol type="1">
<li>LL型：左子树高-&gt;左子树的左子树高；右旋根结点解决</li>
<li>LR型：左子树高-&gt;左子树的右子树高；先左旋左子树，后右旋根结点</li>
<li>RR型：右子树高-&gt;右子树的右子树高；左旋解决</li>
<li>RL型：右子树高-&gt;右子树的左子树高；右旋右子树，后左旋根结点</li>
</ol>
<p>插入操作的代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(Node* &amp;root, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (root==<span class="literal">NULL</span>) &#123;</span><br><span class="line">    root = newNode(x);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(root-&gt;data &gt; x) &#123; <span class="comment">// 插入到左子树</span></span><br><span class="line">    insert(root-&gt;lchild, x);</span><br><span class="line">    updateHeight(root);</span><br><span class="line">    <span class="keyword">if</span>(getBalanceFactor(root) == <span class="number">2</span>) &#123; <span class="comment">// 如果左子树失衡了，因为是递归，总能保证从下往上调整失衡树</span></span><br><span class="line">			<span class="keyword">if</span>(getBalanceFactor(root-&gt;lchild) == <span class="number">1</span>) &#123; <span class="comment">// LL型</span></span><br><span class="line">        R(root);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(getBalanceFactor(root-&gt;lchild) == <span class="number">-1</span>) &#123; <span class="comment">// LR型</span></span><br><span class="line">        L(root-&gt;lchild);</span><br><span class="line">        R(root);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123; <span class="comment">// 插入右子树</span></span><br><span class="line">    insert(root-&gt;rchild, x);</span><br><span class="line">    updateHeight(root);</span><br><span class="line">    <span class="keyword">if</span>(getBalanceFactor(root) == <span class="number">-2</span>) &#123; <span class="comment">// 如果左子树失衡了</span></span><br><span class="line">			<span class="keyword">if</span>(getBalanceFactor(root-&gt;rchild) == <span class="number">1</span>) &#123; <span class="comment">// RL型</span></span><br><span class="line">        R(root-&gt;child);</span><br><span class="line">        L(root);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(getBalanceFactor(root-&gt;rchild) == <span class="number">-1</span>) &#123; <span class="comment">// RR型</span></span><br><span class="line">        L(root);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AVL树的删除，书上没有提及。</p>
<h2 id="并查集">并查集</h2>
<p>并查集是一种维护集合的数据结构，主要针对合并、查找与集合三个单词。</p>
<p>并查集的实现就是一个数组，</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> father[N];</span><br></pre></td></tr></table></figure>
<p><code>father[i]</code>指的是元素<code>i</code>的父亲结点。在并查集中，一个集合只有一个结点满足<code>father[i]=i</code>，叫做根结点，把这个根结点看做是集合的标志。</p>
<p>并查集支持的操作，</p>
<p>初始化：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;n;++i) &#123;</span><br><span class="line">  father[i] = i; <span class="comment">// 初始化时，默认每个结点的父结点都是自身</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>查找当前集合的根结点：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findFather</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(father[i]!=i) &#123;</span><br><span class="line">    i = father[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>合并操作，如果两个元素实际是属于同一集合，就合并这两个元素分属的两集合的根结点，只保留一个根结点：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Union</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> fatherX = findFather(x);</span><br><span class="line">  <span class="keyword">int</span> fatherY = findFather(y);</span><br><span class="line">  <span class="keyword">if</span>(fatehrX!=fatherY) &#123;</span><br><span class="line">    father[fatherX] = fatherY; <span class="comment">// 集合X的根结点变换为集合Y的根结点</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>路径压缩操作，是一种简化<code>father</code>数组，从而提高寻找根结点效率的方法，直接让<code>father[i]</code>指向根结点，而不是父结点。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findFather</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> tmp = i;</span><br><span class="line">  <span class="keyword">while</span>(father[i]!=i) &#123;</span><br><span class="line">    i = father[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 此时i是根结点，在此从i结点出发，逐次修改结点的父结点为根结点</span></span><br><span class="line">  <span class="keyword">while</span>(father[tmp]!=tmp) &#123;</span><br><span class="line">    <span class="keyword">int</span> current_node = tmp;</span><br><span class="line">    tmp = father[tmp];</span><br><span class="line">    father[current_node] = i;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="堆">堆</h2>
<p>堆是一课完全二叉树。它区别于BST和AVL的是，它只规定根结点要<code>&gt;=</code>或者<code>&lt;=</code>两个结点，根结点是当前树最大值的完全二叉树叫做大顶堆，反之叫做小顶堆。</p>
<p>如果现在我们已经有一棵完全二叉树，如何把它调整为一个大顶堆？</p>
<p>原则是从右到左，从下到上依次检查当前结点是否满足条件：</p>
<ul>
<li>叶子结点无需调整</li>
<li>非叶子结点，将当前根结点与左、右子结点的最大值进行比较，如果当前根结点已经是最大值就无需变动；否则就互换，互换之后，由于左右子树在之前的调整过程中已经保证了大顶堆，那么新的根结点一定是最大值，只需要继续让被换以后的根结点与下一级子树进行比较即可。重复这个过程，直至无需再调整位置。</li>
</ul>
<p>类似的，如果我们想新建一个小顶堆，只需要总是寻找根结点、左、右结点中的最小值即可，整体过程与上述过程类似。</p>
<p>从代码的角度分析，如何实现大顶堆？按照之前的讨论，完全二叉树可以使用根结点在位置<span class="math inline">\(1\)</span>的数组进行存储。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxn = <span class="number">110</span>;</span><br><span class="line"><span class="keyword">int</span> heap[maxn]; <span class="comment">// 堆</span></span><br></pre></td></tr></table></figure>
<p>实现下上面的调整过程，让当前位置的<span class="math inline">\(i\)</span>一直向下调整。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// high一般为n</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">downAdjust</span><span class="params">(<span class="keyword">int</span> low, <span class="keyword">int</span> high)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i = low, child = <span class="number">2</span> * i;</span><br><span class="line">  <span class="keyword">while</span>(child &lt;= high) &#123;</span><br><span class="line">    <span class="keyword">if</span>(child+<span class="number">1</span> &lt;= high &amp;&amp; heap[child] &lt; heap[child]) &#123;</span><br><span class="line">      child = lchild + <span class="number">1</span>; <span class="comment">// 寻找child中的最大值，此时为右结点</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(heap[i]&gt;=heap[child]) </span><br><span class="line">      <span class="keyword">break</span>; <span class="comment">// 如果当前根结点已经保证是最大值，退出</span></span><br><span class="line">    swap(heap[i], heap[child]);</span><br><span class="line">    <span class="comment">// 交换位置后，继续遍历子树</span></span><br><span class="line">    i = child;</span><br><span class="line">    child = <span class="number">2</span> * child;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>建堆过程，从最右边，最低层的非叶子结点开始遍历，逐个执行上述函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createHeap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 如果完全二叉树有n个结点，那么非叶子结点有 取下限(n/2) 个</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = n/<span class="number">2</span>; i&gt;=<span class="number">1</span>; i--) &#123;</span><br><span class="line">    downAdjust(i, n);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>删除堆顶元素，让最末端的叶子结点替换堆顶元素，然后执行向下调整</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteTop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  heap[<span class="number">1</span>] = heap[n--];</span><br><span class="line">  downAdjust(<span class="number">1</span>, n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>新增元素，让新元素放在堆的最末端，然后执行从下到上的调整</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// low一般为1， high是当前要进行向上调整的元素</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">upAdjust</span><span class="params">(<span class="keyword">int</span> low, <span class="keyword">int</span> high)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i = high, parent = high / <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">while</span>(high&gt;=low) &#123;</span><br><span class="line">    <span class="keyword">if</span> (heap[parent]&gt;=heap[i]) </span><br><span class="line">      <span class="keyword">break</span>; <span class="comment">// 父亲结点已经比当前结点大，无需再调整</span></span><br><span class="line">    swap(heap[parent], heap[i]);</span><br><span class="line">    i = parent;</span><br><span class="line">    parent = parent / <span class="number">2</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  heap[++n] = x;</span><br><span class="line">  upAdjust(<span class="number">1</span>, n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>堆的基本元素讲完后，我们可以使用堆来实现堆排序，下面是一个实现从小到大递增排序的例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">heapSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 建好堆之后，每次把堆顶元素和最末端的元素互换，然后执行向下调整</span></span><br><span class="line">  crateHeap();</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = n; i&gt;<span class="number">1</span>; --i) &#123;</span><br><span class="line">    swap(heap[<span class="number">1</span>], heap[i]);</span><br><span class="line">    downAdjust(<span class="number">1</span>, i<span class="number">-1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="哈夫曼树">哈夫曼树</h2>
<p>哈夫曼树的构建方法：</p>
<ul>
<li>初始状态的n个结点看做是单独的n个二叉树</li>
<li>选择根结点值最小的两个结点进行合并，生成新的父结点，父结点的值是两个结点的和</li>
<li>重复上述过程，直至形成一棵完整的二叉树</li>
</ul>
<p>叶子结点的权值<span class="math inline">\(\times\)</span>根结点该叶子结点的路径长度，叫做改叶子结点的带权路径长度。一棵二叉树的带权路径长度Weight Path Length of tree（WPL）是所有叶子结点带权路径长度的和。哈夫曼树是满足一组叶子结点，带权路径长度最小的树。在建立哈夫曼树的过程中，能够保证哈夫曼树的WPL是最小的，但是可能存在多个哈夫曼树，比如可能同时存在多个相同的最小值结点。</p>
<p>哈夫曼树用来计算某个值的时候，可以考虑使用优先队列/小顶堆，每次取出最小的两个值合并后再入队。</p>
<p>现在考虑给字符用01编码的问题，如果随便给字符编码，就可能导致某个叶子结点的编码是另一个叶子结点编码的前缀，这样在使用这种编码过程的时候就可能出现问题。如果任一字符的编码都不是另一字符的编码前缀，这种编码方式叫做前缀编码。</p>
<p>对于这种情况，可以使用任意一棵二叉树，根结点到叶子结点的路径（左子树0，右子树1）作为该叶子结点的编码。它能够满足前缀编码的要求。</p>
<p>但是，另一个问题是如果我们希望一段字符串的01编码长度最小呢？这就可以使用哈夫曼编码来解决，统计字符串中各个字符的出现次数作为权值，然后建立哈夫曼树，就能够保证最后字符串的编码一定是最短的。</p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>8-search</title>
    <url>/algorithm-note/8-search/</url>
    <content><![CDATA[<h1 id="搜索专题">搜索专题</h1>
<p>《算法笔记》第8章搜索专题，包括BFS和DFS。</p>
<span id="more"></span>
<h2 id="深度优先搜索">深度优先搜索</h2>
<p>Depth first search（DFS），以深度作为首要因素，每次都遍历一条完整的路径，然后返回上一层的岔路口，继续进行深度的遍历。</p>
<p>假设是在一个迷宫当中寻找出口，那么DFS的意思是每次找到一个岔路口，做个标记，然后找第一条岔路，往下走，找不到出口就回来，继续下一条岔路。对于岔路口的标记属于越往后出现的岔路，越是会被首先回顾，这个是属于栈的思想。</p>
<p>在实现的时候，我们可以使用递归的方式。对于递归的子函数，新生成的子函数会被首先返回，递归的实现本身就依赖于系统栈。</p>
<p>DFS的伪代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DFS</span><span class="params">(<span class="keyword">int</span> depth, <span class="keyword">int</span> args)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 对当前的depth进行某些题目需要的操作，判断是否满足条件，比如是否越界，是否找到迷宫的出口等等</span></span><br><span class="line">  <span class="keyword">if</span> (depth==MAX_DEPTH) <span class="keyword">return</span>;</span><br><span class="line">  <span class="comment">// 开始遍历岔路，不同的岔路深度是一样的，区别在于其它和题目相关的条件</span></span><br><span class="line">  DFS(depth+<span class="number">1</span>, args1);</span><br><span class="line">  DFS(depth+<span class="number">1</span>, args2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="广度优先搜索">广度优先搜索</h2>
<p>Breadth first search（BFS），以广度作为第一关键词，它访问当前岔路口的所有岔路，而不是顺着某一条岔路继续走下去。</p>
<p>因此，在实现的时候，就不能再采用DFS以递归为途径的遍历手段。还是以迷宫为背景，假设我们希望找到最短的路径是什么。对于当前到达的岔路口S，依次访问岔路A、岔路B、岔路C....，如果都不满足条件，再顺着岔路A的下一个岔路继续走。可以看出来，这个实际是队列的思想，把当前路口的所有岔路入队，然后依次出队，对于出队的岔路，把它的子岔路再入队等待后续的访问。</p>
<p>BFS的伪代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BFS</span><span class="params">(<span class="keyword">int</span> data, <span class="keyword">int</span> args)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">queue</span>&lt;node&gt; q; <span class="comment">// BFS需要用到的队列</span></span><br><span class="line">  <span class="comment">// 创建队首元素</span></span><br><span class="line">  node * n = <span class="keyword">new</span> node;</span><br><span class="line">  n.data = data;</span><br><span class="line">  q.push(n);</span><br><span class="line">  <span class="keyword">while</span>(!q.empty()) &#123;</span><br><span class="line">    <span class="comment">// 当前的队首元素出队</span></span><br><span class="line">    node n_tmp = q.front();</span><br><span class="line">    q.pop();</span><br><span class="line">    <span class="comment">// 进行某些判断，例如求和，是否超出边界等</span></span><br><span class="line">    <span class="comment">// n_tmp的所有子结点入队</span></span><br><span class="line">    <span class="keyword">while</span>(n_tmp的所有子结点) &#123;</span><br><span class="line">      q.push()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>MLP-Mixer</title>
    <url>/cv/MLP-Mixer/</url>
    <content><![CDATA[<h1 id="mlp-mixer-an-all-mlp-architecture-for-vision">MLP-Mixer: An all-MLP Architecture for Vision</h1>
<p>2021-5-4</p>
<p>谷歌大脑团队的新作<a href="https://github.com/google-research/vision_transformer">MLP-Mixer</a>，使用纯MLP进行CV任务，没有超越目前业界SOTA，但是效果很不错。最关键的是只使用了MLP，便于部署。同时要注意，该模型训练使用了TPU3.0，外加众多training skills，model size也很大，不是个人可以玩儿转的。</p>
<span id="more"></span>
<blockquote>
<p>Convolutional Neural Networks (CNNs) are the go-to model for computer vision. Recently, attention-based networks, such as the Vision Transformer, have also become popular. In this paper we show that while convolutions and attention are both sufﬁcient for good performance, neither of them are necessary. <strong>We present MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).</strong> MLP-Mixer contains two types of layers: one with MLPs applied independently to image patches (i.e. “mixing” the per-location features), and one with MLPs applied across patches (i.e. “mixing” spatial information). When trained on large datasets, or with modern regularization schemes, MLP-Mixer attains competitive scores on image classiﬁcation benchmarks, with pre-training and inference cost comparable to state-of-the-art models. We hope that these results spark further research beyond the realms of well established CNNs and Transformers.1</p>
</blockquote>
<h2 id="introduction">1 Introduction</h2>
<p>CNN是CV领域目前de-facto标准，近期的transformers-like的模型Vision Transformers (ViT)，也得到了SOTA的结果。</p>
<h2 id="mixer-architecture">2 Mixer Architecture</h2>
<p>本文提出了MLP-Mixer，完全使用MLP的架构。看一下整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210507150754155.png" style="zoom:50%;" /></p>
<p>接收的输入固定size的，将输入划分为一系列的patch，然后所有的patch经过一个投影层，进入核心的Mixer层。</p>
<p>对于Mixer层，由两个不同的MLP组成，加上layer norm和GELU</p>
<ul>
<li><p>token-mixing：不同patch的相同维度，应该如何产生输出</p>
<blockquote>
<p>The token-mixing MLPs allow communication between different spatial locations (tokens); they operate on each channel independently and take individual columns of the table as inputs.</p>
</blockquote></li>
<li><p>channel-mising：相同patch不同channel，应该如何产生输出</p>
<blockquote>
<p>The channel-mixing MLPs allow communication between different channels; they operate on each token independently and take individual rows of the table as inputs.</p>
</blockquote></li>
</ul>
<p>写成公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210507145147282.png" style="zoom:50%;" /></p>
<p>两个MLP的操作区别就是对于输入简单的转置操作。</p>
<p>另外，MLP-Mixer保持MLP的输出dim都是固定的。</p>
<ul>
<li>channel-mixing MLPs对于不同patch的处理是一样的，这提供了位置不变性，it provides positional invariance, a prominent feature of convolutions.</li>
<li>token-mixing MLPs是跨patch，对于所有的channel使用相同的kernel，这点是和很多CNN模型有区别的。它带来的一个好处是不会随着channel的增加而增加参数量。另外，token-mixing MLPs是对输入patch的位置有感知的。一个patch的位置发生变化，对于channel-mixing来说，没有区别。但是对于token-mixing来说，patch位置变动在参数不变的情况下，会导致输出会发生变化，最终参数也会更新。所以它隐式的可以学习位置的表示。</li>
</ul>
<h2 id="experiments">3 Experiments</h2>
<p>没有细看，很多细节都不了解，看不懂。</p>
<p>总结一下：</p>
<ol type="1">
<li>至少8层起步的MLP，也就是至少16层全连接；另外，MLP的size都是很大的，256size起步</li>
<li>使用了非常多的训练技巧！！</li>
<li>使用了谷歌的TPU 3.0，1小时8$</li>
<li>先预训练，再fine-tuning，但没看过CV paper，不理解为什么这么做</li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
        <category>ML</category>
      </categories>
  </entry>
  <entry>
    <title>ResNet</title>
    <url>/cv/ResNet/</url>
    <content><![CDATA[<h1 id="deep-residual-learning-for-image-recognition">Deep Residual Learning for Image Recognition</h1>
<p>深度残差网络，将CNN拓展到152层乃至更深层，同时表现出更好效果的里程碑文章。核心是将residual connection代入到深层CNN中，使得深层的模型效果不比浅层的模型效果差。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220324174625698.png" alt="image-20220324174625698" style="zoom:50%;" /></p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<h3 id="problem">Problem</h3>
<p>作者认为在CNN中，搭建deep的model能够捕获更高level的特征，最后表现出更好的效果。但是如果model越来越深，导致的问题就是可能出现梯度消失或者梯度爆炸的问题。这个问题被初始值正则化和正则化层所解决。</p>
<p>但是没有解决另外的一个问题，那就是深度的model效果比浅层的model效果还要差，出现了degradation问题，如图所示。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220324175027867.png"  style="zoom:50%;" /></p>
<h3 id="solution">Solution</h3>
<p>作者提出，理论上来看，一个更深的模型不应该比一个浅层的模型效果差。因为一个深层的模型，如果所有深的layer的操作都是identity mapping，即什么都不做，那么效果至少应该和浅层的模型效果相近。</p>
<p>但实际不是这样，因为单纯的非线性层，可能比较难训练出这样的identity mapping。虽然理论上多层感知器都能够逼近任意的函数，但是学习的困难程度可能是不一样的，可能需要某种人为的引导降低训练难度。</p>
<p>因此，作者提出对于深层，不再直接学习理想的映射<span class="math inline">\(\mathcal{H}(\mathbf{x})\)</span>，<span class="math inline">\(\mathbf{x}\)</span>表示浅层的输出，而是让深层学习理想的映射<span class="math inline">\(\mathcal{H}(\mathbf{x})\)</span>减去<span class="math inline">\(\mathbf{x}\)</span>之后的残差<span class="math inline">\(\mathcal{F}(\mathbf{x})\)</span>： <span class="math display">\[
\mathcal{F}(\mathbf{x})=\mathcal{H}(\mathbf{x})-\mathbf{x}
\]</span> 这样，就可以反向获得<span class="math inline">\(\mathcal{H}(\mathbf{x})\)</span>，让<span class="math inline">\(\mathcal{H}(\mathbf{x})\)</span>再输入到后续的层级 <span class="math display">\[
\mathcal{H}(\mathbf{x}) = \mathcal{F}(\mathbf{x})+\mathbf{x}
\]</span> 也就是下面的图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220324174625698.png" alt="image-20220324174625698" style="zoom:50%;" /></p>
<p>这里作者使用了一个shortcut connection，这并不是什么特别的操作，比如之前在Highway network中，也有shortcut connection，但是Highway network中的shortcut connection是gate-based，本身是有自己的参数的。</p>
<p>但是作者定义这个shortcut connection是一个identity mapping：如果channel相同，直接相加；如果channel不同，可以通过1x1卷积或者padding 0或者线性转换，之后再相加。</p>
<h2 id="explanation">Explanation</h2>
<p>为什么ResNet能够训练深层的模型，最后效果更好呢？作者在原论文中没有提出详细的说明和解释，下面是<a href="https://www.bilibili.com/video/BV1P3411y7nn/?spm_id_from=333.788">李沐大神的课程</a>中的解释，主要是因为能够更好的传递梯度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220324181048718.png" alt="image-20220324181048718" style="zoom:30%;" /></p>
<p>可以看到，上面的式子中，原来的梯度是链式的相乘，后面的梯度额外增加了一个之前浅层<span class="math inline">\(\mathcal{g}{(\mathbf{x})}\)</span>对<span class="math inline">\(\mathbf{x}\)</span>的梯度，这样最后计算得到的梯度更大。因为一般情况下得到的梯度都是在0左右绝对值较小的值。</p>
<h2 id="deep-residual-learning">Deep Residual Learning</h2>
<p>先来看一下ResNet的结构细节：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220324180551759.png" alt="image-20220324180551759" style="zoom:50%;" /></p>
<p>这里需要注意的一点是，ResNet在layer到了50层的时候，每一层使用了bottleneck的设计，先使用1X1的卷积压缩通道数，然后再3X3卷积，最后再1X1卷积回来，目的是为了减小运算复杂度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220324180751368.png" alt="image-20220324180751368" style="zoom:40%;" /></p>
<p>最后直接看一下模型结构图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220324180457763.png" alt="image-20220324180457763" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
  </entry>
  <entry>
    <title>GNN-Collection</title>
    <url>/collection/GNN-Collection/</url>
    <content><![CDATA[<h1 id="collection-of-gnn-papers">Collection of GNN papers</h1>
<ul>
<li><a href="#highway-gnn">Highway GNN（ACL 2018）</a></li>
<li><a href="#hgsl">HGSL（AAAI 2021）</a></li>
<li>HGAT（EMNLP 2019）</li>
<li>HetGNN（KDD 2019）</li>
<li><a href="/gnn/HetSANN/" title="HetSANN">HetSANN</a>
（AAAI 2020）</li>
<li>RHINE（AAAI 2019）</li>
<li>JK（ICML 2018）</li>
<li>PATHCON（KDD 2021）</li>
<li>HeteGNN（WSDM 2021）</li>
<li>KGNN（IJCAI 2020）</li>
<li>CPRL（NAACL 2021）</li>
<li>CLHG（ACL 2021）</li>
<li>EAGCN（Neurocomputing）</li>
<li>ETGAT（ACL-IJCNLP 2021）</li>
<li>GAEAT（CIKM 2020）</li>
<li>M-GNN（IJCAI 2019）</li>
<li>RDGCN（IJCAI 2019）</li>
<li>SLiCE（WWW 2021）</li>
<li>M<sup>2</sup>GNN（WWW 2021）</li>
<li>LGNN（IJCAI 2021）</li>
<li>RevGNN（ICML 2021）</li>
</ul>
<span id="more"></span>
<h2 id="highway-gnn">Highway GNN</h2>
<p><a href="https://github.com/%20afshinrahimi/geographconv"><strong>Semi-supervised User Geolocation via Graph Convolutional Networks</strong></a> ACL 2018</p>
<p>应用场景是社交媒体上的用户定位。单纯的在GNN上的创新点是使用Gate机制来控制传入的邻居的信息。</p>
<p>在每一层，借鉴Highway networks的思路，计算一个门weight</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210708195301778.png" style="zoom:50%;" /></p>
<h2 id="hgsl">HGSL</h2>
<p><strong>Heterogeneous Graph Structure Learning for Graph Neural Networks</strong> AAAI 2021</p>
<a href="/gnn/HGSL/" title="[详细博客]">[详细博客]</a>
<p>作者声称是首个尝试为异质图神经网络寻找最优的图结构进行学习的方法，提出了HGSL（Heterogeneous Graph Structure Learning）。核心方法有两个，异质图结构学习和图神经网络。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706213222126.png" style="zoom:40%;" /></p>
<p><strong>motivation</strong>：目前的异质图神经网络基于一个假设，学习使用的graph是足够好的。但是实际上这个假设不一定总能够满足。两个方面的原因，（1）在建模graph的时候，使用到的信息难免会包含错误的信息，导致最终的graph是不够好的（2）另一个原因是异质图结构本身与下游任务是独立的，不一定是有利于下游任务的最优解。为了解决上面的问题，图结构学习graph structure learning (GSL)被提出来，但是这些方法主要是在考虑同质图，无法很好的考虑异质图中的异质性以及异质图中存在的复杂的交互。</p>
<p><strong>method</strong>：提出HGSL，首先学习合适的graph structure，然后在这个graph structure上使用GCN进行学习。这种heterogeneous graph structure learning是核心创新点，包括三种graph的融合，<strong>feature similarity graph</strong>，<strong>feature propagation graph</strong>,和<strong>semantic graph</strong>。</p>
<h2 id="hgat">HGAT</h2>
<p><strong>Heterogeneous Graph Attention Networks for Semi-supervised Short Text Classification</strong> EMNLP 2019</p>
<p>为短文本分类任务（semi-supervised short text classification）设计了一个异质图神经网络HGAT。</p>
<p>首先是利用原始文本构造一个异质图（HIN），把不同来源的文本组合到一起。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180026169.png"   style="zoom:50%;" /></p>
<p>重点在于，其中的node type各不相同，各自具有差异性很大的特征。</p>
<p>然后是设计的网络结构，重点在于设计了一个两层的attention。</p>
<p>不同type的node有不同的卷积核：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180219517.png"   style="zoom:50%;" /></p>
<p>然后，type-level的attention，聚合邻居下所有相同type的node embedding，然后计算attention weight。这样同一type下的所有neighbor node共享一个type level的weight。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180348109.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180319175.png"  style="zoom:50%;" /></p>
<p>不同type之间softmax。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180440793.png"   style="zoom:50%;" /></p>
<p>然后是node-level的attention，不同邻居node，计算attention。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180538577.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180555435.png"   style="zoom:50%;" /></p>
<p>最后结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210728180643981.png"  style="zoom:50%;" /></p>
<h2 id="hetgnn">HetGNN</h2>
<p><a href="https://github.com/chuxuzhang/KDD2019_HetGNN">Heterogeneous Graph Neural Network</a> KDD 2019</p>
<p>作者提出了一种同时处理node content和heterogeneous graph structure的GNN，HetGNN。</p>
<p>看一下整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210802205726358.png"   style="zoom:50%;" /></p>
<p>核心模块有三方面：</p>
<p><strong>Sampling Heterogeneous Neighbors</strong>：使用了random walk with restart (RWR)的邻居采样策略，需要注意的是这个采样策略保证对于node <span class="math inline">\(v\)</span>，能够采样到所有不同类型的邻居。然后相同类型的邻居聚合到一起。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210802205956510.png"   style="zoom:50%;" /></p>
<p><strong>Encoding Heterogeneous Contents</strong>：对于不同格式的content，使用不同的网络进行处理，然后使用Bi-LSTM进行融合，不同type的node有自己的Bi-LSTM网络。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210802210216977.png"   style="zoom:50%;" /></p>
<p><strong>Aggregating Heterogeneous Neighbors</strong>：对于相同类型的邻居，先基于Bi-LSTM进行聚合。然后不同类型的邻居基于attention进行聚合。</p>
<h2 id="hetsann">HetSANN</h2>
<a href="/gnn/HetSANN/" title="[个人详细博客]">[个人详细博客]</a>
<p><a href="https://github.com/didi/hetsann"><strong>An Attention-based Graph Neural Network for Heterogeneous Structural Learning</strong></a> AAAI 2020 HetSANN</p>
<p>提出了Heterogeneous Graph Structural Attention Neural Network (<a href="/gnn/HetSANN/" title="HetSANN">HetSANN</a>），主要创新点有三个：</p>
<ul>
<li>对于预测标签任务，采用多任务学习，不同type的节点进行预测有不同的classifier（实际是全连接层+softmax）</li>
<li>针对edge和reversed edge，除了一般的基于拼接的方法计算attention外，提出了voice-sharing product的计算注意力方法。</li>
<li>在不同type的邻居信息转换中，提出了一个保持weight matrix的cycle consistent的方法。</li>
</ul>
<p>看一下模型的整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193220627.png"   style="zoom:50%;" /></p>
<p>核心是一个注意力层，TAL层如图所示。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803194602158.png"   style="zoom:50%;" /></p>
<p>首先是基于type的邻居信息转化，node <span class="math inline">\(i\)</span> 提供给node <span class="math inline">\(j\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193433545.png"   style="zoom:50%;" /></p>
<p>然后基于注意力聚合邻居信息，下面的是一般的GAT的方法，作者叫做<em>concat product</em>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193632456.png"  style="zoom:50%;" /></p>
<p>需要注意的是，这里的注意力向量<span class="math inline">\(\alpha_r\)</span>，是每个edge type各有一个。然后就是基于softmax的attention聚合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193716164.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193733856.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193750622.png"   style="zoom:50%;" /></p>
<p>实际上，作者还提出了<em>voice-sharing</em>的注意力计算方法，主要是希望考虑关系和逆关系之间的对应联系。让注意力向量<span class="math inline">\(\alpha_r\)</span>​互为负数，然后利用相加计算注意力。详见博客。</p>
<h2 id="rhine">RHINE</h2>
<p><strong>Relation Structure-Aware Heterogeneous Information Network Embedding</strong> AAAI 2019</p>
<p>这篇文章不是GNN领域的文章，但是由于它也尝试捕获relation在结构上的角色，所以干脆放到一起了。</p>
<p>它核心创新点是把所有的relation划分为了两类：</p>
<ul>
<li>Afﬁliation Relations (ARs)：one-centeredby-another structures</li>
<li>Interaction Relations (IRs)：peer-to-peer structures</li>
</ul>
<p>划分的依据是作者根据不同relation的头尾节点类型的平均数量比，对于关系<span class="math inline">\(&lt;u,r,v&gt;\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210804154636282.png"   style="zoom:50%;" /></p>
<p>里面的<span class="math inline">\(\overline{d}_{t_u}\)</span>，<span class="math inline">\(t_u\)</span>表示的是头节点<span class="math inline">\(u\)</span>的类型，<span class="math inline">\(\overline{d}_{t_u}\)</span>是指这一类型下的所有节点的平均度degree。在这样的网络中，能够确定某个relation两边的entity type，所以可以这样评估。但是在KG中，无法确定entity的type，也就无法这样计算。</p>
<p><span class="math inline">\(D(r)\)</span>比较小的划分为IR关系，<span class="math inline">\(D(r)\)</span>比较大的划分为AR关系。</p>
<p>这样划分完之后，对于AR关系和IR关系使用两种不同的embedding model。</p>
<p>AR，直接评估两个点之间的欧氏距离。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210804155417686.png"  style="zoom:50%;" /></p>
<p>IR，借助TransE的思想，建模这种1-1的关系。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210804155434262.png"   style="zoom:50%;" /></p>
<h2 id="jk">JK</h2>
<p><strong>Representation Learning on Graphs with Jumping Knowledge Networks</strong> ICML 2018</p>
<p>作者认为一般GCN模型实际假定了为不同的node都学习固定范围/半径的邻居信息，这种情况下不一定是最优解。比如通常GCN只需要两层就达到了最优解，但是对于一个graph来说，有的node可能是tree-like的，两层邻居也只包含了很少的邻居信息，而有的node是expander-like core，两层邻居就包含了非常多的邻居信息。比如下面的GooglePlus社交网络：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210804172507196.png"   style="zoom:50%;" /></p>
<p>因此，作者希望设计一种方法能够实现adaptively adjust (i.e., learn) the inﬂuence radii for each node and task。提出了<em>Jumping Knowledge Networks (JK-Nets)</em>。</p>
<p>主要结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210804172641046.png"   style="zoom: 33%;" /></p>
<p>JUMP的意思是每一层输出都jump到最后一层，在最后一层进行layer aggregation。</p>
<p>作者提出三种方法</p>
<ul>
<li>Concatenation</li>
<li>Max-pooling</li>
<li>LSTM-attention：双向LSTM</li>
</ul>
<p>简单的论文的实验结果看，前两个方法还不错，但是后面的LSTM-attention，效果并不好。通过使用前面的JK设计，作者能够在不同数据集下，基于更多更深的GCN层达到最好的结果。</p>
<h2 id="pathcon">PATHCON</h2>
<p><a href="https://github.com/hwwang55/PathCon"><strong>Relational Message Passing for Knowledge Graph Completion</strong></a> KDD 2021</p>
<a href="/kge/PATHCON/" title="[个人详细博客]">[个人详细博客]</a>
<p>在这篇论文中，作者只考虑了KG中的relation embedding，没有学习entity embedding。更具体的说，学习两个方面的结构信息，relational context和relation paths。前者是头/尾实体的邻居relation，后者是头尾实体在KG中相连的relational path。提出了<a href="https://github.com/hwwang55/PathCon">PATHCON</a></p>
<p>作者预测的是relation prediction，<span class="math inline">\(&lt;h,?,t&gt;\)</span>，区别于常见的head/tail prediction，这样情况下relation prediction的候选项是所有的relation，会少很多候选项。这篇文章，作者还提出了一个新的数据集，DDB14，基于医药和疾病的一个知识图谱。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807105609410.png"   style="zoom:50%;" /></p>
<h2 id="hetegnn">HeteGNN</h2>
<p><strong>HeteGCN: Heterogeneous Graph Convolutional Networks for Text Classification</strong> WSDM 2021</p>
<p>针对文本预测任务，简化TEXTGCN，将原来整个TEXTGCN中使用的graph分解为几个不同的小graph，每个graph有自己的<span class="math inline">\(W_r\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210809161131674.png"   style="zoom:50%;" /></p>
<h2 id="kgnn">KGNN</h2>
<p><a href="https://github.com/xzenglab/KGNN"><strong>KGNN: Knowledge Graph Neural Network for Drug-Drug Interaction Prediction</strong></a> IJCAI 2020</p>
<p>针对DDI问题（Drug-drug interaction），首先从数据集中构造一个关于drug的KG，然后使用GNN捕获drug的邻居信息。在GNN上没有太大的创新，发现在聚合的时候使用自身embedding与邻居embedding各自具有不同的weight matrix比较合适。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210809171558677.png"   style="zoom:50%;" /></p>
<h2 id="cprl">CPRL</h2>
<p><strong>Heterogeneous Graph Neural Networks for Concept Prerequisite Relation Learning in Educational Data</strong> NAACL 2021</p>
<p>CPRL（concept prerequisite relation learning），在GNN上没有太大创新，主要是属于应用场景的一个创新。针对概念之间的依赖关系进行预测，作者创建了一个异质图，然后直接使用R-GCN进行学习，方法上没有太多可以借鉴的地方。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210810105105557.png"   style="zoom:50%;" /></p>
<p>这里使用了一个Siamese network，以前没见过。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210810105626109.png"   style="zoom: 33%;" /></p>
<h2 id="clhg">CLHG</h2>
<p><a href="https://github.com/%20TencentGameMate/gnn_cross_lingual"><strong>Cross-lingual Text Classiﬁcation with Heterogeneous Graph Neural Network</strong></a> ACL 2021</p>
<p>CLHG（Cross-Lingual Heterogeneous GCN），针对跨语言的文本分类任务，使用HGCN捕获不同语言的异质信息。这篇文章在GNN上没有太大创新，直接使用了前面HGAT的方法，根据邻居节点类型有不同的weight matrix。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210810151243856.png"   style="zoom:50%;" /></p>
<h2 id="eagcn">EAGCN</h2>
<p><a href="https://github.com/Luckick/EAGCN"><strong>Multi-view spectral graph convolution with consistent edge attention for molecular modeling</strong></a> Neurocomputing</p>
<p>EAGCN，预测任务是molecular graph property prediction，核心创新点个人认为是把异质图根据edge type分为不同view的graph，然后在molecular graph的背景下，同一个type的edge有不同的取值，这些取值会有不同的weight scalar。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210811150803687.png"   style="zoom:50%;" /></p>
<p>另外作者开源了项目，里面有attention的可视化这些操作，如果需要可以参考。</p>
<h2 id="eigat">EIGAT</h2>
<p><strong>Incorporating Global Information in Local Attention for Knowledge Representation Learning</strong> ACL 2021</p>
<p>核心创新点在于建模KG中实体的重要性，为每个实体赋值一个实数scalar，然后根据邻居实体的重要性评估中心实体的重要性。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210824160654200.png"   style="zoom:50%;" /></p>
<p><strong>local attention</strong></p>
<p>与KBGAT的方法一样。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210824160807701.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210824160745666.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210824160828759.png"   style="zoom:50%;" /></p>
<p><strong>entity importance</strong></p>
<p>核心创新点，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210824160908960.png"   style="zoom:50%;" /></p>
<p>从in edge出发，聚合邻居的重要性，注意，这里融合了前面计算的message的重要性。每个邻居提供的重要性是相对于自身所有的out message重要性来计算的。</p>
<p>其中<span class="math inline">\(d\)</span>是一个超参，第一项是为了给KG中没有in-degree的实体一个初始值。</p>
<p>在实验时，所有的<span class="math inline">\(EI\)</span>初始化为0.1，<span class="math inline">\(d\)</span>初始化为0.85。</p>
<p>最后，两种attention进行融合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210824161639285.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210824161622524.png"   style="zoom:50%;" /></p>
<h2 id="gaeat">GAEAT</h2>
<p><strong>GAEAT: Graph Auto-Encoder Attention Networks for Knowledge Graph Completion</strong> CIKM 2020</p>
<p>CIKM的short track。实际没有什么创新，使用KBGAT作为编码器，然后DistMult作为解码器。不过可以作为对比的Baseline。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210825164436321.png"   style="zoom:50%;" /></p>
<h2 id="m-gnn">M-GNN</h2>
<p><strong>Robust Embedding with Multi-Level Structures for Link Prediction</strong> IJCAI 2019</p>
<a href="/gnn/M-GNN/" title="[个人详细博客]">[个人详细博客]</a>
<p>这篇文章提出了一种multi-level graph neural network，M-GNN。使用GIN中的MLP学习结构信息，然后提出了一种基于KG中图的不同粒度进行建模的方法。它会从原始的KG出发，不断合并邻居节点，合并边，构造出一系列不同粒度的graph，在这些graph上进行图卷积操作，得到最后的输出。除了一般的链路预测实验，作者还进行了在不同稀疏度以及加入noising edges的实验。</p>
<p>和一般的GNN消息聚合方式不同，M-GNN希望能够建模KG中不同尺度中的信息。</p>
<p>首先构造k个Coarsened graph：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826143747570.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826145202651.png"   style="zoom:50%;" /> 最后模型结构。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826150505564.png"   style="zoom:50%;" /></p>
<h2 id="rdgcn">RDGCN</h2>
<p><strong>Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs</strong> IJCAI 2019</p>
<a href="#">Post not found: gnn/RDGCN [个人详细博客]</a>
<p><a href="https://github.com/StephanieWyt/RDGCN"><strong>RDGCN</strong></a> (Relation-aware Dual-Graph Convolutional Network)，预测任务是KG的实体对齐，主要是为了捕获更多的在dual KG中的relation的信息。核心创新点是对于dual KG（即要对齐的两个KG），构造了Dual Relation Graph，捕获relation和relation之间的联系。之后在这个Dual Relation Graph上学习relation的表示，融入到original KG中进行entity的表示学习，最终用于entity之间的对齐。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827161832004.png"   style="zoom:50%;" /></p>
<h2 id="slice">SLiCE</h2>
<p><a href="https://github.com/pnnl/SLICE"><strong>Self-Supervised Learning of Contextual Embeddings for Link Prediction in Heterogeneous Networks</strong></a> WWW 2021</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210830195131960.png"   style="zoom:50%;" /></p>
<p>作者希望考虑的是，单个节点在特定的subgraph下的表示。对于节点对，利用随机游走寻找两个节点之间的context subgraph。首先，利用一个embedding function，在全图下学习每个node的初始表示，作为global embedding。</p>
<p>然后，有两个阶段，pre-training和Fine-tuning。pre-training预测被mask掉的node，fine-tuning进行link prediction。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210830200013984.png"   style="zoom:50%;" /></p>
<h2 id="m2gnn">M<sup>2</sup>GNN</h2>
<p><strong>Mixed-Curvature Multi-Relational Graph Neural Network for Knowledge Graph Completion</strong> WWW 2021</p>
<p>首个将mixed-curvature geometry与GNN联系起来学习KGE的方法，作者尝试利用不同的空间对KG中的异质性结构进行建模。但是由于对mixed-curvature space和manifold不了解，看不懂论文内容。之后可以找时间仔细补充下基本知识。可参照</p>
<p>John M Lee. 2013. Smooth manifolds. In Introduction to Smooth Manifolds. Springer, 1–31.</p>
<h2 id="lgnn">LGNN</h2>
<p><strong>Node-wise Localization of Graph Neural Networks</strong> IJCAI 2021</p>
<p>作者认为对于整个图学习同样的weight matrix，可能导致模型倾向于建模最常见的pattern，而不是针对不同node的不同的local context进行学习。作者让graph中不同node拥有不同的weight matrix。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195057584.png"   style="zoom:50%;" /></p>
<p>具体有两个Node-level localization和Edge-level localization.</p>
<p><strong>Node-level localization</strong></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195215512.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195243176.png"   style="zoom:50%;" /></p>
<p>注意，这里没有给不同node都定义新的vector，而是直接从上一层的邻居直接mean聚合，然后进行转换，生成的向量<span class="math inline">\(a_v\)</span>和<span class="math inline">\(b_v\)</span>之后用于生成node <span class="math inline">\(v\)</span>的weight matrix。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195358969.png"   style="zoom:50%;" /></p>
<p>注意这里，是把<span class="math inline">\(a_v\)</span>和<span class="math inline">\(b_v\)</span>作为一行，然后复制，最后作用到graph global matrix<span class="math inline">\(W_l\)</span>上。</p>
<p><strong>Edge-level localization</strong></p>
<p>作者对node <span class="math inline">\(v\)</span>的不同邻居edge进一步建模：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195557949.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195613526.png"  style="zoom:50%;" /></p>
<p>最后聚合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195641977.png"   style="zoom:50%;" /></p>
<h2 id="srgcn">SRGCN</h2>
<p><strong>SRGCN: Graph-based multi-hop reasoning on knowledge graphs</strong> Neurocomputing 2021</p>
<p>这篇文章在预测<span class="math inline">\(&lt;h, r, t&gt;\)</span>的时候，首先构建<span class="math inline">\(h\)</span>和<span class="math inline">\(t\)</span>之间的graph，然后在这个graph上，逐步使用R-GCN得到对于尾实体的预测embedding，最后使用MLP获得score。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303170039139.png"   style="zoom:40%;" /></p>
<p>图中的label指的是从头实体出发，遇到的第几阶邻居。一个实体与头实体之间存在多个不同长度的path时，以最长的path作为label。</p>
<p>之后在使用R-GCN进行图卷积时，并不是以头实体为中心不断的聚合邻居。而是将头实体作为一开始，不断聚合到下一阶邻居实体上，直到聚合到具有最大label的实体上。</p>
<h2 id="chen-et-al.">Chen et al.</h2>
<p><strong>Learning graph attention-aware knowledge graph embedding</strong> Neurocomputing 2021</p>
<p>这篇文章核心是提出了一种新的在KG上计算attention的方法，有三个部分：entity attention、relation attention和structure attention。最核心的创新点是计算structural attention。</p>
<p>Entity attention：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303183431157.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303183447999.png"   style="zoom:50%;" /></p>
<p>Relation attention：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303183517954.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303183538437.png"   style="zoom:50%;" /></p>
<p>Structure attention：</p>
<p>使用带重启机制的随机游走方法（Random Walk with Restart，RWR），</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303183705455.png"   style="zoom:50%;" /></p>
<p>其中，<span class="math inline">\(w_i \in \mathbb{R}^{N\times 1}\)</span>，其中的entry <span class="math inline">\(p\)</span>表示实体<span class="math inline">\(i\)</span>通过随机游走到达实体<span class="math inline">\(p\)</span>的概率，这个概率越大，表示这两个实体在结构上的相关性越大。</p>
<p>然后，由于每个实体<span class="math inline">\(i\)</span>都有一个对应的<span class="math inline">\(w_i\)</span>，计算邻居边<span class="math inline">\(&lt;i,j&gt;\)</span>在结构上的权重，使用了jaccard相似度计算方法，核心思想是某个实体<span class="math inline">\(p\)</span>如果同时出现在实体<span class="math inline">\(i\)</span>和实体<span class="math inline">\(j\)</span>的邻居中，那么如果实体<span class="math inline">\(i\)</span>和实体<span class="math inline">\(j\)</span>的结构相似度越大，实体<span class="math inline">\(p\)</span>在<span class="math inline">\(w_i\)</span>和<span class="math inline">\(w_j\)</span>中的差距应该越小。因此有：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303184150967.png"   style="zoom:50%;" /></p>
<p>最后是softmax：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303184212826.png"   style="zoom:50%;" /></p>
<p>整体结构图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303184251972.png"   style="zoom:30%;" /></p>
<h2 id="mte">MTE</h2>
<p><strong>Relation-based multi-type aware knowledge graph embedding</strong> Neurocomputing 2021</p>
<p>这篇文章将本体（ontology）考虑到了GNN当中，从而学习KGE。ontology是描述entity的类型的语法树。</p>
<p>作者将ontology树使用bi-directional transformer model获得关于type的embedding。其中的输入是从root到leaf的序列。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303202610179.png"   style="zoom:40%;" /></p>
<p>获得type的embedding之后，对于某个具体实体<span class="math inline">\(e\)</span>，不同type的比重应该不同。作者认为如果实体<span class="math inline">\(e\)</span>链接的triples中，关系<span class="math inline">\(r\)</span>属于某个type <span class="math inline">\(t\)</span>的数量越多，则比重越大。比如在上图，对于实体<em>Ang_Lee</em>，类型<em>director</em>的比重应该比<em>actor</em>更大，因为属于<span class="math inline">\(director\)</span>的triple数量更多。</p>
<p>实体<span class="math inline">\(e\)</span>的type embedding应该是：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203115074.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203130712.png"   style="zoom:50%;" /></p>
<p>上面第二个公式的含义就是统计属于某个type <span class="math inline">\(t\)</span>的triples的数量占比。</p>
<p>之后，作者提出一种基于relation的attention聚合方法。</p>
<p>单个relation下的实体聚合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203413691.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203428588.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203449437.png"   style="zoom:50%;" /></p>
<p>多个relation的聚合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203516612.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203532350.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303203547104.png"   style="zoom:50%;" /></p>
<h2 id="revgnn">RevGNN</h2>
<p><strong>Training Graph Neural Networks with 1000 Layers</strong> ICML 2021</p>
<a href="/gnn/GNN-1000-layers/" title="[个人详细博客]">[个人详细博客]</a>
<p>这篇文章通过在GNN中引入grouped reversible connections，实现了将GNN拓展到1000层，可能是当前最深的GNN之一。这篇文章的意义在于，实现了GNN的层数与模型所需的显存无关，使用较少的显存就可以在显存基本不增加的情况下，任意增加GNN深度。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323192539787.png"   style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title>IE-Collection1</title>
    <url>/collection/IE-Collection1/</url>
    <content><![CDATA[<p>信息抽取论文调研集合1。</p>
<span id="more"></span>
<h1 id="ie-papers">IE Papers</h1>
<h2 id="metaner">MetaNER</h2>
<p>Learning In-context Learning for Named Entity Recognition，<a href="/nlp/MetaNER/" title="[详细博客]">[详细博客]</a></p>
<p>ACL 2023，中科院，<a href="https://%20github.com/chen700564/metaner-icl">代码</a>。</p>
<blockquote>
<p>Named entity recognition in real-world applications suffers from the diversity of entity types, the emergence of new entity types, and the lack of high-quality annotations. To address the above problems, this paper proposes an in-context learning-based NER approach, which can effectively inject in-context NER ability into PLMs and recognize entities of novel types on-the-fly using only a few demonstrative instances. Specifically, we model PLMs as a meta-function <span class="math inline">\(λ\)</span> instruction, demonstrations, text .M 1 , and a new entity extractor can be implicitly constructed by applying new instruction and demonstrations to PLMs, i.e., <span class="math inline">\((λ.M)(instruction, demonstrations) \rightarrow F\)</span> where <span class="math inline">\(F\)</span> will be a new entity extractor, i.e., <span class="math inline">\(F: text \rightarrow entities\)</span>. To inject the above in-context NER ability into PLMs, we propose a meta-function pre-training algorithm, which pre-trains PLMs by comparing the (instruction, demonstration)-initialized extractor with a surrogate golden extractor. Experimental results on 4 few-shot NER datasets show that our method can effectively inject in-context NER ability into PLMs and significantly outperforms the PLMs+fine-tuning counterparts.</p>
</blockquote>
<p>作者提出了一种让小参数量的预训练语言模型学会针对NER任务的in-context learning的方法。</p>
<p>少次NER任务的出现就是为了解决实体类型多样、新实体类型和高质量标注缺乏的问题。现有的少次NER方法包括fine-tuning-based和metric-based methods。</p>
<ul>
<li>The main drawbacks of fine-tuning-based methods are that re-training is often expensive (especially for large-scale models) and new entity types cannot be addressed on-the-fly.</li>
<li>Metric-based methods are limited to the matching architectures and are sensitive to domain shift since they do not fully explore the information of target domain.</li>
</ul>
<p>因此作者提出了让PLM模型学会ICL，根据新出现的样例学会抽取新的实体类型。（这一问题事实上LLM已经学会了，不需要额外的训练。这篇论文的重点在于如何让小的模型学会针对特定任务的上下文学习能力）。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613000405586.png" alt="image-20230613000405586" /><figcaption>image-20230613000405586</figcaption>
</figure>
<p>作者针对NER任务构造的ICL模板：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612233331196.png"   style="zoom:50%;" /></p>
<p>为了让PLM能够根据demonstrations学会抽取新的实体类型，作者提出了Meta-Function Pre-training for In-Context NER。</p>
<p>重点在于如何让PLM能够学会从demonstrations学习特征，然后能够抽取新的实体类型是重点。如果我们已知了理想的实体抽取函数，那我们只需要最小化PLM的上下文学习的输出和理想的实体抽取函数之间的差距即可。但是这样的理想函数并不存在。</p>
<p>因此，作者使用一个在demonstrations上进行参数更新的抽取模型作为替代（a surrogate extractor）。具体来说，在给定instruction <span class="math inline">\(I\)</span>, demonstration <span class="math inline">\(D\)</span>和text <span class="math inline">\(T\)</span>的情况下。先让PLM进行编码，获取到 <span class="math inline">\(I\)</span>, <span class="math inline">\(T\)</span>的特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612234144717.png"   style="zoom:50%;" /></p>
<p>instruction <span class="math inline">\(I\)</span>里包括了新的实体类型信息，text <span class="math inline">\(T\)</span>包含了待抽取的文本信息。作者拿这两种feature去和一个经过了demonstrations训练后的模型，编码的特征靠拢：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235325601.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235253164.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235433252.png"   style="zoom:40%;" /></p>
<p>注意一下，这里的<span class="math inline">\(Encoder^\prime\)</span>是拷贝了原来的encoder之后，进行梯度更新之后的编码器，不会影响原来的encoder。</p>
<p>仅仅是学习如何进行上下文学习是不够的，更重要的是我们要学会识别实体。因此作者还有一个loss是针对实体识别进行优化的。不过作者是用语言模型的loss来构造实体抽取的loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235631628.png"  style="zoom:40%;" /></p>
<p>作者除了一般的信息抽取任务的形式，还提出了一种Pseudo Extraction Language Modeling Task。因为有实体标注的数据和没有实体标注数据之间的比例差距很大。因此作者想办法从一般的句子中也能够仿照NER任务构造出未标注来。比如：</p>
<p>instruction=<code>Target types:&lt;type2&gt;;&lt;type14&gt;</code></p>
<p>demonstrations=<code>Text: [MASK1] is cool and I really [MASK2] it [MASK3]. Entities: [MASK1] is &lt;type2&gt;. [MASK2] is &lt;type14&gt;</code>（原来的句子I think this movie is cool and I really like it very much）</p>
<p>text=<code>Text: I do not like it.</code></p>
<p>要预测的输出output是<code>like is &lt;type14&gt;</code></p>
<p>将语言mask建模和span-based NER任务进行了统一。</p>
<p>实验部分：</p>
<p>预训练的数据是通过对齐Wikipedia和Wikidata进行构造的。</p>
<p>测试结果（没有在对应NER数据集上进行训练）：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613000330165.png" alt="image-20230613000330165" /><figcaption>image-20230613000330165</figcaption>
</figure>
<h2 id="demonstration-based-ner">Demonstration-based NER</h2>
<p>Good Examples Make A Faster Learner Simple Demonstration-based Learning for Low-resource NER <a href="/nlp/Demonstration-based-NER/" title="[详细博客]">[详细博客]</a></p>
<p>南加州大学，ACL 2022，<a href="https://github.com/INK-USC/fewNER">代码</a>。</p>
<blockquote>
<p>Recent advances in prompt-based learning have shown strong results on few-shot text classiﬁcation by using cloze-style templates. Similar attempts have been made on named entity recognition (NER) which manually design templates to predict entity types for every text span in a sentence. However, such methods may suffer from error propagation induced by entity span detection, high cost due to enumeration of all possible text spans, and omission of inter-dependencies among token labels in a sentence. Here <strong>we present a simple demonstration-based learning method for NER, which lets the input be prefaced by task demonstrations for in-context learning.</strong> We perform a systematic study on demonstration strategy regarding what to include (entity examples, with or without surrounding context), how to select the examples, and what templates to use. Results on in-domain learning and domain adaptation show that the model’s performance in low-resource settings can be largely improved with a suitable demonstration strategy (e.g., 4-17% improvement on 25 train instances). We also find that good demonstration can save many labeled examples and consistency in demonstration contributes to better performance.</p>
</blockquote>
<p>作者试了几种为NER任务设计的demonstrations检索和对应的模板构造方法，只不过是在bert-base上进行的实验。</p>
<p>作者的方法图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613221916295.png" alt="image-20230613221916295" /><figcaption>image-20230613221916295</figcaption>
</figure>
<p>作者提了2种检索NER demonstrations的方法：</p>
<ul>
<li>Entity-oriented：就是以实体为核心进行检索，包括简单的3种方式：
<ul>
<li>random：每一类entity type中，从训练集所有的对应实体进行检索（动态的）</li>
<li>popular：每一类entity type中，选择出现次数最多top-k的对应实体（静态的）</li>
<li>search：每一类entity type中，选择出现次数最多top-k的对应实体，grid search可能的实体组合，然后在验证集上找到效果最好的那种组合（静态的）</li>
</ul></li>
<li>Instance-oriented：以查询的当前句子为核心，进行检索，计算和其它训练集中句子的相似度，包括2种相似度计算方法：
<ul>
<li>SBERT：计算两个句子编码后CLS token embedding的余弦相似度（动态的）</li>
<li>BERTScore：两个句子不同token之间的相似度的和（动态的）</li>
</ul></li>
</ul>
<p>在找到了训练集中的demonstration之后，怎么样构造模板，作者提了3种方式：</p>
<ul>
<li>no-context：没有训练样例里面的句子，只保留实体，“entity is type.&quot;</li>
<li>context：保留对应的句子，再加上“entity is type.&quot;的描述</li>
<li>lexical：把原来句子中的entity替换为对应的entity type。这样获取能够直接捕获到不同label之间的对应关系</li>
</ul>
<p>demonstration模板示例：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613222921680.png" alt="image-20230613222921680" /><figcaption>image-20230613222921680</figcaption>
</figure>
<p>实验部分是基于bert-base-cased去做的。把找到的demonstrations拼接到要查询的query text前面，用bert编码以后的embedding过一个CRF，就得到了NER序列标注。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613223525296.png" alt="image-20230613223525296" /><figcaption>image-20230613223525296</figcaption>
</figure>
<p>效果最好的，就是在验证集上进行评估，选择保留context。</p>
<h2 id="promptner">PromptNER</h2>
<p>PromptNER: Prompt Locating and Typing for Named Entity Recognition</p>
<p>ACL 2023，浙大，<a href="https://github.com/%20tricktreat/PromptNER">代码</a>。</p>
<blockquote>
<p>Prompt learning is a new paradigm for utilizing pre-trained language models and has achieved great success in many tasks. To adopt prompt learning in the NER task, two kinds of methods have been explored from a pair of symmetric perspectives, populating the template by enumerating spans to predict their entity types or constructing type-specific prompts to locate entities. However, these methods not only require a multi-round prompting manner with a high time overhead and computational cost, but also require elaborate prompt templates, that are difficult to apply in practical scenarios. <strong>In this paper, we unify entity locating and entity typing into prompt learning, and design a dual-slot multi-prompt template with the position slot and type slot to prompt locating and typing respectively.</strong> Multiple prompts can be input to the model simultaneously, and then the model extracts all entities by parallel predictions on the slots. To assign labels for the slots during training, we design a dynamic template filling mechanism that uses the extended bipartite graph matching between prompts and the ground-truth entities. We conduct experiments in various settings, including resource-rich flat and nested NER datasets and low-resource indomain and cross-domain datasets. Experimental results show that the proposed model achieves a significant performance improvement, especially in the cross-domain few-shot setting, which outperforms the state-of-the-art model by +7.7% on average.</p>
</blockquote>
<p>这篇paper准确的讲不应该出现在cross-domain IE方向内。它只是在实验部分做了跨域IE的实验。</p>
<p>主要创新点在于作者期望能够一次性的用prompt的方法抽取出句子中包括的所有实体span和实体type。这样能够提高模型的速度。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612162253219.png"   style="zoom:40%;" /></p>
<p>作者提出的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612162443446.png" /></p>
<p>首先是提前构造<span class="math inline">\(M\)</span>个prompt，实验中使用了<span class="math inline">\(M=50\)</span>。所有的prompt里包括了一个position slot和type slot，最终和原始的句子一起输入到BERT中进行编码：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612162601219.png"   style="zoom:40%;" /></p>
<p>经过编码之后，作者还增加了一个不同prompt之间的interaction layer。即包括prompt之间的self-attention between slots with the same type，也包括从sentence to prompt slots的attention：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612162917336.png"   style="zoom:40%;" /></p>
<p>在进行解码阶段，不同prompt中的type slot的embedding直接拿出来进行softmax分类：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612163128048.png"   style="zoom:40%;" /></p>
<p>而position slot需要和不同位置的word embedding相加，然后判断是不是某个实体的左边界：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612163112798.png"   style="zoom:40%;" /></p>
<p>同样的可以获得右边界的预测值<span class="math inline">\(\mathbf{p}^r_{ij}\)</span>。</p>
<p>现在我们要进行优化，那么就需要知道一个prompt输出的预测结果，真实期望是哪个entity，要不然无法优化。我们有很多个prompt，应该想一种办法对这些prompt的结果进行整合，最后和实际的entity对应上。</p>
<p>作者这里使用了一个bipartite graph matching的思路。就是期望那个最好的匹配结果，能够使prompts的预测结果和entities之间的cost最小：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612163636157.png"   style="zoom:40%;" /></p>
<p>上面<span class="math inline">\(i\)</span>是指<span class="math inline">\(i\)</span>-th entity，<span class="math inline">\(\sigma(i)\)</span>是指<span class="math inline">\(\sigma(i)\)</span>-th prompt。<span class="math inline">\(Cost_{match}\)</span>的定义如下，实际上就是让一个entity去和最倾向于预测它的prompt匹配，方便最后计算loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612163724720.png" style="zoom:40%;" /></p>
<p>作者这里还提出了让一个entity能够和多个prompt匹配，具体做法就是重复多次相同的entity。作者使用Hungarian algorithm来求解最佳的匹配，然后计算loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612164233873.png"   style="zoom:40%;" /></p>
<p>实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612164255376.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612164314322.png"   style="zoom:40%;" /></p>
<p>个人认为这篇工作更大的意义在于，可以一次性prompt可以快速抽取entity：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829221510309.png"   style="zoom:35%;" /></p>
<h2 id="templatener">TemplateNER</h2>
<p>Template-Based Named Entity Recognition Using BART</p>
<p>ACL 2021 Findings, <a href="https://github.com/Nealcly/templateNER">代码</a>。</p>
<blockquote>
<p>There is a recent interest in investigating fewshot NER, where the low-resource target domain has different label sets compared with a resource-rich source domain. Existing methods use a similarity-based metric. However, they cannot make full use of knowledge transfer in NER model parameters. To address the issue, <strong>we propose a template-based method for NER, treating NER as a language model ranking problem in a sequence-to-sequence framework, </strong> where original sentences and statement templates filled by candidate named entity span are regarded as the source sequence and the target sequence, respectively. For inference, the model is required to classify each candidate span based on the corresponding template scores. Our experiments demonstrate that the proposed method achieves 92.55% F1 score on the CoNLL03 (rich-resource task), and significantly better than fine-tuning BERT 10.88%, 15.34%, and 11.73% F1 score on the MIT Movie, the MIT Restaurant, and the ATIS (low-resource task), respectively.</p>
</blockquote>
<p>首个把template-based的方法应用到NER的序列标注任务。作者提出这种方法一开始的出发点是期望从模型结构的角度能够更好的解决低资源NER任务。之前的利用CRF或者一个线性层的序列标注方法严格的限制了能够预测和匹配的标签范围，不同数据集下的标签不同，必须重新训练新的预测层。</p>
<p>作者提出的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630102935108.png"   style="zoom:30%;" /></p>
<p>整体上是一个编码器+解码器的结构，编码器把整个句子进行编码，随后编码的embedding输入到解码器，和对应的查询prompt的编码进行对比计算。</p>
<p>核心是查询时候的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630103433819.png"   style="zoom:50%;" /></p>
<p>作者采用效果最好的第一种prompt。除此之前还有对应非实体的prompt template：<em><candidate_span > is not a named entity</em>。</p>
<p>在推理的时候，对于长度为<span class="math inline">\(n\)</span>的句子，可能的span数量是<span class="math inline">\(n(n-1)\)</span>，为了效率，作者设置一个span的最大长度为<span class="math inline">\(8\)</span>。通过穷举span和对应的不同entity type，计算概率，然后排序。计算某个填充后的prompt是否成立的概率为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630103737930.png"   style="zoom:50%;" /></p>
<p>实现的时候基于BART：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630104145213.png"   style="zoom:40%;" /></p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630104223459.png"   style="zoom:40%;" /></p>
<h2 id="uie">UIE</h2>
<p>Unified Structure Generation for Universal Information Extraction</p>
<p>中国信息处理实验室，百度，ACL 2022, <a href="https://universal-ie.github.io/">代码</a>。</p>
<blockquote>
<p>Information extraction suffers from its varying targets, heterogeneous structures, and demandspecific schemas. In this paper, <strong>we propose a unified text-to-structure generation framework, namely UIE, which can universally model different IE tasks, adaptively generate targeted structures</strong>, and collaboratively learn general IE abilities from different knowledge sources. Specifically, UIE uniformly encodes different extraction structures via a structured extraction language, adaptively generates target extractions via a schema-based prompt mechanism – structural schema instructor, and captures the common IE abilities via a large-scale pretrained text-to-structure model. Experiments show that UIE achieved the state-of-the-art performance on 4 IE tasks, 13 datasets, and on all supervised, low-resource, and few-shot settings for a wide range of entity, relation, event and sentiment extraction tasks and their unification. These results verified the effectiveness, universality, and transferability of UIE.</p>
</blockquote>
<p>UIE的模型图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630104511551.png"   style="zoom:30%;" /></p>
<p>UIE从两个角度统一IE任务：</p>
<ol type="1">
<li><p>结构化信息的格式SEL：包括三个描述元素，Spot Name用来描述span的类型（Entity/Event Type）；Asso Name用来描述和上级Spot关联的类型（Relation/Role Type）；Info Span对应的在原始text中的文本（Entity mention/Argument mention/Trigger word）；</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630104627488.png"   style="zoom:50%;" /></p></li>
<li><p>统一的抽取prompt：指定要抽取的信息，通过加入特殊符号<code>[spot]+spot name</code>，<code>[asso]+Asso Name</code>和<code>[text]+source text</code>指定要抽取的信息。可以参考上面的方法图示例。</p></li>
</ol>
<p>UIE的训练包括两个阶段，一个是在大规模的抽取语料中进行预训练（这一部分参考原始论文）；另一个是针对特定的任务进行快速的微调：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630105501812.png"   style="zoom:40%;" /></p>
<p>在微调阶段，有个需要特别注意的细节是，为了防止可能的exposure bias，作者引入了Rejection Mechanism。也就是说随机的插入负样例：（个人的理解就是让模型不要倾向于认为prompt中指定的要抽取的结构化信息是全部存在的，偏好给每一个要抽取的类型信息都要强制找到对应的span，而是能够学会判断各种结构化信息是否存在）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630105730830.png"   style="zoom:40%;" /></p>
<p>这一点在实验部分有非常大的影响，能够有12-13点左右的变化。</p>
<p>UIE基于T5，也是编码器+解码器的结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630110116780.png"   style="zoom:30%;" /></p>
<p>从实验结果来看，即使是不经过微调，直接在不同数据集上进行推理时的信息抽取（对应表格中的SEL列），也能够达到比较好的效果。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630110209780.png"  style="zoom:30%;" /></p>
<h2 id="sure">SuRE</h2>
<p>Summarization as Indirect Supervision for Relation Extraction</p>
<p>EMNLP 2022，<a href="https://github.com/luka-group/SuRE">代码</a>。</p>
<blockquote>
<p>Relation extraction (RE) models have been challenged by their reliance on training data with expensive annotations. Considering that summarization tasks aim at acquiring concise expressions of synoptical information from the longer context, these tasks naturally align with the objective of RE, i.e., extracting a kind of synoptical information that describes the relation of entity mentions. <strong>We present SuRE, which converts RE into a summarization formulation.</strong> SuRE leads to more precise and resource-efficient RE based on indirect supervision from summarization tasks. To achieve this goal, we develop sentence and relation conversion techniques that essentially bridge the formulation of summarization and RE tasks. We also incorporate constraint decoding techniques with Trie scoring to further enhance summarization-based RE with robust inference. Experiments on three RE datasets demonstrate the effectiveness of SuRE in both full-dataset and low-resource settings, showing that summarization is a promising source of indirect supervision signals to improve RE models.</p>
</blockquote>
<p>作者认为如果直接把RE任务看做是多分类任务的话有两个缺点：</p>
<ul>
<li>缺少对实体之间关系语义的理解。因为关系被转化为了logits，仅仅是个分类的匹配标签，实际的关系语义信息没有被学习到。</li>
<li>非常依赖于足够的RE标注数据来提供direct supervision。而在少资源的情况下，效果下降非常严重。</li>
</ul>
<p>因此作者将RE任务和Summarization task关联起来，引入了Summarization相关的和RE任务不是直接关联的监督信号。</p>
<p>方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630164230877.png"   style="zoom:30%;" /></p>
<p>首先是如何处理输入的句子，能够进一步插入额外的实体信息，作者试验了两种方法：</p>
<ol type="1">
<li><p>Entity typed marker. 作者试了几种不同的标记方法，最终采用了下面的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630164850191.png"  style="zoom:40%;" /></p></li>
<li><p>Entity information verbalization. 直接在句子前面加入实体信息的描述：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630165053978.png"   style="zoom:40%;" /></p></li>
</ol>
<p>各种尝试的变化：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630165132956.png"   style="zoom:30%;" /></p>
<p>从实验效果来看，加入实体描述信息是有用的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630165226787.png"   style="zoom:30%;" /></p>
<p>接下来的问题是怎么样描述relation，作者在前人的工作基础上，进行了微小的改动，获得了自己的模板：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630165334851.png"   style="zoom:30%;" /></p>
<p>作者在实现的时候，基于BART和Pegasus这两个已经在summarization相关数据上pre-train过的模型。然后在对应的RE数据集上按照sequence-to-sequence方法进行微调。</p>
<p>在推理阶段，作者将所有的relation template聚合在一起构造了一个Trie tree。通过在Trie树上计算每一个路径，得到最后的关系预测概率。编码器输入原始的句子，解码器不断输入对应的路径，具体可以参考方法图。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230630170430071.png"   style="zoom:30%;" /></p>
<h2 id="clner">CLNER</h2>
<p>Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning</p>
<p>ACL 2021，Alibaba DAMO，<a href="https://github.com/Alibaba-NLP/CLNER">代码</a>。</p>
<blockquote>
<p>Recent advances in Named Entity Recognition (NER) show that document-level contexts can significantly improve model performance. In many application scenarios, however, such contexts are not available. <strong>In this paper, we propose to find external contexts of a sentence by retrieving and selecting a set of semantically relevant texts through a search engine, with the original sentence as the query.</strong> We find empirically that the contextual representations computed on the retrieval-based input view, constructed through the concatenation of a sentence and its external contexts, can achieve significantly improved performance compared to the original input view based only on the sentence. Furthermore, we can improve the model performance of both input views by Cooperative Learning, a training method that encourages the two input views to produce similar contextual representations or output label distributions. Experiments show that our approach can achieve new state-of-the-art performance on 8 NER data sets across 5 domains.</p>
</blockquote>
<p>这是一篇利用搜索引擎来为sentence-level NER任务寻找external context来提升性能的工作。</p>
<p>出发点是说在这篇工作前出现了用document-level contexts来作为外部知识提升NER性能的工作，但是很多情况下document-level contexts是没法获得的，比如social media domain。</p>
<p>方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829214333402.png"  style="zoom:30%;" /></p>
<p>首先，作者利用Google search来寻找每个sentence的相关搜索结果。由于这个搜索结果可能是比较模糊的，还需要精排。因此作者用BERTScore（Roberta-Large based）来计算不同搜索结果和query之间的语义相似性。下面是计算Recall, Precision of BERTScore的公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829214744759.png"   style="zoom:40%;" /></p>
<p>作者计算F1进行排序，取top-<span class="math inline">\(l\)</span>的搜索结果以及对应的F1作为external context拼接到原始text上：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829215031549.png"  style="zoom:40%;" /></p>
<p>实现中如果要查询的句子太长，那么就按照标点符号拆分为不同的子句子，分别进行查询，然后汇聚结果。查询得到的结果首先要过滤掉可能包含了数据集内容的部分。最终保留最多<span class="math inline">\(l=6\)</span>个查询结果作为外部上下文。</p>
<p>使用XLM-RoBERTa进行编码，除biomedical domain之外。</p>
<p>作者额外的考虑到有些情况下通过搜索引擎来寻找external context可能是不实际的，比如线上场景。在这种情况下，作者考虑使用Cooperative Learning来拉近retrieval-based input view和original input views without external contexts的差异：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829220559378.png"   style="zoom:40%;" /></p>
<p>需要注意的是有external contexts的计算图，不会进行梯度传播。梯度只通过<span class="math inline">\(h([x])\)</span>进行反向传播。</p>
<ul>
<li><p>一个是用来<span class="math inline">\(L_2\)</span> Norm拉近两种embedding的距离：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829215340090.png"   style="zoom:40%;" /></p>
<p>上面的<span class="math inline">\(v\)</span>是指经过了Transformer，要输入到CRF层之前的embedding。</p></li>
<li><p>另一个是用KL散度拉近output distributions的差异：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829215530881.png"  style="zoom:40%;" /></p>
<p>需要注意的一点是，由于使用了CRF作为decoder，上面的公式计算起来非常复杂（由于<span class="math inline">\(y\)</span>的可能很多），作者通过独立计算每个位置上的<span class="math inline">\(y_i\)</span>的概率<span class="math inline">\(q_i\)</span>来估计上面的公式值：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829220317882.png"   style="zoom:40%;" /></p>
<p>公式里的<span class="math inline">\(\psi(\cdot)\)</span>函数是CRF中的potential function。最后计算公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829220450301.png"   style="zoom:40%;" /></p>
<p>上面的公式思想不是作者第一个提出的，在之前的工作中有相关的论述 [<em>Structural Knowledge Distillation: Tractably Distilling Information for Structured Predictor</em>]。</p></li>
</ul>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230829215611176.png"   style="zoom:30%;" /></p>
<p>可以看到加入external context之后，不同数据集的提升幅度不一样。在social media domain上的提升幅度最大。在News和Biomedical domain上提升不是很显著。</p>
<h2 id="luke">LUKE</h2>
<p>LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention</p>
<p>EMNLP 2020，日本Studio Ousia，<a href="https://github.com/studio-ousia/luke">代码</a>。</p>
<blockquote>
<p>Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer (Vaswani et al., 2017). <strong>The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them.</strong> Our model is trained using a new pretraining task based on the masked language model of BERT (Devlin et al., 2019). <strong>The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia.</strong> We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at https://github.com/studio-ousia/luke.</p>
</blockquote>
<p>预训练+微调的例子，不仅仅是IE任务，作者还测试了QA等其它任务。</p>
<p>主要目的是为了在预训练的过程中，让模型能够学会对entity信息的建模。BERT的mask建模方式是针对单个token的，而一个entity有很多token组成。单纯的self-attention可能无法准确的推断不同entity之间的关系。</p>
<p>方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230830163126277.png"   style="zoom:50%;" /></p>
<p>针对entity进行的预训练过程的优化：</p>
<ul>
<li><p>除去token有自己的embedding matrix <span class="math inline">\(A\)</span>之外，每个entity也有自己独立的embedding。为了减小entity embedding matrix 的参数量，使用了秩分解分为两个小的matrix <span class="math inline">\(B\times U\)</span>。</p></li>
<li><p>token有自己的position embedding，entity也有自己的position embedding。</p></li>
<li><p>entity还额外加入了一个表示embedding是entity而不是token的type embedding <span class="math inline">\(\mathbf{e}\)</span>。</p></li>
<li><p>在self-attention中，作者提出了一个Entity-aware Self-attention，就是根据embedding的类型，有不同的query matrix：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230830163823518.png"   style="zoom:40%;" /></p></li>
<li><p>预训练的loss，除去BERT的mask token loss，还加入了一个mask entity的loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230830163959020.png"   style="zoom:40%;" /></p></li>
<li><p>预训练的时候，在Wikipedia pages上进行预训练，所有被mask的entity就是有对应超链接的Wikipedia entity，一共包括了500K个实体。如果一个实体不在entity vocabulary内，就用<span class="math inline">\([UNK]\)</span>来替换。</p></li>
</ul>
<p>实验结果：</p>
<p>实体识别时穷举所有的span，然后经过线性分类器判断实体类别。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230830164303683.png"  style="zoom:40%;" /></p>
<p>需要注意的一点是，这个方法follow了BERT在NER任务上的做法，加入了document-level context。在检查过<a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb">源码</a>后发现，CoNLL-2003的句子通过特殊的字符串<code>-DOCSTART-</code>是标记了是否来自于同一document的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230830164510802.png"   style="zoom:40%;" /></p>
<p>BERT和LUKE方法都通过将属于同一document的sentence拼接在一起进行预测，而不是一个一个句子的进行预测。这样原来一个sentence就能够获得来自其它sentence的语义，并且由于属于同一document，表达上是一致的。</p>
<p>关系分类任务：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230830164846860.png"   style="zoom:40%;" /></p>
<h2 id="retrieving-correlated-samples">Retrieving Correlated Samples</h2>
<p>Domain-Specific NER via Retrieving Correlated Samples</p>
<p>天津大学，COLING 2022，<a href="https://github.com/izhx/NER-unlabeled-data-retrieval">代码</a>。</p>
<blockquote>
<p>Successful Machine Learning based Named Entity Recognition models could fail on texts from some special domains, for instance, Chinese addresses and e-commerce titles, where requires adequate background knowledge. Such texts are also difficult for human annotators. In fact, we can obtain some potentially helpful information from correlated texts, which have some common entities, to help the text understanding. Then, one can easily reason out the correct answer by referencing correlated samples. <strong>In this paper, we suggest enhancing NER models with correlated samples. We draw correlated samples by the sparse BM25 retriever from large-scale in-domain unlabeled data.</strong> To explicitly simulate the human reasoning process, we perform a training-free entity type calibrating by majority voting. To capture correlation features in the training stage, we suggest to model correlated samples by the transformerbased multi-instance cross-encoder. Empirical results on datasets of the above two domains show the efficacy of our methods.</p>
</blockquote>
<p>在某些情况下进行实体标注需要额外的knowledge，即使对于人类标注者来说也很难识别。人也通常需要去检索后再做决定。</p>
<p>因此作者提出可以通过检索和query text相关的text来辅助NER：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230831151308214.png"   style="zoom:30%;" /></p>
<p>比如上图的白城和白城镇在没有对应背景知识的情况下是不可能分辨出来的。在检索到的额外样例中有白城市这样的关键描述能够帮助辅助判别。对于实例中的“吉林”也一样，到底是吉林省还是吉林市需要从额外样例中寻找。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230831151501330.png"   style="zoom:40%;" /></p>
<p>作者的检索源是一个large-scale in-domain unlabeled data，通过Elasticsearch搜索引擎，使用BM25获取top-K的correlated samples。检索的query text应该是整个待抽取的文本。而这个unlabeled data从哪里来，作者没有在论文中进行详细描述。</p>
<p>对于检索到的correlated samples怎么用，作者提出两种思路：</p>
<ul>
<li>一种方法是使用一个已有的NER model对检索到的correlated samples和query text都进行初步NER标注。然后通过majority voting的思想对于shared entities的label进行修正Calibrating。这种方法不需要额外训练，是training-free的。（此时取<span class="math inline">\(K=100/50\)</span>）</li>
<li>另一种方法是把correlated samples和query拼接后作为一个input，经过SentenceBERT的cross-encoder编码后，利用BiLSTM-CRF预测。此时的correlated samples就是作为一个external context在输入层进行辅助。（此时取<span class="math inline">\(K=12\)</span>）</li>
</ul>
<p>实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230831152411895.png"   style="zoom:25%;" /> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230831152426093.png"  style="zoom:25%;" /></p>
<p>能够看到最终是第二种的方法好一点，但是第一种方法是没有单独训练过的。</p>
<h2 id="kb-ner">KB-NER</h2>
<p>DAMO-NLP at SemEval-2022 Task 11: A Knowledge-based System for Multilingual Named Entity Recognition</p>
<p>SemEval-2022 workshop，阿里达摩，<a href="https://github.com/Alibaba-NLP/KB-NER">代码</a>。</p>
<blockquote>
<p>The MultiCoNER shared task aims at detecting semantically ambiguous and complex named entities in short and low-context settings for multiple languages. The lack of contexts makes the recognition of ambiguous named entities challenging. <strong>To alleviate this issue, our team DAMO-NLP proposes a knowledge-based system, where we build a multilingual knowledge base based on Wikipedia to provide related context information to the named entity recognition (NER) model.</strong> Given an input sentence, our system effectively retrieves related contexts from the knowledge base. The original input sentences are then augmented with such context information, allowing significantly better contextualized token representations to be captured. Our system wins 10 out of 13 tracks in the MultiCoNER shared task.</p>
</blockquote>
<p>在本地下载Wikipedia数据，通过ElasticSearch去检索相关的context，然后进行Multilingual NER任务。</p>
<p>方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230831164919431.png"   style="zoom:40%;" /></p>
<p>从<a href="https://dumps.wikimedia.org/">Wikimedia</a>上下载Wikipedia dump，然后定义了三个field：sentence, paragraph and title field。在sentence field和title field上创建了inverted indexes用于检索。</p>
<p>有两种检索策略：</p>
<ul>
<li>Sentence Retrieval：通过query sentence和sentence field进行匹配，然后返回top-k的结果</li>
<li>Iterative Entity Retrieval：把query sentence中的entities拼接，用<code>|</code>分割，和title field进行配。这种方法可以迭代T次</li>
</ul>
<p>对于检索到的结果，有三类context可以作为external context和原有的query sentence一起输入：</p>
<ul>
<li>use the matched paragraph（paragraph包含了matched sentence的上下文）</li>
<li>use the matched sentence（如<code>&lt;e:Steve Jobs&gt;Steve Jobs&lt;/e&gt; founded &lt;e:Apple_inc&gt;Apple&lt;/e&gt;</code>）</li>
<li>use the matched sentence but remove the wiki anchors（如<code>Steve Jobs founded Apple</code>）</li>
</ul>
<p>使用的model是XLM-R large。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230831170233150.png"   style="zoom:50%;" /></p>
<p>Table 1中的Baseline是指没有对应的Wikipedia搜索模块的变体，能够看到加入external knowledge之后，效果提升了有20%。</p>
<p>和用Google search的对比：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230831170123476.png"   style="zoom:50%;" /></p>
<p>虽然Google search比Baseline要好，但是总体上效果比不上用Wikipedia进行检索。另外一个关键问题是Google search比在本地检索要慢很多，一个量级的差距（具体参考paper中的Table 6）。</p>
<p>Table 3中的<code>Wiki-Para</code>，<code>Wiki-Sent</code>，<code>Wiki-Sent-Link</code>分表代表上面说的三种处理检索结果的方法。<code>Wiki-Para+IterG</code>是指用dev set中的gold entity进行检索，并且之后使用match paragraph作为external context。</p>
<h2 id="metaretriever">MetaRetriever</h2>
<p>Universal Information Extraction with Meta-Pretrained Self-Retrieval</p>
<p>ACL Findings 2023，中科院与阿里达摩，<a href="https://github.com/AlibabaResearch/DAMO-ConvAI/%20tree/main/metaretriever">代码</a>。</p>
<blockquote>
<p>Universal Information Extraction (Universal IE) aims to solve different extraction tasks in a uniform text-to-structure generation manner. Such a generation procedure tends to struggle when there exist complex information structures to be extracted. Retrieving knowledge from external knowledge bases may help models to overcome this problem but it is impossible to construct a knowledge base suitable for various IE tasks. <strong>Inspired by the fact that large amount of knowledge are stored in the pretrained language models (PLM) and can be retrieved explicitly, in this paper, we propose MetaRetriever to retrieve task-specific knowledge from PLMs to enhance universal IE.</strong> As different IE tasks need different knowledge, we further propose a Meta-Pretraining Algorithm which allows MetaRetriever to quicktly achieve maximum task-specific retrieval performance when fine-tuning on downstream IE tasks. Experimental results show that MetaRetriever achieves the new state-of-the-art on 4 IE tasks, 12 datasets under fully-supervised, low-resource and few-shot scenarios.</p>
</blockquote>
<p>问题：</p>
<ul>
<li>作者认为类似于UIE方法的通用IE model在面对复杂信息抽取结构的时候，由于缺乏对信息结构之间的上下文语义关联，而难以输出准确的抽取结果</li>
<li>利用检索增强的方法能够利用外部知识来获取与task相关的信息，但是很难搭建这样一种适用于各种IE任务的知识库/检索方式。事实上，搭建这样的通用知识库就是IE任务的终极目标。</li>
</ul>
<p>最近，通过knowledge probing任务发现PLM中蕴含了很多knowledge，如果使用PLM就无需构造额外的外部知识库。因此作者提出利用PLM作为知识库，从PLM中检索相关knowledge并且提升通用信息抽取任务的效果：</p>
<blockquote>
<p>In light of these findings, the question arises: can PLMs be used as knowledge bases to retrieve knowledge and improve universal IE models? If so, universal IE models would be able to generate more accurate results.</p>
</blockquote>
<p>作者提出的MetaRetriever基于T5-base，方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909225239718.png"   style="zoom:40%;" /></p>
<p>作者直接使用了UIE中提出的Structured extraction language来建模各类IE任务。</p>
<p>第一步是检索，作者对于PLM中能够辅助UIE的knowledge的定义很简单，就是直接使用预测的抽取结果作为knowledge。using the ground truth linearized SEL sequence of the corresponding input text as the knowledge we wish to retrieve. （个人认为这样不就是相当于进行了两次抽取吗？）</p>
<p>第二步是抽取，将上一步预测的抽取结果和原本的text拼接，输入model，进行最终的抽取。</p>
<p>为了让模型快速学会如何检索自身和IE任务相关的implicit knowledge，作者使用meta-learning的方法，分为inner loop和outer loop两步进行快速的梯度更新。经典的meta learning方法。</p>
<p>值得一提的是，为了训练MetaRetriever，作者构造了一个10-million-level的语料库，并且首次开源。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909225937421.png"   style="zoom:40%;" /></p>
<h2 id="knowprompt">KnowPrompt</h2>
<p>KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. 浙大. WWW 2022. <a href="https://github.com/zjunlp/KnowPrompt">代码</a>.</p>
<blockquote>
<p>Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, <strong>determining an appropriate prompt template requires domain expertise</strong>, and it is cumbersome and time-consuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Extensive experimental results on five datasets with standard and low-resource settings demonstrate the effectiveness of our approach. Our code and datasets are available in GitHub 1 for reproducibility.</p>
</blockquote>
<p><strong>Issue</strong>: 基于prompt的方法比基于standard finetuning的方法能够更好的bridge the gap between pre-training and fine-tuning。而对prompt-tuning based RE存在的两个问题：</p>
<ol type="1">
<li>如何决定合适的prompt，人工的方法需要domain expertise；自动化方法需要额外的计算代价；</li>
<li>搜索合适的label需要很高的代价，而为RE任务构造合适的label并不是一个很easy的任务；直接使用数据集里原始的label不能够很好的适应RE任务。</li>
</ol>
<p><strong>Solution</strong>: 作者的解决思路是，利用knowledge注入到learnable prompts里。</p>
<p>具体来说，作者从数据集里的relation label出发，为entity type和relation分别构造了virtual words。</p>
<p>对于entity，作者没有假设数据集中会提前给定entity type。作者是利用人工的先验知识，判断某个relation对应的头尾实体类型。然后，基于frequency statistics，从整个数据集上计算不同实体类型的频率。根据频率和对应的type相应的embedding加权求和，得到了总体上的头尾实体的type embedding。这个entity type embedding，会作为特殊token <span class="math inline">\([sub]/[obj]\)</span>插入到具体sample的头尾实体前后。</p>
<p>对于relation，作者分解原始的relation，然后使用分解后的不同word，相乘后作为初始化的relation embedding。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231115193524656.png"  style="zoom:50%;" /></p>
<p>初始化后的entity type embedding会加入到prompt里，放在头尾实体左右，作为weakened type marker，然后初始化的relation embedding会作为候选的关系，和[MASK] token embedding相乘，选择最大概率的作为输出relation。下面是方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231115193729623.png"  style="zoom:50%;" /></p>
<p>具体，作者在训练时使用了两步训练策略，有两种loss：</p>
<p>一个是给定了prompt之后，预测[MASK]是正确relation的交叉熵：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231115193908166.png"  style="zoom:40%;" /></p>
<p>一个是期望学习structural knowledge的结构化loss，也就是利用TransE思想构造的判断<span class="math inline">\(&lt;s,r,o&gt;\)</span>成立的loss。只不过，这里的<span class="math inline">\(&lt;s&gt;&lt;o&gt;\)</span>不是具体的entity embedding，而是他们句子中的<span class="math inline">\([sub]\)</span>和<span class="math inline">\([obj]\)</span> token的用来表示entity type的embedding：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231115194204849.png"  style="zoom:40%;" /></p>
<p>作者在full dataset和low-resource两种RE任务设置下进行了实验。基于<code>RoBERT_large</code> model，而在DialogRE数据集上基于<code>RoBERTa_base</code> model。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231115194346193.png"  style="zoom:50%;" /></p>
<p>可以看到，这种提前注入knowledge来构造合适的soft prompt的方法在低资源的情况下，效果提升最明显。</p>
<h1 id="cross-domain-ie">Cross-domain IE</h1>
<h2 id="cp-ner">CP-NER</h2>
<p>One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER</p>
<p>IJCAI 2023，浙大ZJUNLP，<a href="https://github.com/zjunlp/DeepKE/tree/main/example/ner/cross">代码</a>。</p>
<blockquote>
<p>Cross-domain NER is a challenging task to address the low-resource problem in practical scenarios. Previous typical solutions mainly obtain a NER model by pre-trained language models (PLMs) with data from a rich-resource domain and adapt it to the target domain. Owing to the mismatch issue among entity types in different domains, previous approaches normally tune all parameters of PLMs, ending up with an entirely new NER model for each domain. Moreover, current models only focus on leveraging knowledge in one general source domain while failing to successfully transfer knowledge from multiple sources to the target. To address these issues, we introduce Collaborative Domain-Prefix Tuning for cross-domain NER (Cp -NER) based on text-to-text generative PLMs. Specifically, we present textto-text generation grounding domain-related instructors to transfer knowledge to new domain NER tasks without structural modifications. We utilize frozen PLMs and conduct collaborative domain-prefix tuning to stimulate the potential of PLMs to handle NER tasks across various domains. Experimental results on the Cross-NER benchmark show that the proposed approach has flexible transfer ability and performs better on both one-source and multiple-source cross-domain NER tasks.</p>
</blockquote>
<p>作者期望解决下面三个问题：</p>
<ul>
<li>之前的跨域IE方法依赖于为不同的domain设计不同的architecture</li>
<li>大多数现有的方法需要tuning PLM的所有参数，计算代价较高</li>
<li>之前的方法只考虑单源的跨域IE</li>
</ul>
<p>作者提出的方法</p>
<ul>
<li><p>使用prefix-tuning，这样就不需要为不同的domain设计不同的architecture</p></li>
<li>使用frozen PLM parameters，这样就不需要更新模型的所有参数</li>
<li><p>考虑多源的跨域IE</p></li>
</ul>
<p>下面是方法图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230525230232411.png" alt="image-20230525230232411" /><figcaption>image-20230525230232411</figcaption>
</figure>
<p>作者方法基于T5-base（220M参数），重点在于prefix embedding的学习，prefix embedding会加入到输入的sentence tokens的左边（简单看了下代码，应该是长度为10）。按照prefix-tuning的原论文，prefix-tuning可以看做是continuous instruction，是用来学习和task相关的context信息，进而激发LM去执行特定的任务，特别是对于那些没有表现出利用人类自然语言描述的instruction去执行特定任务的小模型（BERT、GPT-1,2等）。</p>
<p>prefix embedding是要从每个领域都进行训练学习，prefix embedding在T5的每一层都有独立的表示。学习的方法就是在加入prefix embedding之后，再按照T5的训练loss，在domain data下进行训练，过程中保持T5原来的所有参数不变。（对应图中的domain-specific warm-up过程）</p>
<p>之后，作者因为要考虑多源IE，因此通过source domain的实体label和target domain的实体label计算相似度；domain prefix embedding之间也计算相似度这样来评估不同来源对于target domain的影响大小。（对应图中的dual-query domain selector过程）</p>
<p>最后，在前一步计算得到的相似度经过softmax之后和多源prefix embedding进行加权求和，再加入到target domain的prefix embedding上。作者最后还进行了再一次的微调，训练最终学习到的target domain prefix embedding。</p>
<p>实验结果，下面是单源IE，以CONLL2003作为source domain，CrossNER数据集下的多个子集作为target domain：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230525231607634.png"   style="zoom:40%;" /></p>
<p>下面是多源的跨域抽取，以CoNLL 2003, Politics, Literature, and Music作为source domain，使用Mit-Movie, AI, Science, and Mit-Restaurant作为target domain：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230525231642332.png"   style="zoom:40%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>IE</category>
      </categories>
      <tags>
        <tag>IE</tag>
      </tags>
  </entry>
  <entry>
    <title>KGE-Collection</title>
    <url>/collection/KGE-Collection/</url>
    <content><![CDATA[<h1 id="collection-of-kge-papers-volume-1">Collection of KGE Papers Volume 1</h1>
<p>Collection of KGE papers, volume 1.</p>
<p>Now it contains models of:</p>
<ul>
<li>HoLE (AAAI 2016)</li>
<li>TACT(AAAI 2021)</li>
<li>TransF(ICPR 2018)</li>
<li>TransCoRe(JCST 2018)</li>
<li>Interpreting-KGE(ICLR 2021)</li>
<li>TuckER(EMNLP 2019)</li>
<li>MLP for KGE(KDD 2014)</li>
<li>TransH(AAAI 2014)</li>
<li>TransA(arXiv 2015)</li>
<li>TransR(AAAI 2015)</li>
<li>TransD(IJNLP 2015)</li>
<li>TransG(ACL 2016)</li>
<li>CP for KGE(ICML 2018)</li>
<li>SimplE(NIPS 2018)</li>
<li>Complex(ICML 2016)</li>
<li>REInceptionE(AAAI 2020)</li>
<li>R-MeN(ACL 2020)</li>
<li>HypER(ICANN 2019)</li>
<li>RSN(ICML 2019)</li>
<li>NSCaching(ICDE 2019)</li>
</ul>
<span id="more"></span>
<h2 id="hole">HoLE</h2>
<p><strong>Holographic Embeddings of Knowledge Graphs</strong> AAAI 2016</p>
<p>这篇文章提出了holographic embeddings (HOLE)，来学习KG的compositional vector space representations。</p>
<p><strong>motivation</strong>：However, existing embedding models that can capture rich interactions in relational data are often limited in their scalability. Vice versa, models that can be computed efficiently are often considerably less expressive.</p>
<p><strong>methods</strong>：直接从subject entity embedding和object entity embedding中，使用circular correlation获得新的embedding，称作holograph embedding，然后使用这个holograph embedding与relation embedding做点积，得到预测概率。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210418184909978.png" style="zoom:50%;" /></p>
<p>一个图示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210511102258964.png" style="zoom:50%;" /></p>
<p>从这个图能够看出来，Circular Correlation可以看做是tensor dot的一种压缩方式，它的输出结果的每一维都是tensor dot结果的一部分。</p>
<h2 id="tact">TACT</h2>
<p><strong>Topology-Aware Correlations Between Relations for Inductive Link Prediction in Knowledge Graphs</strong> AAAI 2021</p>
<a href="/kge/TACT/" title="[个人详细博客]">[个人详细博客]</a>
<p><a href="https://github.com/MIRALab-USTC/KG-TACT">TACT</a>，作者主要考虑的是inductive link prediction，使用gnn，捕获relation之间的语义上的关联性，即semantic correlation。作者认为relation之间的关联性通过relation的拓扑结构得到体现，因此，作者将所有的relation之间相连的拓扑结构分为7种，在relation形成的graph中进行学习，提出了RCN。</p>
<p>然后看一下整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210511102445139.png" style="zoom:50%;" /></p>
<h2 id="transf">TransF</h2>
<p><strong>Knowledge Graph Embedding with Multiple Relation Projections</strong> ICPR 2018</p>
<p>基于翻译的方法，在TransR的思想上的改进。考虑了每个relation不是独立的，而是具有Correlation，比如关系<em>/people/person/place_of_birth</em>和<em>/people/person/nationality</em>就有较强的相关性，比如居住在纽约的人大概率是美国人。为了解决这个问题，作者直接将每个relation独立的matrix分为一系列的basis space的组合，对于不同relation有不同的组合系数。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210511102512774.png" style="zoom:50%;" /></p>
<p>公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210418181121701.png" style="zoom:50%;" /></p>
<p>在实验中，在FB15k-237数据集上，作者使用了维度100，s数量5；在WN18RR数据集上，维度50，s数量5。最后使用TransR的方法投影：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210511110706718.png" style="zoom:50%;" /></p>
<h2 id="transcore">TransCoRe</h2>
<p><strong>Modeling the Correlations of Relations for Knowledge Graph Embedding</strong> JCST</p>
<p>作者考虑了关系之间的correlation，首先利用SVD和PCC方法分析了TransE这些方法学习到的relation embedding之间的相关性，然后发现在所有relation组成的matrix中，存在low-rank的structure。因此，作者直接将relation matrix拆分为两个矩阵的乘积，一个是通用矩阵，一个是关系矩阵，每一列对应不同的relation。 <span class="math display">\[
\mathbf{R}=\mathbf{U}\mathbf{V}
\]</span> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210511110904912.png" style="zoom:50%;" /></p>
<p>在这种情况下，矩阵<span class="math inline">\(\mathbf{U}\)</span>的列是关系空间的basis</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210511110958068.png" style="zoom:50%;" /></p>
<p>最后</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210518225522673.png" style="zoom:50%;" /></p>
<h2 id="interpreting-kge">Interpreting-KGE</h2>
<p><strong>INTERPRETING KNOWLEDGE GRAPH RELATION REPRESENTATION FROM WORD EMBEDDINGS</strong> ICLR 2021</p>
<p>从最新的基于PMI（pointwise mutual information (PMI)）的对于word embedding的理解角度出发，尝试从relation描述的subject和object entity的语义关联性角度进行解释；将所有的relation分为3类，并且解释了为了捕获它们的特征需要如何学习。</p>
<p><strong>很多地方没看懂。</strong></p>
<p>三个不同的分类：</p>
<ul>
<li>highly related (R);</li>
<li>generalised specialisation (S);</li>
<li>and generalised context-shift (C).</li>
</ul>
<p>三者是包含关系，C&gt;S&gt;R</p>
<p>在WN18RR下不同关系的分类，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210510170730416.png" style="zoom:50%;" /></p>
<p>FB15k-237的relation大多是type C，也就是说该数据集中的relation没有特别明显的结构联系。</p>
<h2 id="tucker">TuckER</h2>
<p><strong>TuckER: Tensor Factorization for Knowledge Graph Completion</strong> EMNLP 2019</p>
<p>这篇文章使用1996年就被提出来的分解方法 Tucker decomposition，提出了TuckER，TuckER的主要结构如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210520160757408.png" style="zoom:50%;" /></p>
<p>其中的参数<span class="math inline">\(W\)</span>是所有关系共享的，<span class="math inline">\(e_s,w_r,e_o\)</span>是subject, relation和object entity的embedding，都是向量化的表示。</p>
<p>具体计算公式是，沿着不同维度（mode）进行乘法运算</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/v2-930f8a5f6ef0dd9db35e1e6f5a7f112f_1440w.png" style="zoom:50%;" /></p>
<p>这篇文章可以考虑用来简化R-GCN中的<span class="math inline">\(W_r\)</span>。</p>
<h2 id="mlp-for-kge">MLP for KGE</h2>
<p><strong>Knowledge Vault: A Web-Scale Approach to Probabilistic Knowledge Fusion</strong> KDD 2014</p>
<p>这篇文章介绍了Knowledge Vault</p>
<blockquote>
<p>a Web-scale probabilistic knowledge base that combines extractions from Web content (obtained via analysis of text, tabular data, page structure, and human annotations)</p>
</blockquote>
<p>在文章中，使用了MLP来获得KGE，主要用于评估构造的KG中的edge存在的概率，主要方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210520193708498.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(\beta \in \mathbb{R}^{L\times 1}\)</span>，<span class="math inline">\(u_s, w_p, v_o\)</span>是subject、relation和object。</p>
<h2 id="transh">TransH</h2>
<p><strong>Knowledge Graph Embedding by Translating on Hyperplanes</strong> AAAI 2014</p>
<p>这篇文章的贡献有两点</p>
<ul>
<li>在TransE的基础上，提出了TransH，将subject和object entity投影到不同relation的超平面上，该超平面由一个法向量<span class="math inline">\(w_r\)</span>决定，超平面上有一个偏移向量<span class="math inline">\(d_r\)</span>，用于算头实体和尾实体投影之间的偏移。</li>
<li>使用了一个简单基于统计的，能够减小负采样错误率的方法。原理是one-to-many的relation应该倾向于替换head entity；many-to-one的relation倾向于替换tail entity。直接统计number of tail entities per head entity和number of head entities per tail entity，然后使用二元分布，计算替换head或者tail entity的概率。这种方法区别于以前的uniform的采样，可以叫做Bernoulli采样。</li>
</ul>
<p>TransH的结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210520220253182.png" style="zoom:50%;" /></p>
<p>数学公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210524162955001.png" style="zoom:50%;" /></p>
<p>在训练中，保证<span class="math inline">\(||w_r||_2=1\)</span>，同时<span class="math inline">\(w_r \perp d_r\)</span>。</p>
<h2 id="transa">TransA</h2>
<p><strong>TransA: An Adaptive Approach for Knowledge Graph Embedding</strong> arxiv 2015</p>
<p>这篇文章提出了一个新的计算loss的方法，将计算欧氏距离，换为计算马氏距离。</p>
<p>作者认为对于以前的loss形式过于简单</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210524163344113.png" style="zoom:50%;" /></p>
<p>缺点两个：</p>
<ul>
<li>这个loss metric实际是在计算一个球面等位超面spherical equipotential hyper-surfaces，这种方式过于简单，不够灵活，泛化</li>
</ul>
<blockquote>
<p>Firstly, due to the inflexibility of loss metric, current translation-based methods apply spherical equipotential hyper-surfaces with different plausibilities, where more near to the centre, more plausible the triple is.</p>
</blockquote>
<ul>
<li>它实际是假设embedding的不同entry的weight在计算最终loss的时候一样</li>
</ul>
<blockquote>
<p>Secondly, because of the oversimplified loss metric, current translation-based methods treat each dimension identically.</p>
</blockquote>
<p>作者提出的新指标，将计算欧氏距离，换为计算马氏距离：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210520220226480.png" style="zoom:50%;" /></p>
<h2 id="transr">TransR</h2>
<p><strong>Learning Entity and Relation Embeddings for Knowledge Graph Completion</strong> AAAI 2015</p>
<p>这篇文章改进了TransE和TransH认为embedding都在相同的semantic space中。TransR认为不同关系具有不同的space，实体在entity space下，提出了TransR。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210520223201288.png" style="zoom:50%;" /></p>
<p>数学公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210520223130667.png" style="zoom:50%;" /></p>
<p>能够看到，还是有单独的relation embedding。</p>
<p>作者还提出了一个改进版，CTransR（Cluster-based TransR）。它对于一个单独的relation r，将不同的(head, tail)对分成几个不同的clusters，不同的clusters拥有自己的relation vector <span class="math inline">\(r_c\)</span>，整个relation下的所有clusters有一个共同的relation vector <span class="math inline">\(r\)</span>，此时的scoring function为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210524193736657.png" style="zoom:50%;" /></p>
<h2 id="transd">TransD</h2>
<p><strong>Knowledge Graph Embedding via Dynamic Mapping Matrix </strong> IJCNLP 2015</p>
<p>作者将所有的entities和relations都赋予了两个vectors，一个vectors和以前的embedding一样，作为实体和关系的向量化embedding；一个vectors用来构件转换矩阵：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210520223607761.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210524193757495.png" style="zoom:50%;" /></p>
<h2 id="transg">TransG</h2>
<p><strong>TransG : A Generative Model for Knowledge Graph Embedding</strong> ACL 2016</p>
<p>这是第一篇在KGE上使用generative model的论文，第一次明确提出并且讨论<strong>multiple relation semantics</strong>，即一个relation可能有不同的语义含义，这个语义含义是由它链接的头/尾实体决定的。</p>
<blockquote>
<p>In spite of the success of these models, none of the previous models has formally discussed the issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples.</p>
</blockquote>
<p>为了让relation有更多不同的表示，作者使用Bayesian non-parametric inﬁnite mixture embedding model [1]的思路，为每个relation都学习多个不同的component。</p>
<p>[1] The indian buffet process: An introduction and review.</p>
<p>对生成模型不了解，这篇文章没有细读。</p>
<h2 id="cp-for-kge">CP for KGE</h2>
<p><strong>Canonical tensor decomposition for knowledge base completion</strong> ICML 2018</p>
<p><a href="https://github.com/facebookresearch/kbc" class="uri">https://github.com/facebookresearch/kbc</a></p>
<p>作者集中在使用canonical decomposition of tensors (also called CANDECOMP/PARAFAC or CP)来学习KGE。对于CP的改进集中在两方面：</p>
<ul>
<li>引入关系的逆关系，分别具有不同的表示，显示使用这种办法能够很好的提升效果</li>
<li>使用tensor nuclear p-norms正则化CP，虽然最后结果显示没有很显著的提升CP效果</li>
</ul>
<p>最终效果没有超越ComplEX，但是提升CP效果很多。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210526215137325.png" style="zoom:50%;" /></p>
<p>CP分解：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210530213931363.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(\mathbf{X}\)</span>是整个KG张量。</p>
<p>后续调研张量分解的方法可以从这篇文章出发。</p>
<h2 id="simple">SimplE</h2>
<p><strong>SimplE Embedding for Link Prediction in Knowledge Graphs</strong> NIPS 2018</p>
<p><a href="https://github.com/Mehran-k/SimplE">SimplE</a> 使用CP分解，改进了一般的CP分解，与一般的CP分解一样，每个entity有两种表示对于head和tail，每个relation有唯一的表示。在预测triple是否成立时，同时用原关系和逆关系是否成立进行平均打分。在论文中，作者证明了SimplE是fully expressivene的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210530214019324.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(&lt;&gt;\)</span>函数是向量内积，定义为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210526215101906.png" style="zoom:67%;" /></p>
<h2 id="complex">Complex</h2>
<p><strong>Complex Embeddings for Simple Link Prediction</strong> ICML 2016</p>
<p><a href="https://github.com/ttrouill/complex">Complex</a>应该是首个将KGE中的embedding从实数域扩展到复数域的方法，它的思想还是基于矩阵分解的思路，但是在RESCAL和DistMult这些方法的基础上，通过引入复数域，能够建模关系的对称/不对称关系，同时还能保证参数的有效性。因为在复数域的向量内积就变为了Hermitian (or sesquilinear) dot product，拥有了一个共轭的转置表示conjugate-transpose</p>
<p>具体公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210626220840153.png" style="zoom:50%;" /></p>
<p>其中的，<span class="math inline">\(Re\)</span>是实数部分，<span class="math inline">\(Im\)</span>是虚数部分。</p>
<p>之后，预测概率</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210626221427316.png" style="zoom:50%;" /></p>
<h2 id="reinceptione">REInceptionE</h2>
<p><a href="https://github.com/JuneTse/ReInceptionE."><strong>ReInceptionE: Relation-Aware Inception Network with Joint Local-Global Structural Information for Knowledge Graph Embedding</strong></a> AAAI 2020</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210707181438099.png" style="zoom:40%;" /></p>
<p>使用Inception网络学习对所有的<span class="math inline">\((h,r,?)\)</span>都可以编码为一个embedding。</p>
<p>如果要查询<span class="math inline">\((h,r,?)\)</span>，<span class="math inline">\(h,r\)</span>可以通过inception网络变为为一个查询embedding。</p>
<p>对于头实体<span class="math inline">\(h\)</span>的邻居，都可以通过inception网络变为邻居embedding，之后使用查询embedding去计算邻居embedding注意力，然后进行聚合。</p>
<p>对于要查询的关系<span class="math inline">\(r\)</span>，对于图中所有属于<span class="math inline">\(r\)</span>的头尾实体应该可以提供某种特定的特征，因此，利用查询embedding，计算所有属于<span class="math inline">\(r\)</span>的头实体的注意力然后聚合；同样，聚合特定的尾实体的信息。</p>
<p>最后，融合三方面的信息，通过一个MLP，进行预测。</p>
<h2 id="r-men">R-MeN</h2>
<p><a href="https://github.com/daiquocnguyen/%20R-MeN"><strong>A Relational Memory-based Embedding Model for Triple Classiﬁcation and Search Personalization</strong></a> R-MeN ACL 2020</p>
<p>为了能够记忆KG中的三元组之间可能存在的潜在依赖，提出了R-MeN方法，模型图</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709221208885.png" style="zoom:50%;" /></p>
<p>在一个三元组<span class="math inline">\((s,r,o)\)</span>中，首先编码为三个不同的embedding</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709221647609.png" style="zoom:50%;" /></p>
<p>模仿Transformer加入了位置embedding。然后，设计了一个记忆力单元<span class="math inline">\(M\)</span>，设计中<span class="math inline">\(M\)</span>应该拥有<span class="math inline">\(N\)</span>个memory slot，每一行是一个记忆力插槽。但是在实现的时候发现只有一个记忆力插槽的时候效果最好。</p>
<p>之后，依次输入<span class="math inline">\(x_t\)</span>，使用transformer的注意力机制聚合<span class="math inline">\(x_t\)</span>和<span class="math inline">\(M\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709222104512.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709222043286.png" style="zoom:50%;" /></p>
<p>在这个之后，加入了MLP，残差，gate。实际从结果来看，没有特别大的提升。</p>
<h2 id="hyper">HypER</h2>
<p><a href="https://github.com/ibalazevic/HypER"><strong>Hypernetwork Knowledge Graph Embeddings</strong></a> ICANN 2019</p>
<p>这篇文章在ConvE的基础上改进，提出了HypER，使用relation embedding通过一个hypernetwork（Hypernetworks. In: International Conference on Learning Representations.）为每个关系都产生一个1D卷积核。和ConvE有的区别是不使用2D的卷积，不需要reshape entity embedding和relation embedding。作者另外证明了这种1D卷积的方法最终可以归类到tensor factorization中。</p>
<blockquote>
<p>A hypernetwork is an approach by which one network generates weights for another network, that can be used to enable weight-sharing across layers and to dynamically synthesize weights given an input.</p>
</blockquote>
<p>结构图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210719154018301.png" style="zoom:50%;" /></p>
<p>核心公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210719154108887.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(vec^{-1}\)</span>是重新将向量转化为矩阵形式。<span class="math inline">\(w_r\)</span>就是relation embedding，它的实际维度与entity embedding维度一致。</p>
<p>从tensor operation的角度看HypER。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210719154328117.png" style="zoom:50%;" /></p>
<h2 id="rsn">RSN</h2>
<p><a href="https://github.com/nju-websoft/RSN"><strong>Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs</strong></a> ICML 2019</p>
<p>使用带残差的RNN的方法建模KG的relational path，预测实体对齐和链路预测两个任务。</p>
<p>核心的模型结构，首先提出了一种Biased random walk sampling，偏好采用更深的实体路径，输出relational path。</p>
<p>然后使用RSN(Recurrent skipping network)建模这个path，核心思想在于强调relational path中triple的重要性。将subject entity的hidden state作为残差输出到object entity的上一步hidden state中。一个relational path元素个数为奇数，头尾都是实体，<span class="math inline">\((x_1,\dots,x_{odd})\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210719200737571.png"   style="zoom:50%;" /></p>
<p>然后，对实体和关系做区别对待：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210719200912943.png"   style="zoom:50%;" /></p>
<p>模型结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210719201218600.png"   style="zoom:50%;" /></p>
<p>使用Type-based noise contrastive estimation(NCE)进行优化，对这个优化方法没有很了解。</p>
<h2 id="nscaching">NSCaching</h2>
<p><a href="https://github.com/yzhangee/NSCaching"><strong>NSCaching: Simple and Efﬁcient Negative Sampling for Knowledge Graph Embedding</strong></a> ICDE 2019</p>
<a href="/kge/NSCaching/" title="[个人详细博客]">[个人详细博客]</a>
<p>提出了一种针对KGE的动态负采样方法<a href="https://github.com/yzhangee/NSCaching">NSCaching</a>，核心思想是得分高的负样本很重要但是数量少，因此，作者直接使用cache来保存得分高的负样本，同时随着训练动态更新cache，可以看做是基于GAN的负采样方法的distilled版本。</p>
<p>在训练KGE的时候，负样本的质量很重要，也就是说那些越难与正样本区分的负样本可能越重要。<em>high-quality negative triplets should have large scores</em>，因为基于embedding的model实际上对于大多数负样本不敏感，给出的都是比较低的打分。如果使用random采样，采样得到的负样本，激活函数如果是sigmoid函数，那么如果负样本得分在&lt;&lt;0的区间内，那么梯度会很小，造成梯度消失的问题。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210722173128966.png" style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210722173851214.png"   style="zoom:40%;" /></p>
<h2 id="structure">StructurE</h2>
<p><strong>Structural context-based knowledge graph embedding for link prediction</strong> Neurocomputing 2022</p>
<p>这篇文章是基于trans的KGE方法，它对于两个预测任务<span class="math inline">\(&lt;h, t, ?&gt;\)</span>和<span class="math inline">\(&lt;?, r, t&gt;\)</span>分别设计了不同的score function。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303152549137.png"   style="zoom:50%;" /></p>
<p>核心是两个公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303152702651.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220303152749096.png"   style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
      <tags>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title>IE-data-augment-collection1</title>
    <url>/collection/IE-data-augment-collection1/</url>
    <content><![CDATA[<h1 id="data-augment-for-ie-papers-1">Data Augment for IE papers 1</h1>
<p>基于数据增强策略的信息抽取论文合集 1。</p>
<span id="more"></span>
<h1 id="cross-domain-ie">Cross-domain IE</h1>
<h2 id="cda">CDA</h2>
<p>Data Augmentation for Cross-Domain Named Entity Recognition</p>
<p>简写是Cross-domain Data Augmentation (CDA)方法。</p>
<p>EMNLP 2021，休斯顿大学与Snap，<a href="https://github.com/RiTUAL-UH/style_NER">代码</a>。</p>
<blockquote>
<p>Current work in named entity recognition (NER) shows that data augmentation techniques can produce more robust models. However, most existing techniques focus on augmenting in-domain data in low-resource scenarios where annotated data is quite limited. In contrast, <strong>we study cross-domain data augmentation for the NER task.</strong> We investigate the possibility of leveraging data from highresource domains by projecting it into the lowresource domains. Specifically, we propose a novel neural architecture to transform the data representation from a high-resource to a <strong>low-resource domain by learning the patterns (e.g. style, noise, abbreviations, etc.)</strong> in the text that differentiate them and a shared feature space where both domains are aligned. We experiment with diverse datasets and show that transforming the data to the low-resource domain representation achieves significant improvements over only using data from high-resource domains.</p>
</blockquote>
<p>应该是首个考虑用数据增强策略做跨域NER任务的方法。</p>
<p>之前的数据增强IE方法主要是利用in-domain data进行数据增强。作者发现不同domain有不同的patterns：</p>
<blockquote>
<p>Based on our observations, the text in different domains usually presents unique patterns (e.g. style, noise abbreviations, etc.).</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913185736771.png"   style="zoom:30%;" /></p>
<p>例如上面例子中新闻domain的句子更长，表达也更加正式；而social domain的句子有更多的噪音，句子更短，有更多口语/个性化的表达。</p>
<p>但是，作者认为不同domain的text的语义是可以迁移的，并且是存在领域不变量invariables的。作者研究从high-resource domain到low-resource domain数据增强NER方法。</p>
<p>和之前的数据增强方法一样，作者同样训练了一个LM来生成数据，编码器+解码器。编码器是biLSTM，解码器是另一层LSTM。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913191836826.png"   style="zoom:30%;" /></p>
<p>作者提出的训练模型包括两步：</p>
<ul>
<li><p>Denoising Reconstruction：learn the textual pattern and generate compressed representations of the data from each domain</p>
<ul>
<li><p>在输入的text中加入噪音，能够强迫model更加学会保留原始的数据结构信息，所以作者首先通过几种word-level operation来插入噪音：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913190334476.png"  style="zoom:30%;" /></p></li>
<li><p>使用相同参数的encoder和decoder去重建两个domain的input sentence。模型的参数可以看做是学习了隐式的领域对齐。loss是解码器输出和input text之间的差异。</p></li>
<li><p>这一步还额外训练了一个对抗式判别器discriminator用来判断编码器的输出是来自哪个领域，为下一步model学习domain mapping做准备。</p></li>
</ul></li>
<li><p>Detransforming Reconstruction：align the compressed representations of the data from different domains so that the model can project the data from one domain to another</p>
<ul>
<li>首先，用上一步学习好的encoder+decoder，把source domain的sentence转化为target domain style的sentence；把target domain的sentence转化为source domain style的sentence</li>
<li>然后，利用跨域转化后的句子，经过编码器和解码器，期望能够恢复在原来domain的句子</li>
<li>这一步继续训练对抗式判别器discriminator，如果判别器根据编码器的输出，判断领域变换后的sentence是原来domain的概率越小，则认为domain mapping效果越好</li>
</ul></li>
</ul>
<p>作者基于Ontonotes 5.0 Dataset（domains：Broadcast Conversation (BC), Broadcast News (BN), Magazine (MZ), Newswire (NW), and Web Data (WB).）和Temporal Twitter Dataset（Social Media (SM) domain）进行实验。基于source domain的data生成target domain的新training data。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913192010655.png"   style="zoom:30%;" /></p>
<p>上面实验结果中能够看出，原来的in-domain的数据增强方法（如DAGA方法）无法很好的处理跨域问题。这说明原来数据增强方法无法直接生成对应domain的数据。</p>
<p>实验用的NER model是BERT+Linear Layer。</p>
<h2 id="style-transfer">Style Transfer</h2>
<p>Style Transfer as Data Augmentation: A Case Study on Named Entity Recognition</p>
<p>与前面CDA是同一作者。EMNLP 2022，<a href="https://github.com/RiTUAL-UH/DA_NER">代码</a>。</p>
<blockquote>
<p>In this work, we take the named entity recognition task in the English language as a case study and explore style transfer as a data augmentation method to increase the size and diversity of training data in low-resource scenarios. We propose a new method to effectively transform the text from a high-resource domain to a low-resource domain by <strong>changing its style-related attributes to generate synthetic data for training.</strong> Moreover, we design a constrained decoding algorithm along with a set of key ingredients for data selection to guarantee the generation of valid and coherent data. Experiments and analysis on five different domain pairs under different data regimes demonstrate that our approach can significantly improve results compared to current state-of-the-art data augmentation methods. Our approach is a practical solution to data scarcity, and we expect it to be applicable to other NLP tasks.</p>
</blockquote>
<p>作者探究使用style transfer来为cross-domain NER任务做数据增强的方法。由于并没有带有NER label的style transfer数据集，因此作者提出可以利用非NER任务的style transfer数据集。（风格转换一定程度上不局限在特定任务，但是作者这种做法有个隐含的前提，就是NER的source domain和target domain中的styles已经包括在了非NER任务的style transfer数据集中）。</p>
<p>作者同样训练一个encoder+decoder的LM进行数据生成。这篇论文中作者使用的是T5-base。</p>
<p>第一步就是在非NER任务的style transfer数据集GYAFC (Rao and Tetreault, 2018)上进行训练。这个数据集包括了formal and informal的句子对。通过输入某个style的句子，让T5学会输出对应其它style的句子，优化重建loss <span class="math inline">\(L_{pg}\)</span>。作者follow前人的工作，将style transfer看做是改写生成的问题paraphrase generation problem。和作者之前工作CDA中的domain判别器类似，这一步也额外训练了一个对抗性的style判别器，用来判断编码器输出的embedding是属于哪种style。</p>
<p>第二步是想办法让T5能够学会在NER的句子上进行风格转换。首先要把label注入到sentence中，这里作者把<code>&lt;START_ENTITY_TYPE&gt;</code> and <code>&lt;END_ENTITY_TYPE&gt;</code>插入到entity span的左右侧。然后就是作者提出的cycle-consistent reconstruction，简单说是输入某个sentence，让T5转化为另一种style的sentence，把这个转换后的sentence再输入到T5中，让T5重新回复原来style的sentence。第二步同样优化对抗性style判别器。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913215520630.png"   style="zoom:40%;" /></p>
<p>第三步是生成。为了保证生成数据是valid的，提出了基于prefix tree的Constrained Decoding策略，是保留top-K或top-p的token候选项，然后约束生成句子的输出范围，比如之前输出的span是属于<code>&lt;Text&gt;</code>，那么接下来输出的span就必须是<code>&lt;EOS&gt;</code> or <code>&lt;B_ENT&gt;</code>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913220118855.png"   style="zoom:30%;" /></p>
<p>即使经过上一步，也不能保证生成数据是可靠的。为了进一步提升质量，比如过滤掉简单的重复、胡言乱语等生成的text，计算四个方法的4个metric，然后加权求和作为对于生成data质量的评估：</p>
<ul>
<li>Consistency: a confidence score from a pretrained style classifier as the extent a generated sentence is in the target style. 基于T5 base，用一个外部的model判断是否符合特定style</li>
<li>Adequacy: a confidence score from a pretrained NLU model on how much semantics is preserved in the generated sentence. 基于<a href="https://github.com/%20PrithivirajDamodaran/Parrot_Paraphraser">开源model</a>，判断生成句子保留的语义</li>
<li>Fluency: a confidence score from a pretrained NLU model indicating the fluency of the generated sentence. 基于<a href="https://github.com/%20PrithivirajDamodaran/Parrot_Paraphraser">开源model</a>，判断生成句子的流程程度</li>
<li>Diversity: the edit distance between original sentences and the generated sentences at the character level. 利用原始sentence和生成sentence的编辑距离来衡量生成句子的多样性。</li>
</ul>
<p>实验数据集与CDA中的一样，使用OntoNotes 5.0作为source domain和Temporal Twitter Corpus作为target domain。OntoNotes 5.0的domain style是formal的，Temporal Twitter Corpus的domain style是informal的。</p>
<p>作者的NER model是基于BERT base+Linear，与CDA的一致。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913230108250.png"   style="zoom:30%;" /></p>
<h2 id="fact-mix">Fact-Mix</h2>
<p>FactMix: Using a Few Labeled In-domain Examples to Generalize to Cross-domain Named Entity Recognition. COLING 2022，西湖大学 ，<a href="https://github.%20com/lifan-yuan/FactMix">代码</a>。</p>
<blockquote>
<p>Few-shot Named Entity Recognition (NER) is imperative for entity tagging in limited resource domains and thus received proper attention in recent years. Existing approaches for few-shot NER are evaluated mainly under in-domain settings. In contrast, little is known about how these inherently faithful models perform in cross-domain NER using a few labeled in-domain examples. <strong>This paper proposes a two-step rationale-centric data augmentation method to improve the model’s generalization ability.</strong> Results on several datasets show that our model-agnostic method significantly improves the performance of crossdomain NER tasks compared to previous state-of-the-art methods, including the data augmentation and prompt-tuning methods. Our codes are available at https://github.com/lifan-yuan/FactMix.</p>
</blockquote>
<p>作者主要从数据增强的角度解决跨域NER问题。作者认为跨域的NER任务要考虑两个核心问题：</p>
<ul>
<li>NER任务作为序列标注任务，它的label之间是相互依赖的，而不是相互独立的。不同领域这种label依赖不一样。it is essential to understand dependencies within the labels instead of classifying each token independently.</li>
<li>不同domain的文本中的non-entity tokens的语义是不一致的，这种不一致可能增大NER模型进行跨域NER的困难程度。non-entity tokens in NER do not hold unified semantic meanings, but they could become noisy when combined with entity tokens in the training set.</li>
</ul>
<p>因此，作者认为NER模型学习到的non-entity token和要预测的label之间隐式联系可能影响跨域性能。比如在医学domain上的句子'Jane monitored the patient’s heart rate'，Jane是一个person，在医学domain上训练好的一个NER model可能学习到Jane和monitored之间的潜在关联。但是如果迁移到关于movie review的跨域数据集上，Jane和monitor之间的在医疗领域的潜在关联就不再合适了。</p>
<p>因此，作者提出了一种新的数据增强策略Context-level semi-fact generations：</p>
<ul>
<li>随机使用MLM的[MASK] token代替source domain文本中的某个non-entity token，选择预测时概率最大的词进行替换。这样就引入了out-of-domain的context信息（被预训练model在预训练阶段学习到的信息）</li>
<li>为了避免替换后的词引起entity label标注的影响，作者只保留那些能够被NER模型正确预测所有token NER tag的替换后的样例</li>
</ul>
<p>这种数据增强策略Context-level semi-fact generations和之前研究者提出的Entity-level semi-fact generations结合起来：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530110812914.png" alt="image-20230530110812914" /><figcaption>image-20230530110812914</figcaption>
</figure>
<p>实验以CONLL2003作为source domain，CrossNER数据集下的多个子集作为target domain。训练的时候应用到了fine-tuning based和prompt-tuning based两种NER微调策略，具体参考论文。作者在BERT和RoBERT两类模型不同size的LM上进行了实验。</p>
<p>只使用source domain的数据来进行训练，然后测试在target domain上的效果，验证模型的领域泛化性。</p>
<h1 id="in-domain-ie">In-domain IE</h1>
<h2 id="daga">DAGA</h2>
<p>DAGA: Data Augmentation with a Generation Approach for Low-resource Tagging Tasks</p>
<p>南洋理工与阿里达摩，EMNLP 2020，<a href="https://github.com/ntunlp/daga">代码</a>。</p>
<blockquote>
<p>Data augmentation techniques have been widely used to improve machine learning performance as they enhance the generalization capability of models. In this work, to generate high quality synthetic data for low-resource tagging tasks, <strong>we propose a novel augmentation method with language models trained on the linearized labeled sentences. Our method is applicable to both supervised and semi-supervised settings.</strong> For the supervised settings, we conduct extensive experiments on named entity recognition (NER), part of speech (POS) tagging and end-to-end target based sentiment analysis (E2E-TBSA) tasks. For the semi-supervised settings, we evaluate our method on the NER task under the conditions of given unlabeled data only and unlabeled data plus a knowledge base. The results show that our method can consistently outperform the baselines, particularly when the given gold training data are less.</p>
</blockquote>
<p>作者声称是首个在序列标注task上，引入LM做数据增强的文章。</p>
<p>数据增强是用来人造数据的一种在各个领域都被广泛应用的方法。NLP上的数据增强有它自己独特的特征：在image上简单的修改通常不会改变image本身的信息；但是在natural language上删除或替换一个词就可能完全改变整个sentence的意思。</p>
<p>而一般的NLP 数据增强方法包括synonym replacement, random deletion/swap/insertion, generation with VAE or pre-trained language models、back translation、systematically reordering the dependents of some nodes in gold data、leveraging knowledge base for question generation等等。</p>
<p>和上面的NLP任务相比，类似NER这类的token-level的sequence tagging任务对数据增强时引入的噪音更加敏感。序列标注有的3种尝试（2020年前）：</p>
<ul>
<li>Annotating unlabeled data with a weak tagger [<em>Automated phrase mining from massive text corpora. 2018</em>] 使用已有的标注工具直接进行标注，需要标注工具已经提前具备了相应的domain knowledge，否则面临domain-shift problem [<em>Multimix: A robust data augmentation framework for cross-lingual nlp. 2020</em>]</li>
<li>leveraging aligned bilingual corpora to induce annotation [<em>Inducing multilingual text analysis tools via robust projection across aligned corpora. 2001</em>] 要求有额外的外语语料，很多情况下不实际</li>
<li>synonym replacement [<em>Biomedical named entity recognition via reference-set augmented bootstrapping. 2019</em>] 需要WordNet这类外部知识和人工设计的规则，难以覆盖所有的低资源场景</li>
</ul>
<p>因此，作者提出使用生成式的数据增强方法。作者首先训练一个LM学会现有gold data中语言的特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912161946176.png"   style="zoom:30%;" /></p>
<p>单层的LSTM作为语言模型，使用一般的单向language objectives进行优化。作者通过sentence linearization把所有的序列标注sentence都转换为带有tag的句子（NER任务中忽略tag <span class="math inline">\(O\)</span>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912162201735.png"   style="zoom:30%;" /></p>
<p>将tag放在对应的word前面，作者发现这样比tag在word后面效果好。推测原因是这样子可能更加符合一般的语言中形容词-名词的pattern（Modifier-Noun pattern）。</p>
<p>在生成的时候，输入是<code>[BOS]</code>，让LSTM LM直接输出各种不同的句子。对于输出的句子进行后处理，比如删除没有tag的句子、删除有错误tag的情况等。</p>
<p>除了上面直接在gold data上让LM学习特征外，作者还提出了conditional generation method让LM能够利用unlabeled data or knowledge bases。从外部的数据源中获取更多的knowledge：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912162711987.png"  style="zoom:50%;" /></p>
<p>conditional generation本质就是在sentence之前添加condition tags：<span class="math inline">\(\{ [labeled], [unlabeled], [KB] \}\)</span>。</p>
<p>在实验中，作者的NER使用BiLSTM-CRF模型在gold data和生成的data上进行训练，然后评估。作者使用了过采样gold data的策略，采样1个generated data，过采样4个gold data。</p>
<p>在CoNLL2002/2003 NER数据集的多个语言子集（English, German, Dutch and Spanish）上进行验证：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163003964.png"  style="zoom:30%;" /></p>
<p>实验中有一个可以注意的是作者如何评估生成数据的多样性，一个是用entity出现的周围token作为上下文；计算unique上下文token数量；一个是统计unique entity的数量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163929108.png"   style="zoom:25%;" /> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163954188.png" style="zoom:25%;" /></p>
<h2 id="melm">MELM</h2>
<p>MELM: Data Augmentation with Masked Entity Language Modeling for Low-Resource NER</p>
<p>阿里达摩与南洋理工，ACL 2022，<a href="https://github.com/RandyZhouRan/MELM/">代码</a>。</p>
<blockquote>
<p>Data augmentation is an effective solution to data scarcity in low-resource scenarios. However, when applied to token-level tasks such as NER, <strong>data augmentation methods often suffer from token-label misalignment, which leads to unsatsifactory performance.</strong> In this work, <strong>we propose Masked Entity Language Modeling (MELM) as a novel data augmentation framework for low-resource NER.</strong> To alleviate the token-label misalignment issue, we explicitly inject NER labels into sentence context, and thus the fine-tuned MELM is able to predict masked entity tokens by explicitly conditioning on their labels. Thereby, MELM generates high-quality augmented data with novel entities, which provides rich entity regularity knowledge and boosts NER performance. When training data from multiple languages are available, we also integrate MELM with codemixing for further improvement. We demonstrate the effectiveness of MELM on monolingual, cross-lingual and multilingual NER across various low-resource levels. Experimental results show that our MELM presents substantial improvement over the baseline methods.</p>
</blockquote>
<p>前人工作指出，增强上下文带来的提升比较少[<em>A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land? EMNLP 2020</em>]。作者也发现，增强新entity多样性带来的效果要大于增强上下文patterns：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912200034085.png"  style="zoom:30%;" /></p>
<p>作者使用masked LM来给low-resource NER任务做数据增强。作者只会根据一定的概率mask entity的token。然后在mask data上fine-tuning pretrained MLM，让MLM学会根据context预测entity。</p>
<p>如果只是mask entity，然后让MLM预测，可能能够符合context，但是不一定符合原来的entity label。为了让生成的entity和原来的entity有相同的label，作者在原来的句子中插入entity type marker：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912200407792.png"   style="zoom:50%;" /></p>
<p>在进行数据生成的时候，输入masked sentence，为了增强生成数据的多样性。没有使用greedy decoding策略，而是在top-K的候选项上进行随机选择。</p>
<p>同时在生成的时候，采用了新的mask策略。每一次生成都有不同的mask阈值，这样进一步增大了mask结果的差异。</p>
<p>生成的数据需要经过处理以减低噪音，作者用一个训练好的NER模型，去处理增强的句子；只有NER model的标注和生成句子原来的entity label标注一致，才会被保留。</p>
<p>最后，作者在这篇论文中着重考虑多语言场景，引入code-mixing技术。随机从某个其它语言中，选择有相同label的entity作为候选项，之后选择在embedding space上余弦相似度的外语entity替换原来language entity（使用MUSE作为编码方法）。并且在替换后的entity前加入language tag表示替换后的entity原来的语言是什么。</p>
<p>增强的数据比例是3倍。作者实现中使用的LM是XLM-RoBERTa-base，使用的NER model是XLM-RoBERTa-Large+CRF。</p>
<p>在CoNLL 2002/2003数据集的不同语言子集上的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912201243434.png"   style="zoom:30%;" /></p>
<h2 id="gpda">GPDA</h2>
<p>Improving Low-resource Named Entity Recognition with Graph Propagated Data Augmentation</p>
<p>ACL 2023 short paper，上海科技与阿里达摩，<a href="https://github.com/modelscope/AdaSeq/tree/master/examples/GPDA">代码</a>。</p>
<blockquote>
<p>Data augmentation is an effective solution to improve model performance and robustness for low-resource named entity recognition (NER). <strong>However, synthetic data often suffer from poor diversity, which leads to performance limitations. In this paper, we propose a novel Graph Propagated Data Augmentation (GPDA) framework for Named Entity Recognition (NER), leveraging graph propagation to build relationships between labeled data and unlabeled natural texts.</strong> By projecting the annotations from the labeled text to the unlabeled text, the unlabeled texts are partially labeled, which has more diversity rather than synthetic annotated data. To strengthen the propagation precision, a simple search engine built on Wikipedia is utilized to fetch related texts of labeled data and to propagate the entity labels to them in the light of the anchor links. Besides, we construct and perform experiments on a real-world lowresource dataset of the E-commerce domain, which will be publicly available to facilitate the low-resource NER research. Experimental results show that GPDA presents substantial improvements over previous data augmentation methods on multiple low-resource NER datasets.</p>
</blockquote>
<p>data augmentation对于sentence-level NLP task两大思路：</p>
<ol type="1">
<li>One is manipulating a few words in the original sentence, which can be based on synonym replacement (Zhang et al., 2015; Kobayashi, 2018; Wu et al., 2019; Wei and Zou, 2019), random insertion or deletion (Wei and Zou, 2019), random swap (¸Sahin and Steedman, 2018; Wei and Zou, 2019; Min et al., 2020). 修改原有句子的部分表述，获得新data。</li>
<li>The other is generating the whole sentence with the help of back-translation (Yu et al., 2018; Dong et al., 2017; Iyyer et al., 2018), sequence to sequence models (Kurata et al., 2016; Hou et al., 2018) or pre-trained language models (Kumar et al., 2020). 构造完全新的data。</li>
</ol>
<p>作者认为之前的 Data Augmentation会使用人造的数据，这可能inevitably introduces incoherence, semantic errors and lacking in diversity.</p>
<p>因此作者提出要直接使用已有的natural text作为辅助数据增强的来源。</p>
<p>方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201331433.png"  style="zoom:30%;" /></p>
<p>步骤：</p>
<ul>
<li>从外部源如Wikipedia corpus中，通过BM25 sparse retrieval或者L2 dense retrieval的方法检索和句子相似的sentence</li>
<li>然后进行label propagation，在Wikipedia中带有链接的anchor text如果和有label的entity是完全匹配的，就赋值给anchor text对应的label。（但是完全一样text的entity就是相同的entity吗？）使用这样的新标注的数据和原有的有标注数据训练一个NER model</li>
<li>使用训练好的NER model，重新标注一次外部的text，然后使用重新标注后的数据和原有的有标注数据训练一个更好的NER model（Explored Entity Annotations，EEA）</li>
</ul>
<p>实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201751825.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201830377.png"   style="zoom:40%;" /></p>
<h2 id="entda">ENTDA</h2>
<p>Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks</p>
<p>ACL 2023 Findings，清华与阿里达摩，<a href="/nlp/ENTDA/" title="[详细博客]">[详细博客]</a></p>
<blockquote>
<p>Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). <strong>Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks.</strong> In this work, we propose a novel Entity-to-Text based data augmentation technique named ENTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data and low resource settings) show that ENTDA could bring more performance improvements compared to the baseline augmentation techniques.</p>
</blockquote>
<p>基于entity list生成对应的新data：</p>
<p>作者提出的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191701967.png"   style="zoom:50%;" /></p>
<p>作者的生成data思路是根据entity list，让language model来直接生成相应的句子。</p>
<p>然后，让language model基于entity list生成对应的句子。为了提升生成句子的多样性diversity，作者提出了一种diversity beam search decoding策略：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191955856.png"  style="zoom:30%;" /></p>
<p>作者在flat, nested, and discontinuous NER tasks都进行了实验。在full data的情况下，提升不太大，但是在低资源的情况下提升很多。we randomly choose 10% training data from CoNLL2003/ACE2005/CADEC：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193116491.png"  style="zoom:30%;" /></p>
<p>低资源的情况下，效果提升明显，有<span class="math inline">\(2\)</span>%的提升幅度。</p>
<p>在真实的低资源NER数据集CrossNER的表现：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193212164.png"   style="zoom:40%;" /></p>
<p>同样提升比较明显。</p>
<h2 id="aclm">ACLM</h2>
<p>ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER</p>
<p>ACL 2023，University of Maryland，<a href="https://github.com/Sreyan88/ACLM">代码</a>。</p>
<blockquote>
<p>Complex Named Entity Recognition (NER) is the task of detecting linguistically complex named entities in low-context text. In this paper, we present ACLM (Attention-map aware keyword selection for Conditional Language Model fine-tuning), a novel data augmentation approach, based on conditional generation, to address the data scarcity problem in low-resource complex NER. <strong>ACLM alleviates the context-entity mismatch issue, a problem existing NER data augmentation techniques suffer from and often generates incoherent augmentations by placing complex named entities in the wrong context.</strong> ACLM builds on BART and is optimized on a novel text reconstruction or denoising task - we use selective masking (aided by attention maps) to retain the named entities and certain keywords in the input sentence that provide contextually relevant additional knowledge or hints about the named entities. Compared with other data augmentation strategies, ACLM can generate more diverse and coherent augmentations preserving the true word sense of complex entities in the sentence. We demonstrate the effectiveness of ACLM both qualitatively and quantitatively on monolingual, crosslingual, and multilingual complex NER across various low-resource settings. ACLM outperforms all our neural baselines by a significant margin (1%-36%). In addition, we demonstrate the application of ACLM to other domains that suffer from data scarcity (e.g., biomedical). In practice, ACLM generates more effective and factual augmentations for these domains than prior methods.</p>
</blockquote>
<p>作者主要希望通过数据增强来解决complex NER任务：</p>
<blockquote>
<p>complex NER benchmarks like MultiCoNER (Malmasi et al., 2022) present several contemporary challenges in NER, including short low-context texts with emerging and semantically ambiguous complex entities (e.g., movie names in online comments) that reduce the performance of SOTA methods previously evaluated only on the existing NER benchmark datasets.</p>
</blockquote>
<p>作者认为之前SOTA的数据增强方法效果不好，因为对于complex NER任务来说，特定的entity要依赖于特定的context：</p>
<blockquote>
<p>We first argue that certain types of complex NEs follow specific linguistic patterns and appear only in specific contexts (examples in Appendix 4), and augmentations that do not follow these patterns impede a NER model from learning such patterns effectively.</p>
</blockquote>
<p>方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230917235747765.png"   style="zoom:50%;" /></p>
<p>作者分为四步来获取corrupted sentence（paper里叫做template）：</p>
<ol type="1">
<li><p>Keyword Selection：使用attention map寻找对entity最有意义的context tokens，然后将top-<span class="math inline">\(p\)</span>%的context tokens用看做是<em>keywords</em>。具体来说，使用XLM-RoBERTa-large进行在训练集上进行训练，然后使用它最后4层所有Transformer attention head的注意力权重作为选择依据。</p>
<ul>
<li><p>低资源的情况下，attention map可能是比较noisy的，所有head相加比较robust</p></li>
<li><p>BERT的低层更加关注其它token，而BERT的高层更加专注某个token</p></li>
<li><p>作者处理的entity可能有多个span或者1个span。对于1个span，每个token的attention score相加。对于有多个span的entity，每个span分别计算attention score获取重要tokens</p></li>
</ul></li>
<li><p>Selective Masking：对于非entity和非重要keywords的其它tokens，用<span class="math inline">\([MASK]\)</span> token进行替换。mask后的句子作为template。</p></li>
<li><p>Labeled Sequence Linearization：模仿MELM在entity token前后插入<code>&lt;tag&gt;</code>。</p></li>
<li><p>Dynamic Masking：动态的选择一部分keywords的token也进行替换，增加多样性</p></li>
</ol>
<p>根据上面获取的corrupted sentence，微调mBart-50-large，让其重建原来的句子。</p>
<p>在进行数据生成的时候，对于每个sentence，创建<span class="math inline">\(R\)</span>个corrupt text，生成<span class="math inline">\(R\)</span>个augmented training samples（实现中<span class="math inline">\(R=5\)</span>）。</p>
<p>为了进一步增加多样性，作者在数据生成阶段，提出了一个mixer方法，根据一定的概率选择另外一个语义相似的句子生成的template进行拼接，然后生成新的句子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230918000541961.png"  style="zoom:40%;" /></p>
<p>实现中基于multi-lingual Sentence-BERT的embedding计算不同句子之间的余弦相似度。</p>
<p>最后对生成的数据进行后处理，对与和原sentence非常相似的生成sentence等数据，进行移除。</p>
<p>作者在MultiCoNER上的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230918000749168.png"   style="zoom:40%;" /></p>
<p>在其它NER数据集（CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003) (news), BC2GM (Smith et al., 2008) (bio-medical), NCBI Disease (Do˘gan et al., 2014) (bio-medical) and TDMSci (Hou et al., 2021) (science)）上的结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230918000837774.png"  style="zoom:40%;" /></p>
<p>这个实验解释了一个重要的结论，在CoNLL2003这种entity和明确的数据集上，LwTR（替换相同entity type的其它entity）这种rule-based的方法反而取得了最好的结果。</p>
<p>对于生成数据的定量评估：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230918001054785.png"   style="zoom:40%;" /></p>
<p>其中，Diversity-E指生成sentence中新出现的实体，Diversity-N指新出现的非entity的tokens，Diversity-L指新生成的句子长度与原来句子的比值。ACLM更擅长引入更多新的context tokens。</p>
<h2 id="gda">GDA</h2>
<p>GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks</p>
<p>ACL 2023 Findings，清华与浙大，<a href="https://github.com/THU-BPM/GDA">代码</a>。</p>
<blockquote>
<p>Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. <strong>These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations.</strong> In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augment diverse sentences. Experimental results in three datasets under a low-resource setting showed that GDA could bring 2.0% F1 improvements compared with no augmentation technique. Source code and data are available.</p>
</blockquote>
<p><strong>Issue</strong>: 之前方法存在的问题：</p>
<ul>
<li>之前的rule-based techniques的数据增强方法不能够保证构造出来的句子和原来的句子是语义一致的，并且由于忽略了语法结构还有可能扭曲原来的语义</li>
<li>model-based techniques能够保持语义一致性 [<em>Data augmentation in natural language processing: a novel text generation approach for long and short text classifiers. 2022</em>]，但是不能够生成多样性的表达。the model generates less diverse sentences – it includes similar entities and identical relational expressions under the same relation.</li>
</ul>
<p>生成的数据既需要多样性，又需要和原来句子的语义一致性。</p>
<p>作者基于多任务学习提出的数据增强方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909170611490.png"  style="zoom:30%;" /></p>
<p>基于BART或T5这样的encoder+decoder结构，有两个decoder：</p>
<ul>
<li><p>Original sentence restructuring. 左侧的decoder，重建原来的sentence，让模型学会产生和原来句子语义一致的句子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909170816949.png"   style="zoom:30%;" /></p></li>
<li><p>Original sentence pattern approximation. 右侧的decoder用来生成新的sentence。由于归纳偏执，seq2seq decoder总是会倾向高频率出现的pattern，就失去生成数据的多样性。因此作者限制生成的新句子的pattern和原来的句子一致。具体做法是使用两个entity之间的语法路径作为relation pattern，生成句子的relation pattern和原来句子的relation pattern要接近：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909171308055.png"   style="zoom:30%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230917152104901.png"   style="zoom:40%;" /></p>
<p>另外，为了进一步控制输出句子。作者会从数据集中同属于一个relation的样例中选择entity，输入解码器，让模型输出带有entity的句子。</p></li>
</ul>
<p>训练的时候，先训练编码器和restructuring decoder；然后使用restructuring decoder的参数初始化pattern approximation decoder参数，和编码器一起训练；pattern approximation decoder参数继续用来初始化restructuring decoder。</p>
<p>两个decoder分别独立迭代优化；encoder一直进行优化。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909171514198.png"   style="zoom:40%;" /></p>
<p>可以看到，利用作者的数据增强方法生成的数据来训练，能够有效提升Base model的效果。</p>
<p>不断增加数据增强数量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231128160709908.png" style="zoom:30%;" /></p>
<h2 id="mboxs2ynre"><span class="math inline">\(\mbox{S}^2\)</span>ynRE</h2>
<p>S2ynRE: Two-stage Self-training with Synthetic data for Low-resource Relation Extraction</p>
<p>中科大，ACL 2023，<a href="https:%20//github.com/BenfengXu/S2ynRE">代码</a>。</p>
<blockquote>
<p>Current relation extraction methods suffer from the inadequacy of large-scale annotated data. While distant supervision alleviates the problem of data quantities, there still exists domain disparity in data qualities due to its reliance on domain-restrained knowledge bases. In this work, <strong>we propose S2ynRE, a framework of two-stage Self-training with Synthetic data for Relation Extraction.</strong> We first leverage the capability of large language models to adapt to the target domain and automatically synthesize large quantities of coherent, realistic training data. We then propose an accompanied two-stage self-training algorithm that iteratively and alternately learns from synthetic and golden data together. We conduct comprehensive experiments and detailed ablations on popular relation extraction datasets to demonstrate the effectiveness of the proposed framework. Code is available at https://github.com/BenfengXu/S2ynRE.</p>
</blockquote>
<p>对于RE任务来说，高质量有标注的data获取很难，之前一种解决这个问题的思路是远监督distant supervision，尽管远监督获得了效果的提升，但是远监督的数据不能够保证和下游任务的schema、context分布特征等是相符的：</p>
<blockquote>
<p>Although this line of methods have seen certain improvements, they still inevitably raise the concern that the distantly annotated data can vary considerably from downstream tasks both in target schema and in context distributions, thus may not be able to offer optimal transferability.</p>
</blockquote>
<p>换句话说，要获得理想的领域特征一致的远监督数据本身也可能是比较难的。</p>
<p>因此，作者顺着最近的一些利用LLM生成text data的工作的思路，考虑使用LM来生成数据。作者的贡献主要有两点：</p>
<ul>
<li>利用GPT-3.5和finetuned GPT-2 Large去适应target domain distribution，然后生成无label的RE data</li>
<li>提出了a two-stage self-training训练策略，更好的利用生成的无标注数据和原有标注数据</li>
</ul>
<p>作者的RE任务是给定头尾实体，预测relation。</p>
<p>利用GPT-2 Large生成数据，首先按照language modeling的loss在训练集上微调；然后在推理阶段，输入<code>&lt;bos&gt;</code>开始进行采样生成new data。</p>
<p>利用GPT-3生成数据，采用5-shot ICL，随机找demonstrations的策略：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926161739020.png"  style="zoom:50%;" /></p>
<p>注意这里prompt对于结果的可控，只是通过一些指令性的表述，如<code>similar topic, domain and the same sub-obj format</code>。</p>
<p>然后是如何利用生成的无标注data，一般的策略是self-training，即给无标注data伪标注然后和原有data混合，训练小模型，训练好的小模型再重新标注无标注data。</p>
<p>作者认为这种直接将生成的数据加入到原有的数据方法前提是，要求生成的数据需要和原来的数据有一样的分布。</p>
<p>相反，作者将无标注数据和有标注数据分开，先使用gold data训练多个teacher model，然后标注生成的data，注意是soft label；然后用一个新初始化的student model在带有soft label的生成数据上训练，更新参数；之后继续在gold data上训练，更新后的model重新标注生成的data；这样迭代式的训练：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926162246951.png"   style="zoom:50%;" /></p>
<p>对于实验结果具体可以参考原paper，这里提供几个值得记录的结果：</p>
<p>作者使用BERT+Linear作为RE model。</p>
<p>直接用GPT不一定能够超过finetuned LM来生成data，下面的结果没有找到是具体哪个dataset上的测试结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926162817492.png"  style="zoom:50%;" /></p>
<p>作者使用type-token ratio ([<em>Evaluating story generation systems using automated linguistic analyses. 2017</em>]; <em>Data augmentation using pre-trained transformer models. 2020</em>)来评估diversity。</p>
<h2 id="dare">DARE</h2>
<p>DARE: Data Augmented Relation Extraction with GPT-2. arXiv 2020</p>
<p>作者声明是首个利用GPT-2进行RE数据增强的工作：</p>
<blockquote>
<p>Real-world Relation Extraction (RE) tasks are challenging to deal with, either due to limited training data or class imbalance issues. In this work, <strong>we present Data Augmented Relation Extraction (DARE), a simple method to augment training data by properly fine-tuning GPT-2 to generate examples for specific relation types.</strong> The generated training data is then used in combination with the gold dataset to train a BERT-based RE classifier. In a series of experiments we show the advantages of our method, which leads in improvements of up to 11 F1 score points against a strong baseline. Also, DARE achieves new state of the art in three widely used biomedical RE datasets surpassing the previous best results by 4.7 F1 points on average.</p>
</blockquote>
<p>具体方法比较简单，对于头尾实体，用<code>$</code>符号进行标记，<code>$ENTITY_A$</code>和<code>$ENTITY_B$</code>；然后作者对于数据集中每个relation type对应的子数据集，都训练一个GPT2（774M）进行数据生成，原因是作者发现如果让一个GPT2直接生成所有的relation type的data，效果比较差。</p>
<p>同时，针对每个relation都生成对应的新数据，可以看做是一种过采样，作者认为这种过采样策略能够缓解class imbalance问题。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231022111615306.png"  style="zoom:35%;" /></p>
<p>值得一提的是，为了缓解生成句子可能存在的噪音问题，作者采用了集成学习的策略。作者训练了20个基于BERT的classifier，每个classifier都是在full gold data和采样的生成数据的子集上进行了训练。</p>
<p>作者的RE任务是给定了头尾实体的RE，在3个biomedical RE数据集上进行了实验，实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015110634969.png" style="zoom:50%;" /></p>
<h2 id="relationprompt">RelationPrompt</h2>
<p>RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction. ACL 2022 Findings. 阿里达摩. <a href="github.com/declare-lab/RelationPrompt">代码</a>。</p>
<blockquote>
<p>Despite the importance of relation extraction in building and representing knowledge, less research is focused on generalizing to unseen relations types. We introduce the task setting of Zero-Shot Relation Triplet Extraction (ZeroRTE) to encourage further research in lowresource relation extraction methods. Given an input sentence, each extracted triplet consists of the head entity, relation label, and tail entity where the relation label is not seen at the training stage. To solve ZeroRTE, we propose to synthesize relation examples by prompting language models to generate structured texts. Concretely, <strong>we unify language model prompts and structured text approaches to design a structured prompt template for generating synthetic relation samples when conditioning on relation label prompts (RelationPrompt).</strong> To overcome the limitation for extracting multiple relation triplets in a sentence, we design a novel Triplet Search Decoding method. Experiments on FewRel and Wiki-ZSL datasets show the efficacy of RelationPrompt for the ZeroRTE task and zero-shot relation classification. Our code and data are available at github.com/declare-lab/RelationPrompt.</p>
</blockquote>
<p>作者是提出的zero-shot relation extraction任务，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015180312116.png" style="zoom:40%;" /></p>
<p>给定sentence，然后抽取triples。test set里包含没有在train set里出现的relation（但是entity type是都在train set里出现过的）。</p>
<p>作者解决zero-shot relation triple extraction任务的思路是，先为unseen relation生成sentence，构造一个人工训练集，然后用这个生成的人工训练数据集训练一个IE model，输出triples。作者没有考虑其它可能的解决zero-shot relation triple extraction任务的思路的原因：</p>
<ul>
<li>distant supervision：可能已有的外部knowledge base只包含了部分unseen relation的data</li>
<li>修改task objective，让model能够输出非提前定义好的label，</li>
</ul>
<p>具体的训练流程如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015181429386.png" style="zoom:40%;" /></p>
<p>具体的实现细节：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015182917671.png" style="zoom:40%;" /></p>
<ul>
<li>Relation Gnerator：GPT-2（124M），输入<code>Relation:</code>，输出<code>Context: s. Head Entity: e head, Tail Entity: e tail</code>，在training set上用language modeling objective进行finetune。然后用来为不同的unseen relation生成sentence。生成的sentence只包含一个triple，主要是考虑到如果让sentence直接包含多个triples，可能生成的句子质量难以保证；</li>
<li>Relation Extractor：BART（140M），输入<code>Context: s</code>，生成<code>Head Entity: e head, Tail Entity: e tail, Relation: y</code>。先在training set上进行finetune，然后在Relation Gnerator生成的人造数据集上进行finetune，最后用于inference；</li>
</ul>
<p>对于Relation Extractor，由于作者生成的sentence只包含一个triple，但是真实的sentence可能包含多个triples，一般的三元组抽取model都是假设text会抽取出多个triple，这样就和作者生成只包含一个triple的sentence不符了。为了解决这种training和testing过程中，sentences包含的triples不一致的问题，作者提出了一种Triplet Search Decoding方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015183802616.png" style="zoom:40%;" /></p>
<p>简单说，就是在输出head/tail/relation的第一个token的时候，保持前top-<span class="math inline">\(b\)</span>的tokens，最后生成多个候选triples。这样即使在训练阶段，训练数据只有1个triples，在测试阶段也可以生成多个triples：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015184239134.png"  style="zoom:50%;" /></p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015184331144.png"  style="zoom:40%;" /></p>
<p>通过在Wiki-ZSL和FewRel两个数据集上，选择<span class="math inline">\(m\)</span>个relation从训练集中拿出，作为unseen relations进行测试，实现zero-shot relation extraction。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231015184357689.png" style="zoom:30%;" /></p>
<h2 id="dgre">DGRE</h2>
<p>Generating Labeled Data for Relation Extraction: A Meta Learning Approach with Joint GPT-2 Training. ACL 2023. University of Oregon</p>
<blockquote>
<p>Relation Extraction (RE) is the task of identifying semantic relation between real-world entities mentioned in text. Despite significant progress in RE research, a remaining challenge for RE concerns the lack of training data for data-hungry deep learning models. Cost of annotation and difficulty of the task are among hindrance to collect a large-scale RE dataset in different domains. To address this limitation, we propose a novel framework to automatically generate labeled data for RE. Our framework presents the pre-trained language model GPT-2 for data generation. In addition, <strong>to optimize the generated samples for an RE model, we introduce a meta learning approach to allow the GPT-2 model to be updated during the training process for RE.</strong> In particular, to leverage the feedback from the RE model to improve the data generation from GPT-2, we propose a novel reward function to update the GPT-2 model with REINFORCE, seeking to promote the similarity of the RE loss function’s gradients computed for generated data and a meta development set. We conduct extensive experiments on two benchmark datasets to produce state-of-the-art performance for RE.</p>
</blockquote>
<p><strong>Issue</strong>: 利用数据增强的技术，生成的data和RE model期望的data中间可能存在gap。</p>
<blockquote>
<p>However, an issue with this approach involves the separation between the fine-tuning process of GPT-2 and the target RE model that might cause a mismatch between the generated data from GPT-2 and the data expected by the RE model (e.g., the generated data can be noisy or redundant for RE).</p>
</blockquote>
<p><strong>Solution</strong>: 为了解决这一点，作者提出要使得生成新数据的语言模型能够从执行具体RE任务的base model中学到反馈。</p>
<p>作者的生成模型是GPT-2，RE任务抽出模型是BERT-base。</p>
<p>对于GPT-2，首先是pre-training。通过在句子中的头尾实体tokens左右插入特殊符号，输入句子变为：<span class="math inline">\(T^\prime= [w_1, w_2, \dots , &lt;SUB-l&gt;w_s&lt;/SUB-l&gt;, \dots , &lt;OBJ-l&gt;w_o&lt;/OBJ-l&gt;, \dots , w_n]\)</span>。这里的<span class="math inline">\(l\)</span>是一个特殊标记，<span class="math inline">\(l=p\)</span>表示头尾实体之间存在某种relation，<span class="math inline">\(l=n\)</span>表示头尾实体之间不存在relation。通过language modeling的方式，让GPT-2适应领域data。</p>
<p>要注意，作者生成的sentence只通过<span class="math inline">\(&lt;SUB-l&gt;&lt;OBJ-l&gt;\)</span>表明了在两个entity之间存在某种relation，而没有说明具体是哪种relation type。</p>
<p>对于BERT-base，在进行抽取的时候，在预测层采用了Dynamic Pooling技术[<em>Event extraction via dynamic multipooling convolutional neural networks. ACL 2015</em>]。具体来说，最后一层的embedding，转化为：<span class="math inline">\(h = [e_{[CLS]}:f(e_1 ,\dots , e_{s−1} ) : e_s : f(e_{s+1} , \dots , e_{o−1} ) : e_o :f(e_{o+1}, \dots , e_n)]\)</span>，<span class="math inline">\(f\)</span>表示Max Pooling操作，使用embedding <span class="math inline">\(h\)</span>进行relation分类。</p>
<p>由于生成的数据没有relation type，BERT RE model上增加了一个额外的task head，判断实体之间是否存在某种relation的二元分类。这样就有针对原有标注数据和生成数据两种loss。</p>
<p>为了能够让GPT-2学会生成符合BERT RE model期望数据，接下来将GPT-2和BERT进行一起针对训练集，分batch进行训练，每次迭代同时更新GPT-2和BERT。</p>
<p>最直接的想法是利用performance metric的变化来评估generated data的好坏。这种做法需要提前划分出一个meta development set <span class="math inline">\(D_{meta}\)</span>来计算reward，优化GPT-2参数。但是由于没有足够多的有标注数据，这种基于performance metric变化计算得到的reward，可能有很大的方差，非常不稳定。</p>
<p>因此，作者提出可以通过loss计算的梯度，来评估一条生成数据是否适合训练RE model：</p>
<blockquote>
<p>Intuitively, a generated sample <span class="math inline">\(T_g\)</span> is helpful for the RE model <span class="math inline">\(M_{\theta_t}\)</span> if the gradient of <span class="math inline">\(L_{base}\)</span> with this sample aligns with the steepest direction with the development data (i.e., similar gradients from <span class="math inline">\(T\)</span> gand <span class="math inline">\(D_{meta}\)</span>)</p>
</blockquote>
<p>一条生成数据与在meta development set上数据的平均梯度越相似/方向一致，认为这个生成数据质量越好，reward越大。然后reward作为这条生成数据梯度计算的权重，更新GPT-2参数。具体的训练过程如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231020204405334.png"  style="zoom:35%;" /></p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231020204456352.png"  style="zoom:25%;" /> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231020204523024.png"  style="zoom:25%;" /></p>
<p>使用数据增强，大概给模型带来了1个点的提升：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231020204638134.png"  style="zoom:30%;" /></p>
<p>根据反馈，更新生成数据model的参数，能够减低各类错误：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231020204806626.png" style="zoom:30%;" /></p>
<p>作者生成的具体cases：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231020204725003.png"  style="zoom:50%;" /></p>
<h2 id="drnn">DRNN</h2>
<p>Improved Relation Classification by Deep Recurrent Neural Networks with Data Augmentation. COLING 2016. 北大. <a href="https://sites.google.com/site/drnnre/">代码</a>.</p>
<blockquote>
<p>Nowadays, neural networks play an important role in the task of relation classification. By designing different neural architectures, researchers have improved the performance to a large extent in comparison with traditional methods. <strong>However, existing neural networks for relation classification are usually of shallow architectures (e.g., one-layer convolutional neural networks or recurrent networks). They may fail to explore the potential representation space in different abstraction levels.</strong> In this paper, we propose deep recurrent neural networks (DRNNs) for relation classification to tackle this challenge. Further, we propose a data augmentation method by leveraging the directionality of relations. We evaluated our DRNNs on the SemEval-2010 Task 8, and achieve an F 1-score of 86.1%, outperforming previous state-of-the-art recorded results.</p>
</blockquote>
<p>以前的RE方法常常利用浅层的神经网络，缺少对于不同层级表征空间的学习。</p>
<p>作者的方法是提出了利用多层级的RNN：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021111943293.png"  style="zoom:50%;" /></p>
<p>输入包括了4种信息通道，也就是4种不同的输入embedding。每种信息通道有自己独立的RNN网络。最终结果拼接起来进行分类。</p>
<p>模型的左右两侧的输入是句子里头尾实体在语法依赖树上到共同父结点的最短路径，作者认为这两条路径对应了<code>subject-predicate</code>和<code>object-predicate</code>两个relation components：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021112102393.png"  style="zoom:40%;" /></p>
<p>另外，作者提出了一种基于规则的，利用relation方向性的简单数据增强方法。通过互换头尾实体对应的路径，预测逆关系。比如原来预测的是relation <span class="math inline">\(Content-Container(e_1, e_2)\)</span>，互换路径后，输入model，应该预测逆关系<span class="math inline">\(Container-Content(e_1, e_2)\)</span>。如上图右侧(b)所示。在实验里，作者发现对于有方向的relation进行增强效果最好，对于所有的relations都进行增强，模型效果反而降低。</p>
<p>总体实验结果，SemEval-2010 Task 8数据集：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021113123326.png"  style="zoom:30%;" /></p>
<h2 id="gradlre">GradLRE</h2>
<p>Gradient Imitation Reinforcement Learning for Low Resource Relation Extraction. 清华. EMNLP 2021. <a href="https://github.com/THU-BPM/GradLRE">代码</a>.</p>
<blockquote>
<p>Low-resource Relation Extraction (LRE) aims to extract relation facts from limited labeled corpora when human annotation is scarce. Existing works either utilize self-training scheme to generate pseudo labels that will cause the gradual drift problem, or leverage metalearning scheme which does not solicit feedback explicitly. <strong>To alleviate selection bias due to the lack of feedback loops in existing LRE learning paradigms, we developed a Gradient Imitation Reinforcement Learning method to encourage pseudo label data to imitate the gradient descent direction on labeled data and bootstrap its optimization capability through trial and error.</strong> We also propose a framework called GradLRE, which handles two major scenarios in low-resource relation extraction. Besides the scenario where unlabeled data is sufficient, GradLRE handles the situation where no unlabeled data is available, by exploiting a contextualized augmentation method to generate data. Experimental results on two public datasets demonstrate the effectiveness of GradLRE on low resource relation extraction when comparing with baselines. Source code is available.</p>
</blockquote>
<p><strong>Issue</strong>：低资源RE方法中，</p>
<ul>
<li>远监督方法有个strong assumption假设外部KB中共同出现的实体具有某种特定关系，忽略了具体的context，这使得makes model generate relations based on contextless rules and limits the generalization ability.</li>
<li>自训练self-training的方法，容易受到noisy伪标注的影响，出现gradual drift problem问题(Curran et al., 2007; Zhang et al., 2016)</li>
</ul>
<p>对于自训练的方法，直接将伪标注的数据加入进来不可避免的会出现selection bias，影响model的泛化能力。</p>
<p><strong>Solution</strong>：作者提出，不要直接将伪标注数据加入进来，将现有的标注作为guideline，去选择伪标注；并且根据选择结果实现反馈feedback，更新模型参数，缓解selection bias，下一次实现更高质量的伪标注。</p>
<p>作者假设，正确的伪标注数据对应的梯度方向，应该和在实际数据上的平均梯度方向是接近的：</p>
<blockquote>
<p>We assume that when pseudo-labeled data are correctly labeled in RLG, partial derivatives to the RLG parameters on the pseudo-labeled data would be highly similar to standard gradient descending.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023212454496.png"  style="zoom:40%;" /></p>
<p>作者提出的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023212522199.png" style="zoom:40%;" /></p>
<p>Relational Label Generator（RLG）用来作为weak annotator，基于<code>BERT-Base_Cased</code>，使用头尾实体对应的embedding，拼接后经过softmax分类层。RLG会提前在labeled data上进行训练。</p>
<p>Gradient Imitation Reinforcement Learning（GIRL）。使用上面的RLG对unlabeled data进行伪标注：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023212847111.png"  style="zoom:40%;" /></p>
<p>然后，分别计算在<span class="math inline">\(N\)</span> labeled data上的standard gradient descent direction <span class="math inline">\(g_l\)</span>和在某个pseudo-labeled data上的梯度<span class="math inline">\(g_p\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023213051931.png"  style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023213117303.png"  style="zoom:40%;" /></p>
<p>使用余弦相似度计算梯度下降方向的相似性，作为reward：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023213223479.png"  style="zoom:40%;" /></p>
<p><span class="math inline">\(R^t\)</span>超过阈值<span class="math inline">\(\lambda = 0.5\)</span>的伪标注数据，会被看做是positive reinforcement能够用来进一步提升RLG的性能，将其加入到有标注数据集中。</p>
<p>最后，采用REINFORCE algorithm (Williams, 1992)进行优化：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023213436345.png" style="zoom:40%;" /></p>
<p>强迫选择出来的质量越高（即<span class="math inline">\(R^t\)</span>越大）的伪标注，越要输出confidence的predictive distributions。</p>
<p>上面的过程是针对有无标注数据，需要生成伪标注的情况。作者还考虑了另外一种情况，也就是连无标注数据都没有，需要自己生成无标注数据的情况。</p>
<p>为此，作者提出了Contextualized Data Augmentation，简单的说，就是在句子中随机的采样mask头尾entities外的spans，破坏原有的context，然后利用BERT Masked Language Modeling填充mask，生成新的无标注数据。举例，如果将句子<code>A letter was delivered to my office in this morning.</code>中的<code>delivered to</code>移除，生成新句子<code>A letter was sent from my office in this morning.</code>，那么原来的relation就被改变了。具体的，作者follow了前人的工作，按照一定概率分布mask不同长度的context spans[<em>Spanbert: Improving pre-training by representing and predicting spans. 2020</em>]。</p>
<p>作者在SemEval 2010 Task 8 (SemEval)和TACRED数据集上的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023214536354.png"  style="zoom:50%;" /></p>
<p>下面是作者提出的填充mask的数据增强方法的实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231023215038849.png"  style="zoom:40%;" /></p>
<h2 id="lrebench">LREBench</h2>
<p>Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study. EMNLP 2022 Findings. 浙大NLP. <a href="https://zjunlp.github.io/project/LREBench">代码</a>.</p>
<blockquote>
<p>This paper presents an empirical study to build relation extraction systems in low-resource settings. Based upon recent pre-trained language models, <strong>we comprehensively investigate three schemes to evaluate the performance in low-resource settings:</strong> (i) different types of promptbased methods with few-shot labeled data; (ii) diverse balancing methods to address the longtailed distribution issue; (iii) data augmentation technologies and self-training to generate more labeled in-domain data. We create a benchmark with 8 relation extraction (RE) datasets covering different languages, domains and contexts and perform extensive comparisons over the proposed schemes with combinations. Our experiments illustrate: (i) Though prompt-based tuning is beneficial in low-resource RE, there is still much potential for improvement, especially in extracting relations from cross-sentence contexts with multiple relational triples; (ii) Balancing methods are not always helpful for RE with longtailed distribution; (iii) Data augmentation complements existing baselines and can bring much performance gain, while self-training may not consistently achieve advancement to low-resource RE.</p>
</blockquote>
<p>低资源关系抽取Low-resource RE (LRE)任务，较早传统的方法包括：</p>
<ul>
<li>Mintz et al. (2009) proposes <strong>distant supervision</strong> for RE, which leverages facts in KG as weak supervision to obtain annotated instances.</li>
<li>Rosenberg et al. (2005); Liu et al. (2021a); Hu et al. (2021) try to <strong>assign pseudo labels to unlabeled data</strong> and leverage both pseudo-labeled data and gold-labeled data to improve the generalization capability of models iteratively.</li>
<li>Some studies apply <strong>meta-learning</strong> strategies to endow a new model with the ability to optimize rapidly or leverage <strong>transfer learning</strong> to alleviate the data-hungry issue (Gao et al., 2019; Yu et al., 2020b; Li et al., 2020a; Deng et al., 2021).</li>
<li>Other studies (Zhang et al., 2019) focus on the <strong>long-tailed class distribution</strong>, especially in tail classes that only allow learning with a few instances.</li>
<li>More recently, a new methodology named <strong>prompt learning</strong> has made waves in the community by demonstrating astounding few-shot capabilities on LRE (Han et al., 2021; Chen et al., 2022d).</li>
</ul>
<p>作者这篇empirical study主要针对下面三种思路的方法进行实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024164853116.png"  style="zoom:40%;" /></p>
<p>作者主要对比的方法示意图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024164932389.png" style="zoom:50%;" /></p>
<p>这里提一下基于prompt的方法，它通过提前创建和label相关的template，然后和原来的text拼接，让MLM去填充被mask的label tokens。这种方法之所以能够被用来解决LRE任务，主要是由于它通过提供task-specific information和relation label semantic，从而填充了pre-train到fine-tune阶段的gap。作者在实验里也发现，这种做法通常要比一般的方法效果好。</p>
<p>作者的数据增强方法是基于替换单词的方法，基于开源工具<a href="https://github.com/makcedward/nlpaug">nlpaug</a>从WordNet’s synonyms、TF-IDF similarity和contextual word embedding，替换原来句子中的contexts、entities、contexts与entities同时替换。在这一过程中，认为替换单词后，新句子和原来句子有相同的relation label。</p>
<p>作者实验基于8个数据集：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024165709999.png"  style="zoom:50%;" /></p>
<p>基于<code>RoBERTa-large</code>作为RE model。</p>
<p>总体实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024165808082.png"  style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>prompt learning方法通常要好于一般的微调方法</li>
<li>数据增强策略通常是有效的</li>
<li>self-training策略并不总能起到效果</li>
</ul>
<p>不同prompt类型对比：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024170126186.png"  style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>Entity type information in prompts is helpful for low-resource RE. 类似于PTR和KnowPrompt这种加入了实体类型信息的prompt对于LRE任务来说是有帮助的</li>
<li>PTR和KnowPrompt在TACREV数据集上效果比没有entity type类型信息的prompt效果差。作者认为这是由于TACREV数据集中存在标注错误的情况[<em>An improved baseline for sentence-level relation extraction.</em>]，可能导致高估依赖于entity name、span和type信息的方法的效果</li>
</ul>
<p>不同DA方法对比：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024165855510.png"  style="zoom:50%;" /></p>
<h2 id="paraphrasere">ParaphraseRE</h2>
<p>Improving Relation Extraction with Relational Paraphrase Sentences. COLING 2020. 苏州大学. <a href="https://github.com/jjyunlp/ReP-RE/tree/main">代码</a>.</p>
<blockquote>
<p>Supervised models for Relation Extraction (RE) typically require human-annotated training data. Due to the limited size, the human-annotated data is usually incapable of covering diverse relation expressions, which could limit the performance of RE. To increase the coverage of relation expressions, we may enlarge the labeled data by hiring annotators or applying Distant Supervision (DS). <strong>However, the human-annotated data is costly and non-scalable while the distantly supervised data contains many noises.</strong> <strong>In this paper, we propose an alternative approach to improve RE systems via enriching diverse expressions by relational paraphrase sentences.</strong> Based on an existing labeled data, we first automatically build a task-specific paraphrase data. Then, we propose a novel model to learn the information of diverse relation expressions. In our model, we try to capture this information on the paraphrases via a joint learning framework. Finally, we conduct experiments on a widely used dataset and the experimental results show that our approach is effective to improve the performance on relation extraction, even compared with a strong baseline.</p>
</blockquote>
<p><strong>Issue</strong>: RE任务依赖于大量有标注数据，但是一个semantic relation fact有很多不同的expressions，比如<code>Steve Jobs co-founded Apple Computer.</code>; (2) <code>Steve Jobs was the co-founder of Apple Computer.</code>; and (3) <code>Steve Jobs started Apple Computer with Wozniak.</code>。前面两句话都有<code>co-found</code>，一个只见过前面两句话的model，可能无法从第3个句子中正确的识别出和前两句有一样的relation。引入更多的expressions是必要的。</p>
<p>为了引入更多的expressions，第一种解决方法是雇佣更多的人去标注，但受限于时间和money，不可能；第二种解决方法是远监督，但是远监督的强假设使得会带来很多错误的标注，存在大量噪音。</p>
<p><strong>Issue</strong>: 因此，作者提出使用基于改写的方法来获得更多的expressions。</p>
<blockquote>
<p>we use an alternative solution that uses a paraphrase data which collects sentences conveying the same meaning in different wording.</p>
</blockquote>
<p>为了实现改写，作者考虑了直接使用目前已有的改写数据集，例如Simple Wikipedia (Kauchak, 2013), Twitter URL corpus (Lan et al., 2017), and Para-NMT (Wieting and Gimpel, 2018)，但是在作者早期的实验中发现，仅仅是利用已有的general 的改写数据不能很好的适应RE任务。这就要求要构造适用于RE任务的paraphrase training data。</p>
<p>作者采用back-translation方法，为每个句子构造改写后的新句子，认为改写后的relation label保持不变（人工检查后发现，还是存在relation被改变的情况），构造Relational Paraphrase (ReP)数据集（首个适用于RE任务的paraphrase数据集）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024212659964.png"  style="zoom:50%;" /></p>
<blockquote>
<p>The back-translation is a procedure that first translates a sentence from a source language into a target language, then translates it back to the source language.</p>
</blockquote>
<p>构造流程：</p>
<ol type="1">
<li><p>以特定的RE数据集TACRED为基础，对于其中的每个sentence，采用3个Neural Machine Translation (NMT) systems：Google Translation, Baidu Translation and Xiaoniu Translation。将原来English sentence翻译为Chinese，然后再翻译回来。这样每个sentence，会有对应3个翻译后被改写的新句子；</p></li>
<li><p>改写可能会导致原来sentence中的entities也被改写了，因此，作者利用BERT对应的不同sentence之间的embedding，计算余弦相似度，对齐改写后句子中的头尾entities和原来句子中的entities：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024213305041.png"  style="zoom:50%;" /></p></li>
</ol>
<p>从上面，Table 2中能够看出，78%改写后的句子是对的。这说明了改写后的新句子是存在noise的。作者在实验中发现，如果直接把改写的句子和原有的gold data混合，反而降低了RE性能。因此，需要想办法解决这一问题：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024213542687.png"  style="zoom:30%;" /></p>
<p>流程：</p>
<ul>
<li><p>sentence encoder是<code>BERT-base</code>或<code>BERT-large</code>；relation extractor是带softmax的线性分类层；</p></li>
<li>对于原有的gold data还是一样的交叉熵loss</li>
<li><p>为了减小改写后新句子中的噪音问题，采用multi-instance learning strategies，也就是把3个对应的改写后的sentences作为一个bag，混合起来输出一个bag-level representation，用与进行最后的分类，这3句话有相同的relation label标注。背后的直觉是，每个句子可能有noise，但是3个句子总体上，应该是有类似的relation semantic的。具体混合方法可以是选择单独的某个句子、加权求和、attention、选择对应的预测probability最confidence的句子等。具体论文中有描述。</p></li>
</ul>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024214324379.png"  style="zoom:40%;" /></p>
<h2 id="selflre">SelfLRE</h2>
<p>SelfLRE: Self-refining Representation Learning for Low-resource Relation Extraction. SIGIR 2023. 清华. <a href="https://github.com/THU-BPM/SelfLRE">代码</a>.</p>
<blockquote>
<p>Low-resource relation extraction (LRE) aims to extract potential relations from limited labeled corpus to handle the problem of scarcity of human annotations. Previous works mainly consist of two categories of methods: (1) <strong>Self-training methods</strong>, which improve themselves through the models’ predictions, thus <strong>suffering from confirmation bias when the predictions are wrong</strong>. (2) <strong>Self-ensembling methods</strong>, <strong>which learn task-agnostic representations, therefore, generally do not work well for specific tasks.</strong> In our work, <strong>we propose a novel LRE architecture named SelfLRE, which leverages two complementary modules, one module uses self-training to obtain pseudo-labels for unlabeled data, and the other module uses self-ensembling learning to obtain the taskagnostic representations,</strong> and leverages the existing pseudo-labels to refine the better task-specific representations on unlabeled data. The two models are jointly trained through multi-task learning to iteratively improve the effect of LRE task. Experiments on three public datasets show that SelfLRE achieves 1.81% performance gain over the SOTA baseline. Source code is available at: https://github.com/THU-BPM/SelfLRE.</p>
</blockquote>
<p><strong>Issue</strong>：作者认为目前有两种利用unlabeled data解决LRE任务的方法：</p>
<ul>
<li>Self-training methods (e.g., Co-training [28], GradLRE [9], and STAD [27]) leverage the fine-tuned models to pseudo-label the unlabeled data, and adopt the pseudo-labeled data as the guidance to continue to optimize the model. However, these methods inevitably suffer from the confirmation bias when the pseudo labels are wrong. As incorrect pseudo-labeled data is continuously added to the labeled data for iterative training, the model will drift away from the local optimum.</li>
<li>Self-ensembling methods (e.g., Mean Teacher [24], DualRE [17], and MRefG [16]) first adopt data augmentation methods to generate sentences with similar relational semantics, and leverages the fine-tuned mapping model to obtain representations of two sentences. However, these methods can only learn task-agnostic representations, while RE task-specific representations, such as relation labels, cannot be learned specifically.</li>
</ul>
<p>这两种方法各有缺点。</p>
<p><strong>Soluation</strong>：集成这两种方法，互补优缺点：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024234108871.png"  style="zoom:30%;" /></p>
<p>作者提出的SelfLRE方法，基于BERT，有两个head，classifier head分类relation，mapping head是个两层MLP用来映射从BERT中获得的relational representations。总体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024234301892.png"  style="zoom:40%;" /></p>
<p>对于输入的句子，插入标记entities的特殊token，然后将头尾实体<span class="math inline">\([E1_{start}][E2_{start}]\)</span>对应的embedding拼接，作为句子的relation representations <span class="math inline">\(\mathbf{m}\)</span>.</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024234442110.png"  style="zoom:50%;" /></p>
<p>利用BERT可以给unlabeled data进行伪标注，然后作者表示pseudo-label graph，node是sample，edge是samples之间伪标注的相似度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024234723757.png" style="zoom:50%;" /></p>
<p>接下来，作者学习另一个embedding graph，通过随机除entities外的同义词替换获得新的句子。新的句子也可以通过BERT获得relation representation <span class="math inline">\(\mathbf{m}^\prime\)</span>。然后<span class="math inline">\(\mathbf{m}\)</span>和<span class="math inline">\(\mathbf{m}\)</span>都经过mapping head获得新的表示<span class="math inline">\(\mathbf{e}\)</span>。embedding graph的构造：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024235226664.png"  style="zoom:50%;" /></p>
<p>使用constrastive loss作为self-ensembling loss，优化embedding graph：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024235321152.png" style="zoom:50%;" /></p>
<p>即让原始sentence relational embedding和同义词替换后的sentence relational embedding更加相近；和其它sentence relational embedding没有那么接近。</p>
<p>然后，作者利用pseudo-label graph去指导embedding graph：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024235534767.png"  style="zoom:50%;" /></p>
<p>这个loss第一项，同样是让原始sentence relational embedding和同义词替换后的sentence relational embedding相近；第二项，是让有相似伪标注的sentences之间的relational embedding相近。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231024235754334.png"  style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>IE</category>
        <category>Data Augment</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>IE</tag>
        <tag>Data Augment</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-ICL</title>
    <url>/collection/LLM-ICL1/</url>
    <content><![CDATA[<h1 id="llm-in-context-learning">LLM in-context learning</h1>
<p>LLM上下文学习，相关论文合集1。</p>
<span id="more"></span>
<h2 id="ape">APE</h2>
<p>Large Language Models are Human-Level Prompt Engineers</p>
<p>ICLR 2023，University of Toronto，<a href="https://github.com/keirp/automatic_prompt_engineer">代码</a>。</p>
<blockquote>
<p>By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, <strong>we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection.</strong> In our method, we treat the instruction as the “program,” optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. <strong>Extensive experiments show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 24/24 Instruction Induction tasks and 17/21 curated BIG-Bench tasks.</strong> We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts are able to improve few-shot learning performance (by simply prepending them to standard in-context learning prompts), find better zero-shot chain-of-thought prompts, as well as steer models toward truthfulness and/or informativeness.</p>
</blockquote>
<p>作者提出一种从几个样例中自动创建task instruction的training free的方法APE（Automatic Prompt Engineer）。</p>
<p>由于LLM对于prompt的理解和人类不一样，因此简单的语言prompt不一定能够得到理想的结果。因此往往需要大量的人工去设计prompt，去搜索寻找最好的prompt实践。作者将自动寻找最能够激发LLM执行具体task能力的prompt的过程看做是一个black-box optimization problem，称之为natural language program synthesis。</p>
<p>作者提出的APE方案如下：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230601201707682.png" alt="image-20230601201707682" /><figcaption>image-20230601201707682</figcaption>
</figure>
<p>简单来说就是3步，</p>
<ol type="1">
<li>让LLM从几个样例中产生一系列的task instructions</li>
<li>让LLM使用不同的task instructions，评估不同task instructions的效果。先选一个子集评估所有的instruction，然后对于score比较高的instructions，再选新的子集评估筛选，直至选出一定数量的候选instructions</li>
<li>[可选] 为了防止在某些任务下，LLM一开始没有找到合适的instructions，重新采样。让LLM在当前score最高的instructions附近采样</li>
</ol>
<p>第1步采样初始的task instructions，作者使用了三种方式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230601202801649.png"   style="zoom:40%;" /></p>
<p>第一种forward mode prompt是最直接的，让LLM续写query，但是instructions只会出现在句子最后。作者提出第2种reverse mode prompt让LLM填空，让instructions可以出现在句子的任意地方。最后是对于一些已经发现了效果比较好的模板，可以加进来（具体在实验中可能作者只是在TruthfulQA数据集下使用了？）。</p>
<p>第2步怎么样评价不同instructions的效果，当然最直接的是根据任务指标来验证。在一般情况下，作者建议可以直接使用0-1 loss来给不同生成的instructions打分。还可以使用log probability。同时，让每个instructions都在所有的训练样例下进行评估是不实际的，因此作者就提出使用训练子集来筛选合适的instructions。如果一个子集筛选过后的instructions还是太多，就继续采样新的不重叠的训练子集，继续筛选instructions。</p>
<p>第3步是针对一些情况下，LLM生成的所有instructions没有找到合适的instructions，让LLM继续在当前效果最好的instructions周围进行寻找。we consider exploring the search space locally around the current best candidates. 这一步是可选的，因为作者发现不断增加更多的迭代步骤没有带来更多的提升，同时这种提升也不是在所有task中都会出现。（在实验中APE默认无迭代，APE-IT是加入了迭代）</p>
<p>zero-shot instruction induction实验结果来看，APE方法在很多任务上已经达到了人工prompting的效果：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230601204311989.png" alt="image-20230601204311989" /><figcaption>image-20230601204311989</figcaption>
</figure>
<p>生成更多的候选instructions带来了更好的效果，同时iterative search对于那些一开始没有办法找到合适的instructions的task有提升作用，而在另外task上仅仅是生成一次就效果比较好了：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230601204823591.png" alt="image-20230601204823591" /><figcaption>image-20230601204823591</figcaption>
</figure>
<h2 id="sg-icl">SG-ICL</h2>
<p>Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator</p>
<p>NAACL 2022 Workshop，首尔大学</p>
<blockquote>
<p>Large-scale pre-trained language models (PLMs) are well-known for being capable of solving a task simply by conditioning a few input-label pairs dubbed demonstrations on a prompt without being explicitly tuned for the desired downstream task. Such a process (i.e., in-context learning), however, naturally leads to high reliance on the demonstrations which are usually selected from external datasets. In this paper, <strong>we propose self-generated in-context learning (SG-ICL), which generates demonstrations for in-context learning from PLM itself to minimize the reliance on the external demonstration.</strong> We conduct experiments on four different text classification tasks and show SG-ICL significantly outperforms zero-shot learning and is generally worth approximately 0.6 gold training samples. Moreover, our generated demonstrations show more consistent performance with low variance compared to randomly selected demonstrations from the training dataset.</p>
</blockquote>
<p>利用LLM自动生成demonstrations来增强zero-shot ICL的能力（作者声称是首个这么做的工作）。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230601223224356.png" alt="image-20230601223224356" /><figcaption>image-20230601223224356</figcaption>
</figure>
<p>需要注意的一点是，在使用LLM生成demonstrations的时候，是输入了对应的test instance和期望生成的class一起生成的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230601223450763.png"   style="zoom:40%;" /></p>
<p>作者在实验部分使用LLM位每个test instance生成8个构造的demonstrations，发现效果和在进行5-shot的LLM ICL效果差不多，因此作者认为1个LLM生成的demonstration价值相当于0.6个gold training sample：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230601223612766.png"  style="zoom:40%;" /></p>
<h2 id="self-instruct">Self-Instruct</h2>
<p>ACL 2023，华盛顿大学，<a href="https://github.com/%20yizhongw/self-instruct">代码</a>。</p>
<a href="/llm/Self-Instruct/" title="[个人详细博客]">[个人详细博客]</a>
<blockquote>
<p>Large “instruction-tuned” language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. <strong>We introduce SELF-INSTRUCT, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations.</strong> Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on SUPER-NATURALINSTRUCTIONS, on par with the performance of InstructGPT 001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT 001 . SELF-INSTRUCT provides an almost annotation-free method for aligning pretrained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.</p>
</blockquote>
<p>人工生成instructions一方面代价很大，另一方面人工生成的instructions难以保证quantity, diversity, and creativity。</p>
<p>作者提出使用LLM从已有的task instruction出发，自动生成新的task instruction和对应的input-output，然后过滤掉不符合规则的新task instructions，再加入到已有的task instructions集合中。作者在这个自动构造的instruction data上fine-tuning GPT3，发现效果提升了33%，非常接近InstructGPT001的效果。</p>
<p>作者提出的方法：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150047353.png" alt="image-20230603150047353" /><figcaption>image-20230603150047353</figcaption>
</figure>
<p>首先，作者拥有一个task pool，包括175 tasks (1 instruction and 1 instance for each task)。这175个初始的task instructions都是由本文作者自己创建的。</p>
<p>然后，作者从task pool中随机抽取8个task instructions（6 are from the human-written tasks, and 2 are from the model-generated tasks）。下面是产生新task instruction的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150335100.png" style="zoom: 25%;" /></p>
<p>之后，作者使用LLM判断新产生的instruction是否是一个classification task（using 12 classification instructions and 19 non-classification instructions）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150505630.png"   style="zoom:25%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150518579.png" alt="image-20230603150518579" style="zoom:25%;" /></p>
<p>随后，对于新产生的task instruction，用LLM生成新的对应的instance。对于生成任务，作者先生成input，再生成output，作者称为Input-first Approach：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150903068.png"   style="zoom:25%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150941339.png"  style="zoom:25%;" /></p>
<p>对于分类任务，作者发现如果是先生成input，LLM总是会倾向于生成某一个label的输入。因此作者使用LLM先生成output label，再让LLM生成input，作者称为Output-first Approach：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151018452.png"   style="zoom:25%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151030519.png"   style="zoom:25%;" /></p>
<p>对于LLM生成的task instruction、input和output，需要通过一些规则过滤，比如：</p>
<ul>
<li>只有当和已有的task instruction相似度全部比较低（<span class="math inline">\(\mbox{ROUGE-L}&lt; 0.7\)</span>）的时候，一个新task instruction会被添加到task pool里</li>
<li>We also exclude instructions that contain some specific keywords (e.g., image, picture, graph) that usually can not be processed by LMs.</li>
<li>When generating new instances for each instruction, we filter out instances that are exactly the same or those with the same input but different outputs.</li>
<li>Invalid generations are identified and filtered out based on heuristics (e.g., instruction is too long or too short, instance output is a repetition of the input).</li>
</ul>
<p>作者从原始的175个task出发，最后构造了5万多的task，并且差异性也比较大：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151912820.png"   style="zoom:30%;" /></p>
<p>在SuperNI数据集上的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603152723289.png"   style="zoom:30%;" /></p>
<p>SuperNI数据集大多是已有的NLP任务，为了进一步评估模型在实际使用场景下的价值，作者人工创建了一个包括252 task的新数据集。</p>
<h2 id="discrete-prompt-for-different-slm">Discrete prompt for different SLM</h2>
<p>Can discrete information extraction prompts generalize across language models?</p>
<p>ICLR 2023，<a href="https://github.com/ncarraz/prompt_%20generalization">代码</a>。</p>
<p>作者探究了不同小参数量语言模型对于discrete prompt的泛化性的情况，并且提出了mixed-training autoprompt。也就是在AutoPrompt的方法基础上，用一个LM进行候选prompt生成，另一个LM进行评估。</p>
<blockquote>
<p>We study whether automatically-induced prompts that effectively extract information from a language model can also be used, out-of-the-box, to probe other language models for the same information. After confirming that discrete prompts induced with the AutoPrompt algorithm outperform manual and semi-manual prompts on the slot-filling task, we demonstrate a drop in performance for AutoPrompt prompts learned on a model and tested on another. We introduce a way to induce prompts by mixing language models at training time that results in prompts that generalize well across models. We conduct an extensive analysis of the induced prompts, finding that the more general prompts include a larger proportion of existing English words and have a less order-dependent and more uniform distribution of information across their component tokens. Our work provides preliminary evidence that it’s possible to generate discrete prompts that can be induced once and used with a number of different models, and gives insights on the properties characterizing such prompts.</p>
</blockquote>
<p>作者对比了三种方法产生的prompt：</p>
<ul>
<li>LPAQA：使用预先定义好的几个prompt，通过mining和paraphrasing发现更多的prompt</li>
<li>AutoPrompt：让LM自动生成prompt</li>
<li>OptiPrompt：使用了soft prompt</li>
</ul>
<p>作者在下面一系列的小LM上进行了实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230614215935769.png"   style="zoom:50%;" /></p>
<p>在LAMA数据集上的对比效果如下，表格中LAMA是指该数据集本身提供的人工写的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230614215904682.png"   style="zoom:50%;" /></p>
<p>作者发现使用了soft prompt的OptiPrompt方法效果最好，而AutoPrompt这种自动生成discrete prompt的方法效果次之，但也是好于人工写的prompt。</p>
<p>soft prompt虽然在自动生成prompt和使用prompt的LM是一致的情况下效果最好，但是泛化性很差：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230614220633652.png"   style="zoom:50%;" /></p>
<p>同时soft prompt还要求能够访问LM的内部结构，能够使用它的embeddings。</p>
<p>作者进而测试了在使用AutoPrompt的情况下，这些生成的prompt在source LM和target LM不一致的情况下的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230614220800480.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230614220826142.png"   style="zoom:50%;" /></p>
<p>可以看出来，当两个LM是一样的情况下，效果最好。如果target LM和source LM不一致的情况下，基本上效果都会下降。中间GPT-2的一系列变种变化不大，作者解释原因是GPT-2本身效果已经比较差了，再差点也没有什么太大变化了。</p>
<p>为了解决这一问题，作者提出了AutoPrompt的一个简单改动：</p>
<blockquote>
<p>Recall that the AutoPrompt algorithm involves two phases: one in which candidate prompts are generated, and one in which the prompts are evaluated. Rather than relying on the same model for the two phases, we now use two different LMs. <strong>The first model, which we call the generator, proposes a set of candidates. Then, the second model, that we call the evaluator, evaluates the candidates and chooses the best one.</strong></p>
</blockquote>
<p>下面是作者的实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230614221621275.png"   style="zoom:50%;" /></p>
<p>可以看到，不同架构的LM混合在一起，是可能生成具有更好泛化性的prompt的。但是作者在论文中也指出，这种更好的泛化性的生成和哪两个LM组合到一起有关，不是说只要组合在一起，就能够生成泛化性更好的prompt。</p>
<p>在最后，作者尝试从4个方面对找到的泛化性更好的prompt进行定量分析：</p>
<ol type="1">
<li>Semantic overlap with English: We thus hypothesize that prompts that generalize better will have a larger semantic overlap with manually crafted English prompts.
<ul>
<li>作者的观察：对于作者提出的mixed-training AutoPrompt方法来说，泛化性更强的prompt和人类实际语言之间的相似度有很强的相关性。但是这种相似度，和泛化性更弱的单个模型比如BERT-base产生的prompt对比的话，相似度耕地（说明这个假设还有待验证）。</li>
</ul></li>
<li>Real-word ratio: We thus conjecture that prompts that generalize better will contain a larger proportion of real English words.
<ul>
<li>作者的观察：进行了混合策略的方法总是自动产生了更多real world的单词；但是不一定能够带来更好的泛化性。</li>
</ul></li>
<li>Shuffling: We thus conjecture that a “bag-of-token” prompt sequence that does not require the tokens to be in any special order will be more general than one where order matters and, consequently, generalizing prompts will be more robust to token shuffling.
<ul>
<li>作者的观察：更加泛化的prompt确实对于token的顺序更加不敏感</li>
</ul></li>
<li>Token deletion: We thus conjecture that generalizing prompts will distribute information more evenly across tokens and thus they will be more robust to single-token deletion.
<ul>
<li>作者的观察：随机去掉prompt上不同位置token，测试prompt不同位置上，LM的关注程度是不是不同的。发现总是对于prompt最后一个位置的token有最大的关注。</li>
</ul></li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230614221822454.png"  style="zoom:50%;" /></p>
<h2 id="wang-et-al.">Wang et al.</h2>
<p>Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning</p>
<p>arXiv 2023, <a href="https://github.com/WANGXinyiLinda/concept-based-demonstration-selection">代码</a>。</p>
<blockquote>
<p>In recent years, pre-trained large language models have demonstrated remarkable efficiency in achieving an inference-time few-shot learning capability known as incontext learning. However, existing literature has highlighted the sensitivity of this capability to the selection of few-shot demonstrations. The underlying mechanisms by which this capability arises from regular language model pretraining objectives remain poorly understood. In this study, we aim to examine the in-context learning phenomenon through a Bayesian lens, viewing large language models as topic models that implicitly infer task-related information from demonstrations. On this premise, we propose an algorithm for selecting optimal demonstrations from a set of annotated data and demonstrate a significant 12.5% improvement relative to the random selection baseline, averaged over eight GPT2 and GPT3 models on eight different real-world text classification datasets. Our empirical findings support our hypothesis that large language models implicitly infer a latent concept variable.</p>
</blockquote>
<p>作者提出了一种看待ICL中的demonstration的作用的角度，认为LLM可以从demonstrations中学习到隐式的任务相关的信息。并且给出了一些理论上的分析。</p>
<p>基于此假设，作者提出一种新的找demonstrations的方法，整体流程如下：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230615203143639.png" alt="image-20230615203143639" /><figcaption>image-20230615203143639</figcaption>
</figure>
<p>首先是利用prompt-tuning的思想，固定LM，学习和task相关的soft prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230615203205166.png"   style="zoom:50%;" /></p>
<p>然后，作者认为最佳的demonstrations就是能够在给定样例的情况下，使得输出上一步学习到的soft prompt的概率最大的样例。直观上的理解就是说最能够“体现”任务的demonstrations就是最佳的找到的demonstrations。demonstrations的候选集应该是各种数量、各种排序的组合，但是为了减小搜索空间，作者简化到了假设最佳的单个demonstration的采样是相互独立的，然后再排序：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230615203224510.png"   style="zoom:50%;" /></p>
<p>最后，找到的这种最佳的demonstrations，可以用于其它的LM。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230615203308965.png"  style="zoom:50%;" /></p>
<h2 id="kate">KATE</h2>
<p>What Makes Good In-Context Examples for GPT-3?</p>
<p>DeeLIO 2022，杜克大学与Microsoft，<a href="https:%20//github.com/jiachangliu/KATEGPT3">代码</a>。</p>
<blockquote>
<p>GPT-3 has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its in-context learning abilities. Despite its success, we found that the empirical results of GPT-3 depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting incontext examples (relative to random sampling) that better leverage GPT-3’s in-context learning capabilities. Inspired by the recent success of leveraging a retrieval module to augment neural networks, <strong>we propose to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt.</strong> Intuitively, the examples selected with such a strategy may serve as more informative inputs to unleash GPT-3’s power of text generation. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline. Moreover, it is observed that the sentence encoders fine-tuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-totext generation (44.3% on the ToTTo dataset) and open-domain question answering (45.5% on the NQ dataset).</p>
</blockquote>
<p>在GPT-3中的原始ICL是随机找上下文样例，作者发现上下文样例的选择会极大的影响GPT-3的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919105659374.png"   style="zoom:35%;" /></p>
<p>因此，寻找适用于GPT的上下文样例很关键。最粗暴的做法是穷举所有样例的可能排列，但这个是不实际的。作者提出，利用kNN方法，从训练集中寻找sentence-level语义相似的样例来辅助ICL：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919105832312.png"  style="zoom:50%;" /></p>
<p>利用kNN找相似样例首先是需要将样例转化为embedding，作者提出两个考虑：</p>
<ul>
<li>The first category includes generally pre-trained sentence encoders such as the BERT.</li>
<li>The second category includes sentence encoders fine-tuned on specific tasks or datasets.</li>
</ul>
<p>从实验上看，效果提升很明显：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919110027138.png"   style="zoom:35%;" /></p>
<h2 id="effect-of-ordered-examples">Effect of ordered examples</h2>
<p>Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity</p>
<p>伦敦大学，ACL 2022</p>
<blockquote>
<p>When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models. <strong>We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance</strong>: essentially some permutations are “fantastic” and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true fewshot setting as it requires additional annotated data. Instead, <strong>we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set</strong>, we identify performant prompts. Our method yields a 13% relative improvement for GPTfamily models across eleven different established text classification tasks.</p>
</blockquote>
<p>之前已经有很多讨论sample structure/formatting的工作，作者声称这篇论文是首个讨论sample顺序对ICL性能影响的paper。</p>
<p>要注意，作者的ICL是corpus-level的prompt，对于所有query，有相同的demonstrations。直接来看作者实验得到的几个结论：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919165336543.png"   style="zoom:35%;" /></p>
<p>观察：</p>
<ul>
<li>ICL中demonstrations的排列顺序很重要，最坏的情况下是50%准确率，也就是随机猜测；最好的排列是性能接近有监督SOTA方法</li>
<li>LLM对于demonstrations的order很敏感，增大model size虽然似乎会一定程度缓解模型对example order的敏感程度，但是在一些任务下，这种缓解趋势并不存在（如Figure 1下面在Subj数据集的实验结果）</li>
<li>与之相反的，传统的有不同初始化设置的有监督训练的方法的性能variance，可能就是在1%-2%（反正肯定在个数百分比）的变化。</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919165630284.png"   style="zoom:40%;" /></p>
<p>观察：</p>
<ul>
<li>Adding training samples does not significantly reduce variance. 增加上下文样例数量并不会缓解对order的敏感性。</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919165745295.png"   style="zoom:40%;" /></p>
<p>观察：</p>
<ul>
<li>Performant prompts are not transferable across models. 不同LLM偏好的order是不通用的（图中的pairwise Spearman’s rank correlation系数很小）</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919165849595.png"   style="zoom:40%;" /></p>
<p>观察：</p>
<ul>
<li>表现不好的order原因之一可能是，不够平衡的label估计，总是对某一类label过于自信。</li>
</ul>
<p>从上面可以看出，表现不好的prompt可能会导致有不平衡的label输出估计。因此，作者提出了一种无监督的评估方法，选择ICL样例的合适排序。</p>
<p>首先，作者根据随机采样得到的样例集合，使用它们的所有可能排列，如有<span class="math inline">\(n\)</span>个example，那么对应<span class="math inline">\(n!\)</span>种排列permutations，每个permutation，让LLM生成对应的新的data和label，要注意此时生成的label不能保证是正确的，因此会丢弃。所有生成的sequences作为<em>probing set</em>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919210208784.png"   style="zoom:40%;" /></p>
<p>接下来，对于每种可能的排列，作者通过在<em>probing set</em>上计算两种无监督基于熵的指标，来选择合适ordered prompt：</p>
<ul>
<li>Global Entropy (GlobalE)：avoid the issue of extremely unbalanced predictions. 用LLM计算在给定某种排列顺序的demonstrations之后，对于整个probing set上所有data预测label的分布，如果让这个总体分布熵越小，表示越倾向输出一致/不平衡的label，更有可能出错。</li>
<li>Local Entropy (LocalE)：if a model is overly confident for all probing inputs, then it is likely that the model is not behaving as desired. 分别计算probing data预测label分布的熵，然后平均。</li>
</ul>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230919210604445.png"   style="zoom:50%;" /></p>
<p>采用GlobalE或LocalE指标能够减小LLM order对于效果的variance。</p>
<h2 id="rethinking-the-role-of-demonstrations">Rethinking the role of demonstrations</h2>
<p>华盛顿大学与Meta，EMNLP 2022，<a href="github.com/Alrope123/rethinking-demonstrations">代码</a>。<a href="/llm/rethinking-role-of-demonstrations/" title="[详细博客]">[详细博客]</a></p>
<blockquote>
<p>Large language models (LMs) are able to incontext learn—perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. <strong>In this paper, we show that ground truth demonstrations are in fact not required—randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choice tasks</strong>, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of end task performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.</p>
</blockquote>
<p>作者对于上下文学习中，什么样的signal是对LLM进行task learning有帮助的进行了实验探究。</p>
<p>作者主要针对4个ICL中的demonstrations可能提供的learning signal进行了实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161615499.png"   style="zoom:40%;" /></p>
<p>作者的第一个重要发现是ICL中demonstrations的input-label是否正确匹配，对模型效果的影响不大。作者用随机的label来替换demonstrations的ground truth label，发现效果下降不是很多：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161132344.png"   style="zoom:50%;" /></p>
<h2 id="self-adaptive-icl">Self-adaptive ICL</h2>
<p>Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering</p>
<p>Shanghai AI Laboratory和厦门大学，ACL 2023，<a href="https://github.com/Shark-NLP/self-adaptive-ICL">代码</a>。</p>
<blockquote>
<p>Despite the impressive few-shot performance of in-context learning (ICL), it remains a common practice to randomly select examples to serve as the context. In this paper, we advocate self-adaptive in-context learning, a new principle for ICL, in which <strong>the self-adaption mechanism is introduced to help each input find an in-context example organization</strong> (i.e., selection and permutation) that can derive the correct output, thus maximizing performance. To validate the effectiveness of self-adaptive ICL, we propose a general <strong>select-then-rank</strong> framework and a set of novel selection and ranking algorithms. Upon extensive evaluation on eight different NLP datasets, our self-adaptive ICL method achieves a 40% relative improvement over the common practice setting. Further analysis reveals the great potential of selfadaptive ICL as a promising method to close the gap between ICL and finetuning. Our code will be released to facilitate future research.</p>
</blockquote>
<p>作者提出，针对每个test example进行demonstrations selection，然后进行ranking也就是排列。首先，作者建议有以下的寻找demonstrations的策略：</p>
<ul>
<li>TopK：KATE方法和<em>Making pre-trained language models better few-shot learners</em> 工作中提出，选择test sample的nearest neighbors作为demonstrations。</li>
<li>VoteK：在TopK的策略上，通过惩罚和已选择的样例相似的候选样例，考虑多样性[<em>Selective annotation makes language models better few-shot learners</em>]。</li>
<li>DPP：作者进一步尝试了determinantal point process (DPP)，同样是一种考虑样例多样性的指标[<em>k-dpps: Fixed-size determinantal point processes. ICML 2011</em>]。</li>
</ul>
<p>为了找合适的样例排列顺序，作者从Solomonoff’s general theory of inference (Solomonoff, 1964)和Minimum Description Length (MDL) principle (Grünwald, 2007)出发，倾向于选择能够无损压缩test sample的demonstrations：</p>
<blockquote>
<p>We assume that a good organization of in-context examples is the organization that is good at losslessly compressing testing samples.</p>
</blockquote>
<p>换句话说，无损的压缩test sample，意味着可以从demonstrations中，正确的推导出test sample对应的label：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920211244740.png"   style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(c\)</span>表示某种demonstrations组织。<span class="math inline">\(L_{\theta}(y | c, x)\)</span>是指在给定样例<span class="math inline">\(c\)</span>和test input <span class="math inline">\(x\)</span>，能够真正压缩与还原test label <span class="math inline">\(y\)</span>的codelength。<span class="math inline">\(L(\theta)\)</span>是指描述model本身所需的codelength，对于所有的候选demonstrations是一样的，因此可以忽略。</p>
<p>上述公式定义最佳的demonstrations应该使无损压缩test sample所需的codelength最短。</p>
<p>使用Shannon-Huffman code来计算进行data transmission的codelength：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920211720814.png"   style="zoom:50%;" /></p>
<p>但是test label <span class="math inline">\(y\)</span>在实际中是未知的，因此作者使用codelength的期望来代替：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920211806895.png"  style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(q(y_i | Y)\)</span>是test label <span class="math inline">\(y\)</span>的先验分布，对于每个test sample来说可能是不一样的，因此作者再次使用model进行估计：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920212034299.png"   style="zoom:50%;" /></p>
<p>现在，从理论上，对于每个排列<span class="math inline">\(c\)</span>，我们都可以计算出一个无监督的metric来进行选择；但是由于作者的demonstrations是instance-level的，潜在的排序数量仍然过多，不可能真正的计算一遍所有的候选排序。因此，作者实际上只是在对应的<span class="math inline">\(K=8\)</span>采样集合中，随机采样<span class="math inline">\(10\)</span>种排列，然后进行ranking。</p>
<p>对于最终的公式5，此时作者是在计算熵，也就是寻找熵最小的情况，寻找让LLM的预测分布非常confident的demonstrations。这和上面<em>Effect of ordered examples</em>工作中提出的GlobalE和LocalE的思想是相反的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920212534148.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>使用TopK选择demonstrations，然后使用MDL进行ranking取得了最好的结果</li>
<li>TopK的instance-level的ICL策略，已经在大多数据集上优于corpus-level的ICL策略</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920212653543.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>不同任务下需要selection偏好不同。在分类任务下，使用TopK策略取得了最好的效果，在QA任务下，使用VoteK等考虑多样性的策略效果更好。</li>
</ul>
<h2 id="udr">UDR</h2>
<p>Unified Demonstration Retriever for In-Context Learning</p>
<p>复旦，ACL 2023，<a href="https://github.com/KaiLv69/UDR">代码</a>。</p>
<blockquote>
<p>In-context learning is a new learning paradigm where a language model conditions on a few input-output pairs (demonstrations) and a test input, and directly outputs the prediction. It has been shown highly dependent on the provided demonstrations and thus promotes the research of demonstration retrieval: given a test input, relevant examples are retrieved from the training set to serve as informative demonstrations for in-context learning. While previous works focus on training task-specific retrievers for several tasks separately, these methods are often hard to transfer and scale on various tasks, and separately trained retrievers incur a lot of parameter storage and deployment cost. In this paper, <strong>we propose Unified Demonstration Retriever (UDR), a single model to retrieve demonstrations for a wide range of tasks.</strong> To train UDR, we cast various tasks’ training signals into a unified list-wise ranking formulation by language model’s feedback. Then we propose a multi-task list-wise ranking training framework, with an iterative mining strategy to find high-quality candidates, which can help UDR fully incorporate various tasks’ signals. Experiments on 30+ tasks across 13 task families and multiple data domains show that UDR significantly outperforms baselines. Further analyses show the effectiveness of each proposed component and UDR’s strong ability in various scenarios including different LMs (1.3B ∼ 175B), unseen datasets, varying demonstration quantities, etc.</p>
</blockquote>
<p>目前对于ICL进行demonstrations选择的方法有两类：</p>
<ul>
<li>无监督的：比如使用BM25或者SBERT等embedding进行相似度计算</li>
<li>有监督的：针对特定task，在某种ranking的监督信号下，训练一个demonstration retriever</li>
</ul>
<p>作者期望解决的问题是，能够设计一种适用于不同task的Demonstration Retriever。</p>
<p>作者提出的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230921172022780.png"  style="zoom:50%;" /></p>
<p>首先，作者计算query sample和candidate example的方式是基于dense passage retriever (DPR) [<em>Dense passage retrieval for open-domain question answering. EMNLP 20</em>]的思路。也就是使用encoder，将query example <span class="math inline">\(x\)</span>和candidate example <span class="math inline">\(z\)</span>分别进行编码，然后计算相似度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230921172309663.png"   style="zoom:40%;" /></p>
<p>为了能够辨别来自不同task的example，编码的时候会将task instruction <span class="math inline">\(I\)</span>和example一起进行编码。</p>
<p>实现中，作者使用BERT-base来编码。</p>
<p>然后，作者的ranking signal来自LM本身的conditional probability，继承于之前的的工作EPR的思想：</p>
<blockquote>
<p>This indicates how helpful this candidate is for decoding the target (independent of all other candidates).</p>
</blockquote>
<p>公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230921221943481.png"   style="zoom:40%;" /></p>
<p>其中<span class="math inline">\(G\)</span>代表LLM，<span class="math inline">\(z_j\)</span>是某个candidate example，<span class="math inline">\(s_{gen}\)</span>和<span class="math inline">\(s_{cls}\)</span>分别代表生成任务和分类任务下，加入example <span class="math inline">\(z_j\)</span>后LM对query <span class="math inline">\(x\)</span>输出正确<span class="math inline">\(y\)</span>的概率。<span class="math inline">\(r(z_j)\)</span>代表<span class="math inline">\(z_j\)</span>在所有candidate examples中的rank。</p>
<p>作者期望通过相似度计算的retriever对于candidate examples的排序结果，能够靠近LM基于条件概率的排序结果，作者引入了两种loss：</p>
<ul>
<li><p>LambdaRank loss [<em>From RankNet to LambdaRank to LambdaMART: An overview. 2010</em>]：其中<span class="math inline">\(w\)</span>是一个根据不同pair <span class="math inline">\(z_i,z_j\)</span>动态调整的值</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230921222500768.png"   style="zoom:40%;" /></p></li>
<li><p>in-batch negative loss：让rank 1的example <span class="math inline">\(z^{*}\)</span>应该在所有可能的examples中和<span class="math inline">\(x\)</span>是最相似的</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230921222539791.png"   style="zoom:40%;" /></p></li>
</ul>
<p>最后，为了保证效率，在训练阶段，使用迭代的采样策略；最后在推理时，基于FAISS [<em>Billion-scale similarity search with gpus. 2021</em>]使用基于相似度的计算来寻找demonstrations（考虑到如果在推理阶段，使用LM来ranking的巨大代价）。</p>
<p>实验结果（基于GPT-Neo-2.7B作为LM）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230921223126629.png"   style="zoom:40%;" /></p>
<h2 id="cover-ls">Cover-LS</h2>
<p>Diverse Demonstrations Improve In-context Compositional Generalization</p>
<p>ACL 2023，<a href="https://github.com/itayle/diverse-demonstrations">代码</a>。</p>
<blockquote>
<p>In-context learning has shown great success in i.i.d semantic parsing splits, where the training and test sets are drawn from the same distribution. In this setup, models are typically prompted with demonstrations that are similar to the input utterance. However, in the setup of compositional generalization, where models are tested on outputs with structures that are absent from the training set, selecting similar demonstrations is insufficient, as often no example will be similar enough to the input. In this work, <strong>we propose a method to select diverse demonstrations that aims to collectively cover all of the structures required in the output program, in order to encourage the model to generalize to new structures from these demonstrations.</strong> We empirically show that combining diverse demonstrations with in-context learning substantially improves performance across three compositional generalization semantic parsing datasets in the pure in-context learning setup and when combined with fine-tuning.</p>
</blockquote>
<p>作者针对的是Compositional generalization问题。在组合泛化中，仅仅寻找和query example相似的单个example是不够的，需要考虑更加多样diverse的examples set来提供足够的信息。</p>
<p>Follow前人的工作[<em>Unobserved local structures make compositional generalization hard. 2022</em>]，作者定义的example的多样性体现在example的local structures。local structures是指Compositional generalization问题的答案program对应的抽象语法树的各个子图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230921235901953.png"   style="zoom:40%;" /></p>
<p>作者期望找到的demonstrations一方面能够尽可能和query example相似；一方面能够有更多样的local structures去覆盖query example的predicted local structures。作者训练T5-large来针对query example输出local structures，而不是whole program。这样能够减低预测的难度。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922000447451.png"   style="zoom:40%;" /></p>
<p>在找demonstrations时：</p>
<ul>
<li>作者先对T5-large预测的query example的local structures根据长度进行降序排列；这一思想和前人的工作[<em>Generate-and-Retrieve: Use Your Predictions to Improve Retrieval for Semantic Parsing. COLING 2022</em>]一致，先进行preliminary prediction，然后基于preliminary prediction再进行检索；</li>
<li>然后迭代的选择当前最长的local structure，寻找training set里覆盖了当前local structure中，和query example最相似的example。相似度的计算可以基于BM25或者SBERT；</li>
<li>最后，移除和已经选择的example的program一样的其它候选examples，继续进行选择；直至达到上限。</li>
</ul>
<p>找到的demonstrations不仅可以辅助与LLM的ICL，作者还直接用来fine-tuning一个SLM（同样是基于T5-large）。</p>
<p>实验结果（LLM基于<code>code-davinci-002</code>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922000836121.png"   style="zoom:40%;" /></p>
<p>（相关工作里有一些寻找多样example的paper，只不过并非是为prompt设计的）</p>
<h2 id="mutual-information">Mutual information</h2>
<p>An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels</p>
<p>ACL 2022，<a href="github.com/BYU-PCCL/information-theoretic-prompts">代码</a>。</p>
<blockquote>
<p>Pre-trained language models derive substantial linguistic and factual knowledge from the massive corpora on which they are trained, and prompt engineering seeks to align these models to specific tasks. Unfortunately, existing prompt engineering methods require significant amounts of labeled data, access to model parameters, or both. We introduce a new method for selecting prompt templates without labeled examples and without direct access to the model. <strong>Specifically, over a set of candidate templates, we choose the template that maximizes the mutual information between the input and the corresponding model output.</strong> Across 8 datasets representing 7 distinct NLP tasks, we show that when a template has high mutual information, it also has high accuracy on the task. On the largest model, selecting prompts with our method gets 90% of the way from the average prompt accuracy to the best prompt accuracy and requires no ground truth labels.</p>
</blockquote>
<p>这篇属于评价哪个prompt template/ICL formatting比较好的工作，适用于任何分类的NLP任务，并且只要各个分类的开头token是独一无二的。</p>
<p>LLM的prompt是指：</p>
<blockquote>
<p>“prompt” refers to any language passed to the model via the context window.</p>
</blockquote>
<p>prompt的template可以理解为待填充的prompt，用来构建prompt：</p>
<blockquote>
<p>a template refers to a natural language scaffolding filled in with raw data, resulting in a prompt.</p>
</blockquote>
<p>prompt template的好坏能够极大的影响LLM的task performance，一种最general的找最好的template的思路是通过在validation set上进行评估，但这要求有提前的labeled set。</p>
<p>作者的方法是可以在不需要ground truth label的情况下，通过计算不同templates和LLM输出结果的mutual information来找合适的template：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230924210415173.png"   style="zoom:40%;" /></p>
<p>步骤：</p>
<ul>
<li>人工设计<span class="math inline">\(K\)</span>个prompt template，然后用几个samples测试下template，排除或者修改那些无法将对应label最开头的token输出在前几位的templates；</li>
<li>针对每个template，采样数据，填充template，创建测试数据；</li>
<li>对于输出结果，将不同label对应的开头token的权重重新归一化。计算mutual information，选择最大互信息的template；</li>
</ul>
<p>什么是互信息：</p>
<blockquote>
<p>Mutual information is a measure of the amount of shared information between two random variables (Cover and Thomas, 2006); in other words, it is the reduction in entropy that is observed in one random variable when the other random variable is known.</p>
</blockquote>
<p>假定templates <span class="math inline">\(f_{\theta}(X)=\{f_{\theta}(x)\}\)</span>是random variable，<span class="math inline">\(Y\)</span>是labels，计算mutual information <span class="math inline">\(I(f_{\theta(X)};Y)=D_{KL}(P_{(f_{\theta(X)},Y)}||P_{f_{\theta}} \otimes P_Y)\)</span>，进一步化简为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230924211332259.png"   style="zoom:50%;" /></p>
<p>使用下面的采样期望进行估计：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230924211421422.png"   style="zoom:40%;" /></p>
<p><span class="math inline">\(H(\cdot)\)</span>代表熵。作者认为更高的mutual information更好，代表采用该template之后，熵减小的更多。</p>
<p>如何理解一个template有更大的互信息就更好？</p>
<ol type="1">
<li><p>根据上面的公式2，最大化互信息，意味着最大化<span class="math inline">\(H(Y)\)</span>和最小化<span class="math inline">\(H(Y|f_{\theta}(X))\)</span>。也就是一个更好的template，对原始的label有更少的bias（更uniform，不潜在的偏好某种label）；同时该template倾向于输出更confident的label probability</p></li>
<li><p>从data processing inequality [<em>Elements of Information Theory 2nd Edition (Wiley Series in Telecommunications and Signal Processing) 2006</em>]的角度分析，<span class="math inline">\(I(f_{\theta(X)};Y) \leq I(X;Y)\)</span>，也就是说<span class="math inline">\(I(f_{\theta(X)};Y)\)</span>是<span class="math inline">\(I(X;Y)\)</span>的lower bound。更大的<span class="math inline">\(I(f_{\theta(X)};Y)\)</span>意味着更tight的lower bound，因此保留了<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>之间更多的信息</p></li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>ICL</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>LLM</tag>
        <tag>ICL</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-PEFT</title>
    <url>/collection/LLM-PEFT/</url>
    <content><![CDATA[<h1 id="llm的peft方法">LLM的PEFT方法</h1>
<p>参数高效微调PEFT(Parameter-Efficient Fine Tuning)方法调研。</p>
<span id="more"></span>
<h2 id="prefix-tuning">Prefix-Tuning</h2>
<p>Prefix-Tuning: Optimizing Continuous Prompts for Generation</p>
<p>ACL 2021，斯坦福。</p>
<blockquote>
<p>Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead <strong>optimizes a sequence of continuous task-specific vectors, which we call the prefix.</strong> Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were “virtual tokens”. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by modifying only 0.1% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.</p>
</blockquote>
<p>作者提出了一种区别于所有模型参数更新方法的新微调方法，prefix-tuning：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530212950351.png"   style="zoom:30%;" /></p>
<p>简单的说就是在LLM模型的每一层输入最前面，加入一个embedding序列，作为prefix。这样每一层模型的输出（encoder/decoder）都会被prefix影响：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530213218349.png" alt="image-20230530213218349" /><figcaption>image-20230530213218349</figcaption>
</figure>
<p>需要注意的是，作者发现如果只是单纯的给每一层输入加入独立的embedding，会导致模型训练不稳定，效果下降。因此作者是使用一个MLP来生成要输入到每一层左侧的prefix embedding。在inference阶段，就可以丢掉这个prompt而直接使用最终训练好的prefix embedding即可。</p>
<p>作者基于GPT-2进行了相关的实验。</p>
<p>一个发现是随着prefix length的增加，模型性能先增加后减低：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530214405258.png"  style="zoom:40%;" /></p>
<p>作者还进行了一个只在embedding层加入prefix的结果，发现效果会下降很多（这一点可能是因为GPT-2的model size还不够大，后面的prompt-tuning方法证明越大的模型需要微调的参数量越少）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530214521415.png"  style="zoom:40%;" /></p>
<h2 id="prompt-tuning">Prompt-tuning</h2>
<p>The Power of Scale for Parameter-Efficient Prompt Tuning</p>
<p>EMNLP 2021，Google brain，<a href="https://github.com/google-research/%20prompt-tuning">代码</a>。</p>
<blockquote>
<p>In this work, we explore “prompt tuning,” a simple yet effective mechanism for learning “soft prompts” to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3’s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method “closes the gap” and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. <strong>Our method can be seen as a simplification of the recently proposed “prefix tuning” of Li and Liang (2021) and we provide a comparison to this and other similar approaches.</strong> Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient “prompt ensembling.” We release code and model checkpoints to reproduce our experiments.</p>
</blockquote>
<p>更近一步的简化，只是在embedding输入层最左边加入soft prompt作为task prompts。作者发现，这种方法随着model size增加，效果逐渐能够比拟fine-tuning的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530215325711.png"   style="zoom:30%;" /></p>
<p>这种soft prompt比起text prompt/hard prompt来说，好处就是它可以看做是一种信息压缩。如果用text prompt要达到比较好的效果，依赖于输入的长度和是否准确的描述了足够的context信息。实际上所有的text token也最终会被fixed LLM转化为fixed embedding。prompt tuning只不过让某些tokens能够被更新/或者是理解为创造代表新语义的token embedding。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530215555584.png"   style="zoom:30%;" /></p>
<p>方法很简单，更重要的是几个实验。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530215710746.png" alt="image-20230530215710746" /><figcaption>image-20230530215710746</figcaption>
</figure>
<p>从这个图(a)能够看出很重要的一点信息，越大的LLM，对于prompt length要求越低，可能LLM越能够快速的学习好condition signal，也只需要微调更少的参数即可。</p>
<p>作者实验了三种不同的初始化prompt的方法：</p>
<ul>
<li>random initialization: we sample uniformly from the range [−0.5, 0.5]</li>
<li>initializing from sampled vocabulary: we restrict to the 5,000 most “common” tokens in T5’s SentencePiece vocabulary (Kudo and Richardson, 2018), which is ordered by likelihood in the pre-training corpus.</li>
<li>“class label” initialization: we take the embeddings for the string representations of each class in the downstream task and use them to initialize one of the tokens in the prompt.</li>
</ul>
<p>实验结果如上图的(b)，可以看到使用“class label” initialization在model size较小的情况下效果最好，但是当model size达到一定程度的时候，不同的初始化方法没有区别了。</p>
<p>这种prompt-tuning方法和model-tuning的方式比起来，另一个好处可能是保持了模型本身学习到的知识和能力，不会由于fine-tuning降低泛化能力，从而带来更好的领域迁移能力。（This reduces the model’s ability to overfit to a dataset by memorizing specific lexical cues and spurious correlations.）下面是作者在一个in-domain数据集上训练，在out-domain的数据集上直接测试的结果，可以看到这种方法具有更好的领域迁移能力：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530221537562.png"  style="zoom:40%;" /></p>
<p>由于LLM的规模，要集成多个LLM是很难的。但是作者还把不同的prefix prompt token看做是训练了不同的model。使用由多个tokens的prompt-tuning方法，看做是一种prompt ensembling方法。作者直接拿单个的prefix token出来作为prefix，基于fixed T5，使用majority voting方法集成结果，发现效果都提升了：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530220419620.png"   style="zoom:40%;" /></p>
<p>作者最后是尝试解释了一下学习到的prompt embedding的含义，基于余弦相似度计算和其它word embedding之间的相似性，使用最近邻算法聚合邻居，有如下发现：</p>
<ul>
<li>发现使用word-like的prompt初始化，让最相似的邻居聚类也都是相似语义的。</li>
<li>发现label word也会在最近邻中出现，但是如果是使用随机初始化，同一个label word可能会在多个prompt embedding的最近邻里出现。如果是使用class labels去初始化，会让label word只出现在一个对应的prompt embedding的最近邻里。</li>
<li>发现label的最近邻居中确实会出现和domain相关的一些关键词，比如science，technology等。说明prompt-tuning这种方法确实可能domain specific的信息。</li>
</ul>
<h2 id="p-tuning">P-tuning</h2>
<p>GPT Understands, Too</p>
<p>arXiv 2021.03，清华大学，<a href="https://github.com/THUDM/P-tuning">代码</a>。</p>
<blockquote>
<p>While GPTs with traditional fine-tuning fail to achieve strong results on natural language understanding (NLU), we show that GPTs can be better than or comparable to similar-sized BERTs on NLU tasks with <strong>a novel method P-tuning which employs trainable continuous prompt embeddings.</strong> On the knowledge probing (LAMA) benchmark, the best GPT recovers 64% (P@1) of world knowledge without any additional text provided during test time, which substantially improves the previous best by 20+ percentage points. On the SuperGlue benchmark, GPTs achieve comparable and sometimes better performance to similar-sized BERTs in supervised learning. Importantly, we find that P-tuning also improves BERTs’ performance in both few-shot and supervised settings while largely reducing the need for prompt engineering. Consequently, P-tuning outperforms the state-of-the-art approaches on the few-shot SuperGlue benchmark.</p>
</blockquote>
<p>作者提出了一种直接在输入层生成continuous prompt embeddings作为输入的微调方法。作者这里的continuous prompt或者叫soft prompt是由一个外部可训练的模型（LSTM+MLP）生成的。对于原来的输入离散的prompt，只保留在prompt模板中关键的context token和mask token。其它的token都是重新学习的：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530225350953.png" alt="image-20230530225350953" /><figcaption>image-20230530225350953</figcaption>
</figure>
<p>之所以不重新直接学习新的embedding，而是要由一个model生成，是因为：</p>
<ul>
<li>Discreteness: 随机初始化的embedding，在更新之后可能差异性不够大，可能只有一些部分邻居element获得了更新。the original word embedding <span class="math inline">\(e\)</span> of <span class="math inline">\(M\)</span> has already become highly discrete after pre-training. If <span class="math inline">\(h\)</span> is initialized with random distribution and then optimized with stochastic gradient descent (SGD), which has been proved to only change the parameters in a small neighborhood.</li>
<li>Association: 保证输入的soft prompt之间应该是连续的。another concern would be, intuitively, we believe the values of prompt embeddings <span class="math inline">\(h_i\)</span> should be dependent on each other rather than independent. We need some mechanism to associate prompt embeddings with each other.</li>
</ul>
<p>所以作者实际的获取prompt方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530225724824.png"   style="zoom:40%;" /></p>
<p>方法本质上是用一个model来重新学习几乎所有的word embedding。</p>
<p>实验结果：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530230349720.png" alt="image-20230530230349720" /><figcaption>image-20230530230349720</figcaption>
</figure>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>PEFT</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>PEFT</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-data-augment2</title>
    <url>/collection/LLM-data-augment2/</url>
    <content><![CDATA[<h1 id="llm数据增强">LLM数据增强</h1>
<p>基于LLM的数据增强论文合集2。</p>
<span id="more"></span>
<h2 id="promptmix-emnlp23">PromptMix-emnlp23</h2>
<p>PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation. University of Waterloo. EMNLP 2023. <a href="https://github.com/%20ServiceNow/PromptMix-EMNLP-2023">代码</a>.</p>
<blockquote>
<p>Data augmentation is a widely used technique to address the problem of text classification when there is a limited amount of training data. Recent work often tackles this problem using large language models (LLMs) like GPT3 that can generate new examples given already available ones. <strong>In this work, we propose a method to generate more helpful augmented data by utilizing the LLM’s abilities to follow instructions and perform few-shot classifications.</strong> Our specific PromptMix method consists of two steps: 1) generate challenging text augmentations near class boundaries; however, generating borderline examples increases the risk of false positives in the dataset, so we 2) relabel the text augmentations using a prompting-based LLM classifier to enhance the correctness of labels in the generated data. We evaluate the proposed method in challenging 2-shot and zero-shot settings on four text classification datasets: Banking77, TREC6, Subjectivity (SUBJ), and Twitter Complaints. Our experiments show that generating and, crucially, relabeling borderline examples facilitates the transfer of knowledge of a massive LLM like GPT3.5-turbo into smaller and cheaper classifiers like DistilBERTbase and BERT base . Furthermore, 2-shot PromptMix outperforms multiple 5-shot data augmentation methods on the four datasets. Our code is available at https://github.com/ServiceNow/PromptMix-EMNLP-2023.</p>
</blockquote>
<p><strong>Issue</strong>: 已经出现的prompt-based的LLM做数据增强的方法只考虑使用单个class的信息来进行生成，这样无法生成能够处于class boundary上的hard samples。</p>
<blockquote>
<p>We hypothesize that training a robust text classifier requires the training data to have a good mix of borderline examples (Swayamdipta et al., 2020).</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231103220806464.png" alt="image-20231103220806464" style="zoom:30%;" /></p>
<p><strong>Solution</strong>：作者的策略是，一次给LLM提供多个class的信息，并且要求生成的data需要能够同时包含两个class的信息，让生成的数据能够处在class boundary上。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231103220936841.png"  style="zoom:50%;" /></p>
<p>第一步，作者提出的用来生成hard samples的prompt。一次提供<span class="math inline">\(t=4\)</span>个class的描述prompt（人工构造），每个class随机找<span class="math inline">\(k=0/2\)</span>个样例，然后对于每个单独的class，要求生成的数据能够包括<span class="math inline">\(\alpha \%\)</span>的class信息和<span class="math inline">\((1-\alpha) \%\)</span>的另一种class的信息：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231103221214983.png" style="zoom:30%;" /></p>
<p>第二步，由于生成的句子包括了两个class的信息，无法保证最后生成的text到底是属于哪个class，因此需要用LLM进行relabelling。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231103221335778.png"  style="zoom:30%;" /></p>
<p>作者的实验基于<code>GPT-3.5-turbo</code>进行生成，然后微调<code>DistilBERT-base</code>和<code>BERT-base</code>，进行text classification任务。</p>
<p>进行了class混合后的结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231103221439337.png"  style="zoom:30%;" /></p>
<p>总体实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231103221522879.png"  style="zoom:40%;" /></p>
<p>观察：</p>
<ul>
<li>最后一行，在这些任务上，直接让GPT结合kNN ICL进行分类效果最好…作者这里提出的数据增强方法只是能够被声明为不到1%的参数量，达到了GPT类似的效果</li>
<li>A1是只使用生成的数据；A2是使用real data和生成data；由于作者是生成的hard数据，因此如果完全使用生成数据训练的话，学习的分类器性能不好。只不过如果是同时使用，model的泛化性能够得到很好的提升</li>
</ul>
<p>使用不同LLM对比的结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231103221744002.png"  style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>GPT-4比起GPT3.5，效果又提升了接近10个点</li>
<li>LLaMA2-70B接近GPT3.5</li>
</ul>
<h2 id="msp-emnlp23">MSP-emnlp23</h2>
<p>Mixture of Soft Prompts for Controllable Data Generation. Columbia University. EMNLP 2023. <a href="https://github.com/derekchen14/mixture_soft_prompts">代码</a>.</p>
<blockquote>
<p>Large language models (LLMs) effectively generate fluent text when the target output follows natural language patterns. However, structured prediction tasks confine the output format to a limited ontology, causing even very large models to struggle since they were never trained with such restrictions in mind. <strong>The difficulty of using LLMs for direct prediction is exacerbated in few-shot learning scenarios, which commonly arise due to domain shift and resource limitations.</strong> We flip the problem on its head by leveraging the LLM as a tool for data augmentation rather than a model for direct prediction. Our proposed Mixture of Soft Prompts (MSP) serves as a parameter-efficient procedure for generating <strong>multi-attribute data in a controlled manner</strong>. Denoising mechanisms are further applied to improve the quality of synthesized data. Automatic metrics show our method is capable of producing diverse and natural text, while preserving label semantics. Moreover, MSP achieves state-of-the-art results on three benchmarks when compared against strong baselines. Our method offers an alternate data-centric approach for applying LLMs to complex prediction tasks.</p>
</blockquote>
<p><strong>Issue</strong>: 直接利用LLM执行不同的低资源任务，在面临需要hierarchy or compositionality的NLU任务时，效果表现不好。</p>
<blockquote>
<p>However, off-the-shelf LLMs have shown evidence of struggling with direct prediction in more complicated NLU tasks, such as those involving hierarchy or compositionality (Furrer et al., 2020; Qiu et al., 2022; Dziri et al., 2023). LLMs with ICL also exhibit problems when the target output requires a specific structure not represented in the training data (Reynolds and McDonell, 2021; Min et al., 2022).</p>
</blockquote>
<p>另一种解决低资源问题的思路是数据增强，问题是缺少对于输出结果<em>label preservation</em>和<em>diversity</em>的控制。作者利用LLM来作为工具为数据增强生成更多fluent text。</p>
<p><strong>Solution</strong>: 作者为数据集中的每一个attribute（在论文中的意思是指某种具体的type比如entity type）都学习一个对应的soft prompt；由于一个句子可能有多个attributes（比如多个entities），因此需要想办法混合soft prompts，根据混合后的soft prompt来生成最后的data。</p>
<p>作者的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231104224610748.png"  style="zoom:50%;" /></p>
<p>作者的prompt有如下几部分：</p>
<ul>
<li>an instruction prefix：<code>Show me three distinct utterances that all express the X</code>;</li>
<li>soft prompts: 利用attributes的name和description来初始化，如&quot;song is a musical song or melody&quot;；</li>
<li>meta-data：和具体task相关的信息，比如domain name或slot-values</li>
<li>exemplars：包括了前面attributes的样例<span class="math inline">\(k=2\)</span></li>
</ul>
<p>由于一个句子可能对应多个attributes，比如&quot;greet&quot;和”change“ intents，就会有多个soft prompts，因此需要设计某种混合soft prompts的方法。具体来说作者设计了5种组合prompt的方法，比如concat：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231104225247975.png"  style="zoom:50%;" /></p>
<p>其它的还有pooling、Attention、Bottleneck和CNN的方法。</p>
<p>基于设计的prompt方法和attribute mixing方法，作者针对target domain的数据进行微调。微调后的LLM可以作为数据生成器。对于生成的数据，作者提出了两个Data Denoising的指标：</p>
<ul>
<li>由于数据中存在数据不平衡的现象，作者采样生成数据的时候，按照某个attribute在数据集中出现的频率的进行反向采样</li>
<li>作者发现很多生成的错误数据和目标label之间有很大差异，因此作者只保留和原有数据sentence embedding相似的生成数据</li>
</ul>
<p>作者的实验设置强调了从source domain到target domain的迁移。但实际上，作者生成target domain的数据时，只利用了target domain的数据，生成后的数据与原有的target domain真实数据，以及source domain的数据合并，训练下游任务模型。</p>
<p>作者在实验时，微调<code>FLAN-T5-XXL(11B)</code>来生成数据，下游任务使用<code>GODEL</code>。在实验时，作者使用了CrossNER数据集。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231104230653178.png"  style="zoom:30%;" /></p>
<p>几个示例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231104230725419.png"  style="zoom:30%;" /></p>
<h2 id="s3-emnlp23">S3-emnlp23</h2>
<p>Let’s Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models. EMNLP 2023. <a href="https://github.com/RickySkywalker/Synthesis_Step-by-Step_Official">代码</a>.</p>
<blockquote>
<p>Data Synthesis is a promising way to train a small model with very little labeled data. One approach for data synthesis is to leverage the rich knowledge from large language models to synthesize pseudo training examples for small models, making it possible to achieve both data and compute efficiency at the same time. <strong>However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the real task data distribution.</strong> Thus, in this paper, we propose Synthesis Step by Step (S3), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model. Extensive experiments on multiple NLP tasks show that our approach improves the performance of a small model by reducing the gap between the synthetic dataset and the real data, resulting in significant improvement compared to several baselines: 9.48% improvement compared to ZeroGen, 2.73% compared to GoldGen, and 15.17% improvement compared to the small model trained on human-annotated data.</p>
</blockquote>
<p><strong>Issue</strong>：虽然LLM已经在各类下游任务都已经取得了很好的效果。但受限于large model sizes and high inference latency，很难在实际中部署。也因此，在很多资源受限的任务中，使用small model仍然是收到偏好的。而要训练好一个small model关键是需要特定任务的大量有标注数据。但获取大量标注数据是很难的。</p>
<p>有一系列的方法讨论如何降低对人工标注数据的依赖：</p>
<ul>
<li>knowledge distillation (Hinton et al., 2015; Beyer et al., 2022; Hsieh et al., 2023; Xu et al., 2020; Zhou et al., 2020; Shridhar et al., 2023)</li>
<li>data augmentation (DeVries and Taylor, 2017; Shorten and Khoshgoftaar, 2019; Li et al., 2022)</li>
<li>module replacing (Xu et al., 2020; Zhou et al., 2023), semi-supervised learning (Chen et al., 2020; Wang et al., 2021; Smith et al., 2022)</li>
<li>data synthesis (Anaby-Tavor et al., 2020; Puri et al., 2020).</li>
</ul>
<p>data synthesis方法最大的问题在于生成的data和real data之间存在large distributional discrepancy。提高生成数据的质量能够使用更少的生成数据训练处更好的task model。减少让训练的模型取得比较好的效果所需要的生成数据的数量</p>
<p>如何提高生成数据的质量，减小和real data之间的distributional discrepancy。</p>
<p><strong>Solution</strong>: 作者的方法思想核心是利用LLM生成数据，训练好的task model，在gold data上预测错误的samples，来反映生成data和real data之间的差异。让LLM模仿这些被错误预测的samples生成更多的数据，重新训练task model。</p>
<p>作者提出的Synthesis Step by Step (S3)方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231106160108421.png"  style="zoom:40%;" /></p>
<p><strong>Seed Data Synthesis with Rationales</strong>. 作者首先考虑如何生成训练数据。作者的改进之处在于，首先利用LLM找出每个label可能对应的不同rationales；然后联合label和相应的rationales让LLM生成更加diverse, informative, and realistic examples。</p>
<p><strong>Error Extrapolation-based Synthesis (EES)</strong>. 作者提出Error Extrapolation-based Synthesis (EES)来找出只利用生成数据训练好的task model，在对应的real data上（实现中就是直接使用了对应task的training set来评估task model）被错误预测的samples，然后让LLM仿照这些被错误预测的samples生成更多的数据，加入到之前构造的seed data中。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231106160531409.png"  style="zoom:30%;" /></p>
<p>作者对不同任务使用的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231106160647118.png"  style="zoom:30%;" /></p>
<p>作者的实验使用了<code>GPT3.5</code>，temperature of 0.9；task model是<code>DistilBERT-base-uncased</code>。在text classification、Natural Language Inference (NLI)和QA三类task上进行了测试：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231106160746609.png"  style="zoom:30%;" /></p>
<h2 id="doctor-emnlp23">DOCTOR-emnlp23</h2>
<p>Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents. EMNLP 2023. Yonsei University. <a href="https://github.com/kyle8581/DialogueCoT">代码</a>。</p>
<blockquote>
<p>Human-like chatbots necessitate the use of commonsense reasoning in order to effectively comprehend and respond to implicit information present within conversations. Achieving such coherence and informativeness in responses, however, is a non-trivial task. Even for large language models (LLMs), the task of identifying and aggregating key evidence within a single hop presents a substantial challenge. <strong>This complexity arises because such evidence is scattered across multiple turns in a conversation, thus necessitating integration over multiple hops.</strong> Hence, our focus is to facilitate such multi-hop reasoning over a dialogue context, namely dialogue chain-of-thought (CoT) reasoning. To this end, we propose a knowledge distillation framework that leverages LLMs as unreliable teachers and selectively distills consistent and helpful rationales via alignment filters. We further present DOCTOR, a DialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for response generation 1 . We conduct extensive experiments to show that enhancing dialogue agents with high-quality rationales from DOCTOR significantly improves the quality of their responses.</p>
</blockquote>
<p><strong>Issue</strong>：在Commonsense reasoning任务中，之前的方法大多是集中在对最后一轮对话中的context进行推理，而忽略了在之前多轮对话中会出现的evidence。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231122161043130.png"  style="zoom:30%;" /></p>
<p><strong>Solution</strong>: 作者将multi-hop commonsense reasoning看做是Chain-ofThought (CoT) reasoning (Wei et al., 2022) for dialogue response generation, namely Dialogue CoT。作者认为CoT生成的rationales能够帮助response generation。</p>
<p>但是LLM生成的rationales存在问题：</p>
<ol type="1">
<li>LLMs tend to rely much on explicit cues, necessitating taskspecific constraints to seek implicit knowledge.</li>
<li>LLMs exhibit poor alignment between rationales and dialogues, resulting in inconsistent and unhelpful rationales.</li>
</ol>
<p>因此，作者将已有的LLM看做是unreliable reasoner，将其生成的rationales过滤后，作为好的rationales。尝试蒸馏一个新的LM让其能够直接输出过滤后的好的reliable rationales。</p>
<p>作者的方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231122154349946.png"  style="zoom:50%;" /></p>
<p>首先，是QA-driven Rationalization。作者给定LLM之前轮的context <span class="math inline">\(U_{&lt;t}\)</span>和下一步的real response <span class="math inline">\(u_{t}\)</span>，然后用不同的prompt提问，找到对应的rationales。每一轮对有对应的rationales集合，这样就实现了对于多轮问答中线索的搜寻。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231122155011482.png"  style="zoom:40%;" /></p>
<p>提问的prompt是作者从ATOMIC中选择的11种commonsense relations，然后构造问题，如：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231122154603791.png"  style="zoom:30%;" /></p>
<p>然后，为了保证生成的rationales的质量，作者利用了两个alignment filters：</p>
<ul>
<li><p>Rationale-to-context alignment：为了判断rationales是否和给定的context是否一致，作者基于<code>RoBERTa-large</code>训练了一个二元分类器。训练集的构造是一致的context和rationales、不一致的context和rationales。作者从SODA数据集中随机选择了6K个dialogues，输入给LLM完整的多跳问答的context，然后人工选择出和context一致的rationales。不一致的rationales是作者破坏完整的多轮问答，只给定最后一步的utterance，让LLM生成counterfactual rationales。作者训练出来的不一致分类器能够达到93%的测试准确度。</p></li>
<li><p>Rationale-to-response alignment：为了判断rationales是否和后续的response一致，作者考虑在给定rationales的情况下，能够正确的输入后续的response。基于<code>Cosmo-3B</code>，计算helpfulness ratio。具体是给定了rationales情况下，real utterance出现的perplexity和不给定rationales的perplexity比值：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231122160013373.png" style="zoom:50%;" /></p>
<p>只有helpfulness ratio大于<span class="math inline">\(\tau=0.95\)</span>的rationales会被选择。</p></li>
</ul>
<p>为了蒸馏新的LM reasoner，作者构建了新的数据集DONUT。在其构造过程中，两个filters能够过滤掉近1/4的rationales。</p>
<p>在DONUT数据上，蒸馏出来的新的LM基于<code>OPT-1.3B</code>。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231122161008216.png"  style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Data Augmentation</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>LLM</tag>
        <tag>Data Augmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-reason</title>
    <url>/collection/LLM-reason/</url>
    <content><![CDATA[<h1 id="使用llm的推理方法">使用LLM的推理方法</h1>
<p>使用LLM进行推理的相关论文总结</p>
<span id="more"></span>
<h2 id="cot">CoT</h2>
<p>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</p>
<p>Google Research，NeurIPS 2022</p>
<blockquote>
<p>We explore how generating <strong>a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning.</strong> In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called <strong>chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.</strong></p>
<p>Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.</p>
</blockquote>
<p>首次提出了chain-of-thought思路的论文。简单说就是在上下文学习中，对于每个输出输出样例examplar，加入中间的推理步骤，格式为<code>&lt;input, chain of thought, output&gt;</code>：</p>
<blockquote>
<p>A chain of thought is a series of intermediate natural language reasoning steps that lead to the final output, and we refer to this approach as chain-of-thought prompting.</p>
</blockquote>
<p>CoT灵感的来源是两个：</p>
<ul>
<li>First, techniques for arithmetic reasoning can benefit from generating natural language rationales that lead to the final answer. 之前的rationale-augmented training的方法发现通过利用自然语言描述的中间步骤rationales可以帮助解决数学推理问题；但是这种方法需要获得大量的rationales，实际上是很难获得的。</li>
<li>Second, large language models offer the exciting prospect of in-context few-shot learning via prompting. LLM已经通过上下文学习模拟样例，可以解决很多问题，无需训练。但是在需要推理能力的任务上表现很差</li>
</ul>
<p>作者CoT的思想就是融合了这两种思路，如果能够获得中间推理的步骤，可以帮助解决推理问题；而上下文学习又能够让LLM模拟少数几个样例，无训练的快速学习；那么如果让LLM学会模拟几个样例中的推理步骤，是不是就可以让LLM也迅速学会模拟推理？</p>
<p>方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230906164647259.png"   style="zoom:40%;" /></p>
<p>思考和推理的过程像是一个chain，因此叫做chain of thought。即使出现的prompt样例中的中间step看起来只是一段话，但它本质上仍然表达了思维链的过程。</p>
<p>实验结果显示，通过无训练的CoT prompting方法，可以让PaLM 540B在数学问题上达到sota：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230906164755714.png"   style="zoom:25%;" /></p>
<p>CoT有个潜在的假设/前提，某个任务的输入到输出过程，是可以用自然语言的形式进行描述的。</p>
<p>CoT的几个好处：</p>
<ul>
<li>First, chain of thought, in principle, allows models to decompose multi-step problems into intermediate steps, which means that additional computation can be allocated to problems that require more reasoning steps.</li>
<li>Second, a chain of thought provides an interpretable window into the behavior of the model, <strong>suggesting how it might have arrived at a particular answer and providing opportunities to debug where the reasoning path went wrong</strong> (although fully characterizing a model’s computations that support an answer remains an open question).</li>
<li>Third, chain-of-thought reasoning can be used for tasks such as math word problems, commonsense reasoning, and symbolic manipulation, and is potentially <strong>applicable (at least in principle) to any task that humans can solve via language</strong>.</li>
<li>Finally, chain-of-thought reasoning can be readily elicited in sufficiently large off-the-shelf language models simply by including examples of chain of thought sequences into the exemplars of few-shot prompting.</li>
</ul>
<h2 id="self-verification">Self-Verification</h2>
<p>Large Language Models are Better Reasoners with Self-Verification</p>
<p>arXiv 2013</p>
<blockquote>
<p>Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, <strong>people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities.</strong> We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By taking turns masking the original conditions and predicting their results, <strong>we calculate an explainable answer verification score based on whether the re-predicted conditions are correct.</strong> Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: https://github.com/WENGSYX/Self-Verification.</p>
</blockquote>
<p>使用CoT能够提升LLM的推理能力，但是CoT prompting方法对于个别的小的mistake很敏感从而会出现错误的结果。另外考虑到多次输入相同的prompt，LLM也可能出现不同的推理结果。因此如何从LLM的推理结果中找出正确的答案是很重要的。</p>
<p>之前修正多步推理过程中出现的错误的方法，是training一个额外的验证器verifier。这种做法一方面要求有对应的标注数据；另一方面训练出来的验证器本身又是难以解释的，可靠性难以评估。 因此作者提出了自我验证Self-Verification，无需训练的思路。即让LLM自己验证自己的推理结果。这种做法实际人类也经常做，humans often perform self-verification of inferred conclusions to mitigate mistakes。</p>
<p>作者的方法有两步：</p>
<ul>
<li>Forward Reasoning：通过CoT prompting让LLM生成candidate answers，即从conditions推导出conclusions，<span class="math inline">\(X\rightarrow Y\)</span></li>
<li>Backward Verification：验证上一步的多个候选答案，mask原来的condition，根据LLM推理出的答案，推导被mask掉的condition。准确预测出来的condition越多，验证得分越高。最后选择验证得分最大的答案。<span class="math inline">\(Y\rightarrow X\)</span></li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230906202533743.png"   style="zoom:40%;" /></p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230906203043968.png"  style="zoom:30%;" /></p>
<h2 id="self-consistency-cot">Self-Consistency CoT</h2>
<p>Self-Consistency Improves Chain of Thought Reasoning in Language Models</p>
<p>ICLR 2023，Google research</p>
<blockquote>
<p>Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, <strong>self-consistency</strong>, to replace the naive greedy decoding used in chain-of-thought prompting. It ﬁrst samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. <strong>Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer.</strong> Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%).</p>
</blockquote>
<p>原始的CoT prompting方法是直接生成唯一的推理路径和对应的答案，这种策略可以叫做是greedy decoding strategy，即取推理路径中概率最大的策略。</p>
<p>这篇论文提出一种新的decoding策略 Self-Consistency，它的直觉是一个复杂的推理任务，可能有多种推理路径能够得到最终的答案。越复杂的问题，能够获得最终答案的推理路径可能多样性越大。正确的推理路径不是唯一的。</p>
<p>Self-Consistency的方法很简单，就是让LLM生成多个可能的推理路径和答案，然后选择其中最consistent的答案。作者采用了majority vote的策略，因此最终选择候选答案中出现次数最多的那个答案：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230906213813563.png"   style="zoom:40%;" /></p>
<p>方法很简单，不过论文中有一些发现值得思考：</p>
<ul>
<li><p>这是一种类似于self-ensemble的方法，集成一个model的多个预测结果</p></li>
<li><p>推理路径的出现概率，可以通过每个位置上token的出现概率之和进行估计：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230906214012916.png"   style="zoom:50%;" /></p>
<p>作者发现这样子计算出来的各个推理路径的概率值互相之间很接近，没有太大差距。这证明了LLM实际上没有能力评估出不同solution之间有什么差异。因此，使用这种推理路径的概率去选择最后的答案，和直接认为每个推理路径的权重是1的效果差别不大</p></li>
<li><p>直观的说，self-consistency能够适应的推理任务是答案唯一的情况。不过也可以考虑拓展，比如比较生成的文本之间是否矛盾或者冲突，然后选择互相之间最不冲突的文本</p></li>
</ul>
<p>部分实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230906214258541.png"   style="zoom:30%;" /></p>
<h2 id="maieutic-prompting">Maieutic Prompting</h2>
<p>Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</p>
<p>华盛顿大学，EMNLP 2022，<a href="https://github.com/jaehunjung1/Maieutic-Prompting">代码</a>。</p>
<blockquote>
<p>Pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, <strong>we develop Maieutic Prompting, which aims to infer a correct answer to a question even from the unreliable generations of LM.</strong> Maieutic Prompting induces a tree of explanations abductively (e.g. X is true, because . . .) and recursively, then frames the inference as a satisﬁability problem over these explanations and their logical relations. We test Maieutic Prompting for true/false QA on three challenging benchmarks that require complex commonsense reasoning. Maieutic Prompting achieves up to 20% better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models. We also show that M AIEUTIC PROMPTING improves robustness in inference while providing interpretable rationales.</p>
</blockquote>
<p>虽然之前的paper常常假设LLM可以模拟人类的推理能力。但是实际上目前还做不到。LLM的推理是常常自相矛盾的，不可依赖的：</p>
<ul>
<li>the explanation does not logically lead to the inferred answer 解释和答案不一致</li>
<li>the model infers the same label for a statement and its negation 相反的解释有相同的答案</li>
<li>falsiﬁes its own generated explanation 篡改/伪造自己的解释</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230907163907919.png"   style="zoom:25%;" /></p>
<p>作者是受到了maieutic method的启发，逐步的确认和消除有矛盾的假设：</p>
<blockquote>
<p>Maieutic method brings out deﬁnitions implicit in the interlocutor’s beliefs, ... is a method of hypothesis elimination, steadily identifying and eliminating those that lead to contradictions (Vlastos, 1991).</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230907164128950.png"   style="zoom:50%;" /></p>
<p>一般的CoT prompting的方法对于某个答案是True/False的问题，通常让LLM先给出解释，再给出答案/预测标签（这称为ad-hoc approach，事前解释）。这种方法生成的explanation是a discriminative explanation that helps in choosing one label over the other。</p>
<p>相反，作者让LLM对True/False给出事后解释。也就是先给定True/False，让LLM给出对应的explanation。这种Abductive generation的方式能够让LLM分别考虑不同的答案的可能性，而不是直接做选择。另外一个好处是，给定的True/False的label information，能够诱导LLM给出更加具体specific的解释。</p>
<p>作者提出的一个重要观点是验证LLM生成的propositions的逻辑完整性/完备性logically integral：</p>
<blockquote>
<p>We formalize this idea as logical integrity: a proposition <span class="math inline">\(Q\)</span> is logically integral when the LM consistently infers the truth value of <span class="math inline">\(Q\)</span> and <span class="math inline">\(\neg Q\)</span> (i.e. <span class="math inline">\(Q\)</span> as True and <span class="math inline">\(\neg Q\)</span> as False, or vice versa)</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230907165024823.png"   style="zoom:40%;" /></p>
<p>也就是说对于某个LLM生成的proposition <span class="math inline">\(Q\)</span>，LLM不能认为<span class="math inline">\(Q\)</span>和<span class="math inline">\(\neg Q\)</span>同时成立。</p>
<p>满足logically integral的解释，作者认为是更加可靠的解释。只有满足logically integral的解释会被保留，然后用于最终的逻辑推理。不满足logically integral的解释，会被继续溯因，迭代的让LLM解释，直至获得logically integral的解释。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230907165419259.png"   style="zoom:50%;" /></p>
<p>对于最后生成的逻辑树，作者评估LLM对于叶子节点解释成立的belief：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230907165857365.png"   style="zoom:50%;" /></p>
<p>以及不同解释之间的关系，作者使用了额外的一个NLI model（RoBERTa fine-tuned on MNLI dataset）去判断任意两个不同explanation之间的关系，权重<span class="math inline">\(w\)</span>固定为1：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230907165944830.png"   style="zoom:50%;" /></p>
<p>最后使用MAX-SAT去最大程度的满足各种带有权重的条件。</p>
<h2 id="pal">PAL</h2>
<p>PAL: Program-aided Language Models</p>
<p>ICML 2023，CMU，<a href="https://github.com/reasoning-machines/pal">代码</a>。</p>
<blockquote>
<p>Large language models (LLMs) have demonstrated an impressive ability to perform arithmetic and symbolic reasoning tasks, when provided with a few examples at test time (“few-shot prompting”). Much of this success can be attributed to prompting methods such as “chainof-thought”, which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem. <strong>While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly.</strong> In this paper, we present ProgramAided Language models (PA L): a novel approach that uses the LLM to read natural language problems and <strong>generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter.</strong> With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. We demonstrate this synergy between a neural LLM and a symbolic interpreter across 13 mathematical, symbolic, and algorithmic reasoning tasks from BIG-Bench Hard and others. In all these natural language reasoning tasks, generating code using an LLM and reasoning using a Python interpreter leads to more accurate results than much larger models. For example, PAL using CODEX achieves state-of-the-art few-shot accuracy on GSM8K, surpassing PaLM-540B which uses chain-of-thought by absolute 15% top-1.</p>
</blockquote>
<p>这篇文章主要是解决虽然LLM能够理解问题，并且把问题的推理过程分别为不同步骤，但是在最后根据推理过程计算答案的时候出现错误的问题。有时候即便是推理过程是正确的，LLM最后的计算答案是错误的。</p>
<p>因此作者提出对问题的理解，以及推理步骤的拆分和规划让LLM完成。计算答案、根据推理过程推导答案由外部工具完成。这样就能够缓解推理链正确，最后对应的推理结果错误的问题。让LLM做自己擅长的部分，不擅长的部分让其它工具完成。</p>
<p>让LLM生成推理答案的时候同时生成编程语言，最后使用外部的工具如python interpreter计算答案：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230907215210863.png"  style="zoom:40%;" /></p>
<h2 id="least-to-most">Least-to-Most</h2>
<p>Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</p>
<p>ICLR 2023, Google research</p>
<blockquote>
<p>Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. <strong>However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts.</strong> To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, <strong>least-to-most prompting</strong>. <strong>The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence.</strong> Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difﬁcult problems than those seen in the prompts. A notable ﬁnding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99% using just 14 exemplars, compared to only 16% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.</p>
</blockquote>
<p>前面的CoT prompting方法会面临的问题是，如果要解决的问题比CoT中样例的问题更难的话，效果就很差：</p>
<blockquote>
<p>However, chain-of-thought prompting has a key limitation—it often performs poorly on tasks that require generalization of solving problems harder than the demonstration examples, such as compositional generalization (Lake &amp; Baroni, 2018; Keysers et al., 2020).</p>
</blockquote>
<p>因此，作者提出了一种从简单到复杂，先把问题分解为几个子问题，然后逐步的解决子问题的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908105201421.png"   style="zoom:40%;" /></p>
<p>第一步是通过给定几个样例，让LLM把问题分解成几个子问题Decomposition；</p>
<p>第二步是逐步的解决子问题，子问题的答案又附加到prompt上，作为解决下一个子问题的上下文。</p>
<ul>
<li><strong>Decomposition.</strong> The prompt in this stage contains constant examples that demonstrate the decomposition, followed by the speciﬁc question to be decomposed.</li>
<li><strong>Subproblem solving.</strong> The prompt in this stage consists of three parts: (1) constant examples demonstrating how subproblems are solved; (2) a potentially empty list of previously answered subquestions and generated solutions, and (3) the question to be answered next.</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Reason</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Reason</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-instruction-tuning</title>
    <url>/collection/LLM-instruction-tuning/</url>
    <content><![CDATA[<h1 id="instruction-tuning相关论文">instruction-tuning相关论文</h1>
<span id="more"></span>
<h2 id="instruction-induction">Instruction-induction</h2>
<p>Instruction Induction: From Few Examples to Natural Language Task Descriptions</p>
<p>Tel Aviv University和Meta，<a href="https://github.com/orhonovich/instruction-induction">代码</a>。首次提出从几个demonstrations使用LLM自动生成task instruction的任务。</p>
<blockquote>
<p>Large language models are able to perform a task by conditioning on a few input-output demonstrations – a paradigm known as in-context learning. We show that language models can explicitly infer an underlying task from a few demonstrations by prompting them to generate a natural language instruction that fits the examples. <strong>To explore this ability, we introduce the instruction induction challenge, compile a dataset consisting of 24 tasks, and define a novel evaluation metric based on executing the generated instruction.</strong> We discover that, to a large extent, the ability to generate instructions does indeed emerge when using a model that is both large enough and aligned to follow instructions; InstructGPT achieves 65.7% of human performance in our execution-based metric, while the original GPT-3 model reaches only 9.8% of human performance. This surprising result suggests that instruction induction might be a viable learning paradigm in and of itself, where instead of fitting a set of latent continuous parameters to the data, one searches for the best description in the natural language hypothesis space.</p>
</blockquote>
<p>之前的工作已经证明通过给定几个demonstrations，LLM能够模拟demonstrations对给定的query text产生类似的输出（即In-context learning）。作者进一步提出让LLM直接描述demonstrations表达的task是什么。</p>
<p>作者提出的进行Instruction Induction的prompt：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603165654412.png" alt="image-20230603165654412" /><figcaption>image-20230603165654412</figcaption>
</figure>
<p>作者创建了一个新的包括24个task的数据集，下面是示例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603170121068.png"  style="zoom:30%;" /></p>
<p>为了评估LLM进行指令归纳的效果，作者提出使用两个指标：</p>
<ul>
<li>BERTScores: 评估LLM生成的指令和人工设计的指令</li>
<li>execution accuracy: 作者新提出的指标，意思是让LLM zero-shot的执行自身生成的task instruction，计算执行的效果。</li>
</ul>
<p>在实验部分，是使用5个demonstrations进行归纳。作者发现InstructGPT才表现出了较好的instruction-induction能力，没有经过instruction-tuning的GPT-3没有表现出这种能力：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603170218546.png"   style="zoom:40%;" /></p>
<h2 id="self-instruct">Self-Instruct</h2>
<p>ACL 2023，华盛顿大学，<a href="https://github.com/%20yizhongw/self-instruct">代码</a>。</p>
<a href="/llm/Self-Instruct/" title="[个人详细博客]">[个人详细博客]</a>
<blockquote>
<p>Large “instruction-tuned” language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce SELF-INSTRUCT, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on SUPER-NATURALINSTRUCTIONS, on par with the performance of InstructGPT 001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT 001 . SELF-INSTRUCT provides an almost annotation-free method for aligning pretrained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.</p>
</blockquote>
<p>人工生成instructions一方面代价很大，另一方面人工生成的instructions难以保证quantity, diversity, and creativity。</p>
<p>作者提出使用LLM从已有的task instruction出发，自动生成新的task instruction和对应的input-output，然后过滤掉不符合规则的新task instructions，再加入到已有的task instructions集合中。作者在这个自动构造的instruction data上fine-tuning GPT3，发现效果提升了33%，非常接近InstructGPT001的效果。</p>
<p>作者提出的方法：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150047353-20230603165425791.png" alt="image-20230603150047353" /><figcaption>image-20230603150047353</figcaption>
</figure>
<p>首先，作者拥有一个task pool，包括175 tasks (1 instruction and 1 instance for each task)。这175个初始的task instructions都是由本文作者自己创建的。</p>
<p>然后，作者从task pool中随机抽取8个task instructions（6 are from the human-written tasks, and 2 are from the model-generated tasks）。下面是产生新task instruction的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150335100-20230603165425854.png" style="zoom: 25%;" /></p>
<p>之后，作者使用LLM判断新产生的instruction是否是一个classification task（using 12 classification instructions and 19 non-classification instructions）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150505630-20230603165425906.png"   style="zoom:25%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150518579-20230603165425957.png" alt="image-20230603150518579" style="zoom:25%;" /></p>
<p>随后，对于新产生的task instruction，用LLM生成新的对应的instance。对于生成任务，作者先生成input，再生成output，作者称为Input-first Approach：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150903068-20230603165426058.png"   style="zoom:25%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150941339-20230603165426247.png"  style="zoom:25%;" /></p>
<p>对于分类任务，作者发现如果是先生成input，LLM总是会倾向于生成某一个label的输入。因此作者使用LLM先生成output label，再让LLM生成input，作者称为Output-first Approach：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151018452-20230603165426327.png"   style="zoom:25%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151030519-20230603165426380.png"   style="zoom:25%;" /></p>
<p>对于LLM生成的task instruction、input和output，需要通过一些规则过滤，比如：</p>
<ul>
<li>只有当和已有的task instruction相似度全部比较低（<span class="math inline">\(\mbox{ROUGE-L}&lt; 0.7\)</span>）的时候，一个新task instruction会被添加到task pool里</li>
<li>We also exclude instructions that contain some specific keywords (e.g., image, picture, graph) that usually can not be processed by LMs.</li>
<li>When generating new instances for each instruction, we filter out instances that are exactly the same or those with the same input but different outputs.</li>
<li>Invalid generations are identified and filtered out based on heuristics (e.g., instruction is too long or too short, instance output is a repetition of the input).</li>
</ul>
<p>作者从原始的175个task出发，最后构造了5万多的task，并且差异性也比较大：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151912820.png"   style="zoom:30%;" /></p>
<p>在SuperNI数据集上的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603152723289.png"   style="zoom:30%;" /></p>
<p>SuperNI数据集大多是已有的NLP任务，为了进一步评估模型在实际使用场景下的价值，作者人工创建了一个包括252 task的新数据集。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>instruction-tuning</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>instruction-tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-data-augment1</title>
    <url>/collection/LLM-data-augment1/</url>
    <content><![CDATA[<h1 id="llm数据增强">LLM数据增强</h1>
<p>基于LLM的数据增强论文合集1。</p>
<span id="more"></span>
<h2 id="gpt3mix">GPT3Mix</h2>
<p>GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation</p>
<p>EMNLP 2021 Findings，NAVER AI lab，<a href="https://github.com/naver-ai/hypermix">代码</a>。</p>
<blockquote>
<p>Large-scale language models such as GPT3 are excellent few-shot learners, allowing them to be controlled via natural text prompts. Recent studies report that prompt-based direct classification eliminates the need for fine-tuning but lacks data and inference scalability. <strong>This paper proposes a novel data augmentation technique that leverages large-scale language models to generate realistic text samples from a mixture of real samples.</strong> We also propose utilizing soft-labels predicted by the language models, effectively distilling knowledge from the large-scale language models and creating textual perturbations simultaneously. We perform data augmentation experiments on diverse classification tasks and show that our method hugely outperforms existing text augmentation methods. We also conduct experiments on our newly proposed benchmark to show that the augmentation effect is not only attributed to memorization. Further ablation studies and a qualitative analysis provide more insights into our approach.</p>
</blockquote>
<p>作者声称是首个用LLM来进行数据增强工作的文章。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922204210110.png"   style="zoom:35%;" /></p>
<p>作者认为的需要用LLM来做数据增强，而不是直接执行特定任务的理由：</p>
<ul>
<li>First, the number of incontext training examples is hard limited by the maximum prompt length enabled by the inherent language model architecture.</li>
<li>Second, prompt-based approaches require online inference on the expensive large-scale language models. The inference may not be scalable in real-world use cases, because it is slow and incurs huge memory overhead.</li>
<li>Lastly, the prompt-based approaches do away with conventional machine learning techniques, making it mostly incompatible with existing established fine-tuning methods.</li>
</ul>
<p>提出的GPT3Mix方法图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922203338068.png" alt="image-20230922203338068" /><figcaption>image-20230922203338068</figcaption>
</figure>
<p>作者构造的生成训练数据的prompt template包括：</p>
<ul>
<li>Text Type：输入的text的类型，比如movie review</li>
<li>Label Type：label class的类型，比如情感分类中是sentiment</li>
<li>Label-token Verbalizer：将label转化为text tokens</li>
</ul>
<p>构造数据的ICL prompt示例（不指定生成数据的label、prompt中一次性提供所有的label信息只适用于label数量较少的情况）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922203610701.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922203625168.png"   style="zoom:40%;" /></p>
<p>生成数据的时候，注意两点：</p>
<ul>
<li>同时生成data和label，并且label在data之后出现，这样保证label是依赖于生成的data的</li>
<li>不是简单的生成label，还使用LLM对label tokens的conditional probability来作为soft-label。带有soft-label的GPT生成的text加入到原来的数据中，获得效果的提升。</li>
</ul>
<p>上下文的demonstrations是从训练集中随机采样，默认使用的样例数量是2。</p>
<p>作者在实验部分针对text classification，主要基于<code>GPT-3(davinci)</code>。还自己构造了一个RT20 binary sentiment classification数据集（关于movie reviews），收集的是GPT3使用的最新data之后出现的新评论。下面是实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922204133079.png"  style="zoom:40%;" /></p>
<h2 id="data-augmentation-for-intent-classification">Data Augmentation for Intent Classification</h2>
<p>Data Augmentation for Intent Classification with Off-the-shelf Large Language Models. ACL 2022 Workshop NLP4ConvAI 2022，<a href="https://github.com/ElementAI/data-augmentation-with-llms">代码</a>。</p>
<blockquote>
<p>Data augmentation is a widely employed technique to alleviate the problem of data scarcity. <strong>In this work, we propose a prompting-based approach to generate labelled training data for intent classification with off-the-shelf language models (LMs) such as GPT-3.</strong> An advantage of this method is that no task-specific LM-fine-tuning for data generation is required; hence the method requires no hyper-parameter tuning and is applicable even when the available training data is very scarce. We evaluate the proposed method in a few-shot setting on four diverse intent classification tasks. We find that GPT-generated data significantly boosts the performance of intent classifiers when intents in consideration are sufficiently distinct from each other. In tasks with semantically close intents, we observe that the generated data is less helpful. Our analysis shows that this is because GPT often generates utterances that belong to a closely-related intent instead of the desired one. <strong>We present preliminary evidence that a prompting-based GPT classifier could be helpful in filtering the generated data to enhance its quality.</strong></p>
</blockquote>
<p>作者认为之前的GPT3Mix工作，由于每次prompt会直接提供所有的label，并且不限制生成数据的label类型，只使用与label数量少的任务。而意图分类Intent Classification（IC）任务可能有上百个不同的intent，并且可能存在非常相近的intent，导致GPT3Mix不适用于意图分类task。</p>
<blockquote>
<p>an intent is a type of request that the conversational agent supports; e.g. the user may want to change the language of the conversation, play a song, transfer money between accounts, etc.</p>
</blockquote>
<p>作者的方法主要有两点：</p>
<ul>
<li><p>每次只生成一类label的数据（但同样是随机找的demonstrations）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922224921205.png"   style="zoom:30%;" /></p></li>
<li><p>提出可以用LLM分类的能力，过滤掉text和label不对应的生成数据</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922225011759.png"   style="zoom:30%;" /></p></li>
</ul>
<p>作者实验基于<code>GPT-3</code>。发现GPT3无法准确的理解相似label，导致生成数据质量差，然后作者尝试了简单的使用GPT-3再来重新分类生成句子的方法。</p>
<blockquote>
<p>We hypothesize that one limiting factor can be GPT-3’s inability to understand ﬁne-grained differences in the meanings of utterances.</p>
</blockquote>
<h2 id="inpars">InPars</h2>
<p>InPars: Unsupervised Dataset Generation for Information Retrieval. SIGIR 2022 Short paper，<a href="https://github.com/zetaalphavector/inpars">代码</a>。</p>
<blockquote>
<p>The Information Retrieval (IR) community has recently witnessed a revolution due to large pretrained transformer models. Another key ingredient for this revolution was the MS MARCO dataset, whose scale and diversity has enabled zero-shot transfer learning to various tasks. However, not all IR tasks and domains can benefit from one single dataset equally. Extensive research in various NLP tasks has shown that using domain-specific training data, as opposed to a general-purpose one, improves the performance of neural models [45, 56]. <strong>In this work, we harness the few-shot capabilities of large pretrained language models as synthetic data generators for IR tasks.</strong> We show that models fine-tuned solely on our synthetic datasets outperform strong baselines such as BM25 as well as recently proposed self-supervised dense retrieval methods. Code, models, and data are available at https://github.com/zetaalphavector/inpars.</p>
</blockquote>
<p>大模型可以直接用来判断query和document之间的相关性，但是由于候选document的数量过多，在实践中，要用LLM来进行检索还是不实际的。</p>
<p>传统的dense retriever通过提前计算document的embedding，利用现有的搜索框架，可以高效的寻找相关documents。但是训练dense retriever需要足够的domain-specific training data。</p>
<p>因此，作者提出使用LLM来生成IR任务的数据 <span class="math inline">\((query, document)\)</span> pairs：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230922235622982.png"   style="zoom:30%;" /></p>
<p>步骤：</p>
<ul>
<li><p>通过corpus-level ICL，人工构造3个样例，实现利用LLM为document生成对应的问题</p></li>
<li><p>从语料库中采样<span class="math inline">\(100,000\)</span>个documents，让LLM针对documents生成一个初步相关question，生成question用了两个模板：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923000908755.png"   style="zoom:30%;" /></p>
<p>第一个模板是原始的训练集中document和对应的question，第二个模板是作者提出的Guided by Bad Questions（GBQ）模板，将原来的question作为bad question，然后人工写一个更加复杂的question作为good question，让LLM生成good question。</p></li>
<li><p>利用LLM的conditional probability估计document-question之间的相关性：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923001145634.png"   style="zoom:50%;" /></p>
<p>依据相关性排序，从<span class="math inline">\(100,000\)</span>个document-question pairs中，选择<span class="math inline">\(1,000\)</span>个topK的数据作为训练数据。</p></li>
</ul>
<p>实验基于<code>GPT-3</code>，从实验结果中发现，在无监督的IR方法上效果不错，但是距离有监督的IR方法还有差距：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923001337490.png"   style="zoom:40%;" /></p>
<h2 id="auggpt">AugGPT</h2>
<p>AugGPT: Leveraging ChatGPT for Text Data Augmentation</p>
<p>arXiv 2023-03</p>
<blockquote>
<p>Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality. <strong>A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size.</strong> However, current text data augmentation methods either can’t ensure the correct labeling of the generated data (lacking faithfulness) or can’t ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, <strong>we propose a text data augmentation approach based on ChatGPT (named AugGPT).</strong> AugGPT rephrases each sentence in the training samples into multiple conceptually similar but semantically different samples. The augmented samples can then be used in downstream model training. Experiment results on few-shot learning text classification tasks show the superior performance of the proposed AugGPT approach over state-of-the-art text data augmentation methods in terms of testing accuracy and distribution of the augmented samples.</p>
</blockquote>
<p>基于改写方法的利用LLM生成text classification task的训练数据。作者认为LLM适合用来做数据增强的两点理由：</p>
<ul>
<li>LLM通过预训练，在大规模语料中进行预训练，在自己的参数空间中学习编码到了很多隐式的factual knowledge</li>
<li>LLM经过RLHF等训练阶段，能够produce more informative and impartial responses to input</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923151338440.png"   style="zoom:40%;" /></p>
<p>作者的实验是用clinical NLP tasks来进行评估，因为Data augmentation is particularly in demand in clinical NLP, because the significant burden of expert annotation and stringent privacy regulations make large-scale data labeling infeasible.</p>
<p>改写用的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923151506045.png"   style="zoom:40%;" /></p>
<p>值得一提的是，作者在实验部分用生成句子和原来句子的embedding cosine相似度评估语义的一致性；然后用TransRate指标来评估生成的数据是否足够compactness，以至于能够方便对不同的类进行区分：</p>
<blockquote>
<p>TransRate is a metric that quantifies transferability based on the mutual information between the features extracted by a pre-trained model and their labels, with a single pass through the target data. A higher TransRate could indicate better learnability of the data.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923151847434.png"   style="zoom:50%;" /></p>
<h2 id="disco">DISCO</h2>
<p>DISCO: Distilling Counterfactuals with Large Language Models. ACL 2023，EPFL，<a href="https://github.com/eric11eca/disco">代码</a>。</p>
<blockquote>
<p>Models trained with counterfactually augmented data learn representations of the causal structure of tasks, enabling robust generalization. However, <strong>high-quality counterfactual data is scarce for most tasks and not easily generated at scale.</strong> When crowdsourced, such data is typically limited in scale and diversity; when generated using supervised methods, it is computationally expensive to extend to new counterfactual dimensions. In this work, <strong>we introduce DISCO (DIStilled COunterfactual Data), a new method for automatically generating high-quality counterfactual data at scale.</strong> DISCO engineers prompts to generate phrasal perturbations with a large general language model. Then, a task-specific teacher model filters these generations to distill high-quality counterfactual data. While task-agnostic, we apply our pipeline to the task of natural language inference (NLI) and find that on challenging evaluations such as the NLI stress test, comparatively smaller student models trained with DISCO generated counterfactuals are more robust (6% absolute) and generalize better across distributions (2%) compared to models trained without data augmentation. Furthermore, DISCO-augmented models are 10% more consistent between counterfactual pairs on three evaluation sets, demonstrating that DISCO augmentation enables models to more reliably learn causal representations. Our repository are available at: https://github.com/eric11eca/disco</p>
</blockquote>
<p>首个利用LLM生成counterfactual data的工作。</p>
<p>Counterfactual data augmentation (CAD) [<em>Learning the difference that makes a difference with counterfactually-augmented data. 2019</em>]是一种移除spurious correlation，提升模型robustness的数据增强技术。它修改原来数据中的重要组成部分，让原始的label改变：</p>
<blockquote>
<p>Counterfactual data augmentation (CAD) (Kaushik et al., 2019) is one general approach to improve model robustness by training on edited instances that systematically alter the critical or causally salient parts of dataset instances that contributes to the label assignment.</p>
</blockquote>
<p>一个不够鲁棒的model，对于反事实，可能由于在训练过程学习到了伪相关的特征，从而导致反事实的data还是预测的原来的label。</p>
<p>作者针对NLI任务进行实验，NLI任务的输入是premise-hypothesis pair <span class="math inline">\(&lt;P,H&gt;\)</span>，标签<span class="math inline">\(l\in \{ Entailment, Contradiction, Neutral \}\)</span>。作者的反事实数据增强方法就是修改前提premise的部分描述，新的前提<span class="math inline">\(P^{\prime}\)</span>能够让label变更为新<span class="math inline">\(l^{\prime}\)</span>。</p>
<p>作者提出方法的大致流程：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923225708595.png"   style="zoom:35%;" /></p>
<ul>
<li><p>首先，作者只选择了部分训练集中的数据进行训练，利用<em>dataset cartography</em>技术[<em>Dataset cartography: Mapping and diagnosing datasets with training dynamics. 2020</em>]，选择ambiguous和hard samples作为之后进行增强的对象；</p></li>
<li><p>然后，作者利用之前的一个neural syntactic parser[<em>FLAIR: An easy-to-use framework for state-of-the-art NLP. NAACL 2019</em>]将前提premise句子转化为span的集合；</p></li>
<li><p>由于不知道修改哪个span能够导致label的改变，迭代地用<code>[blank]</code>去替换每个span，然后让LLM填补<code>[blank]</code>以至于对应的label变为新的label。作者提出了两种prompt，一种是让LLM补全<code>[blank]</code>，是最常见的GPT的completing mode；一种是利用GPT3的<em>insert mode</em>，让GPT直接回复中间确实内容：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230923230609837.png"   style="zoom:40%;" /></p></li>
<li><p>最后，过滤质量比较低的data；首先是用一系列预定义规则进行过滤heuristic-based automatic filter，如是不是和原来的数据有较多的重叠、是不是使用了negation words作为捷径以反转label。然后用一个现有的SOTA NLI模型，给定原始数据和新数据，确定预测的label分布是否发生了大的变化。</p></li>
</ul>
<p>作者实验基于<code>GPT-3(DaVinci-002)</code>，微调<code>RoBERTa-large</code>进行NLI任务。</p>
<p>实验部分内容较多，具体参考论文。有2个衡量多样性的metric可以注意下：</p>
<ul>
<li>Self-BLEU [<em>Texygen: A benchmarking platform for text generation models. 2018</em>]：评估lexical and syntactic diversity</li>
<li>Dataset Distance：计算新data和旧data的信息多样性，使用OTDD (optimal transport dataset distance) [<em>Geometric dataset distances via optimal transport. 2020</em>]作为指标</li>
</ul>
<h2 id="genread">GenRead</h2>
<p>Generate rather than Retrieve: Large Language Models are Strong Context Generators</p>
<a href="/llm/GenRead/" title="[详细博客]">[详细博客]</a>
<p>。</p>
<p>University of Notre Dame和Microsoft，ICLR 2023，<a href="https://github.com/wyu97/GenRead">代码</a>。</p>
<blockquote>
<p>Knowledge-intensive tasks, such as open-domain question answering (QA), require access to a large amount of world or domain knowledge. A common approach for knowledge-intensive tasks is to employ a retrieve-then-read pipeline that first retrieves a handful of relevant contextual documents from an external corpus such as Wikipedia and then predicts an answer conditioned on the retrieved documents. <strong>In this paper, we present a novel perspective for solving knowledge-intensive tasks by replacing document retrievers with large language model generators.</strong> We call our method generate-then-read (GenRead), which first prompts a large language model to generate contextual documents based on a given question, and then reads the generated documents to produce the final answer. Furthermore, <strong>we propose a novel clustering-based prompting method that selects distinct prompts, in order to generate diverse documents that cover different perspectives, leading to better recall over acceptable answers.</strong> We conduct extensive experiments on three different knowledge-intensive tasks, including open-domain QA, fact checking, and dialogue system. Notably, GenRead achieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantly outperforming the state-of-the-art retrieve-thenread pipeline DPR-FiD by +4.0 and +3.9, without retrieving any documents from any external knowledge source. Lastly, we demonstrate the model performance can be further improved by combining retrieval and generation. Our code and generated documents can be found at https://github.com/wyu97/GenRead.</p>
</blockquote>
<p>作者提出了使用LLM生成的question的documents，作为question的background来回答问题，<em>generate-then-read</em>。</p>
<p>knowledge-intensive tasks如开放域QA任务等，常常需要大量的word knowledge / domain knowledge。之前的常常通过检索外部知识源Wikipedia等来获得relevant contextual documents。</p>
<p><em>retrieve-then-read</em>来解决knowledge-intensive tasks存在的问题：</p>
<ul>
<li>First, candidate documents for retrieval are chunked (e.g., 100 words) and fixed, so the retrieved documents might contain noisy information that is irrelevant to the question.</li>
<li>Second, the representations of questions and documents are typically obtained independently in modern two-tower dense retrieval models (Karpukhin et al., 2020), leading to only shallow interactions captured between them (Khattab et al., 2021).</li>
<li>Third, document retrieval over a large corpus requires the retriever model to first encode all candidate documents and store representations for each document.</li>
</ul>
<p>而作者认为，LLM生成的document比传统的检索结果更加和query question更加相关，原因是：LLM的生成结果是通过基于question的token，然后经过attention等机制生成的，而一般的检索只是利用question和document的embedding相似度去检索的。显然LLM的生成结果会和question更加相关。</p>
<blockquote>
<p>We believe this is because large language models generate contextual documents by performing deep token-level cross-attention between all the question and document contents, resulting in generated documents that are more specific to the question than retrieved documents.</p>
</blockquote>
<p>在检索方法中，检索的答案越多，能够提供更多的不同角度/方面的knowledge，从而增加最后回答答案的准确率。</p>
<p>但是如果是相同的prompt，LLM会倾向不断输出重复的内容。因此作者提出从不同的聚类中选择上下文样例，从而产生更多样的输出documents。</p>
<p>作者提出clustering-based prompt方法，提取不同的上下文样例，构造不同的prompt，生成的多个结果文档，一起再来辅助回答问题。核心包括3步：</p>
<ol type="1">
<li>初始化：先用LLM给训练集中的每个question生成一个document。也可以使用检索的方法，为每个question从外部知识源中检索一个相关document；</li>
<li>编码document，基于K-means无监督聚类：作者使用GPT-3这类LLM为每个question-document进行编码，然后进行K-means聚类。聚类的数量K，和要生成的documents数量一致</li>
<li>采样并且生成K个documents：对每一个聚类，采样n个样例作为上下文，然后生成query question的一个document，最终生成的K个documents。这些documents作为background，和query question组合成一个prompt，获得最终的答案。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230915160124104.png"   style="zoom:50%;" /></p>
<h2 id="increasing-diversity-and-accuracy">Increasing diversity and accuracy</h2>
<p>Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions. 密歇根大学与Microsoft. ACL 2023. <a href="/llm/Increasing-Diver-Acc-Data-Gen-LLM/" title="[详细博客]">[详细博客]</a>。</p>
<blockquote>
<p>Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging. <strong>In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation.</strong> We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user’s domain of interest or to which no considered label applies. With oracle studies, we found that LR increases the absolute accuracy of models trained with diversified datasets by 14.4%. Moreover, we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification. In contrast, OOSF was not effective in increasing model accuracy, implying the need for future work in human-in-the-loop text data generation.</p>
</blockquote>
<p>作者讨论了2种在解码阶段增加多样性的方法：</p>
<ul>
<li><p>Logit Suppression：decreases the probability of high-frequency tokens。之前生成的tokens，根据频率，降低它在下一次采样中的概率。这里叫做logit的原因应该是，作者通过调用OpenAI的logit bias API来实现这一点。</p></li>
<li><p>High Temperature：增大temperature <span class="math inline">\(T\)</span>，更大的temperature意味着最终的概率分布更加平滑flat：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914230956172.png"   style="zoom:40%;" /></p></li>
</ul>
<p>示意图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914231021977.png"   style="zoom:50%;" /></p>
<p>作者调用GPT生成数据的时候，考虑的是短文本分类任务，构造的prompt主要考虑text type和label：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914231203885.png"   style="zoom:40%;" /></p>
<h2 id="vote-k">Vote-k</h2>
<p>Selective Annotation Makes Language Models Better Few-Shot Learners.</p>
<p>香港大学，ICLR 2023，<a href="https://github.com/HKUNLP/icl-selective-annotation">代码</a>。</p>
<blockquote>
<p>Many recent approaches to natural language tasks are built on the remarkable abilities of large language models. Large language models can perform in-context learning, where they learn a new task from a few task demonstrations, without any parameter updates. This work examines the implications of in-context learning for the creation of datasets for new natural language tasks. Departing from recent in-context learning methods, we formulate an annotation-efficient, two-step framework: selective annotation that chooses a pool of examples to annotate from unlabeled data in advance, followed by prompt retrieval that retrieves task examples from the annotated pool at test time. Based on this framework, <strong>we propose an unsupervised, graph-based selective annotation method, vote-k, to select diverse, representative examples to annotate.</strong> Extensive experiments on 10 datasets (covering classification, commonsense reasoning, dialogue, and text/code generation) demonstrate that our selective annotation method improves the task performance by a large margin. On average, vote-k achieves a 12.9%/11.4% relative gain under an annotation budget of 18/100, as compared to randomly selecting examples to annotate. Compared to state-of-the-art supervised finetuning approaches, it yields similar performance with 10-100× less annotation cost across 10 tasks. We further analyze the effectiveness of our framework in various scenarios: language models with varying sizes, alternative selective annotation methods, and cases where there is a test data domain shift. We hope that our studies will serve as a basis for data annotations as large language models are increasingly applied to new tasks.</p>
</blockquote>
<p>利用LLM的ICL能力，为每个instance寻找相似的demonstrations能够极大的提升性能。但是这潜在的要求存在一个规模较大的标注数据能够提供上下文，之前很少有工作讨论LLM的ICL需要的demonstrations的标注代价。</p>
<p>作者提出，不需要为很多的data进行标注而作为候选demonstrations，可以选择<em>representativeness</em>和<em>diversity</em>的少量无标注data进行标注：</p>
<ul>
<li>representativeness will help many test instances to find similar demonstrations</li>
<li>diversity increases the total coverage</li>
</ul>
<p>作者提出的方法vote-k来选择合适的无标注数据进行标注：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230924223545290.png"   style="zoom:50%;" /></p>
<p>步骤：</p>
<ul>
<li><p>首先，通过Sentence-BERT将所有的无标注data编码为embedding，然后计算一个data point和其它data point的余弦相似度，选择<span class="math inline">\(k\)</span>个最相似的data points（实验中发现<span class="math inline">\(k=150\)</span>通常比较合适），创造一条有向边，构造出一个graph <span class="math inline">\(G=(V,E)\)</span>；</p></li>
<li><p>然后，有两个集合<span class="math inline">\(\mathcal{L}\)</span>代表需要被标注的data，<span class="math inline">\(\mathcal{U}\)</span>代表剩下的无标注data。初始<span class="math inline">\(\mathcal{L}=\empty\)</span>，然后迭代的从<span class="math inline">\(\mathcal{U}\)</span>中选择degree score最大的一个data point <span class="math inline">\(u\)</span>加入到<span class="math inline">\(\mathcal{L}\)</span>中：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230924224045081.png"   style="zoom:50%;" /></p>
<p>上面的公式通过超参<span class="math inline">\(\rho\)</span>降低了和已经被标注的data相似的无标注data的权重（实验中发现<span class="math inline">\(\rho=10\)</span>通常比较合适），从而鼓励多样性；选最大的score鼓励代表性。迭代一直进行<span class="math inline">\(M/10\)</span>次；</p></li>
<li><p>为了进一步增加多样性，以标注好的<span class="math inline">\(M/10\)</span>个data作为上下文样例，使用LLM为剩余的无标注数据进行预测，并且按照预测probability排序的划分为<span class="math inline">\(M\)</span>个buckets，选择前<span class="math inline">\(9M/10\)</span>个buckets的结果加入到<span class="math inline">\(\mathcal{L}\)</span>中，不选择那些可以被最confident预测出来的无标注数据，最终<span class="math inline">\(|\mathcal{L}|=M\)</span>；</p></li>
</ul>
<p>在实验中，对于这些选择出来的有标注数据，还是使用基于相似度的kNN方法作为demonstrations，提升LLM的ICL能力。</p>
<h2 id="distilling-step-by-step">Distilling Step-by-Step</h2>
<p>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes</p>
<p>华盛顿大学与Google，ACL 2023 Findings，<a href="https://github.com/google-research/distilling-step-by-step">代码</a>。</p>
<blockquote>
<p>Deploying large language models (LLMs) is challenging because they are memory inefficient and compute-intensive for practical applications. In reaction, researchers train smaller task-specific models by either fine-tuning with human labels or distilling using LLM-generated labels. However, finetuning and distillation require large amounts of training data to achieve comparable performance to LLMs. We introduce Distilling step-by-step, a new mechanism that (a) trains smaller models that outperform LLMs, and (b) achieves so by leveraging less training data needed by finetuning or distillation. <strong>Our method extracts LLM rationales as additional supervision for training small models within a multi-task framework.</strong> We present three findings across 4 NLP benchmarks: First, compared to both finetuning and distillation, our mechanism achieves better performance with much fewer labeled/unlabeled training examples. Second, compared to few-shot prompted LLMs, we achieve better performance using substantially smaller model sizes. Third, we reduce both the model size and the amount of data required to outperform LLMs; our finetuned 770M T5 model outperforms the few-shot prompted 540B PaLM model using only 80% of available data on a benchmark, whereas standard finetuning the same T5 model struggles to match even by using 100% of the dataset.</p>
</blockquote>
<p>作者从540B的PaLM中导出rationales，然后让小模型T5学会输出对应的rationales。</p>
<p>部署大模型需要很高的代价：</p>
<blockquote>
<p>Serving a single 175 billion LLM requires at least 350GB GPU memory using specialized infrastructure (Zheng et al., 2022). To make matters worse, today’s state-of-the-art LLMs are composed of over 500B parameters (Chowdhery et al., 2022), requiring significantly more memory and compute.</p>
</blockquote>
<p>为了避免这一点，有两种做法，一种是传统的在下游task的现有数据集上进行训练，这要求有人工标注；另一种是用LLM为无标注的data进行标注，蒸馏到小模型上，这种做法需要的大规模无标注数据可能是比较难的requires large amounts of unlabeled data which can be hard to obtain (Tang et al., 2019; Liang et al., 2020).</p>
<p>作者提出的Distilling Step-by-Step方法是通过导出LLM的推理rationales，减少小模型训练所需要的训练数据量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925110839590.png"   style="zoom:30%;" /></p>
<p>rationales提供了更多的为什么input能够被输出为output的信息，并且是通常很难仅仅从input上找到的：</p>
<blockquote>
<p>Intuitively, rationales provide richer, more detailed information about why an input is mapped to a specific output label, and often contain relevant task knowledge that may be hard to infer solely from the original inputs.</p>
</blockquote>
<p>rationale可以用来做什么？这一点已经有比较多的研究工作： 1. rationale可以用来规范model behavior；human rationales can be used to regularize model behavior (Ross et al., 2017) 2. rationale可以用来作为输入的一部分，提高预测性能；it can be used as additional inputs to guide a model’s predictions (Rajani et al., 2019); it can be used to improve overall model performance (Zaidan et al., 2007; Zhang et al., 2016; Camburu et al., 2018;Hancock et al., 2019; Pruthi et al., 2022); 3. rationale可以直接作为目标输出的一部分，提升模型预测的可解释性；human rationales can be used as gold standard labels to make models more interpretable by generating similar rationales (Wiegreffe et al., 2021; Narang et al., 2020; Eisenstein et al., 2022).</p>
<p>作者的方法很简单，第一步就是用人工写的CoT prompting模板从LLM中导出rationales；第二步是将rationales作为预测objective，用多任务学习机制加入一个额外的loss，让小模型学会输出rationales：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925110326813.png"   style="zoom:50%;" /></p>
<p>导出rationales的prompt如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925110457736.png"   style="zoom:40%;" /></p>
<p>将rationales看做是一种多任务，而不是和原来的label拼接在一起进行输出是必要的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925110711281.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925110741082.png"   style="zoom:50%;" /></p>
<p>作者在实验中发现，如果是用单任务的方法让模型同时输出label和rationales，有时候会反而减低性能，这一点在前人的工作中也有发现相似的规律。</p>
<h2 id="lm-cppf">LM-CPPF</h2>
<p>LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive Prompt-Based Few-Shot Fine-Tuning</p>
<p>德兰黑大学与Google，ACL 2023 Short Paper，<a href="https://github.com/AmirAbaskohi/LM-CPPF">代码</a>。</p>
<blockquote>
<p>In recent years, there has been significant progress in developing pre-trained language models for NLP. However, these models often struggle when fine-tuned on small datasets. To address this issue, researchers have proposed various adaptation approaches. Promptbased tuning is arguably the most common way, especially for larger models. Previous research shows that adding contrastive learning to prompt-based fine-tuning is effective as it helps the model generate embeddings that are more distinguishable between classes, and it can also be more sample-efficient as the model learns from positive and negative examples simultaneously. One of the most important components of contrastive learning is data augmentation, but unlike computer vision, effective data augmentation for NLP is still challenging. <strong>This paper proposes LM-CPPF, Contrastive Paraphrasing-guided Prompt-based Fine-tuning of Language Models, which leverages promptbased few-shot paraphrasing using generative language models</strong>, especially large language models such as GPT-3 and OPT-175B, for data augmentation. Our experiments on multiple text classification benchmarks show that this augmentation method outperforms other methods, such as easy data augmentation, back translation, and multiple templates.</p>
</blockquote>
<p>作者用LLM改写原有的句子，利用有监督对比学习拉近改写前和改写后的小模型的特征距离。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925214427179.png"   style="zoom:50%;" /></p>
<ul>
<li>第一步是对于要改写的target sentence，mask掉label，然后随机采样几个样例作为demonstrations拼接为一个text。作者微调的小模型是Roberta-base，用其计算被mask的label的loss，Masked Language Modeling (MLM) loss；</li>
<li>第二步是利用GPT-3或者OPT改写target sentence，作者尝试了几种不同的方法，发现了下面最合适的instruction：<code>Generate a paraphrase of the following text using different words and sentence structures while still conveying the same meaning</code>和demonstration format：<code>&lt;Original Text&gt;, in other words &lt;Paraphrased&gt;</code>。改写后的句子在图中对应的是Sent_3。改写的句子同样随机采样几个demonstrations，作为增强数据；</li>
<li>第三步是增强的数据同样输入到Roberta-base中，利用Supervised Contrastive Learning loss [<em>Supervised Contrastive Learning. NeurIPS 2020</em>]去优化；</li>
</ul>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925215531981.png"   style="zoom:50%;" /></p>
<h2 id="cotam">CoTAM</h2>
<p>Generating Efficient Training Data via LLM-based Attribute Manipulation</p>
<p>University of California，arXiv 2023-07，<a href="github.com/KomeijiForce/CoTAM">代码</a>。</p>
<blockquote>
<p>In this paper, we propose a novel method, Chain-of-Thoughts Attribute Manipulation (CoTAM), to guide few-shot learning by carefully crafted data from Large Language Models (LLMs). The main idea is to create data with changes only in the attribute targeted by the task. Inspired by facial attribute manipulation, <strong>our approach generates label-switched data by leveraging LLMs to manipulate task-specific attributes and reconstruct new sentences in a controlled manner.</strong> Instead of conventional latent representation controlling, we implement chainof-thoughts decomposition and reconstruction to adapt the procedure to LLMs. Extensive results on text classification and other tasks verify the advantage of CoTAM over other LLMbased text generation methods with the same number of training examples. Analysis visualizes the attribute manipulation effectiveness of CoTAM and presents the potential of LLMguided learning with even less supervision.</p>
</blockquote>
<p>作者从LLM部署所需要的巨大资源出发，考虑用数据增强训练一个更好的小模型。作者认为之前的LLM数据增强方法没有考虑可控的文本生成，可能影响了生成数据的信息有效性以及可能包含spurious correlation，variance比较大，让小模型比较难去学习</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925233300574.png"   style="zoom:30%;" /></p>
<p>作者收到了attribute manipulation in computer vision (Shen et al., 2020; Shen and Zhou, 2021)方法的启发，这些方法通过修改latent space中的embedding，重新生成新的image。作者提出，使用LLM可以为text生成不同的attributes，通过修改attributes，让生成的text的label发生改变：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925233503184.png"   style="zoom:50%;" /></p>
<p>主要就是利用LLM进行3步prompt：</p>
<p>第一步是让label作为一个attribute，然后让LLM提出更多的其它attributes：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925233545637.png"  style="zoom:50%;" /></p>
<p>第二步是只改变label attribute，让LLM提出能够包括这些attributes句子的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925233603612.png" style="zoom:50%;" /></p>
<p>第三步是让LLM根据上面的方法，写一个新句子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925233627575.png"   style="zoom:50%;" /></p>
<p>作者生成句子的实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230925233913007.png"   style="zoom:50%;" /></p>
<h2 id="pvi">PVI</h2>
<p>Selective In-Context Data Augmentation for Intent Detection using Pointwise V-Information</p>
<p>EACL 2023，台湾大学与Amazon</p>
<blockquote>
<p>This work focuses on in-context data augmentation for intent detection. Having found that augmentation via in-context prompting of large pretrained language models (PLMs) alone does not improve performance, <strong>we introduce a novel approach based on PLMs and pointwise Vinformation (PVI), a metric that can measure the usefulness of a datapoint for training a model.</strong> Our method first fine-tunes a PLM on a small seed of training data and then synthesizes new datapoints – utterances that correspond to given intents. It then employs intent-aware filtering, based on PVI, to remove datapoints that are not helpful to the downstream intent classifier. Our method is thus able to leverage the expressive power of large language models to produce diverse training data. Empirical results demonstrate that our method can produce synthetic training data that achieve state-of-the-art performance on three challenging intent detection datasets under few-shot settings (1.28% absolute improvement in 5-shot and 1.18% absolute in 10-shot, on average) and perform on par with the state-of-the-art in full-shot settings (within 0.01% absolute, on average).</p>
</blockquote>
<p>作者利用ICL基于OPT-66B生成intent classification task的更多数据：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926205005892.png" style="zoom:35%;" /></p>
<p>然后，为了选择什么样的生成数据适合用来训练小模型，作者提出了一种选择模型生成data的方法，利用Pointwise V-Information (PVI) [<em>Understanding dataset difficulty with V-usable information. ICML 2022</em>]：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926205115177.png" style="zoom:50%;" /></p>
<p>也就是有没有用data <span class="math inline">\(x\)</span>微调前后，预测分布class <span class="math inline">\(y\)</span>的概率的变化。如果PVI score越大，代表当前这一data对于class <span class="math inline">\(y\)</span>的信息越多，越应该被挑选出来。</p>
<p>作者为每个intent class在validation set下测试出来PVI的平均值，作为PVI threshold，大于阈值的生成数据才会被使用。</p>
<p>作者在附录中，还尝试了使用data cartography技术[<em>Dataset cartography: Mapping and diagnosing datasets with training dynamics. EMNLP 2020</em>]和classification uncertainty相关metric去选择生成的数据，但是发现还是直接应用全部的生成数据效果最好：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926210132984.png" style="zoom:30%;" /></p>
<h2 id="synthetic-data-subjectivity">Synthetic data: subjectivity</h2>
<p>Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations</p>
<p>Purdue University, 作者评论接收至EMNLP 2023。<a href="/llm/synthetic-data-llm-sub/" title="[详细博客]">[详细博客]</a>。</p>
<blockquote>
<p>The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment. Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, <strong>the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks.</strong> To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the subjectivity of classification. Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data. We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM for synthetic data generation.</p>
</blockquote>
<p><strong>Issue</strong>: 目前在不同的task里，对于使用LLM生成的data是否能够和真实人工标注的data相比，没有定论。</p>
<p><strong>Solution</strong>: 作者认为出现这种现象的原因之一和具体text classification任务的主观程度subjectivity有关，实验发现主观性越强的分类任务，LLM生成数据的效果也会越差。</p>
<p>作者采用了zero-shot和few-shot ICL两种设置。</p>
<p>对于zero-shot ICL prompt：</p>
<ul>
<li>“context prompt” relevant to the targeted domain of interest is used to set the context. 与具体task context相关的prompt</li>
<li>the “data generation prompt”, is provided to the LLM, instructing the model to generate texts with a specific style, label (with respect to the classification task of interest), and word limit. 提供具体的label、生成字数限制等要求的prompt</li>
<li>a “diversity prompt” to the LLM—“Can you provide something more diverse compared to the previously generated data?”—aiming to increase the diversity of the synthetic data generated. 生成具体的几个text data后，提示LLM生成更多不同的text data</li>
</ul>
<p>对于few-shot ICL prompt：</p>
<ul>
<li>“context prompt”与前面zero-shot ICL一样</li>
<li>随机采样的几个demonstrations，其中说明了对应的label</li>
<li>还强制限制了不允许仅仅是修改原来的句子，而是期望生成更多的具体data，比如<code>You should imitate the example I have provided, but you cannot simply modify or rewrite the example I have given</code></li>
</ul>
<p>下面是不同task用到的具体prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021233456402.png"  style="zoom:50%;" /></p>
<p>分别独立的在真实数据、生成数据上进行训练的实验结果（对于关系分类任务，只讨论了FewRel 2.0数据集中‘country’, ‘league’, ‘screenwriter’, and ‘tributary’的4种relation。每种relation生成3000条数据）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021230350077.png"  style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>直接使用真实数据训练的效果最好</li>
<li>few-shot ICL生成数据效果比zero-shot ICL效果好</li>
<li>LLM在生成带有更多人类主观性的数据上，效果更差</li>
</ul>
<p>为什么任务的主观程度会增大LLM生成数据的效果？作者提供了两个解释：</p>
<ol type="1">
<li>highly subjective tasks often require a deep understanding of nuanced human emotions and contextual subtleties, as well as the ability to discern and accurately interpret different perspectives. 越主观，越要求对于人类情感等有非常微妙的理解</li>
<li>it may be challenging for LLMs to generate synthetic data to recover such potentially biased “majority view,” especially if the LLMs are trained to maintain neutrality. 大多数的任务实例是利用众包标注的，也就是说在数据集里的gold label可能只反映了多个人的主要投票意见。对于LLM来说，要生成反映这种majority view的句子可能比较难。</li>
</ol>
<p>使用一小部分真实数据进行训练，然后拿这一小部分真实数据作为demonstrations进行数据增强的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021230653949.png" style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>在关系抽取任务上，作者的这种比较简单的生成数据的方法，没有明显提升效果</li>
</ul>
<h2 id="attprompt">AttPrompt</h2>
<p>Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias. NeurIPS 2023. Georgia Tech. <a href="https://github.com/yueyu1030/AttrPrompt">代码</a>.</p>
<blockquote>
<p>Large language models (LLMs) have been recently leveraged as training data generators for various natural language processing (NLP) tasks. While previous research has explored different approaches to training models using generated data, <strong>they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM.</strong> Thus, <strong>we investigate training data generation with diversely attributed prompts (e.g., specifying attributes like length and style), which have the potential to yield diverse and attributed generated data.</strong> Our investigation focuses on datasets with high cardinality and diverse domains, wherein we demonstrate that attributed prompts outperform simple class-conditional prompts in terms of the resulting model’s performance. Additionally, we present a comprehensive empirical study on data generation encompassing vital aspects like bias, diversity, and efficiency, and highlight three key observations: firstly, synthetic datasets generated by simple prompts exhibit significant biases, such as regional bias; secondly, attribute diversity plays a pivotal role in enhancing model performance; lastly, attributed prompts achieve the performance of simple class-conditional prompts while utilizing only 5% of the querying cost of ChatGPT associated with the latter. We release the generated dataset and used prompts to facilitate future research 2 .</p>
</blockquote>
<p><strong>Issue</strong>: LLM已经在一些工作上被用于生成task-specific的data，但是他们主要是利用simple class-conditional prompt去query LLM来生成新的训练数据，不能保证<strong>diversity of the generated data</strong> [7, 47, 56] and <strong>inheriting systematic biases inherent in LLMs</strong> [60, 21]. 比如，作者在利用之前简单的class-conditional prompt对NYT数据集新闻领域的数据进行生成的时候，在生成数据里，对于<em>location</em>这个属性，68.01%都是<code>North America</code>。相反的，描述了<code>Africa</code>的只有0.69%。</p>
<p><strong>Solution</strong>: 作者主要通过<em>data attributes</em>来缓解LLM生成训练中存在的bias和diversity问题。</p>
<p>下面是作者提出的用于生成具有不同属性的passage的prompt，和之前简单的class-conditional prompt的对比：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025171829991.png"  style="zoom:50%;" /></p>
<p>作者提出的利用ChatGPT半自动构造数据集方式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025200222914.png"  style="zoom:40%;" /></p>
<p>首先，利用ChatGPT询问在生成不同类型text data的时候，不同的属性可能是什么？下面以生成NYT news数据为例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025200620705.png"  style="zoom:50%;" /></p>
<p>然后，人工的选择部分合适data attributes，human-ai collaboration scheme [26, 50, 57]：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025200655334.png"  style="zoom:30%;" /></p>
<p>其值attribute values也可以由GPT提供，比如下面询问attribute <em>subtopic</em>的values：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202054620.png"  style="zoom:50%;" /></p>
<p>对于每种data attributes，可以分为class-independent attributes和class-dependent attributes。class-independent比如<em>length</em>，和具体class无关；class-dependent属性比如<em>subtopic</em>，就和具体的class有关。例如<em>subtopic</em>如果取值是<em>effect of trade tariffs on manufacturing companies</em>，那么可以对应于NYT数据集里的<em>international business</em>类，也可以对应于<em>economy</em>类。为了避免这种模糊的attribute values，作者利用Class-Dependent Attribute Value Filtering (CAF)策略，通过query ChatGPT 5个和当前class最相似的其它class，然后用ChatGPT检查各个class-dependent attribute的values是否和这5个相似的class相关。如果是，就移除这个特定的attribute value。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202117777.png"  style="zoom:50%;" /></p>
<p>然后对于不同class，通过组合不同的data attribute的values，就可以让LLM生成不同的text。</p>
<p>接下来，作者针对生成数据的diversity进行了分析。下面是统计vocabulary size：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202347966.png"  style="zoom:30%;" /></p>
<p>下面是计算same-class内text pairs的sentence embedding相似度分布：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202441780.png"  style="zoom:50%;" /></p>
<p>可以看到gold data有最大的多样性，而LLM生成的text和real data还是有差距。</p>
<p>下面是作者人工检查的100个句子，分析句子中的bias：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202605513.png"  style="zoom:50%;" /></p>
<p>可以看到，如果是简单的让LLM生成新数据，LLM生成的句子有很大的偏差。</p>
<p>下面的表格是作者将生成的数据（和原来数据集数据量一样）加入到gold training data中的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202758797.png" style="zoom:50%;" /></p>
<p>作者在实验里还比较了不同生成数据的prompt在budget（即调用ChatGPT的花费cost与性能比）和sample efficiency（使用更多数据带来的性能变化）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202939822.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025202957634.png"  style="zoom:50%;" /></p>
<p>Figure 7有个很重要的启发，增加生成数据的多样性是必要的，这样才能够让生成数据越多，性能也一直随着增加。如果生成的数据是原来数据的重复，那么更多的新数据就没有意义了。</p>
<blockquote>
<p>Overall, AttrPrompt renders better sample efficiency than SimPrompt, which suggests that increasing the diversity of the prompts could be an effective way to improve the unsatisfactory data scaling trend of using LLM as data generator [52].</p>
</blockquote>
<p>最后，作者实验了将AttPrompt和以前构造训练数据方法结合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025203123175.png"  style="zoom:50%;" /></p>
<h2 id="grammar-prompting">Grammar Prompting</h2>
<p>Grammar Prompting for Domain-Specific Language Generation with Large Language Models. MIT. NeurIPS 2023.</p>
<blockquote>
<p>Large language models (LLMs) can learn to perform a wide range of natural language tasks from just a handful of in-context examples. <strong>However, for generating strings from highly structured languages (e.g., semantic parsing to complex domain-specific languages), it is challenging for the LLM to generalize from just a few exemplars.</strong> We explore grammar prompting as a simple approach for enabling LLMs to use external knowledge and domain-specific constraints, expressed through a grammar expressed in Backus–Naur Form (BNF), during incontext learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perform competitively on a diverse set of DSL generation tasks, including semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and even molecule generation (SMILES).</p>
</blockquote>
<p><strong>Issue</strong>: 由于预训练过程，LLM的上下文学习能力已经得到了证明。但是上下文学习不适用于无法通过几个例子就能够说清楚的task，比如特定领域语言生成Domain-Specific Language Generation任务。</p>
<blockquote>
<p>This approach is however inadequate for applications where the task specifications cannot be fully delineated through just a handful of exemplars, for example in semantic parsing where an LLM must translate a natural language utterance to an executable program in a domainspecific language (DSL)</p>
</blockquote>
<p>领域特定的语言，并不是一般的编程语言，因此LLM可能在预训练过程中没有见过很多，也因此无法简单的通过几个demonstrations就学会如何输出领域特定语言。下面是为calendar assistant生成一个预定会议调用API流程对应的DSL：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025222831446.png"  style="zoom:50%;" /></p>
<p><strong>Soluation</strong>: 为了解决这个问题，作者提出了使用Backus–Naur Form (BNF)重新描述demonstrations的grammar prompting方法。BNF是一种标准元语言，metalanguages，能够用来描述某个语言的语法。比如对于上面的例子，有下面对应的BNF：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025230240533.png"  style="zoom:30%;" /></p>
<p>DSL是由专家定义的特定领域的特定语言，因此LLM在预训练阶段大概率较少遇到。而BNF是通用的元语言，因此LLM在预训练阶段更有可能见过，比如在cs教科书上有对应的介绍。因此作者利用BNF来描述所有的DSL语言。</p>
<p>作者的prompt先是让LLM输出对应的BNF语法grammar，然后再query转化为对应的DSL语言：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025230615539.png"  style="zoom:50%;" /></p>
<p>顺便一提，从BNF到最后的DSL有可能转化错误，比如DSL没有遵循BNF进行生成。因此，作者还提出了一个Earley-based Constrained Decoding策略（这部分没有太看懂，总体上理解是调用外部Earley解析器，找到目前的DSL中有效valid的最长前缀，然后让其提供几个可能的后续，再让LLM从后续当中做选择）。下面是一个修正生成的DSL中可能存在错误的例子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025231024991.png"  style="zoom:50%;" /></p>
<p>实验是基于<code>Codex</code>, <code>GPT-3.5</code>和<code>GPT-4</code>，针对DSLs for semantic parsing (SMCalFlow, Overnight, GeoQuery), an action DSL (PDDL planning), and a molecule generation DSL (SMILES)三种任务进行了实验。</p>
<p>下面是分子预测任务的一个case：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231025231356056.png"  style="zoom:50%;" /></p>
<h2 id="sungen">SunGen</h2>
<p>Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning. ICLR 2023. 香港大学. <a href="https://github.com/SumilerGAO/SunGen">代码</a>.</p>
<blockquote>
<p>There is a rising interest in further exploring the zero-shot learning potential of large pre-trained language models (PLMs). <strong>A new paradigm called data-generationbased zero-shot learning</strong> has achieved impressive success. In this paradigm, the synthesized data from the PLM acts as the carrier of knowledge, which is used to train a task-specific model with orders of magnitude fewer parameters than the PLM, achieving both higher performance and efficiency than prompt-based zero-shot learning methods on PLMs. <strong>The main hurdle of this approach is that the synthesized data from PLM usually contains a significant portion of low-quality samples. Fitting on such data will greatly hamper the performance of the taskspecific model,</strong> making it unreliable for deployment. Previous methods remedy this issue mainly by filtering synthetic data using heuristic metrics(e.g., output confidence), or refining the data with the help of a human expert, which comes with excessive manual tuning or expensive costs. In this paper, we propose a novel noise-robust re-weighting framework SunGen to automatically construct high-quality data for zero-shot classification problems. Our framework features the ability to learn the sample weights indicating data quality without requiring any human annotation. We theoretically and empirically verify the ability of our method to help construct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8% relative improvement than the baseline on average accuracy across eight different established text classification tasks.</p>
</blockquote>
<p><strong>Issue</strong>: 利用PLM生成训练数据，然后微调小模型的范式已经在很多如下游任务上得到了研究。更进一步的，出现了generation-based zero-shot learning，直接让PLM生成zero-shot labels对应的training data，然后微调小的任务模型tiny task model（TAM）。这种做法和经典的和直接利用PLM进行zero-shot任务比较起来，有两个优点：</p>
<ul>
<li>since the task model has orders-of-magnitude fewer parameters than the PLM, it demonstrates much <strong>lower inference latency</strong></li>
<li>with the large amount of PLM-generated training data, the task model often shows <strong>better performance</strong> than prompt-based zero-shot PLM counterparts.</li>
</ul>
<p>对于generation-based zero-shot learning来说，利用PLM可以生成无限数量的训练数据，需要重点关心的问题是生成数据的质量。比如作者观察到的，前人方法ZeroGen，随着生成数据增多，在测试集上的效果下降。这说明其生成数据的质量降低，模型过拟合这些低质量生成数据：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026112236268.png"  style="zoom:30%;" /></p>
<p>经典的自动解决noisy data的影响的方法是re-weighting samples：</p>
<blockquote>
<p>To avoid human intervention, the classic approach to eliminate the effect of noisy data is to re-weight the samples. The core idea is to design a weighting function <span class="math inline">\(w\)</span>, such that the correct samples are associated with larger weights and the noisy ones with smaller weights.</p>
</blockquote>
<p>re-weighting samples方法有两种，一种是基于启发式规则的，例如基于生成数据的confidence、loss等，需要提前根据task-specific knowledge定义好，而且效果也不稳定[<em>Metaweight-net: Learning an explicit mapping for sample weighting. NeurIPS 2019</em>]；另一种是adaptive method自动学习sample weight <span class="math inline">\(w\)</span>，这种方法通常是bi-level optimization problem，需要一个已有的clean validation set作为outer loop来知道inner loop学习<span class="math inline">\(w\)</span>。但问题是，在zero-shot场景下，没有这样的validation set。</p>
<blockquote>
<p>can we design an objective such that the sample weights can be optimized with only access to the noisy synthetic data?</p>
</blockquote>
<p><strong>Solution</strong>: 作者的解决方案是在adaptive re-weighting方法的基础上，在outer loop里加入noise-robust loss，通过其优化samples的weights。</p>
<p>作者提出的Self-gUided Noise-free data GENeration（SunGen）方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026190700833.png"  style="zoom:50%;" /></p>
<p>核心是inner loop和outer loop。inner loop基于cross-entropy(CE) loss，在synthetic training data上，根据sample weights，优化TAM参数：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026191310674.png"  style="zoom:50%;" /></p>
<p>outer loop基于noise-robust loss，在synthetic validation data上，优化sample weights <span class="math inline">\(\mathbf{w}\)</span>:</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026191334955.png"  style="zoom:50%;" /></p>
<p>noise-robust loss拥有特殊的property：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026191440102.png" style="zoom:50%;" /></p>
<p>对于拥有这样property的loss，之前的研究证明了在大部分labels是正确的情况下，有部分noisy labels和全部正确的labels有一致的global minimum。</p>
<blockquote>
<p>More formally, when the majority of the training samples are correctly labelled, the global minimizer (<span class="math inline">\(\mathbf{\theta}^*\)</span> ) of <span class="math inline">\(\ell_{robust}\)</span> robust is the same regardless of whether the training data is clean or noisy.</p>
</blockquote>
<p>具体，作者使用的是reversed cross-entropy loss <span class="math inline">\(\ell_{rce}\)</span>，即将ground-truth label和predicted probability互换：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026200457624.png" style="zoom:50%;" /></p>
<p>上面公式里如果<span class="math inline">\(k\)</span>是ground truth label，那么<span class="math inline">\(q(k|x)=1\)</span>，否则<span class="math inline">\(q(k|x)=0\)</span>。因此对应的<span class="math inline">\(log\ q(k|x)=0\)</span>和<span class="math inline">\(log\ q(k|x)=A\)</span>。<span class="math inline">\(A\)</span>是一个估计常量。可以判断出来，上面的reversed cross-entropy loss <span class="math inline">\(\ell_{rce}=C=-(K-1)A\)</span>。</p>
<p>在根据<span class="math inline">\(\ell_{robust}\)</span>优化sample weights <span class="math inline">\(\mathbf{w}\)</span>的时候，采用的是truncated back-propagation：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026201253170.png"  style="zoom:50%;" /></p>
<p>具体优化流程，先inner loop再outer loop：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026201005040.png"  style="zoom:30%;" /></p>
<p>在实验部分，基于<code>GPT2-XL(1.5B)</code>对8个text classification tasks进行实验。下面是作者在不同数据集里使用的数据生成的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231026201451588.png"  style="zoom:40%;" /></p>
<h2 id="progen">ProGen</h2>
<p>ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback. The University of Hong Kong. EMNLP 2022 Findings. <a href="https://github.com/HKUNLP/ProGen">代码</a>.</p>
<blockquote>
<p>Recently, dataset-generation-based zero-shot learning has shown promising results by training a task-specific model with a dataset synthesized from large pre-trained language models (PLMs). The final task-specific model often achieves compatible or even better performance than PLMs under the zero-shot setting, with orders of magnitude fewer parameters. However, synthetic datasets have their drawbacks. <strong>They have long been suffering from low-quality issues (e.g., low informativeness and redundancy).</strong> This explains why the massive synthetic data does not lead to better performance – a scenario we would expect in the humanlabeled data. To improve the quality of dataset synthesis, we propose a progressive zero-shot dataset generation framework, <strong>ProGen, which leverages the feedback from the task-specific model to guide the generation of new training data via in-context examples.</strong> Extensive experiments on five text classification datasets demonstrate the effectiveness of the proposed approach. We also show ProGen achieves onpar or superior performance with only 1% synthetic dataset size compared to baseline methods without in-context feedback.</p>
</blockquote>
<p><strong>Issue</strong>: 之前PLM已经被利用于数据生成，但还是需要有监督数据。ZeroGen方法首先提出利用task description作为prompt进行Dataset-generation-based Zero-shot Learning。但是这种zero-shot数据增强方法最大的问题是生成数据的low-quality。由于low-quality data（low informativeness，redundancy等），生成更多的数据不一定带来性能提升。</p>
<p><strong>Solution</strong>: 作者的方法是从tiny task model中学习feedback，选择作者定义的高质量的data，然后作为新的demonstrations，生成新的数据。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231029235644809.png"  style="zoom:50%;" /></p>
<p>最大的难点是如何对生成的数据进行评估，作者提出来利用下游task model的influence function (Koh and Liang, 2017)作为评估质量的标准：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231029235847173.png"  style="zoom:35%;" /></p>
<p>但是这需要一个验证集，而作者的验证集只能由生成数据构成，因此作者提出使用Reverse Cross-Entropy (RCE) loss作为noise-tolerant loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231030000023734.png"  style="zoom:35%;" /></p>
<p>最后，计算出来的influence function负值越小，代表着对应生成的数据越可能减小在validation set上的权重，越应该看做是高质量生成数据。</p>
<p>作者的实验是基于<code>GPT2-XL</code>，在text classification任务上进行实验。尽管不是LLM，但是仍然可以适用于各种LLM。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231030000311489.png"  style="zoom:40%;" /></p>
<h2 id="fewgen">FewGen</h2>
<p>Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning. University of Illinois Urbana-Champaign. ICML 2023. <a href="https://github.com/yumeng5/FewGen">Code</a>. <a href="/nlp/FewGen-icml2023/" title="[详细博客]">[详细博客]</a></p>
<blockquote>
<p>Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. <strong>To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective.</strong> A classification PLM can then be fine-tuned on both the few-shot and the synthetic samples with regularization for better generalization and stability. Our approach FewGen achieves an overall better result across seven classification tasks of the GLUE benchmark than existing few-shot learning methods, improving no-augmentation methods by 5+ average points, and outperforming augmentation methods by 3+ average points.</p>
</blockquote>
<p><strong>Issue</strong>: 之前的微调PLM进行数据生成的方法，没有显式地建模不同label之间的区别，可能导致在生成相似label对应的训练数据时，生成数据的质量难以保证。</p>
<p><strong>Soluation</strong>: 作者认为在生成的时候，应该考虑token对于label的独特性。</p>
<p>作者提出的方法的总体结构图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031211555513.png"  style="zoom:50%;" /></p>
<p>假定存在<span class="math inline">\(L\)</span>个label，每个类型有<span class="math inline">\(K\)</span>个训练数据，<span class="math inline">\(K\)</span>是一个很小的值，如<span class="math inline">\(K=16\)</span>。组成了训练集<span class="math inline">\(D_{train} = \{(\mathbf{x}, y)_i\}\)</span>。其中，<span class="math inline">\(\mathbf{x} = [x_1,x_2,\dots,x_n]\)</span>表示长度为<span class="math inline">\(n\)</span>个tokens的text。类似的，还有<span class="math inline">\(D_{dev}\)</span>和<span class="math inline">\(D_{test}\)</span>。</p>
<p>我们要在训练集上训练一个data generator，<span class="math inline">\(G_{\mathbf{\theta}}\)</span>，来构造新的数据，所有新的生成数据构成了新的数据集合<span class="math inline">\(D_{gen}=\{ (\tilde{\mathbf{x}},\tilde{y})_i \}\)</span>。</p>
<p>我们用<span class="math inline">\(C_\phi\)</span>表示训练出来执行downstream task的分类器模型。</p>
<p>之前常见的训练数据生成器的方法是利用autoregressive PLM <span class="math inline">\(G_{\mathbf{\theta}}\)</span>在<span class="math inline">\(D_{train}\)</span>上按照maximum likelihood generation loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231030233718879.png"  style="zoom:40%;" /></p>
<p>其中，<span class="math inline">\(\mathbf{h}_j\)</span>表示是对于第<span class="math inline">\(j\)</span>个位置PLM编码输出的embedding，<span class="math inline">\(\mathbf{e}_{j}\)</span>表示正确的原来token <span class="math inline">\(j\)</span>的token embedding，一共有<span class="math inline">\(V\)</span>个候选token。期望正确token的输出概率<span class="math inline">\(p_\theta\)</span>最大。训练结束后，就可以利用<span class="math inline">\(G_\theta\)</span>按照学习到的概率不断采样新的tokens，获得新的生成数据。</p>
<p>但是如果直接在一个很小的训练集上，更新所有的PLM参数<span class="math inline">\(\mathbf{\theta}\)</span>是不必要的。作者这里是利用prefix-tuning的方法，固定model整体的参数，只更新prefix vectors <span class="math inline">\(\mathbf{\theta}_p\)</span>，即最后学习到的data generator是<span class="math inline">\(G_{\mathbf{\theta}_p}\)</span>。</p>
<p>对于带有label的任务来说，能够让生成的数据和label匹配是必要的。不同的label对应的数据可能有自己特有的pattern。而要学习conditional text generation probability <span class="math inline">\(p(\mathbf{x}|y_l)\)</span>。最直接的方法是针对不同的label <span class="math inline">\(l\)</span>有自己的参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>，直接优化generative likelihood：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031100418153.png"  style="zoom:50%;" /></p>
<p>上面的方法没有考虑到label discriminativeness (/dɪˈskrɪmənətɪv/) <span class="math inline">\(p(y_l|\mathbf{x})\)</span>也就是期望被downstream能够学习到的到的真实/理想分布。最理想的情况下，是期望生成的新数据：</p>
<ul>
<li><span class="math inline">\(y_l\)</span>是正确的</li>
<li>理论上，一个有足够能力的task model，可以根据<span class="math inline">\(\mathbf{x}\)</span>非常confidence/明确的输出<span class="math inline">\(y_l\)</span></li>
</ul>
<p>如果生成的数据从理论上/让人类去判断，根据<span class="math inline">\(\mathbf{x}\)</span>既可以被分类为<span class="math inline">\(y_1\)</span>，又可以被分类为<span class="math inline">\(y_2\)</span>，很明显这个不是我们期望的理想数据。</p>
<p>对于很多challenging NLP tasks，是存在不同label之间有很相似的distributions的，不同label之间的差别很微妙。比如对于一个movie review：<code>a movie where the ending feels like a cop-out</code>，根据最后的<code>cop-out</code>可以判断这个是一个negative review（认为这个电影的结尾是个逃避式的结尾，比如作者选择了一种非常简单没法让人满意的方式结束了剧情，对于很多情节没有交代清楚）；但如果仅仅是调整下最后的表达，换为<code>revelation</code>，就变为了一个positive review（认为电影的结尾有新意，出乎人的意料）。</p>
<p>为了评估label-discriminativeness，作者定义了一个新的loss，也就是某个text token <span class="math inline">\(j\)</span>，在使用label <span class="math inline">\(l\)</span>时的对应参数 <span class="math inline">\(\mathbf{\theta}_p\)</span>的情况下出现的概率和使用其它labels的对应参数时生成的概率的比值：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031104013187.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031104013187-20231102210448282.png" /></p>
<p>在优化生成式loss的过程中，每个token对于最后的loss有相同的loss weight <span class="math inline">\(1\)</span>。而大多数的token是label-indiscriminate，那么优化<span class="math inline">\(\mathcal{L}_{gen}\)</span>只需要让大多数的token，在无论输入参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>的情况下，都进行输出。就能够让<span class="math inline">\(\mathcal{L}_{gen}\)</span>在全局上越来越小。例如输入<code>a movie</code>，接下来的<code>that</code>在输入任意<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>的情况下，出现概率都差不多。让更多的token出现概率不会随着输入参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>变化，可能是让<span class="math inline">\(\mathcal{L}_{gen}\)</span>不断减小的较优解。</p>
<p>那么如何让PLM学会针对不同的label，生成的data有区别呢？</p>
<p>最直接的做法是同时优化label-discriminative loss <span class="math inline">\(\mathcal{L}_{disc}\)</span>。但这么做可能不会带来理想的结果，可能会让PLM倾向于对每个位置上的tokens都针对不同label用独特的描述。但是想到<code>the</code>这些词实际上是不需要随着label变化的。</p>
<p>也就是说我们需要让PLM能够学会将不同的token区分出来，关注到其中是label-discriminative的tokens。我们可以给每个token赋予不同的loss weight <span class="math inline">\(w_j\)</span>，如果一个位置上的token是label-discriminative的，那么就增大它的loss weight <span class="math inline">\(w_j\)</span>。这样实现让PLM在优化生成loss的时候，要更多的关注根据当前输入的label参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>和输出的label-discriminative的对应。比如输入的label是negative，输出的关键token是<code>cop-out</code>这样的词；输入的label是positive，输出的关键token是<code>revelation</code>这样的词。再比如如果出现<code>bad</code>/<code>good</code>这样的word，很明显也应该关注。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031112600909.png"  style="zoom:50%;" /></p>
<p><span class="math inline">\(w_j\)</span>是随着不同的text变化的，要想提前人工设定好是不实际的。那么就需要某种方法来自动学习<span class="math inline">\(w_j\)</span>。</p>
<p>首先，如果让<span class="math inline">\(w_j\)</span>看做是一个可学习的参数，赋值给输入的<span class="math inline">\(\mathbf{x}\)</span>上的不同tokens，然后通过优化上面的<span class="math inline">\(\mathcal{L}_{w-gen}\)</span>学习不同的token loss weight。但这意味着我们需要给每个训练数据的每一个token都学习一个参数<span class="math inline">\(w_j\)</span>。虽然这种做法可以实现，但很明显这种做法很笨拙，并且仅仅在样本量非常小的情况下可以应用。</p>
<p>作者的做法是借鉴了meta-learning的思想，将这个优化问题看做是bi-level optimization问题。</p>
<p>对于generator要优化的参数，还是通过optimize生成loss来获得：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031145421032.png"  style="zoom:50%;" /></p>
<p>这里每个token的loss weight是通过<span class="math inline">\(w_j(\mathbf{\omega})\)</span>函数计算得到的，它是一个带有softmax的feedforward network，输入是每个token计算得到的discriminative loss <span class="math inline">\(\mathcal{L}_{disc}^j\)</span>: <span class="math display">\[
g_{\mathbf{\omega}} (\mathcal{L}_{disc}^j) = FFN(\mathcal{L}_{disc}^j) \\
w_j(\mathbf{\omega}) = \frac{exp(g_{\mathbf{\omega}} (\mathcal{L}_{disc}^j))}{\sum_{j^\prime = 1}^n exp(g_{\mathbf{\omega}} (\mathcal{L}_{disc}^{j^\prime}))}
\]</span> 这样输入的一个text不同位置的所有token的loss weight和是<span class="math inline">\(1\)</span>。</p>
<p>对于要优化的weighting parameters <span class="math inline">\(\omega\)</span>是通过优化outer objective <span class="math inline">\(\mathcal{L}_{disc}\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031150702010.png"  style="zoom:50%;" /></p>
<p>在优化生成式loss的过程中，每个token对于最后的loss有相同的loss weight <span class="math inline">\(1\)</span>。而大多数的token是label-indiscriminate，那么优化<span class="math inline">\(\mathcal{L}_{gen}\)</span>只需要让大多数的token，在无论输入参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>的情况下，都进行输出。就能够让<span class="math inline">\(\mathcal{L}_{gen}\)</span>在全局上越来越小。例如输入<code>a movie</code>，接下来的<code>that</code>在输入任意<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>的情况下，出现概率都差不多。让更多的token出现概率不会随着输入参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>变化，可能是让<span class="math inline">\(\mathcal{L}_{gen}\)</span>不断减小的较优解。</p>
<p>那么如何让PLM学会针对不同的label，生成的data有区别呢？</p>
<p>最直接的做法是同时优化label-discriminative loss <span class="math inline">\(\mathcal{L}_{disc}\)</span>。但这么做可能不会带来理想的结果，可能会让PLM倾向于对每个位置上的tokens都针对不同label用独特的描述。但是想到<code>the</code>这些词实际上是不需要随着label变化的。</p>
<p>也就是说我们需要让PLM能够学会将不同的token区分出来，关注到其中是label-discriminative的tokens。我们可以给每个token赋予不同的loss weight <span class="math inline">\(w_j\)</span>，如果一个位置上的token是label-discriminative的，那么就增大它的loss weight <span class="math inline">\(w_j\)</span>。这样实现让PLM在优化生成loss的时候，要更多的关注根据当前输入的label参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>和输出的label-discriminative的对应。比如输入的label是negative，输出的关键token是<code>cop-out</code>这样的词；输入的label是positive，输出的关键token是<code>revelation</code>这样的词。再比如如果出现<code>bad</code>/<code>good</code>这样的word，很明显也应该关注。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031112600909-20231102210553336.png"  style="zoom:50%;" /></p>
<p><span class="math inline">\(w_j\)</span>是随着不同的text变化的，要想提前人工设定好是不实际的。那么就需要某种方法来自动学习<span class="math inline">\(w_j\)</span>。</p>
<p>首先，如果让<span class="math inline">\(w_j\)</span>看做是一个可学习的参数，赋值给输入的<span class="math inline">\(\mathbf{x}\)</span>上的不同tokens，然后通过优化上面的<span class="math inline">\(\mathcal{L}_{w-gen}\)</span>学习不同的token loss weight。但这意味着我们需要给每个训练数据的每一个token都学习一个参数<span class="math inline">\(w_j\)</span>。虽然这种做法可以实现，但很明显这种做法很笨拙，并且仅仅在样本量非常小的情况下可以应用。</p>
<p>作者的做法是借鉴了meta-learning的思想，将这个优化问题看做是bi-level optimization问题。</p>
<p>对于generator要优化的参数，还是通过optimize生成loss来获得：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031145421032-20231102210553358.png"  style="zoom:50%;" /></p>
<p>这里每个token的loss weight是通过<span class="math inline">\(w_j(\mathbf{\omega})\)</span>函数计算得到的，它是一个带有softmax的feedforward network，输入是每个token计算得到的discriminative loss <span class="math inline">\(\mathcal{L}_{disc}^j\)</span>: <span class="math display">\[
g_{\mathbf{\omega}} (\mathcal{L}_{disc}^j) = FFN(\mathcal{L}_{disc}^j) \\
w_j(\mathbf{\omega}) = \frac{exp(g_{\mathbf{\omega}} (\mathcal{L}_{disc}^j))}{\sum_{j^\prime = 1}^n exp(g_{\mathbf{\omega}} (\mathcal{L}_{disc}^{j^\prime}))}
\]</span> 这样输入的一个text不同位置的所有token的loss weight和是<span class="math inline">\(1\)</span>。</p>
<p>对于要优化的weighting parameters <span class="math inline">\(\omega\)</span>是通过优化outer objective <span class="math inline">\(\mathcal{L}_{disc}\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031150702010-20231102210553373.png"  style="zoom:50%;" /></p>
<p>主要实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031213554404.png"  style="zoom:50%;" /></p>
<p>消融实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031214540871.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Data Augmentation</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>LLM</tag>
        <tag>Data Augmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>MMIE-collection1</title>
    <url>/collection/MMIE-collection1/</url>
    <content><![CDATA[<h1 id="mre-and-mner">MRE and MNER</h1>
<p>多模态信息抽取相关论文总结</p>
<span id="more"></span>
<h2 id="mnre">MNRE</h2>
<p>MNRE: A Challenge Multimodal Dataset for Neural Relation Extraction with Visual Evidence in Social Media Posts</p>
<p>ICME 2021，作者创建了首个用于multimodal relation extraction的数据集MNRE，<a href="https://github.com/thecharm/MNRE">地址</a>，<a href="#">Post not found: mmml/MNRE [详细博客]</a>。</p>
<p>数据来源于Twitter posts，关注点是文本中的上下文信息不够充分时，通过post中的image，来补充上下文信息。</p>
<blockquote>
<p>Extracting relations in social media posts is challenging when sentences lack of contexts. However, images related to these sentences can supplement such missing contexts and help to identify relations precisely. To this end, we present a multimodal neural relation extraction dataset (MNRE), consisting of 10000+ sentences on 31 relations derived from Twitter and annotated by crowdworkers. The subject and object entities are recognized by a pretrained NER tool and then ﬁltered by crowdworkers. All the relations are identiﬁed manually. One sentence is tagged with one related image. We develop a multimodal relation extraction baseline model and the experimental results show that introducing multimodal information improves relation extraction performance in social media texts. Still, our detailed analysis points out the difﬁculties of aligning relations in texts and images, which can be addressed for future research. All details and resources about the dataset and baselines are released on https://github.com/thecharm/MNRE.</p>
</blockquote>
<p>relation extraction（RE）是预测一个句子中两个命名实体之间的关系relation。</p>
<p><strong>challenges</strong>:之前大多数的RE模型关注的是文本信息很充分的场景下的关系抽取，比如newswire domain。但是，一旦文本很短，并且缺少必要的上下文信息的时候，RE模型效果会出现严重的下降。即便是使用了pretrained modal来进行关系抽取，效果也很糟糕。</p>
<p><strong>solution</strong>: 作者认为，对于在推特post这样很可能文本中缺乏足够充分的上下文信息的场景，可以使用image的visual information来补充上下文信息。</p>
<p>比如在下面的图中，如果只有文本，那么可能会判断出来JFK和Obama和Harvard的关系是residence；但是如果能够识别图像中的信息，比如校园、学位帽等，可以判断出来JFK和Obama和Harvard的关系应该是graduated_at。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221012204338075.png"   style="zoom:35%;" /></p>
<p>但是目前并没有这样满足文本+图像的数据集存在，因此作者就希望能够解决这一点，主要贡献如下：</p>
<ul>
<li>创建了在社交媒体posts上的数据集Multimodal dataset for Neural Relation Extraction（MNRE）</li>
<li>在MNRE数据集基础上，构建了几个不同的baseline方法</li>
</ul>
<p>数据来源有三个：</p>
<ul>
<li>Twitter 2015：有8357个候选实例（指一个完整的post和对应image、named entities和relations）</li>
<li>Twitter 2017：有4819个候选实例</li>
<li>Crawled Twitter data：爬取了Twitter 2019年1月到2月的post和对应图片，不限制具体的领域；如果一个post有多张图片，就随机选择一张。最终获取了20000候选实例</li>
</ul>
<p>作者在后续更新了数据集，得到了MNRE-2：</p>
<blockquote>
<p>2021.6.22 We provide MNRE-2, a refined version which merges several ambigious categories with much more support samples. The original version has been moved to <a href="https://github.com/thecharm/MNRE/blob/main/Version-1">Version-1</a></p>
</blockquote>
<p>MNRE-2的统计： <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/20221017115553.png" /></p>
<p>下图是不同关系类型的统计：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221017145814092.png"   style="zoom:30%;" /></p>
<p>经过检查发现，实际的训练集还包括了关系<code>None</code>。上面的统计图没有展现出None关系的分布。</p>
<p>作者的MNRE-2数据集从32变为了23种关系，发现大部分的关系还是和人相关的。MNRE-2训练集有12247、验证集1624和测试集1614实例。</p>
<p>查看下具体的数据集内容，在一个训练实例中，包括</p>
<ul>
<li><p><code>token</code>: <code>['The', 'latest', 'Arkham', 'Horror', 'LCG', 'deluxe', 'expansion', 'the', 'Circle', 'Undone', 'has', 'been', 'released', ':']</code></p></li>
<li><p><code>h</code>: <code>&#123;'name': 'Circle Undone', 'pos': [8, 10]&#125;</code></p></li>
<li><p><code>t</code>: <code>&#123;'name': 'Arkham Horror LCG', 'pos': [2, 5]&#125;</code>，这个<code>Arkham Horror LCG</code>应该是一种卡牌游戏</p></li>
<li><p><code>img_id</code>: <code>'twitter_19_31_16_6.jpg'</code>，所有的图片下载完后是1.2GB，下图是对应的图片</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/twitter_19_31_16_6.jpg"   style="zoom:40%;" /></p></li>
<li><p><code>relation</code>: <code>/misc/misc/part_of</code></p></li>
</ul>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221012210820441.png" alt="image-20221012210820441" /><figcaption>image-20221012210820441</figcaption>
</figure>
<p>上图是数据集中的实例。可以看到，需要同时结合视觉和文本信息，才能够做出准确的关系预测。</p>
<h2 id="hvpnet">HVPNet</h2>
<p>Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction. NAACL 2022</p>
<a href="/mmml/HVPNeT/" title="[详细博客]">[详细博客]</a>
<p>从图像中提取object-level的层级信息，用于补充文本信息。</p>
<p>利用ResNet作为图像encoder导出层级视觉表征，不同的层级信息，通过计算一个gate weight聚合到不同Bert层。输入到不同层的视觉表征，作为Bert的key和value，加入到文本表征学习过程中。</p>
<p>最后的relation预测是通过让[CLS] token embedding输入到MLP-softmax中。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226114745941.png" alt="image-20221226114745941" /><figcaption>image-20221226114745941</figcaption>
</figure>
<h2 id="mkgformer">MKGformer</h2>
<p>Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion. SIGIR 2022</p>
<a href="/mmml/MKGformer/" title="[详细博客]">[详细博客]</a>
<p>文本侧作为key和value输入到视觉侧；</p>
<p>视觉侧在FFN层，通过计算一个token-patch的相似度矩阵，让视觉侧信息进入到文本侧。</p>
<p>论文中声明的是让[CLS] token embedding作为MLP-Softmax输入，但是在代码中却是让[s]和[t] token作为MLP-softmax输入。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226114829074.png" alt="image-20221226114829074" /><figcaption>image-20221226114829074</figcaption>
</figure>
<h2 id="mega">MEGA</h2>
<p>Multimodal Relation Extraction with Efficient Graph Alignment. ACM MM 2021</p>
<a href="/mmml/MEGA/" title="[详细博客]">[详细博客]</a>
<p>通过image graph和textual graph上node对齐得到的结构上的attention weight；</p>
<p>通过image query和textual key计算得到的attention weight；</p>
<p>两个weight相加，将文本表征，融合到图像表征做query的学习过程中；最后把所有视觉表征相加，得到了总的图像表征。</p>
<p>图像表征拼接到文本表征上，进行最后的关系分类。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226115025769.png" alt="image-20221226115025769" /><figcaption>image-20221226115025769</figcaption>
</figure>
<h2 id="fl-msre">FL-MSRE</h2>
<p>FL-MSRE: A Few-Shot Learning based Approach to Multimodal Social Relation Extraction. AAAI 2021</p>
<a href="/mmml/FL-MSRE/" title="[详细博客]">[详细博客]</a>
<p>这里作者构造的数据集主要是包含了脸部图像，不太适用于MNRE数据集。</p>
<p>facial image表征和textual表征拼接后就作为了模态融合模块。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226115624592.png" alt="image-20221226115624592" /><figcaption>image-20221226115624592</figcaption>
</figure>
<h2 id="modality-discriminator">Modality-discriminator</h2>
<p>Different Data, Different Modalities! Reinforced Data Splitting for Effective Multimodal Information Extraction from Social Media Posts. COLING 2022</p>
<a href="/mmml/modality-discriminator/" title="[详细博客]">[详细博客]</a>
<p>重点不在于模态的融合。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226120103740.png" alt="image-20221226120103740" /><figcaption>image-20221226120103740</figcaption>
</figure>
<h2 id="eega">EEGA</h2>
<p>Joint Multimodal Entity-Relation Extraction Based on Edge-enhanced Graph Alignment Network and Word-pair Relation Tagging. AAAI 2023</p>
<a href="/mmml/EEGA/" title="[详细博客]">[详细博客]</a>
<p>比起MEGA，还强调了边的对齐。</p>
<p>使用RCNN导出视觉特征。在Image2Text模块中，文本表征做query，视觉表征做key和value。然后文本表中输入到add&amp;norm层。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226120448953.png" alt="image-20221226120448953" /><figcaption>image-20221226120448953</figcaption>
</figure>
<h2 id="rpbert">RpBERT</h2>
<p>RpBERT: A Text-image Relation Propagation-based BERT Model for Multimodal NER. AAAI 2021</p>
<p>这里提到的relation，是指image和text是否相关。</p>
<p>作者在这里使用的RpBERT是将ResNet的输出和token embedding拼接到一起作为BERT的输入：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226152018529.png"   style="zoom:50%;" /></p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226151035093.png" alt="image-20221226151035093" /><figcaption>image-20221226151035093</figcaption>
</figure>
<h2 id="maf">MAF</h2>
<p>MAF: A General Matching and Alignment Framework for Multimodal Named Entity Recognition. WSDM 2022</p>
<a href="/mmml/MAF/" title="[详细博客]">[详细博客]</a>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117204539318.png" alt="image-20221117204539318" /><figcaption>image-20221117204539318</figcaption>
</figure>
<p>不是在BERT的每一层分别进行视觉信息的融合，而是在不同的模态独立的encoder的输出上进行对齐和融合。</p>
<p>对齐是为了让表征更加一致，作者通过替换post对应的image，利用对比学习，计算文本和图像是否匹配。</p>
<p>最后进行融合的时候，通过给每个token，计算一个gate weight来获得最后的token对应的视觉表征，与文本表征拼接后，输入到CRF层。</p>
<h2 id="mrc-mner">MRC-MNER</h2>
<p>Query Prior Matters: A MRC Framework for Multimodal Named Entity Recognition. ACM MM 2022</p>
<ul>
<li><p>单位：京东</p></li>
<li><p>问题：目前的MNER方法，大多是通过基于attention实现image-sentence的隐式语义对齐，这种方法很难解释和评估实体类型与image region之间的显式关联。</p></li>
<li><p>方法：作者把MNER看做是MRC任务（machine reading comprehension）。把最后要预测关系类型转化为query sentence：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221107193818618.png"   style="zoom:50%;" /></p>
<p>然后使用预训练好的BERT导出文本表征。对于视觉表征，作者首先需要导出一张图片上的regions，作者通过预训练好一个visual grounding模型，然后为了让这个visual grounding模型也能够适用于MNER领域，作者构造了一个语料库，用于微调训练好的visual grounding模型。使用ResNet导出图像表征。</p></li>
<li><p>对于多任务学习：作者除了entity span prediction，还引入了另外两个task辅助NER。region weights estimation和existence detection。region weights estimation是用于评估各个region embedding的重要性；Existence Detection用于预测句子中是否存在某个特定entity type的entity。</p></li>
</ul>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221107164257628.png" alt="image-20221107164257628" /><figcaption>image-20221107164257628</figcaption>
</figure>
<h2 id="umt">UMT</h2>
<p>Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer. ACL 20</p>
<p>作者提出除了要学习word-aware的visual representation外，也要学习image-aware word representation，提出了UMT。为了避免过于强调视觉信息，可能导致会过于强调图像表示的实体，而忽略对其它实体的预测。作者额外训练了一个基于纯文本的模块，让这个模块进行textual entity span detection任务。这个任务实际上和MNER任务是一致的，因此通过设计一个conversion matrix，在优化MNER任务的同时，也优化textual entity span detection任务。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221226165113233.png" alt="image-20221226165113233" /><figcaption>image-20221226165113233</figcaption>
</figure>
<p>MMI模块是模态交互的核心，首先获得image-aware word representation（左侧）和word-aware image representation（右侧）。</p>
<p>将左侧的image-aware word representation再融合到原来的word representation中；然后与word-aware image representation一起经过visual gate，过滤掉不需要视觉信息的token对应的视觉表征（比如the/of/well这些word就不需要视觉信息）。</p>
<p>最后两侧的表征拼接，得到最后的多模态表征。</p>
<h2 id="more">MoRe</h2>
<p>Named Entity and Relation Extraction with Multi-Modal Retrieval</p>
<p>作者通过text和image检索在Wikipedia上相关的text信息来辅助多模态信息抽取。</p>
<p>上海科技与阿里达摩，EMNLP 2022，<a href="http://github.com/modelscope/adaseq/examples/MoRe">代码</a>，<a href="/mmml/MoRe/" title="[详细博客]">[详细博客]</a>。</p>
<blockquote>
<p>Multi-modal named entity recognition (NER) and relation extraction (RE) aim to leverage relevant image information to improve the performance of NER and RE. Most existing efforts largely focused on directly extracting potentially useful information from images (such as pixel-level features, identified objects, and associated captions). However, such extraction processes may not be knowledge aware, resulting in information that may not be highly relevant. <strong>In this paper, we propose a novel Multi-modal Retrieval based framework (MoRe). MoRe contains a text retrieval module and an imagebased retrieval module, which retrieve related knowledge of the input text and image in the knowledge corpus respectively. </strong>Next, the retrieval results are sent to the textual and visual models respectively for predictions. Finally, a Mixture of Experts (MoE) module combines the predictions from the two models to make the final decision. Our experiments show that both our textual model and visual model can achieve state-of-the-art performance on four multi-modal NER datasets and one multimodal RE dataset. With MoE, the model performance can be further improved and our analysis demonstrates the benefits of integrating both textual and visual cues for such tasks.</p>
</blockquote>
<p>作者的方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901151432582.png"   style="zoom:50%;" /></p>
<p>作者从English Wikipedia dump中分别以text和image作为关键进行检索：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901151548710.png"   style="zoom:40%;" /></p>
<p>具体来说：</p>
<ul>
<li>Textual Retrieval System：待抽取text作为query，使用ElasticSearch，基于BM25算法检索Wikipedia中语义相似的句子（key），然后把包含句子的paragraph返回（value）作为检索结果。</li>
<li>Image-base Retrieval System：使用ViTB/32 in CLIP将待抽取image和Wikipedia article中的images都编码为vector，然后基于k-NN算法，使用Faiss进行高效搜索。把检索到的article的introduction section返回未做检索结果。</li>
</ul>
<p>分别检索到top-K（实验中<span class="math inline">\(K=10\)</span>）的结果之后，检索到的结果与原有的待抽取text拼接，分别经过独立的task model输出对于实体或者关系的预测结果。NER任务使用CRF decoder，RE任务使用简单的线性softmax。task model在实验中是XLM-RoBERTa large。</p>
<p>对于两个prediction distributions，作者使用MoE进行混合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152335088.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152320697.png"   style="zoom:40%;" /></p>
<p>这里的MoE是计算两个prediction distributions的对应权重，然后进行混合。对于NER任务，由于CRF将NER看做是序列标注预测，对应可能的序列集合范围很大。因此作者使用了自己之前在CLNER工作中的方法，将序列标注预测转变为认为不同位置的NER label是互相独立的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152615131.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152631421.png"   style="zoom:40%;" /></p>
<p>这样最后预测就是让每一个位置上的token的NER label概率最大，而不是让所有token的NER label组合序列的概率最大。</p>
<p>主要实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152831756.png"   style="zoom:40%;" /></p>
<p>可以看到，如果仅仅是只使用text或image检索，大概带来了1%的提升。通过使用MoE将效果提升到了2%。但是总的效果来看还比不上目前直接使用multimodal representation进行prediction的方法，特别是在MNRE数据集上。</p>
<p>作者MNER任务除了使用最常用的Twitter2015和Twitter2017数据集外，还将WikiDiverse这个multimodal entity linking数据集中对于实体的标注导出来进行预测，这样除了可以对social media domain进行评估外，还可以对News domain进行评估。</p>
<blockquote>
<p>The WikiDiverse dataset is a very recent multi-modal entity linking dataset constructed by Wang et al. (2022d) based on Wikinews. The dataset has annotations of entity spans and entity labels. We convert the multi-modal entity linking dataset into a multi-modal NER dataset to further show the effectiveness of MoRe on the news domain.</p>
</blockquote>
<h2 id="promptmner">PromptMNER</h2>
<p>PromptMNER: Prompt-Based Entity-Related Visual Clue Extraction and Integration for Multimodal Named Entity Recognition</p>
<p>复旦大学计算机科学学院，上海数据科学重点实验室，DASFAA 2022</p>
<p>作者提出了一种利用prompt来更好的导出实体相关的视觉特征的方法。</p>
<blockquote>
<p>Multimodal named entity recognition (MNER) is an emerging task that incorporates visual and textual inputs to detect named entities and predicts their corresponding entity types. However, existing MNER methods often fail to capture certain entity-related but textloosely-related visual clues from the image, which may introduce taskirrelevant noises or even errors. To address this problem, we propose to utilize entity-related prompts for extracting proper visual clues with a pre-trained vision-language model. To better integrate diﬀerent modalities and address the popular semantic gap problem, we further propose a modality-aware attention mechanism for better cross-modal fusion. Experimental results on two benchmarks show that our MNER approach outperforms the state-of-the-art MNER approaches with a large margin.</p>
</blockquote>
<p>作者主要是提出了在图像中，对于MNER任务来说，更加重要的是entity-related的视觉特征，而单纯的text-related的视觉特征是和entity以外的文本关联，可能包括了更多的噪音。</p>
<p>为了解决这一问题，作者设计了entity-related prompts，通过利用pretrained vision-language model来判断不同prompt和图像之间的匹配程度，进而选择合适的prompt来作为entity-related的视觉特征。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512153907747.png" alt="image-20230512153907747" /><figcaption>image-20230512153907747</figcaption>
</figure>
<p>作者定义的prompt形式是<span class="math inline">\(P_i = \mbox{an image of }[w_i]\)</span>，<span class="math inline">\(w_i\)</span>可以是discrete的word/phrase，也可以是continuous的embedding。</p>
<p>discrete的<span class="math inline">\(w_i\)</span>来源如下：</p>
<ul>
<li>NER的所有实体标签，如person, location, organization</li>
<li>从<a href="http://relatedwords.org">Related Words</a>中和实体标签相关的词，如person的关联词有people, someone, individual, worker, child</li>
<li>专家定义的实体标签，如person的人工定义的词有player, pants, hat, suit, group of people, team</li>
</ul>
<p>因为想要找到所有合适的word描述图像内容是不实际的，因此作者也是用了continuous prompts作为补充，也就是定义没有现实意义的embedding直接作为<span class="math inline">\(w_i\)</span>。作者发现定义100个continuous prompt达到了最好的效果。</p>
<p>为了确定哪个prompt是最好的描述了图像信息，作者使用CLIP对图像和prompt分别进行编码，然后计算匹配度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512155631323.png"   style="zoom:50%;" /></p>
<p><span class="math inline">\(&lt;s_i,v&gt;\)</span>是表示余弦相似度。<span class="math inline">\(s_i\)</span>是<span class="math inline">\(i\)</span>-th prompt的embedding，<span class="math inline">\(v\)</span>是图像信息。计算出来的匹配程度与prompt embedding相乘作为找到的视觉特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512155919285.png"   style="zoom:50%;" /></p>
<p>聚合的时候使用了跨模态注意力，这里看图即可，不再赘述。</p>
<p>最后使用基于span的NER分类器：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512160449263.png"   style="zoom:50%;" /></p>
<p><span class="math inline">\(i,j\)</span>表示的token <span class="math inline">\(i\)</span>到token <span class="math inline">\(j\)</span>的序列，把序列的头尾token embedding拿出来进行分类，<span class="math inline">\(\{\mbox{person, location, organization, misc, not entity}\}\)</span>。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512160707006.png" alt="image-20230512160707006" /><figcaption>image-20230512160707006</figcaption>
</figure>
<p>效果上来看还是可以的。</p>
<h2 id="visualpt-moe">VisualPT-MoE</h2>
<p>A Uniﬁed Visual Prompt Tuning Framework with Mixture-of-Experts for Multimodal Information Extraction.</p>
<p>东华大学，DASFAA 2023，<a href="https://github.com/xubodhu/VisualPTMoE">代码</a>。</p>
<blockquote>
<p>Recently, multimodal information extraction has gained increasing attention in social media understanding, as it helps to accomplish the task of information extraction by adding images as auxiliary information to solve the ambiguity problem caused by insuﬃcient semantic information in short texts. Despite their success, current methods do not take full advantage of the information provided by the diverse representations of images. To address this problem, we propose a novel uniﬁed visual prompt tuning framework with Mixture-of-Experts to fuse diﬀerent types of image representations for multimodal information extraction. Extensive experiments conducted on two diﬀerent multimodal information extraction tasks demonstrate the eﬀectiveness of our method. The source code can be found at https://github.com/xubodhu/VisualPTMoE.</p>
</blockquote>
<p>作者的方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926173524966.png"  style="zoom:50%;" /></p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926173555132.png"  style="zoom:50%;" /></p>
<h2 id="wukong-cmner">Wukong-CMNER</h2>
<p>Wukong-CMNER: A Large-Scale Chinese Multimodal NER Dataset with Images Modality</p>
<p>人大，DASFAA 2023</p>
<blockquote>
<p>So far, Multimodal Named Entity Recognition (MNER) has been performed almost exclusively on English corpora. Chinese phrases are not naturally segmented, making Chinese NER more challenging; nonetheless, Chinese MNER needs to be paid more attention. Thus, we ﬁrst construct Wukong-CMNER, a multimodal NER dataset for the Chinese corpus that includes images and text. There are 55,423 annotated image-text pairs in our corpus. Based on this dataset, we propose a lexicon-based prompting visual clue extraction (LPE) module to capture certain entity-related visual clues from the image. We further introduce a novel cross-modal alignment (CA) module to make the representations of the two modalities more consistent through contrastive learning. Through extensive experiments, we observe that: (1) Discernible performance boosts as we move from unimodal to multimodal, verifying the necessity of integrating visual clues into Chinese NER. (2) Cross-modal alignment module further improves the performance of the model. (3) Our two modules decouple from the subsequent predicting process, which enables a plug-and-play framework to enhance Chinese NER models for Chinese MNER task. LPE and CA achieve state-of-the-art (SOTA) results on Wukong-CMNER when combined with W2NER [11], demonstrating its effectiveness.</p>
</blockquote>
<p>作者创建了首个中文MNER数据集：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926173831838.png"   style="zoom:40%;" /></p>
<p>作者也提出了一个方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230926173933775.png"  style="zoom:50%;" /></p>
<h2 id="cot-mie">CoT-MIE</h2>
<p>Chain-of-Thought Prompt Distillation for Multimodal Named Entity Recognition and Multimodal Relation Extraction</p>
<p>阿里Ant group，2023-08 arXiv</p>
<blockquote>
<p>Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction (MRE) necessitate the fundamental reasoning capacity for intricate linguistic and multimodal comprehension. In this study, we explore distilling the reasoning ability of large language models (LLMs) into a more compact student model by generating a chain of thought (CoT) – a sequence of intermediate reasoning steps. Specifically, we commence by exemplifying the elicitation of such reasoning ability from LLMs through CoT prompts covering multi-grain (noun, sentence, multimodality) and data-augmentation (style, entity, image) dimensions. Subsequently, we present a novel conditional prompt distillation method to assimilate the commonsense reasoning ability from LLMs, thereby enhancing the utility of the student model in addressing text-only inputs without the requisite addition of image and CoT knowledge. Extensive experiments reveal that our approach attains state-of-the-art accuracy and manifests a plethora of advantages concerning interpretability, data efficiency, and cross-domain generalization on MNER and MRE datasets.</p>
</blockquote>
<p>作者声称是希望能够将LLM的推理能力交给小模型，但是个人阅读下来感觉小模型也没有学会推理能力。并且这里一直在强调CoT，事实上这篇论文个人更愿意看做是一种数据增强/知识检索的方法，毕竟LLM本身没有针对信息抽取给出中间的推理步骤。</p>
<p>作者的做法出发点是：</p>
<ul>
<li><p>之前的基于检索的模型，难以保证检索到的结果和查询的句子是匹配的，比如下图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824231237542.png"   style="zoom:40%;" /></p></li>
<li><p>大模型的推理成本比较高，但是它的推理能力比较好。希望能够用个小模型学会大模型的推理能力，并且有较低的推理成本。</p></li>
</ul>
<p>作者的方法：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824231405165.png" alt="image-20230824231405165" /><figcaption>image-20230824231405165</figcaption>
</figure>
<p>首先，作者用BLIP2把多模态信息抽取中的图片转化为文本caption。</p>
<p>然后利用LLM生成下面几种额外的知识：</p>
<ul>
<li>Noun：对于句子中的potential entities, slang, and terminology等名词进行查询，对应的prompt是：<code>Help me explain the meaning of special words for understanding. + x</code></li>
<li>Sentence：对于整个句子进行理解，It can explain the sentiment, cause, and subject of users. 对应的prompt是<code>Explain the sentence to me with necessary background. + x</code></li>
<li>Multimodality：让LLM解释潜在的image和text之间的关系，这一步可以用来去噪、潜在的对齐visual object和textual entity，对应的prompt是：<code>What is the relation between the text and the attached image? + x + I</code></li>
</ul>
<p>作者还利用LLM进行了数据增强：</p>
<ul>
<li>Style：利用LLM转换输入句子的风格，让文本的描述保持一致的风格，对应的prompt是<code>Transform the sentence in Twitter style without changing the meaning. + x</code></li>
<li>Entity：用同类型的entity替换候选的entity，然后用LLM判断替换后的伪样本是否成立，判断的prompt是<code>Whether the sentence is possible in fact, answer yes or no. + x</code></li>
<li>Image：让LLM猜测能够和文本描述对应的image长什么样子，对应的prompt是<code>What is a possible image with the text in a tweet? + x</code></li>
</ul>
<p>数据增强后的样本被看做是新的样本。</p>
<p>然后问题的关键是怎么样能够让小模型学会LLM的推理，作者声称提出了Conditional Prompt Distillation的方法。具体做法是首先作者把原始的text <span class="math inline">\(x\)</span>、图像的caption <span class="math inline">\(I\)</span>以及LLM生成的知识<span class="math inline">\(c\)</span>拼接到一起，经过text encoder获得输出分布<span class="math inline">\(H_k\)</span>；然后，作者定义了可学习的soft prompt来作为conditional prompt聚合text：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824232713196.png"   style="zoom:40%;" /></p>
<p>这里生成的<span class="math inline">\(p\)</span>和原始的text <span class="math inline">\(x\)</span>拼接在一起，经过text encoder获得输出分布<span class="math inline">\(H_t\)</span>；最后，作者期望这两种分布是相近的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824232832068.png"   style="zoom:40%;" /></p>
<p>个人对于这个公式有点疑惑，这里的分布到底是信息抽取的classification distribution还是token distribution？</p>
<p>更疑惑的是，最后预测结果仍然是加入了LLM生成知识<span class="math inline">\(c\)</span>的结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233139004.png"   style="zoom:40%;" /></p>
<p>难道是在测试阶段仅仅用小模型，不需要LLM提前处理？</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233204415.png"   style="zoom:30%;" /></p>
<p>和目前的SOTA相比，MNRE数据集上还有10%的差距；而Twitter15和17数据集可以认为是达到了SOTA。</p>
<p>另外从消融的结果来看，对于名词的解释，可能作用相对比较大：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233303269.png"   style="zoom:30%;" /></p>
<p>论文的case study可以看下，感觉这些LLM生成的knowledge还是比较有意义的，问题在于没有CoT..也不确定小模型是否学习到了推理能力：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230824233447694.png" alt="image-20230824233447694" /><figcaption>image-20230824233447694</figcaption>
</figure>
<h2 id="pgim">PGIM</h2>
<p>Prompt ChatGPT In MNER: Improved multimodal named entity recognition method based on auxiliary refining knowledge from ChatGPT</p>
<p>天津大学，2023-05，arXiv</p>
<blockquote>
<p>Multimodal Named Entity Recognition (MNER) on social media aims to enhance textual entity prediction by incorporating image-based clues. Existing research in this domain has primarily focused on maximizing the utilization of potentially relevant information in images or incorporating external knowledge from explicit knowledge bases (KBs). However, <strong>these methods either neglect the necessity of providing the model with relevant external knowledge, or the retrieved external knowledge suffers from high redundancy.</strong> To address these problems, <strong>we propose a conceptually simple two-stage framework called Prompt ChatGPT In MNER (PGIM) in this paper.</strong> We leverage ChatGPT as an implicit knowledge engine to acquire auxiliary refined knowledge, thereby bolstering the model’s performance in MNER tasks. Specifically, we first utilize a Multimodal Similar Example Awareness module to select suitable examples from a small number of manually annotated samples. These examples are then integrated into a formatted prompt template tailored to the MNER task, guiding ChatGPT to generate auxiliary refined knowledge. Finally, the acquired knowledge is integrated with the raw text and inputted into the downstream model for further processing. Extensive experiments show that our PGIM significantly outperforms all existing state-of-the-art methods on two classic MNER datasets.</p>
</blockquote>
<p>作者是期望利用LLM来解决：</p>
<ul>
<li><p>一般的text+image的多模态小模型，可能需要外部的知识来进行识别</p></li>
<li><p>而基于外部knowledge的信息抽取方法检索到的外部知识可能相关性程较低，或者是冗余</p></li>
</ul>
<p>作者同样把LLM看做是一个可以提供high-quality auxiliary knowledge的base。</p>
<p>方法：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825160004278.png" alt="image-20230825160004278" /><figcaption>image-20230825160004278</figcaption>
</figure>
<p>首先，作者在这里使用LLM导出的外部knowledge包括了LLM抽取出的实体，以及推理的原因。</p>
<p>那么怎么样让LLM能够生成这样的knowledge呢？</p>
<p>作者随机从数据集中选择了一小部分样例，然后人工写了推理原因，这一小部分样例会作为待抽取的句子的上下文来获取LLM的knowledge。</p>
<p>作者使用cosine相似度，从这小部分人工标注的样例中选择合适的样例作为上下文（实现中选择<span class="math inline">\(5\)</span>个样例做上下文）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825160618895.png"   style="zoom:40%;" /></p>
<p>公式里的<span class="math inline">\(H\)</span>代表着multimodal representations，作者使用UMT方法导出multimodal representations来计算样例相似度。（但不清楚这里的<span class="math inline">\(H\)</span>具体是指序列中哪个embedding？）</p>
<p>拿到上下文之后，作者用来查询的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825161714124.png"   style="zoom:40%;" /></p>
<p>注意一下，只是使用了纯文本的ChatGPT，因此作者是使用BLIP2把image转化为text caption去查询的。并且在prompt里，作者提示LLM可以选择是否采用来自image的信息。</p>
<p>在拿到了LLM输出的auxiliary knowledge <span class="math inline">\(z\)</span>之后，与原有的text拼接，经过一个Transformer encoder（实验中是XLM-RoBERTa-large），最后过CRF获取实体的BIO预测标注。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825161339967.png"  style="zoom:40%;" /></p>
<p>Twitter2015数据集相比较MoRe方法提升不太明显。（image在这两个Twitter数据集上到底有多大作用，个人现在很怀疑，并且标注也不够好，有很多的噪音…）</p>
<p>case study：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230825161447842.png"   style="zoom:40%;" /></p>
<p>能够看出来，作者倾向于在LLM的输出推理过程中，直接对span进行解释，因此蓝色的句子里会很明显的线索来知道最后识别实体。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Multimodal</category>
        <category>IE</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>MNER</tag>
        <tag>MRE</tag>
      </tags>
  </entry>
  <entry>
    <title>PoE-MoE</title>
    <url>/collection/PoE-MoE/</url>
    <content><![CDATA[<h1 id="product-of-experts-and-mixture-of-experts">Product-of-Experts and Mixture-of-Experts</h1>
<p>这篇博客主要记录PoE和MoE的一些调研笔记。</p>
<span id="more"></span>
<h2 id="products-of-experts">Products of Experts</h2>
<p>Hinton 1999年 ICANN</p>
<blockquote>
<p>It is possible to combine multiple probabilistic models of the same data by multiplying the probabilities together and then renormalizing. This is a very efficient way to model high-dimensional data which simultaneously satisfies many different low dimensional constraints. Each individual expert model can focus on giving high probability to data vectors that satisfy just one of the constraints. Data vectors that satisfy this one constraint but violate other constraints will be ruled out by their low probability under the other expert models. Training a product of models appears difficult because, in addition to maximizing the probabilities that the individual models assign to the observed data, it is necessary to make the models disagree on unobserved regions of the data space. However, if the individual models are tractable there is a fairly efficient way to train a product of models. This training algorithm suggests a biologically plausible way of learning neural population codes.</p>
</blockquote>
<p>PoE实际就是一种融合多个不同分布的方法，大致上可以理解为一种分布求和（&amp;）的操作，具体公式为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321202223632.png" style="zoom:50%;" /></p>
<p>其中，<span class="math inline">\(\mathbf{d}\)</span>是指一个特定的vector，<span class="math inline">\(\theta_m\)</span>是指第<span class="math inline">\(m\)</span>个expert network的参数。上面的公式实质就是多个分布相乘，然后重新归一化。在这篇原始论文中，expert可以理解为一个弱一点的互不相同的model，比如在识别手写数字的任务中，有的expert可以用来识别数字的整体形状，有的expert可以用来关注更小的patch细节。通过融合多个experts，就可能获得一个更加强大的model。</p>
<p>上述公式对<span class="math inline">\(\theta_m\)</span>进行求导：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321203113591.png" style="zoom:50%;" /></p>
<h2 id="generalized-product-of-experts-for-learning-multimodal-representations-in-noisy-environments">Generalized Product-of-Experts for Learning Multimodal Representations in Noisy Environments</h2>
<p>ICMI 2022，一个拓展PoE并且应用到multimodal VAE上的工作。核心是通过动态评估每个模态预测隐藏state <span class="math inline">\(z\)</span>的weight，然后多个模态预测结果相乘：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230326194254000.png"  style="zoom:40%;" /></p>
<p>模型图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230326194444098.png" style="zoom:50%;" /></p>
<p>不同模态编码的隐藏状态<span class="math inline">\(z_i\)</span>的同一维度的weight和是1。</p>
<p>个人感觉这个方法和MoE的最大区别就是使用了相乘操作，而不是相加。</p>
<h2 id="adaptive-mixtures-of-local-experts">Adaptive Mixtures of Local Experts</h2>
<p>MoE，混合专家系统（mixture of experts），1991年，Neural Computation</p>
<blockquote>
<p>We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.</p>
</blockquote>
<p>这篇论文比较早，它提出混合专家系统的出发点是，如果说使用单个网络来执行多个不同的小的子任务，这些子任务之间的互相干扰可能使得学习过程变慢，泛化性也变差。</p>
<p><em>当然，上面这个观点也不总是成立的，随着网络越来越强大，很多之前认为会互相干扰的任务现在不再互相干扰了，反而能互相促进。当然从另一方面讲，这种任务会互相干扰，需要拆分的思想到现在也是随处可见的，只不过是人们对于在哪一个level的任务需要拆分的认识发生了变化。</em></p>
<p>那么，很自然的思路是，如果我们可以提前把数据集进行划分，让不同的model去学习对应的不同的数据bias，最后融合到一起是不是效果能更好，训练更简单？这种尝试学习不同bias的model被称作“expert”。</p>
<p>之前研究者提出过混合expert思路，那就是使用gating network来控制不同expert的权重：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321204741180.png"  style="zoom:50%;" /></p>
<p><span class="math inline">\(\mathbf{d}\)</span>是目标vector，<span class="math inline">\(p_i\)</span>是第<span class="math inline">\(i\)</span>个expert的权重，<span class="math inline">\(o\)</span>是第<span class="math inline">\(i\)</span>个expert的输出。</p>
<p>仔细看一下这个公式，它直接融合多个expert的输出拿到一个总的输出，然后计算这个总的输出和<span class="math inline">\(\mathbf{d}\)</span>之间的差距。它实际上鼓励每个expert去减小其它expert残留的error，这样的耦合程度比较重。如果一个expert发生了改变，那么其它所有的expert也需要发生相应的改变。</p>
<p>上面的做法是鼓励不同expert互相协作。那这篇论文中作者提出不要互相协作，而是互相竞争，每次只选择一个expert进行预测。仅仅通过简单的改变loss function就能够达到这一目的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321205100939.png"  style="zoom:50%;" /></p>
<p>这一个改变的核心是，让每一个expert都单独去靠近<span class="math inline">\(\mathbf{d}\)</span>，因此，不同expert是相对独立的优化和<span class="math inline">\(\mathbf{d}\)</span>之间的差距，而不需要优化其它expert的residual error。</p>
<p>试想下，在这种情况中，如果某个expert的error更小，那么它的权重<span class="math inline">\(p_i\)</span>会被优化得更大；如果某个expert的error更大，那么它的权重<span class="math inline">\(p_i\)</span>会被优化得更小。也就是互相竞争，哪个expert表现更好，模型会直接倾向于完全使用这个expert来解决问题，而不是总需要所有的expert参与。</p>
<p>下面是核心的思路图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321205533961.png" style="zoom:40%;" /></p>
<p>在实际中，作者使用了另一种改进版，能够更快速更好的进行梯度优化：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321205644555.png" style="zoom:50%;" /></p>
<p>梯度的改变：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321205719003.png"  style="zoom:50%;" /></p>
<div class="note info"><p>下面的解释是Hinton的CSC321课件上的说明，感觉更清晰。</p>
</div>
<p>如果输入和输出之间存在不同的映射关系，那么用把输入划分到不同的分区，然后让不同的模型来预测可能更合适。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325154431988.png"  style="zoom:50%;" /></p>
<p>这样子做的核心思想是让expert集中在表现比其它expert都要好的特定情况下。</p>
<blockquote>
<p>The key idea is to make each expert focus on predicting the right answer for the cases where it is already doing better than the other experts.</p>
</blockquote>
<p>但是如果我们直接平均的混合多个预测器，可能使得expert被用来缓解其它expert的残留错误：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325154756254.png"  style="zoom:40%;" /></p>
<p>在上图中，为了让<span class="math inline">\(expert_i\)</span>弥补其它<span class="math inline">\(expert\)</span>的错误error，会导致<span class="math inline">\(expert_i\)</span>的预测<span class="math inline">\(y_i\)</span>反而远离真正的目标<span class="math inline">\(d\)</span>。</p>
<p>因此，作者鼓励不同的expert互相竞争而不是互相合作（如同上文提到的）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325155210675.png"  style="zoom:50%;" /></p>
<p>从另一角度，最小化平方误差可以等价的看做是最大化正确答案的log概率：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325155330742.png"  style="zoom:50%;" /></p>
<p>MoE可以看做是决策树，每个expert看做是叶子节点，通过gating network将输入划分到不同的expert节点上：</p>
<blockquote>
<p>A mixture of experts can be viewed as a probabilistic way of viewing a decision stump so that the tests and leaf functions can be learned by maximum likelihood.</p>
</blockquote>
<h2 id="outrageously-large-neural-networks-the-sparsely-gated-mixture-of-experts-layer">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</h2>
<p>ICLR 2017，Google brain</p>
<blockquote>
<p>The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. <strong>We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks.</strong> A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. <strong>We present model architectures in which a MoE with up to 137 billion parameters</strong> is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.</p>
</blockquote>
<p>这篇论文提出了稀疏的MoE方法，使得基于RNN架构的模型参数量也可以以达到上千亿的规模，从而在机器翻译这些需要处理大量数据的任务上取得了较好的效果。</p>
<p>模型结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321233908500.png" style="zoom:50%;" /></p>
<p>核心在于MoE，作者使用了上千个expert network，每个expert network是<span class="math inline">\(512\times 1024\)</span>+<span class="math inline">\(ReLU\)</span>+<span class="math inline">\(1024\times 512\)</span>+<span class="math inline">\(sigmoid\)</span>总计<span class="math inline">\(1M\)</span>参数量的FFN。最后所有的expert输出相加（这里更像是前面MoE论文中作者改进前的融合形式）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321234503035.png"  style="zoom:50%;" /></p>
<p><span class="math inline">\(G_i(x)\)</span>是权重，<span class="math inline">\(E_i(x)\)</span>是第<span class="math inline">\(i\)</span>个expert的输出。</p>
<p>这么多的expert如果都需要参加计算的话计算负担太大，因此作者提出了Sparsely-Gated MoE。</p>
<p>稀疏是通过只选择少数的<span class="math inline">\(K\)</span>个expert参与最后的输出，在论文中<span class="math inline">\(K\)</span>取值在<span class="math inline">\(2-4\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321234646794.png"  style="zoom:50%;" /></p>
<p>为了让所有的expert都能够在总体样本范围内起作用，加入了高斯noise。其中的<span class="math inline">\(Softplus=log(1+e^x)\)</span>激活函数可以看做是ReLU函数的平滑。</p>
<p>最后，为了避免总是只有少数的expert会起作用，作者加入了额外的loss，希望每个expert在一个batch样本范围内，都能够起作用：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230321235034587.png" style="zoom:50%;" /></p>
<p><span class="math inline">\(X\)</span>是指一个batch的所有样本，<span class="math inline">\(w_{importance}\)</span>是人工超参，<span class="math inline">\(CV\)</span>是指coefficient of variation变异系数。<span class="math inline">\(CV=标准差/均值\)</span>，用来衡量数据的离散/变异程度，消除了量纲的影响。</p>
<p>上述公式的实质是减小不同expert在一个batch内权重和的偏差程度。</p>
<h2 id="modeling-task-relationships-in-multi-task-learning-with-multi-gate-mixture-of-experts">Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts</h2>
<p>谷歌公司，KDD 2018</p>
<blockquote>
<p>Neural-based multi-task learning has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously. However, the prediction quality of commonly used multi-task models is often sensitive to the relationships between tasks. It is therefore important to <strong>study the modeling tradeoffs between task-specific objectives and inter-task relationships.</strong></p>
<p>In this work, <strong>we propose a novel multi-task learning approach, Multi-gate Mixture-of-Experts (MMoE), which explicitly learns to model task relationships from data. We adapt the Mixture-ofExperts (MoE) structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task.</strong> To validate our approach on data with dierent levels of task relatedness, we rst apply it to a synthetic dataset where we control the task relatedness. We show that the proposed approach performs better than baseline methods when the tasks are less related. We also show that the MMoE structure results in an additional trainability benet, depending on different levels of randomness in the training data and model initialization. Furthermore, we demonstrate the performance improvements by MMoE on real tasks including a binary classification benchmark, and a large-scale content recommendation system at Google.</p>
</blockquote>
<p>将MoE应用到多任务学习上的工作，提出了MMoE方法，在推荐任务上进行了验证：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325215048012.png" /></p>
<p>最大的改进点有两个：</p>
<ul>
<li>不同task之间的底层共享网络使用<span class="math inline">\(n\)</span>个expert网络代替</li>
<li>每个task有独立的gating network，这样就让每个task可以自由选择底层共享的网络结构部分</li>
</ul>
<p>核心数学公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325215243677.png"  style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(h^k\)</span>代表task <span class="math inline">\(k\)</span>的上层tower network，<span class="math inline">\(f^k\)</span>是MMoE选择的experts，<span class="math inline">\(g^k\)</span>是task <span class="math inline">\(k\)</span>的gating network，<span class="math inline">\(f_i\)</span>是第<span class="math inline">\(i\)</span>个expert网络。</p>
<p>如果两个task关联性比较大，那么它们选择的experts会重叠的比较多；如果关联性较弱，那么选择experts重叠的就比较少。</p>
<h2 id="gshard-scaling-giant-models-with-conditional-computation-and-automatic-sharding">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</h2>
<p>谷歌公司，ICLR 2021</p>
<blockquote>
<p>Neural network scaling has been critical for improving the model quality in many real-world machine learning applications with vast amounts of training data and compute. Although this trend of scaling is affirmed to be a sure-ﬁre approach for better model quality, there are challenges on the path such as the computation cost, ease of programming, and efficient implementation on parallel devices. In this paper we demonstrate conditional computation as a remedy to the above mentioned impediments, and demonstrate its efficacy and utility. We make extensive use of GShard, a module composed of a set of lightweight annotation APIs and an extension to the XLA compiler to enable large scale models with up to trillions of parameters. GShard and conditional computation enable us to scale up multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-ofExperts. We demonstrate that such a giant model with 600 billion parameters can efficiently be trained on 2048 TPU v3 cores in 4 days to achieve far superior quality for translation from 100 languages to English compared to the prior art.</p>
</blockquote>
<p>首个将MoE应用到Transformer的模型，使用MoE来构建了一个用于机器翻译6千亿参数量的Transformer模型，同时保证计算效率。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230324142555633.png" /></p>
<p>MoE在Transformer中的几点设计：</p>
<ul>
<li>MoE是设计在FFN层，每隔一个Transformer block，替换FFN为MoE</li>
<li>MoE是稀疏的，只选择top-2的experts</li>
<li>每个expert network是个两层MLP<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230324142806356.png" style="zoom:50%;" /></li>
<li>gating network是个简单的softmax<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230324142930731.png" style="zoom:50%;" /></li>
<li>为了让expert负载均衡，每个expert都能够充分训练，给每个expert设计了容量上限，如果某个输入token选择的expert超过了容量上限，这个expert不会处理输入的token</li>
<li>加入了一个辅助的loss来进一步平衡expert负载<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230324143143898.png" style="zoom:50%;" /></li>
<li>对于选择的第2重要expert，如果它的weight过于低可能没有太大必要让它继续处理，因此作者直接让top-2 expert依据weight大小随机决定是否要让top-2 expert网络处理。</li>
</ul>
<h2 id="switch-transformers-scaling-to-trillion-parameter-models-with-simple-and-efficient-sparsity">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</h2>
<p>谷歌公司，JMLR 2022</p>
<blockquote>
<p>In deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) models defy this and instead select different parameters for each incoming example. The result is a sparsely-activated model—with an outrageous number of parameters—but a constant computational cost. However, despite several notable successes of MoE, widespread adoption has been hindered by complexity, communication costs, and training instability. We address these with the introduction of the Switch Transformer. <strong>We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs.</strong> Our proposed training techniques mitigate the instabilities, and we show large sparse models may be trained, for the ﬁrst time, with lower precision (bfloat16) formats. We design models based off T5-Base and T5-Large (Raﬀel et al., 2019) to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the “Colossal Clean Crawled Corpus”, and achieve a 4x speedup over the T5-XXL model.</p>
</blockquote>
<p>作者通过简化MoE实现了在保持computing efficiency的情况下增大模型参数量，最终实现了上万亿参数量的模型。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230323175101552.png" /></p>
<p>这里最大的简化就是仅仅激活top-1的expert。作者把只选择1个expert的做法称为switch，类比了电路开关，一个开关只能够有一个触点让一个灯泡亮。</p>
<p>另一个有趣的设计是考虑expert负载均衡，通过加入一个loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230323175337558.png" style="zoom:50%;" /></p>
<p>上面这个auxiliary loss在每个<span class="math inline">\(f_i\)</span>也就是分配给expert <span class="math inline">\(i\)</span>的token数量不变的情况下，会尝试让<span class="math inline">\(p_i\)</span>减小，那么也会逐渐的让<span class="math inline">\(f_i\)</span>变小，最终让所有expert分配的<span class="math inline">\(f_i\)</span>比较均匀。</p>
<h2 id="multimodal-contrastive-learning-with-limoe-the-language-image-mixture-of-experts">Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts</h2>
<p>谷歌大脑，NeurIPS 2022，使用MoE构建的大规模多模态预训练模型LIMoE。</p>
<blockquote>
<p>Large sparsely-activated models have obtained excellent performance in multiple domains. However, such models are typically trained on a single modality at a time. We present the Language-Image MoE, LIMoE, a sparse mixture of experts model capable of multimodal learning. LIMoE accepts both images and text simultaneously, while being trained using a contrastive loss. MoEs are a natural fit for a multimodal backbone, since expert layers can learn an appropriate partitioning of modalities. However, new challenges arise; in particular, training stability and balanced expert utilization, for which we propose an entropy-based regularization scheme. Across multiple scales, we demonstrate remarkable performance improvement over dense models of equivalent computational cost. LIMoE-L/16 trained comparably to CLIP-L/14 achieves 78.6% zero-shot ImageNet accuracy (vs. 76.2%), and when further scaled to H/14 (with additional data) it achieves 84.1%, comparable to state-of-the-art methods which use larger custom per-modality backbones and pre-training schemes. We analyse the quantitative and qualitative behavior of LIMoE, and demonstrate phenomena such as differing treatment of the modalities and the organic emergence of modality-specific experts.</p>
</blockquote>
<p>下图是LIMoE的结构，单纯从结构图上还不能看出有什么大的特点：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325104045137.png"  style="zoom:30%;" /></p>
<p>LIMoE使用了单塔Transformer同时处理图像和文本，使用对比学习对齐image-language pair：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325104351284.png" style="zoom:50%;" /></p>
<p>LIMoE除了使用一般的expert负载均衡loss外，还额外考虑了当MoE应用到多模态时遇到的新问题。由于不同模态的数据量不平衡，数据量少的模态可能无法均匀分配到不同expert上，但是从整体上来看experts仍然是负载均衡的。</p>
<p>因此LIMoE对于单个模态<span class="math inline">\(m\)</span>引入了额外的两个loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325104753399.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230325105122419.png" style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(\mathcal{H}\)</span>表示熵，<span class="math inline">\(x_i\)</span>是模态<span class="math inline">\(m\)</span>输入的一个token。local loss是每个token对应的expert概率熵的平均，global loss是每个expert在所有输入token范围内的总体概率熵的平均的负值。</p>
<p>local loss迫使每个token对应的expert概率预测分布更加集中；</p>
<p>global loss迫使expert在输入范围内分布更加分散；</p>
<h2 id="using-mixture-of-expert-models-to-gain-insights-into-semantic-segmentation">Using Mixture of Expert Models to Gain Insights into Semantic Segmentation</h2>
<p>CVPR 2020</p>
<p>MoE应用在CV领域的一篇论文，通过将图片划分为不同的子集，然后让两个expert分别去处理，让expert学习不同的映射关系，最后集成两个expert网络的预测输出：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230326164558508.png" /></p>
<p>expert网络的CNN架构一样，中间的gating network接收的是expert网络第42层的feature map输出。作者使用MoE，然后对比expert 1、2和MoE融合的预测label，尝试给一些可解释理由。</p>
<h2 id="moe与poe对比">MoE与PoE对比</h2>
<p>PoE的一个坏处是会让某个过分confident的expert起作用，比如一个expert的概率预测过于低，会导致最后整个融合的概率也低，相比较之下，MoE就更加温和：</p>
<blockquote>
<p>When employing PoE, each expert holds the power of veto—in the sense that the joint distribution will have low density for a given set of observations if just one of the marginal posteriors has low density.</p>
<p>By contrast, MoE does not suffer from potentially overconfident experts, since it effectively takes a vote amongst the experts, and spreads its density over all the individual experts.</p>
<p><em>Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models NeurIPS 19</em></p>
</blockquote>
]]></content>
      <categories>
        <category>Paper</category>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>TemporalKG-survey-list</title>
    <url>/collection/TemporalKG-survey-list/</url>
    <content><![CDATA[<h1 id="temporal-knowledge-graph">Temporal Knowledge Graph</h1>
<p>对目前出现的temporal KG相关论文和资源的调研文献list。</p>
<span id="more"></span>
<table>
<colgroup>
<col style="width: 17%" />
<col style="width: 14%" />
<col style="width: 17%" />
<col style="width: 14%" />
<col style="width: 17%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th>标题</th>
<th>任务</th>
<th>解决问题</th>
<th>主要技术</th>
<th>数据集</th>
<th>参考价值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>RotateQVS: Representing Temporal Information as Rotations in Quaternion Vector Space for Temporal Knowledge Graph Completion. (ACL 22)</td>
<td>知识图谱补全</td>
<td>认为之前的方法无法很好的建模时空relation以及relation之间的联系</td>
<td>Trans系列</td>
<td>ICEWS14、ICEWS05-15、YAGO11k、 GDELT</td>
<td>参考如何在复杂的向量空间下建模时空信息</td>
</tr>
<tr class="even">
<td>Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs (ACL 22)</td>
<td>QA</td>
<td>针对一个问题可能涉及多个不同时间片进行了探究</td>
<td>通过引入一个time-order学习的任务改进了TCompLEx方法</td>
<td>CRONQUESTIONS （目前出现的最大的利用TKG的QA数据集）</td>
<td>可以参考改进的学习任务</td>
</tr>
<tr class="odd">
<td>Search from History and Reason for Future: Two-stage Reasoning on Temporal Knowledge Graphs (ACL 21)</td>
<td>知识图谱补全</td>
<td>作者任务在TKG下的推理，需要两个步骤，首先是线索搜集，然后是具体的推理。大多数的方法忽略了第一步</td>
<td>RL和GNN</td>
<td>ICE14、ICE05-15、ICE18、 GDELT</td>
<td>可以参考第二步，利用GNN建模时空信息</td>
</tr>
<tr class="even">
<td>TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection (WWW 22)</td>
<td>Ethereum Phishing Scams Detection</td>
<td></td>
<td>GCN</td>
<td>作者从Etherscan上爬取的数据集</td>
<td>搞清楚GCN在时序信息建模中的作用</td>
</tr>
<tr class="odd">
<td>Time-aware Entity Alignment using Temporal Relational Attention. （WWW 22）</td>
<td>Entity Alignment</td>
<td>之前没有探究过在TKG和Open KG之间的实体对齐</td>
<td>GCN</td>
<td></td>
<td>GCN用于表示学习，在实体对齐任务下进行了评估</td>
</tr>
<tr class="even">
<td>TREND: TempoRal Event and Node Dynamics for Graph Representation Learning （WWW 22）</td>
<td>Temporal Graph Representation Learning</td>
<td>之前的方法没有探究过如何处理新出现的节点</td>
<td>GCN</td>
<td>CollegeMsg、cit-HepTh、Wikipedia、Taobao</td>
<td>GCN建模时序信息</td>
</tr>
<tr class="odd">
<td>Element-guided Temporal Graph Representation Learning for Temporal Sets Prediction （WWW 22）</td>
<td>Temporal Sets Prediction</td>
<td>之前的方法无法建模不同set之间的协同信息</td>
<td>GCN</td>
<td>DC、TaoBao、JingDong、TMS</td>
<td>GCN建模时序信息</td>
</tr>
<tr class="even">
<td>STAM: A Spatiotemporal Aggregation Method for Graph Neural Network-based Recommendation （WWW 22）</td>
<td>Recommendation</td>
<td>之前利用GNN进行推荐的方法没有考虑时序的信息</td>
<td>GNN</td>
<td>MovieLens、Amazon、Taobao</td>
<td>GCN获取的邻居信息加入了时序信息</td>
</tr>
<tr class="odd">
<td>HINTS: Citation Time Series Prediction for New Publications via Dynamic Heterogeneous Information Network Embedding （WWW 21）</td>
<td>作者提出了一个新的问题，预测一篇论文的引用时间序列</td>
<td>之前的方法大多是根据已有的leading citation value来进行预测，无法处理冷启动问题</td>
<td>GNN</td>
<td>AMiner、APS</td>
<td>HGNN结合时序信息，并且尝试解决冷启动问题</td>
</tr>
<tr class="even">
<td>TLogic: Temporal Logical Rules for Explainable Link Forecasting on Temporal Knowledge Graphs (AAAI 22)</td>
<td>Link Forecasting</td>
<td>作者认为之前对于时序知识图谱的建模缺少可解释性，也缺少对于推理逻辑链的研究</td>
<td>随机游走</td>
<td>ICEWS14、ICEWS18、ICEWS0515</td>
<td>一个可解释的建模方法</td>
</tr>
<tr class="odd">
<td>Temporal Knowledge Graph Completion using Box Embeddings （AAAI 22）</td>
<td>知识图谱补全</td>
<td>作者认为之前的方法都没有从时空推理的角度进行研究</td>
<td>在BoxE方法基础上进行了拓展</td>
<td>ICEWS14、 ICEWS05-15、 GDELT</td>
<td>作者对时空知识图谱的各种性质进行了验证</td>
</tr>
<tr class="even">
<td>Neural Latent Space Model for Dynamic Networks and Temporal Knowledge Graphs （AAAI 21）</td>
<td>Link Forecasting</td>
<td>作者这项工作能够同时处理同构网络和异构网络</td>
<td>GRU</td>
<td>UCI、Enron、Yelp、ML-10M、WIKI、YAGO</td>
<td>作者从概率分布的角度分析出发，逐步建立一个使用神经网络的模型</td>
</tr>
<tr class="odd">
<td>Dynamic Knowledge Graph Alignment （AAAI 21）</td>
<td>Knowledge Graph Alignment</td>
<td>之前在知识图谱对齐中的方法通常假设KG是静态的</td>
<td>GCN</td>
<td>DBP15K</td>
<td>GCN用于时序知识图谱对齐</td>
</tr>
<tr class="even">
<td>Learning from History: Modeling Temporal Knowledge Graphs with Sequential Copy-Generation Networks （AAAI 21）</td>
<td>知识图谱补全</td>
<td>之前对于时序知识图谱建模的方法忽略了在过去的fact当中常常存在重复性的知识</td>
<td>copy-generation</td>
<td>ICEWS18、ICEWS14、GDELT、WIKI、YAGO</td>
<td></td>
</tr>
<tr class="odd">
<td>ChronoR: Rotation Based Temporal Knowledge Graph Embedding （AAAI 21）</td>
<td>知识图谱补全</td>
<td></td>
<td>基于向量空间旋转操作的方法</td>
<td>ICEWS14、ICEWS05-15、YAGO15K</td>
<td></td>
</tr>
<tr class="even">
<td>Relational Learning to Capture the Dynamics and Sparsity of Knowledge Graphs （AAAI 21）</td>
<td>知识图谱补全</td>
<td>作者希望能够同时解决时序问题和数据稀疏的问题</td>
<td></td>
<td>-</td>
<td></td>
</tr>
<tr class="odd">
<td>Diachronic Embedding for Temporal Knowledge Graph Completion （AAAI 2020）</td>
<td>知识图谱补全</td>
<td>作者认为之前的方法大多会给TKG上的实体都赋予一个静态的表示，但是实体的特征会随着时间而改变。因此，作者提出将实体和对应的时间点作为特征，得到随时间改变的向量</td>
<td></td>
<td>ICEWS14、ICEWS05-15、GDELT</td>
<td>一个model agnostic的方法</td>
</tr>
<tr class="even">
<td>Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion (KDD 21)</td>
<td>Temporal Knowledge Graph Completion</td>
<td>作者认为之前出现的很多建模TKG的方法是将静态的KGE方法进行拓展，这导致它们往往无法：1. 考虑相关的邻居信息 2. 进行基于路径的解释</td>
<td>GNN</td>
<td>ICEWS14、ICEWS05-15、Wikidata11k</td>
<td>GNN建模时空知识图谱</td>
</tr>
<tr class="odd">
<td>Temporal Knowledge Graph Reasoning Based on Evolutional Representation Learning （SIGIR 21）</td>
<td>知识图谱补全</td>
<td>作者尝试对之前利用evolutional learning的方法进行改进，作者认为之前的方法无法处理出现在同一时间片下的facts</td>
<td>GNN</td>
<td>ICEWS18、ICEWS14、ICEWS05-15、WIKI、YAGO、GDELT</td>
<td>GNN建模时空知识图谱</td>
</tr>
<tr class="even">
<td>TIE: A Framework for Embedding-based Incremental Temporal Knowledge Graph Completion （SIGIR 21）</td>
<td>知识图谱补全</td>
<td>作者认为之前的方法存在以下问题：1. 信息的遗忘 2. 对于改变的fact的不稳定性 3. 训练效率低</td>
<td>Incremental learning</td>
<td>YAGO11k、Wikidata12k</td>
<td>增量学习，之前没有接触过</td>
</tr>
<tr class="odd">
<td>Time-dependent Entity Embedding is not All You Need: A Re-evaluation of Temporal Knowledge Graph Completion Models under a Unified Framework （EMNLP 21）</td>
<td>知识图谱补全</td>
<td>作者对于六种现存的TKG建模的方法的实现策略进行了全面的评估。作者发现通过实验，不同的方法在不同数据集上的性能并不和论文中声称的一致</td>
<td>-</td>
<td>ICEWS14、 ICEWS11-14、 GDELT-m10</td>
<td>对目前的KGE方法可能存在的问题进行了解，便于后续的学习</td>
</tr>
<tr class="even">
<td>TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph Forecasting （EMNLP 21）</td>
<td>Knowledge Graph Forecasting</td>
<td>作者提出了首个利用强化学习实现知识图谱forecasting的方法</td>
<td>强化学习</td>
<td>ICEWS14、ICEWS18、WIKI、YAGO</td>
<td>强化学习用于时序知识图谱建模</td>
</tr>
<tr class="odd">
<td>Learning Neural Ordinary Equations for Forecasting Future Links on Temporal Knowledge Graphs （EMNLP 21）</td>
<td>Knowledge Graph Forecasting</td>
<td>作者认为之前的方法大多将TKG建模到离散的状态空间下。作者提出将GCN和神经微分方程（neural ordinary differential equations）结合。</td>
<td>GCN</td>
<td>ICEWS14、ICEWS18、 ICEWS05-15、YAGO、WIKI</td>
<td>GCN的拓展版本，用于建模时序知识图谱</td>
</tr>
<tr class="even">
<td>Time-aware Graph Neural Network for Entity Alignment between Temporal Knowledge Graphs （EMNLP 21）</td>
<td>TKG对齐</td>
<td>作者认为之前的知识图谱对齐方法忽略了很多知识图谱中存在的时序信息</td>
<td>GNN</td>
<td>DICEWS-1K、DICEWS-200、YAGO-WIKI50K-5K、YAGO-WIKI50K-1K、YAGO-WIKI20K</td>
<td>GCN用于TKG对齐</td>
</tr>
<tr class="odd">
<td>TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion (EMNLP 20)</td>
<td>知识图谱补全</td>
<td>作者认为之前的方法没有能够显式地利用多跳的邻居信息</td>
<td>GNN</td>
<td>ICEWS、ICEWS05-15、GDELT</td>
<td>GNN建模时空知识图谱</td>
</tr>
<tr class="even">
<td>Recurrent Event Network: Autoregressive Structure Inference over Temporal Knowledge Graphs （EMNLP 20）</td>
<td>知识图谱补全</td>
<td>作者认为之前的方法只能够预测发生在过去的fact，而无法预测要连续发生在未来的fact（类似外推）</td>
<td>GNN</td>
<td>ICEWS18、GDELT、 ICEWS14、WIKI、 YAGO</td>
<td>GNN建模时空知识图谱，并且尝试进行外推</td>
</tr>
<tr class="odd">
<td>Temporal Knowledge Base Completion: New Algorithms and Evaluation Protocols (EMNLP 20)</td>
<td>知识图谱补全</td>
<td>作者提出了一个建模时序知识图谱的新方法 TIMEPLEX。更重要的是，作者发现了在之前的评估策略中可能出现的不正确的评估方式</td>
<td>复数域下的建模方法</td>
<td>WIKIDATA12k、YAGO11k、ICEWS14、ICEWS05-15</td>
<td>评估策略的影响很关键</td>
</tr>
<tr class="even">
<td>Domain Knowledge Empowered Structured Neural Net for End-to-End Event Temporal Relation Extraction （EMNLP 20）</td>
<td>关系抽取</td>
<td>作者在神经网络中加入了分布约束来避免之前的方法常估计的硬约束条件</td>
<td>Bert-based</td>
<td>TimeBank-Dense、I2B2-TEMPORAL</td>
<td></td>
</tr>
<tr class="odd">
<td>DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for Temporal Knowledge Graph Completion (EMNLP 20)</td>
<td>知识图谱补全</td>
<td>作者认为之前的TKG建模方法大多是在欧式空间下的建模方法，而作者尝试基于黎曼流形对实体进行建模</td>
<td>基于语义匹配</td>
<td>ICEWS14、ICEWS05-15、GDELT</td>
<td>非欧式空间下的TKG建模方法</td>
</tr>
<tr class="even">
<td>HIP Network: Historical Information Passing Network for Extrapolation Reasoning on Temporal Knowledge Graph （IJCAI 21）</td>
<td>Extrapolation reasoning</td>
<td>作者认为之前的TKG方法，对于时序信息的利用不够充分。</td>
<td>GNN</td>
<td>ICEWS14、ICEWS18、GDELT、WIKI、YAGO</td>
<td>GNN用于时序知识图谱</td>
</tr>
<tr class="odd">
<td>Temporal Attribute Prediction via Joint Modeling of Multi-Relational Structure Evolution (IJCAI 20)</td>
<td>时序知识图谱推理</td>
<td>之前没有人把temporally evolving graphs和 time series prediction结合到一起</td>
<td>RNN</td>
<td>ATG、CAC、MTG、GDELT</td>
<td>-</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Reading-list</category>
        <category>TKG</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>TKG</tag>
        <tag>Reading-list</tag>
      </tags>
  </entry>
  <entry>
    <title>good-paper-sentences-collection</title>
    <url>/collection/paper-sentences-collection/</url>
    <content><![CDATA[<p>好的句子收集</p>
<span id="more"></span>
<ol type="1">
<li>Our evaluation shows that our approach obtains better results than task-specific handcrafted representations across different tasks and programming languages （我们的评估结果显示....）</li>
<li>Leveraging machine learning models for predicting program properties(利用机器学习模型预测程序属性)</li>
<li>We present a novel program representation （我们提出了一个新的...）</li>
<li>In this paper, we demonstrate the power and generality of AST paths on the following tasks: （利用下面的任务说明了....）</li>
<li>Empirical studies have shown that...（实验性的研究表明...）</li>
<li>Raychev et al. （...等人）i.e. (也就是说) e.g. (比如)</li>
<li>Automatic generation may produce a prohibitively large number of paths.（产生出令人望而却步的代价...）</li>
<li>In Sections 3.1 and 3.2 we present CRFs and word2vec(在第几部分我们介绍了...) in this section(这一部分...)</li>
<li>neural-network based approaches have shown（基于神经网络的方法...）</li>
<li>we base the following definitions on pairwise paths between AST terminals.（base...on... 基于）</li>
<li>if and only if...(当且仅当)</li>
<li>This paper makes the following contributions.（本论文的贡献集中在以下方面）</li>
<li>Section 6 and 7 are dedicated to the discussion of our results and conclusions.（第6部分和第七部分集中于）</li>
<li>In the next section we describe（在下一部分我们描述了）</li>
<li>To summarize, our E.T.-RNN approach would possibly work better than（总的来说.....）</li>
<li>In this following,（在这之后）</li>
<li>Khashman tests NN classiﬁers with different training to validation data ratios （测试了不同训练集和测试集比...）</li>
<li>By employing different kernel functions, SVM technique can be applied to（通过应用不同的核函数...）</li>
<li>The process of boosting continues until the loss function reduction becomes limited.（直至损失函数收敛）</li>
<li>In accordance with the suggestion of Ala’raj and Abbod (2016b),（根据....的建议，不要总是使用according to）</li>
<li>Ranging from early matrix factorization to <strong>recently emerged</strong> deep learning based methods,（从早期的矩阵分解，到现在出现的深度学习方法）</li>
<li><strong>Distinct from HOP-Rec</strong>, we contribute a new technique to integrate high-order connectivities into the prediction model,(与......不同，没有用到different from)</li>
<li>This not only increases the model representation ability, but also <strong>boosts</strong> the performance for recommendation(提升了性能，使用了boost这个词，而不是improve)</li>
<li>Towards this end, we perform experiments over user groups of different sparsity levels. (为此，我们开展了实验.....)</li>
<li>For fair consideration, the latent dimensions of all compared baselines are set the same as in Table 2,（处于公平角度考虑....）</li>
<li>The results demonstrate the significant superiority of RippleNet over strong baselines（结果展示了模型的明显的提升效果）</li>
<li>Recently, many studies on extending deep learning approaches for graph data have emerged（最近出现了很多的研究.....）</li>
<li>Our paper makes notable contributions summarized as follows（我们论文的贡献总结如下：）</li>
<li>we refer the readers to [39]（我们推荐/建议读者参考...）</li>
<li>Attention mechanisms have become almost a de facto standard in many sequence-based tasks（注意力机制已经成为事实上的标准....）</li>
<li>In general, the modeling process boils down to extracting local or global connectivity patterns between entities（通常，建模过程归结为....）</li>
<li>we show marked performance gains in comparison to state-of-the-art methods on all datasets.（和目前最好的结果表现出了显著的结果）</li>
<li>To the best of our knowledge,（就我们目前所知）</li>
<li>aroused considerable research interest（引起了很大的研究兴趣）</li>
<li>we ﬁnd that COMPGCN outperforms all the existing methods in 4 out of 5 metrics on FB15k-237 and in 3 out of 5 metrics on WN18RR dataset.(数据集里的在4个里面的五个指标上取得了更好的结果)</li>
<li>We defer this as future work（我们推迟这个作为将来的工作）</li>
<li>a blowup in the number of parameters that need to be estimated.（大量需要估计的参数）</li>
<li>Another approach for graph embeddings is thus to leverage proven approaches for language embeddings.（使用已经被证明过的方法...）</li>
<li>we also discuss quality metrics that provide ways to measure quantitative aspects of these dimensions. （讨论定量的方面....）</li>
<li>GNNs are notorious for their poor scalability.（GNN因差可扩放性而臭名昭著）</li>
<li>We speculate that（我们推测...）</li>
<li>In this setting, we compare the（在这种设置下）</li>
<li>we leave these results out of our comparison table.（我们在对比结果中排除了....）</li>
<li>Three benchmark datasets (FB15k-237, WN18RR and FB15k-237-Attr) are utilized in this study. （在本文中使用了...数据集）</li>
<li>Our work is mainly related to two lines of research（我们的工作主要与两方面的研究有关）</li>
<li>Empirically, our model yields considerable performance improvements over existing embedding models,（我们的论文取得了很大的效果提升）</li>
<li>We empirically evaluate different choices of entity representations and relation representations under this framework on the canonical link prediction task（我们在典型的，标准的任务上评估了）</li>
<li>SEEK can achieve either state-of-the-art or highly competitive performance on a variety of benchmarks for KGE compared with existing methods.（和现在的方法相比，方法达到了有竞争力或者目前最优的解）</li>
<li>Numerous efforts have since continued to push the boundaries of recurrent language models（人们一直不断努力扩大模型的界限）</li>
<li>Our overarching interest is whether（我们首要的兴趣是...）</li>
<li>Our experimental study provides additional evidence for this ﬁnding.（我们的实验为之间的发现提供了额外的证明）</li>
<li>Similar remarks hold for RESCAL and DistMult as well as (albeit to a smaller extent) ConvE and TransE.（类似的说法对于....也成立）</li>
<li>RESCAL (Nickel et al., 2011), which constitutes one of the ﬁrst KGE models（Resscal被视作KGE的第一个工作之一）</li>
<li>predicting the properties of molecules and materials using machine learning (and especially deep learning) is still in its infancy.（使用机器学习预测化学分子或者材料的属性仍然处在初期阶段）</li>
<li>most research applying machine learning to chemistry tasks has revolved around feature engineering.（大多数的研究都是围绕...）</li>
<li>empowering HGT to maintain dedicated representation for different types of nodes and edges. (使HGT能够为不同的node和edge获得专门的表示)</li>
<li>Figure 1 depicts he macro-structure of Mixer.（图1描绘了整体结构）</li>
<li>Vinyals et al. [32] and Ravi and Larochelle [24] apply Matching Networks using cosine distance. However for both Prototypical Networks and Matching Networks any distance is permissible（对于模型来说...都是允许的）</li>
<li>For Protypical Networks, we conjecture this is primarily due to cosine distance not being a Bregman divergence（我们猜测某种现象/结果可能是因为...）</li>
<li>While suggestive as a research result, in terms of practical applications, the zero-shot performance of GPT-2 is still far from use-able.（作为实验结果有启发性）</li>
<li>We <strong>hold that</strong> the poor performance of the pre-trained multimodal model may be attributed to the fact that the pre-training datasets and objects have gaps in information extraction tasks. (我们认为/我们假设)</li>
<li><strong>To steer our models towards appropriate behaviour</strong> at a more fine-grained level, we rely heavily on our models themselves as tools.（为了使模型更能够…）</li>
</ol>
]]></content>
      <tags>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title>Essence-of-linear-algebra-3b1b</title>
    <url>/math/Essence-of-linear-algebra-3b1b/</url>
    <content><![CDATA[<h1 id="essence-of-linear-algebra">Essence of linear algebra</h1>
<p>这篇文章是3blue1brown的Essence of linear algebra系列视频的笔记</p>
<ol type="1">
<li>Vectors</li>
<li>Linear combinations, span and basis vectors</li>
<li>Linear transformations and matrices</li>
<li>Matrix multiplication</li>
<li>The Determinant</li>
<li>Inverse Matrices, column space and null space</li>
<li>Nonsquare matrices as transformation between dimensions</li>
<li>Dot products and Duality</li>
<li>Cross products</li>
<li>Change of basis</li>
<li>Eignvectors and eigenvalues</li>
<li>Abstract vector spaces</li>
</ol>
<span id="more"></span>
<h2 id="vectors">1 Vectors</h2>
<p>如何认识向量？</p>
<p>从一个物理学生的角度来看，一个向量是长度一定，角度一定，在空间中可以任意的移动。</p>
<p>从一个计算机学生的角度来看，一个向量是一系列数字的list，这些数字可能具有独特的现实含义，比如房子的面积、单位售价等。</p>
<p>从一个数学学家的角度来看，向量可以代表任何事物，只要能够保证向量相加和向量数乘有意义即可。</p>
<p>如果尝试从几何的角度来看，可以看做坐标系下的箭头，起始点是原点，向量是坐标系下的不同数轴的坐标，这些坐标说明了如何从原点到达箭头的终点。</p>
<p>向量的加法，可以看做是先沿着向量<span class="math inline">\(x\)</span>运动，然后沿着向量<span class="math inline">\(y\)</span>运动。</p>
<p>向量的数乘，就是长度的缩放操作。</p>
<h2 id="linear-combinations-span-and-basis-vectors">2 Linear combinations, span and basis vectors</h2>
<p>向量可以看做是基向量的线性组合，不同坐标，表示缩放不同数轴上的基向量。</p>
<p>span的定义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929190419825.png" alt="image-20210929190419825" style="zoom:33%;" /></p>
<p>basis vector的定义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929190523369.png" alt="image-20210929190523369" style="zoom:33%;" /></p>
<h2 id="linear-transformations-and-matrices">3 Linear transformations and matrices</h2>
<p>Linear transformation：</p>
<ul>
<li>transformation就是一种函数，用在线代领域是为了强调对于向量的变换操作</li>
<li>前面的linear有两个限制：转换后的直线仍然是直线，并且原点保持固定</li>
</ul>
<p>原点固定，是因为任何矩阵与0向量相乘，都是0向量，原点始终固定。</p>
<p>线性变换的重要性质是，所有的变换的网格线（网格是想象中的一些向量的终点）是保持平行且等距分布的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210926105607256.png" alt="image-20210926105607256" style="zoom:50%;" /></p>
<p>所有变换后的新向量，都可以通过基向量的变换进行相同的转换操作。</p>
<p>在一个二维转换中，我们可以把矩阵的列完全看做是变换后的基向量</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210926105059810.png" alt="image-20210926105059810" style="zoom:50%;" /></p>
<p>向量<span class="math inline">\([a,c]\)</span>是变换后的基向量<span class="math inline">\(\hat{i}\)</span>，<span class="math inline">\([b,d]\)</span>是变换后的基向量<span class="math inline">\(\hat{j}\)</span>。</p>
<p>因此，linear transformation可以看做是空间的一种变换，即基向量的变换。因此，我们可以直观上把矩阵看做是对空间的变换。</p>
<h2 id="matrix-multiplication">4 Matrix multiplication</h2>
<p>矩阵相乘可以看做是连续的空间变换，这也解释了为什么矩阵位置互换，结果不能保证一样。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210927101847889.png" alt="image-20210927101847889" style="zoom: 33%;" /></p>
<p>上面的矩阵<span class="math inline">\(M_2\)</span>把矩阵<span class="math inline">\(M_1\)</span>的列向量进行变换，矩阵<span class="math inline">\(M_1\)</span>的列向量可以看做是新的基向量<span class="math inline">\(\hat{i}\)</span>。</p>
<h2 id="the-determinant">5 The Determinant</h2>
<p>行列式determinate的几何含义，以二维平面为例，就是以单位basis向量组成的单位正方形的面积的变化。比如：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928104234148.png" alt="image-20210928104234148" style="zoom: 33%;" /></p>
<p>特殊的情况是determine为0：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928104342827.png" alt="image-20210928104342827" style="zoom:33%;" /></p>
<p>此时整个空间被压缩为一条直线，甚至是一个点。因此，如果我们计算某个matrix的行列式是否为0，我们就知道这个矩阵是否表示把空间压缩到更小的维度上。</p>
<p>此时还有另外的问题，那就是行列式是可以为负数的，此时，行列式代表矩阵会把空间翻转（fliping），行列式的绝对值仍然是面积的变化。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928153905266.png" alt="image-20210928153905266" style="zoom:33%;" /></p>
<p>对于行列式的变换，假设<span class="math inline">\(\hat{i}\)</span>逐渐接近<span class="math inline">\(\hat{j}\)</span>，看下面一系列的动画：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928154121351.png" alt="image-20210928154121351" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928154143886.png" alt="image-20210928154143886" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928154205327.png" alt="image-20210928154205327" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928154221033.png" alt="image-20210928154221033" style="zoom:33%;" /></p>
<p>出现了负数的行列式。</p>
<p>如果在三维空间中，那么矩阵行列式就是单位体积的变化：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928154422622.png" alt="image-20210928154422622" style="zoom: 33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928154512960.png" alt="image-20210928154512960" style="zoom:33%;" /></p>
<p>因为矩阵的列向量可以看做是新的基向量，如果行列式为0，就表示出现了列向量线性相关的情况，某个或者多个列向量可以由其它列向量表示。</p>
<p>行列式的计算过程，实际就是在计算这个面积/体积的变化，比如：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928155247793.png" alt="image-20210928155247793" style="zoom:33%;" /></p>
<p>懂了行列式的几何意义，可以很轻松的理解下面的定理：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928155521866.png" alt="image-20210928155521866" style="zoom:33%;" /></p>
<p>对空间进行<span class="math inline">\(M_1M_2\)</span>然后的变换后的面积变化=先进行<span class="math inline">\(M_2\)</span>变换，然后进行<span class="math inline">\(M_1\)</span>变换后的面积变化。本质是一样的。</p>
<h2 id="inverse-matrices-column-space-and-null-space">6 Inverse Matrices, column space and null space</h2>
<p>我们都知道，对于多元一次的方程组，求解未知变量，可以用矩阵的角度来看：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928161330460.png" alt="image-20210928161330460" style="zoom:33%;" /></p>
<p>从矩阵是空间变换的角度来看，我们已知变换后的向量<span class="math inline">\(v\)</span>，只要逆着矩阵<span class="math inline">\(A\)</span>的变换，就能够找到空间变换前的向量<span class="math inline">\(x\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928161613839.png" alt="image-20210928161613839" style="zoom:33%;" /></p>
<p>这就是矩阵的逆矩阵<span class="math inline">\(A^{-1}\)</span>，逆矩阵乘以矩阵，表示的是什么都不做的变换，即一个单位矩阵。</p>
<p>只要行列式不为0，就存在对应的逆矩阵。</p>
<p>如果行列式为0，表示矩阵<span class="math inline">\(A\)</span>将空间的维度进行了压缩，我们此时无法还原原来没有压缩的空间，它对应的解有无数种。</p>
<p>如果矩阵表示的变化，最后把空间压缩为直线，就叫做此时矩阵的秩是1。如果压缩为二维平面，矩阵的秩就是2。</p>
<p>rank表示变化空间后的空间维数，因此，一个矩阵最大的rank就是它本身的维数。</p>
<p>矩阵的列空间：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928163229116.png" alt="image-20210928163229116" style="zoom:33%;" /></p>
<p>矩阵的列空间也就是变换后的空间，rank就是指列空间的维数。</p>
<p>矩阵的零空间null space：</p>
<p>矩阵进行空间变换时，所有变换后落在原点的向量集合，组成了null space。</p>
<p>在线性方程组上，就是变换后的向量是0向量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928163737132.png" alt="image-20210928163737132" style="zoom:33%;" /></p>
<h2 id="nonsquare-matrices-as-transformation-between-dimensions">7 Nonsquare matrices as transformation between dimensions</h2>
<p>前面讨论的都是方阵，如果是一个非方阵，那么表示的是维度的变化，比如从二维变换为三维，三维变化为二维。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928170025088.png" alt="image-20210928170025088" style="zoom:33%;" /></p>
<p>上面的矩阵就是从三维，变化到二维，列表示的基向量，从三维被表示为二维的向量，但是由于原来是三维空间，所有仍然有三个基向量。</p>
<h2 id="dot-products-and-duality">8 Dot products and Duality</h2>
<p>向量的点积就是所有维度的元素相乘然后相加。</p>
<p>如果希望从几何角度来理解，可以把左边的向量<span class="math inline">\(u\)</span>转置，变为矩阵的形式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928190814830.png" alt="image-20210928190814830" style="zoom:33%;" /></p>
<p>此时，从几何角度来看1维矩阵的变换，因为对称性，新的基向量<span class="math inline">\(\hat{i}\)</span>刚好是<span class="math inline">\(u_x\)</span>，新的基向量<span class="math inline">\(\hat{j}\)</span>刚好是<span class="math inline">\(u_y\)</span>。使用新的变换矩阵作用在向量<span class="math inline">\([x, y]^T\)</span>上，就是对其进行和对投影的变化操作。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928190944152.png" alt="image-20210928190944152" style="zoom:33%;" /></p>
<h2 id="cross-products">9 Cross products</h2>
<p>差积的定义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210928193801179.png" alt="image-20210928193801179" style="zoom:33%;" /></p>
<p>一个新的向量，长度是<span class="math inline">\(v\)</span>和<span class="math inline">\(w\)</span>组成的平行四边形的面积，方向垂直于该平行四边形。</p>
<p>该平行四边形面积的计算，可以使用<span class="math inline">\(v\)</span>和<span class="math inline">\(w\)</span>组成矩阵，然后求该矩阵的行列式。</p>
<h2 id="change-of-basis">10 Change of basis</h2>
<p>当我们定义了不同的基向量来描述空间中的同一个向量时，即使是同一个向量，也会使用不同的坐标来描述。</p>
<p>一个矩阵的列向量可以看做是新的基向量，它描述的是另一个坐标系的基向量，在我们想象当中的坐标系中的表示，</p>
<p>比如下面的形式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929100441396.png" alt="image-20210929100441396" style="zoom:33%;" /></p>
<p><span class="math inline">\([2,1]\)</span>和<span class="math inline">\([-1, 1]\)</span>是另外的坐标系的基向量，但是如果在另外的坐标系中，它实际表示的是<span class="math inline">\([1,0]\)</span>和<span class="math inline">\([0,1]\)</span>。我们使用自己的语言/坐标系来描述另一个坐标系的基向量。坐标<span class="math inline">\([-1,2]\)</span>是在另一个坐标系下的坐标。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929102903240.png" alt="image-20210929102903240" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929103010269.png" alt="image-20210929103010269" style="zoom:33%;" /></p>
<p>如果我们是希望自己坐标系下的<span class="math inline">\([-1,2]\)</span>，被转换到另一个坐标系中，那么我们可以用逆矩阵进行转化。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929103031185.png" alt="image-20210929103031185" style="zoom:33%;" /></p>
<p>接下来，如果我们在自己的坐标系下，使用矩阵，进行了一个空间变化/基向量的线性转换，那么在另一个坐标系下，进行相同的转化的矩阵应该是什么？</p>
<p>实际上，我们只需要首先，把另一个坐标系下的基向量变换到自己的坐标系下，然后进行要求的空间变换，最后通过逆矩阵再变换到另一个坐标系下。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929103848552.png" alt="image-20210929103848552" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929103911585.png" alt="image-20210929103911585" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929103944245.png" alt="image-20210929103944245" style="zoom:33%;" /></p>
<p>因此，如果我们看到下面的形式，我们可以直接从中间矩阵<span class="math inline">\(M\)</span>来看发生了什么变化，左右两侧的矩阵表示空间基向量坐标的转化：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929104136552.png" alt="image-20210929104136552" style="zoom:33%;" /></p>
<h2 id="eignvectors-and-eigenvalues">11 Eignvectors and eigenvalues</h2>
<p>如何从几何角度理解特征值和特征向量？</p>
<p>还是假设在一个空间坐标中，进行了空间变换。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929104925700.png" alt="image-20210929104925700" style="zoom:33%;" /></p>
<p>在进行这个空间变换中，大多数的向量都会发生一个角度的偏移，即和原来的向量不在一条直线上。但是有一些向量是和原来的向量还在一条直线上，对于这些向量来说，空间的变换仅仅是发生了长度的缩放，比如说对于所有在x轴上的向量来说，仅仅是长度增长三倍。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929110503345.png" alt="image-20210929110503345" style="zoom:33%;" /></p>
<p>还存在其它的向量，也是类似的只会进行长度的缩放</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929110547707.png" alt="image-20210929110547707" style="zoom:33%;" /></p>
<p>这些向量就叫做特征向量，需要进行的长度缩放就叫做特征值。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929110633803.png" alt="image-20210929110633803" style="zoom:33%;" /></p>
<p>求解特征向量与特征值的一般过程：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929112852029.png" alt="image-20210929112852029" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929112826908.png" alt="image-20210929112826908" style="zoom:33%;" /></p>
<p>根据前面的矩阵是空间变换可知，如果希望把一个向量通过矩阵空间变化，压缩为0向量，那么只有可能是行列式为0。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929113141083.png" alt="image-20210929113141083" style="zoom:33%;" /></p>
<p>当然，这样的性质表明了不是所有的矩阵都会有特征值，有的矩阵会把所有的向量都进行旋转操作，也就不存在特征向量了。</p>
<p>对应特征值的特征向量不一定就在一条直线上，最简单的，考虑一个矩阵是将所有向量都扩放到2倍。那么对于特征值2的特征向量就是整个空间下的所有向量。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929121210291.png" alt="image-20210929121210291" style="zoom:33%;" /></p>
<p>接下来，看一下由特征向量为基，组成的特征空间的作用。</p>
<p>对于一个矩阵，如果它的特征向量有多个，可以组成一个全空间，那么以这些特征向量作为新的基向量，如果我们将这个新的特征基组成的basis change矩阵作用在原始矩阵上：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929163607041.png" alt="image-20210929163607041" style="zoom:33%;" /></p>
<p>我们知道，这样得到的新矩阵，和之前的矩阵对于空间中的向量来说是同一种变换，但是是从新的特征空间下看的。这样得到的新的变换矩阵 ，在特征空间下，一定是对角矩阵，对角值是特征值。</p>
<p>这是因为，整个原始矩阵的空间变换，对于新的特征空间下的作为基向量的特征向量来说，仅仅是起到了缩放的作用，所以新的特征空间下的矩阵变换，就是对角矩阵，只有长度进行了缩放。</p>
<h2 id="abstract-vector-spaces">12 Abstract vector spaces</h2>
<p>线性转换的概念不仅局限在向量上，对于函数同样存在这样的定义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929183502322.png" alt="image-20210929183502322" style="zoom:33%;" /></p>
<p>求导运算，实际就是一种线性运算。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929183650226.png" alt="image-20210929183650226" style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929183711783.png" alt="image-20210929183711783" style="zoom:33%;" /></p>
<p>实际上，向量的很多概念是可以应用到函数上的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929184851866.png" alt="image-20210929184851866" style="zoom:33%;" /></p>
<p>向量的类似概念是可以推广到进行了任意定义的对象的，只要定义的数乘运算和相加运算，能够满足下面的checklist，就可以认为此时定义的新的运算，可以组成一个向量空间，可以使用向量的各种相关概念去思考，定义。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210929185244924.png" alt="image-20210929185244924" style="zoom:33%;" /></p>
]]></content>
      <categories>
        <category>Class</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>AM-GCN</title>
    <url>/gnn/AM-GCN/</url>
    <content><![CDATA[<h1 id="am-gcn-adaptive-multi-channel-graph-convolutional-networks">AM-GCN: Adaptive Multi-channel Graph Convolutional Networks</h1>
<p>2020-8 KDD 2020</p>
<p>AM-GCN主要针对的是节点分类任务，主要贡献包括两点：</p>
<ol type="1">
<li>探究了之前的GCN方法是否能够较好的同时捕获topological structures和node features</li>
<li>设计了 a novel adaptive multi-channel GCN framework, 能够适应的同时捕获两种不同的信息</li>
</ol>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>之前的图卷积神经网络方法使用节点特征（node features）作为初始输入，然后进行图卷积操作。</p>
<p>作者提出的问题：</p>
<blockquote>
<p>What information do GCNs really learn and fuse from topological structures and node features?</p>
</blockquote>
<p>一般的GNN中涉及到两种信息：</p>
<ul>
<li>拓扑结构（主要指一个节点周围有哪些邻居节点）</li>
<li>节点信息（主要指节点本身的特征信息，比如论文节点的标题、关键字等文本信息）</li>
</ul>
<p>这两个信息都可以用来进行图上的预测任务，但是哪个信息或者两个一起作用，对于最终的预测任务影响比较大？</p>
<p>AM-GCN主要针对的是节点分类任务，主要贡献包括两点：</p>
<ol type="1">
<li>探究了之前的GCN方法是否能够较好的同时捕获topological structures和node features</li>
<li>设计了 a novel adaptive multi-channel GCN framework, 能够适应的同时捕获两种不同的信息</li>
</ol>
<h2 id="fusion-capability-of-gcns">2 FUSION CAPABILITY OF GCNS</h2>
<p>探究GCN学习结构信息和节点特征信息的能力，设计了两个实验：</p>
<h3 id="case-1-random-topology-and-correlated-node-features">Case 1: Random Topology and Correlated Node Features</h3>
<p>实验设置：</p>
<ul>
<li>900节点，3 class</li>
<li>0.3的概率随机生成边</li>
<li>对于3类节点，节点特征使用三个相同协方差，不同均值的高斯分布初始化</li>
<li>GCN与基于节点特征的MLP对比</li>
</ul>
<p>结果：GCN分类准确率75.2%，MLP准确率100%</p>
<h3 id="case-2-correlated-topology-and-random-node-features">Case 2: Correlated Topology and Random Node Features</h3>
<p>实验设置：</p>
<ul>
<li>900节点，3 class</li>
<li>设计3 community，community内部建立边的概率是0.03， community内部建立边的概率是0.0015</li>
<li>随机生成节点特征</li>
<li>GCN与Deepwalk（忽略节点特征）</li>
</ul>
<p>结果：GCN分类准确率87%，MLP准确率100%</p>
<h2 id="am-gcn-the-proposed-model">3 AM-GCN: THE PROPOSED MODEL</h2>
<p>对于一个原始图的输入<span class="math inline">\(G=(\mathbf{A},\mathbf{X})\)</span>，<span class="math inline">\(\mathbf{A}\)</span>是邻接矩阵，<span class="math inline">\(\mathbf{X}\)</span>是节点特征矩阵，构造两个图：</p>
<ul>
<li>Topology Graph：<span class="math inline">\(\mathbf{A}_t=\mathbf{A}\)</span>，图原始的结构，与GCN一致</li>
<li>Feature Graph：<span class="math inline">\(\mathbf{A}_f\)</span>，该图中一个节点的相邻节点是k个特征相似的节点，不是原来的结构上的邻居节点</li>
</ul>
<p>构造Feature Graph，首先计算一个节点与其它所有节点的相似度，计算一个余弦相似度矩阵<span class="math inline">\(\mathbf{S}\in \mathbb{R}^{n\times n}\)</span> <span class="math display">\[
\mathbf{S}_{i,j}=\frac{\mathbf{x}_i\cdot \mathbf{x}_j}{|\mathbf{x}_i| |\mathbf{x}_j|}
\]</span> 然后对于节点<span class="math inline">\(i\)</span>，在<span class="math inline">\(\mathbf{S}\)</span>中选择前<span class="math inline">\(k\)</span>个相似度最大的节点作为feature node，得到<span class="math inline">\(\mathbf{A}_f\)</span>。</p>
<p>AM-GCN的整体模型图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210110175132041.png" style="zoom:50%;" /></p>
<p>可以看到其中有三个主要核心模块，包括在Topology Graph和Feature Graph上的卷积，以及捕获两者共有特征的卷积。</p>
<h3 id="specific-convolution-module">3.1 Specific Convolution Module</h3>
<p>在Topology Graph上的卷积： <span class="math display">\[
\mathbf{Z}_t^{(l)} = ReLU(\tilde{D}^{-\frac{1}{2}}_t \tilde{A}_t \tilde{D}^{-\frac{1}{2}}_t \mathbf{Z}_t^{(l-1)} \mathbf{W}_t^{(l)} )
\]</span> 其中，<span class="math inline">\(\tilde{A}_t=A_t+I_t\)</span>，该卷积方法与GCN一模一样</p>
<p>在Feature Graph上的卷积： <span class="math display">\[
\mathbf{Z}_f^{(l)} = ReLU(\tilde{D}^{-\frac{1}{2}}_f \tilde{A}_f \tilde{D}^{-\frac{1}{2}}_f \mathbf{Z}_f^{(l-1)} \mathbf{W}_f^{(l)} )
\]</span> 其中，<span class="math inline">\(\tilde{A}_f=A_f+I_f\)</span></p>
<h3 id="common-convolution-module">3.2 Common Convolution Module</h3>
<p>实际上，feature space和topology space不是完全独立的，两者的信息可能互补然后一起可以用于预测任务。因此，AM-GCN设计了一个common module使用parameter sharing strategy捕获两者的通用特征。</p>
<p>在topology space中导出embedding： <span class="math display">\[
\mathbf{Z}_{ct}^{(l)} = ReLU(\tilde{D}^{-\frac{1}{2}}_t \tilde{A}_t \tilde{D}^{-\frac{1}{2}}_t \mathbf{Z}_{ct}^{(l-1)} \mathbf{W}_c^{(l)} )
\]</span> 在feature space中导出embedding： <span class="math display">\[
\mathbf{Z}_{cf}^{(l)} = ReLU(\tilde{D}^{-\frac{1}{2}}_f \tilde{A}_f \tilde{D}^{-\frac{1}{2}}_f \mathbf{Z}_{cf}^{(l-1)} \mathbf{W}_c^{(l)} )
\]</span> 最后，两个结合得到common embedding： <span class="math display">\[
\mathbf{Z}_{c} = (\mathbf{Z}_{ct} + \mathbf{Z}_{cf})/2
\]</span></p>
<h3 id="two-constraints">3.3 Two Constraints</h3>
<p>Consistency Constraint:</p>
<p>用来控制两个common embedding的consistency，首先将<span class="math inline">\(\mathbf{Z}_{ct}\)</span>和<span class="math inline">\(\mathbf{Z}_{cf}\)</span>使用<span class="math inline">\(l_2\)</span>正则归一化，然后得到下面节点之间的相似度 <span class="math display">\[
\mathbf{S}_T=\mathbf{Z}_{CTnor}\cdot \mathbf{Z}_{CTnor}^T \\
\mathbf{S}_F=\mathbf{Z}_{CFnor}\cdot \mathbf{Z}_{CFnor}^T
\]</span> 之后约束： <span class="math display">\[
\mathcal{L}_c=|| \mathbf{S}_T - \mathbf{S}_F ||^2
\]</span> Disparity Constraint:</p>
<p>因为<span class="math inline">\(\mathbf{Z}_{ct}^{(l)}\)</span>和<span class="math inline">\(\mathbf{Z}_{t}^{(l)}\)</span>都是从topology space中学习得到的，为了保证它们都是反映了不同的信息，因此使用Hilbert-Schmidt Independence Criterion (HSIC)加强它们的disparity。 <span class="math display">\[
HSIC(\mathbf{\mathbf{Z}_{T}},\ \mathbf{\mathbf{Z}_{CT}}) = (n-1)^{-2}tr(\mathbf{R} \mathbf{K}_T \mathbf{R} \mathbf{K}_{CT})
\]</span> 同样的，对于<span class="math inline">\(\mathbf{\mathbf{Z}_{F}},\ \mathbf{\mathbf{Z}_{CF}}\)</span>： <span class="math display">\[
HSIC(\mathbf{\mathbf{Z}_{F}},\ \mathbf{\mathbf{Z}_{CF}}) = (n-1)^{-2}tr(\mathbf{R} \mathbf{K}_F \mathbf{R} \mathbf{K}_{CF})
\]</span> 最终， <span class="math display">\[
\mathcal{L}_d =HSIC(\mathbf{\mathbf{Z}_{T}},\ \mathbf{\mathbf{Z}_{CT}}) +HSIC(\mathbf{\mathbf{Z}_{F}},\ \mathbf{\mathbf{Z}_{CF}})
\]</span></p>
<h3 id="attention-mechanism">3.4 Attention Mechanism</h3>
<p><span class="math display">\[
(\alpha_t, \alpha_c, \alpha_f)=att(\mathbf{Z}_T, \mathbf{Z}_C, \mathbf{Z}_F) 
\]</span></p>
<p>以计算<span class="math inline">\(\alpha_t\)</span>为例： <span class="math display">\[
\omega_T = \mathbf{q}^T \cdot tanh(\mathbf{W} \mathbf{z}_T + \mathbf{b}) \\
\alpha_T = softmax(\omega_T)
\]</span> 最终AM-GCN得到的节点embedding为： <span class="math display">\[
\mathbf{Z} = \mathbf{\alpha}_T \cdot \mathbf{Z}_T + \mathbf{\alpha}_C \cdot \mathbf{Z}_C + \mathbf{\alpha}_F \cdot \mathbf{Z}_F
\]</span></p>
<h2 id="experiments">4 EXPERIMENTS</h2>
<h3 id="node-classification">4.1 Node Classification</h3>
<p>在7个数据集上进行评估，数据集主要是论文的引文网络和社交网络</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210110175336414.png" style="zoom:50%;" /></p>
<p>注意其中的每个数据集训练集有三个级别，分别对应每一类的节点有标签的比例为20%， 40%和60%，测试集恒定每一类由1000个节点评估。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210110180203704.png" style="zoom:50%;" /></p>
<p>其中，kNN-GCN是AM-GCN只在feature graph上进行聚合。</p>
<p>对比GCN和kNN-GCN一个比较有意思的结果是不聚合邻居，有时候根据特征聚合相似的节点，也可能取得更好的结果。</p>
<h3 id="analysis-of-variants">4.2 Analysis of Variants</h3>
<p>比较设计的约束的作用：</p>
<ul>
<li><p>AM-GCN-w/o: AM-GCN without constraints <span class="math inline">\(L_c\)</span> and <span class="math inline">\(L_d\)</span></p></li>
<li><p>AM-GCN-c: AM-GCN with the consistency constraint <span class="math inline">\(L_c\)</span></p></li>
<li><p>AM-GCN-d: AM-GCN with the disparity constraint <span class="math inline">\(L_d\)</span></p></li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210110180340350.png" style="zoom:50%;" /></p>
<p>可以看出来，一般情况下，consistency constraint比disparity constraint更加重要</p>
<h3 id="visualization">4.3 Visualization</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210110175813097.png" style="zoom:50%;" /></p>
<h3 id="analysis-of-attention-mechanism">4.4 Analysis of Attention Mechanism</h3>
<p>分析不同数据集下，三个不同embedding的注意力值的分布</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210110165439556.png" style="zoom:50%;" /></p>
<p>可以看到，不同数据集下，三个不同方面的embedding对应的注意力值不同，说明哪个方面包含了更加丰富的信息是依赖于具体数据的。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>Beyond-Homo</title>
    <url>/gnn/Beyond-Homo/</url>
    <content><![CDATA[<h1 id="beyond-homophily-in-graph-neural-networks-current-limitations-and-effective-designs">Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs</h1>
<p>本文讨论了graph的heterophily</p>
<span id="more"></span>
<div class="pdf-container" data-target="Beyond-Homophily-in-Graph-Neural-Networks.pdf" data-height="1000px"></div>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>Deeper-insights-gcn</title>
    <url>/gnn/Deeper-insights-gcn/</url>
    <content><![CDATA[<h1 id="deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning">Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning</h1>
<p>AAAI 2018，引用量578。</p>
<p>作者对GCN的机制进行了探讨，认为GCN是Laplacian smoothing的一种特殊形式。并且形式化证明了当GCN堆叠到很多层时，所有节点的表示会趋向于同一表示。发现GCN在带有label的data较少的情况下，表现出的性能差，为了解决这一问题，提出了一种联合训练co-traning的方法，主要是使用随机游走和GCN两种方法，寻找不同label下的most confident vertices，然后使用这些most confident vertices继续训练。</p>
<span id="more"></span>
<blockquote>
<p>Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semisupervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires considerable amount of labeled data for validation and model selection.</p>
<p>In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of oversmoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches signiﬁcantly improve GCNs in learning with very few labels, and exempt them from requiring additional labels for validation. Extensive experiments on benchmarks have veriﬁed our theory and proposals.</p>
</blockquote>
<p>作者认为的GCN的优点：</p>
<ul>
<li>图卷积-即拉普拉斯平滑操作，让不同class的特征能够在图上传播</li>
<li>MLP是一个强大的feature extractor</li>
</ul>
<p>缺点：</p>
<ul>
<li>图卷积是一个localized ﬁlter，当labeled data较少的时候，性能较差</li>
<li>使用neural network要求具备较多的训练数据以及使用额外的验证集进行模型选择</li>
</ul>
<p>作者证明graph convolution是laplacian smoothing的过程：</p>
<p>laplacian smoothing在1995年就被提出来，A signal processing approach to fair surface design.</p>
<p>定义为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210504154544997.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(\gamma\)</span>是参数，控制当前vertex和邻居vertex的特征的weight。<span class="math inline">\(\mathbf{x}_j\)</span>是邻居vertex。</p>
<p>将上面的形式写为矩阵形式： <span class="math display">\[
\begin{align}
Y &amp;= (1-\gamma)X + \gamma \tilde{A} \tilde{D}^{-1} X \\
&amp;= X - \gamma (X - \tilde{A} \tilde{D}^{-1} X ) \\
&amp;= X - \gamma \tilde{D}^{-1} (\tilde{D} - \tilde{A}) X \\
&amp;= X - \gamma \tilde{D}^{-1} \tilde{L} X
\end{align}
\]</span> 对上面的式子进行简化，令 <span class="math inline">\(\gamma = 1\)</span>，替换<span class="math inline">\(\tilde{D}^{-1} \tilde{L}\)</span>为<span class="math inline">\(\tilde{D}^{-1/2} \tilde{L} \tilde{D}^{-1/2}\)</span></p>
<p>得到下面的式子： <span class="math display">\[
\begin{align}
Y &amp;= X - \tilde{D}^{-1/2} \tilde{L} \tilde{D}^{-1/2} X \\
&amp;= (I - \tilde{D}^{-1/2} \tilde{L} \tilde{D}^{-1/2} ) X \\
&amp;= (I - \tilde{D}^{-1/2} (\tilde{D} - \tilde{A}) \tilde{D}^{-1/2} ) X \\
&amp;= \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} X
\end{align}
\]</span> 最后得到了GCN。</p>
<p>这一操作背后的原理是属于同一类的vertex倾向于在一个cluster中，smoothing操作让它们具有了相近的表示，这使得之后的classiﬁcation更加容易。</p>
<blockquote>
<p>The Laplacian smoothing computes the new features of a vertex as the weighted average of itself and its neighbors’. Since vertices in the same cluster tend to be densely connected, the smoothing makes their features similar, which makes the subsequent classiﬁcation task much easier.</p>
</blockquote>
<p>另外，为了让GCN能够在data更受限制的情况下进行学习，作者结合ParWalks这种随机游走的方法，寻找各个class下most confident vertices——the nearest neighbors to the labeled vertices of each class。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>GCN</title>
    <url>/gnn/GCN/</url>
    <content><![CDATA[<h1 id="semi-supervised-classification-with-g-raph-convolutional-networks">SEMI-SUPERVISED CLASSIFICATION WITH G RAPH CONVOLUTIONAL NETWORKS</h1>
<p>ICLR 2017</p>
<p>贡献：提出了一种模拟卷积神经网络的变种，直接在图结构上进行类似的卷积操作的神经网络。通过对谱卷积神经网络（Spectral GNN）进行一阶估计简化（ﬁrst-order approximation），提出了一阶图卷积神经网络——GCN。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p><strong>motivation</strong>：一般情景下，对图节点进行半监督的分类任务依赖于假设：</p>
<blockquote>
<p>connected nodes in the graph are likely to share the same label.</p>
</blockquote>
<p>相邻节点倾向于拥有相似的信息，传统的做法是设计基于图的正则项（graph-based regularization）加入到损失函数中，例如下面的图拉普拉斯正则项（a graph Laplacian regularization term）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210628103015253.png" /></p>
<p><span class="math inline">\(L_0\)</span>是有监督的损失，针对graph中有标签的节点；<span class="math inline">\(L_{reg}\)</span>是图拉普拉斯正则项，它假设邻居拥有与中心节点相似的信息。通过设计上面的损失函数，实际上标签的信息就实现了平滑的传播（label information is smoothed over the graph）。</p>
<p>但是作者认为这种做法可能会限制模型的性能，因为一个graph的edge不一定总是描述节点之间的相似性，它可能包含其它的信息。比如可能是不相似的节点。</p>
<p><strong>method</strong>：作者没有继续使用上面的正则化方法，而是直接在graph上建立神经网络，在具体点就是直接基于邻接矩阵或者其它能够描述graph的形式作为输入，输出编码后的信息。</p>
<blockquote>
<p>we encode the graph structure directly using a neural network model <span class="math inline">\(f(X, A)\)</span> and train on a supervised target <span class="math inline">\(L_0\)</span> for all nodes with labels, thereby avoiding explicit graph-based regularization in the loss function.</p>
</blockquote>
<p>这样定义的<span class="math inline">\(f(X, A)\)</span> 在根据损失<span class="math inline">\(L_0\)</span>进行梯度计算时，就能够依赖邻接矩阵<span class="math inline">\(A\)</span>进行梯度的分发(distribute)，即实现了对于图结构的学习，无论是有label还是没有label的节点都能够学习到合适的representations。</p>
<blockquote>
<p>Conditioning <span class="math inline">\(f(\cdot)\)</span> on the adjacency matrix of the graph will allow the model to distribute gradient information from the supervised loss <span class="math inline">\(L_0\)</span> and will enable it to learn representations of nodes both with and without labels.</p>
</blockquote>
<h2 id="preliminaries">2 Preliminaries</h2>
<h3 id="graph-definition">Graph definition</h3>
<p>为了能够利用图结构进行学习，首先我们需要采取某种方式表示图。一个图的常用表达形式是<span class="math inline">\(G=(V,E)\)</span>，<span class="math inline">\(V\)</span>是节点（vertices）的集合，<span class="math inline">\(E\)</span>是边（edge）的集合。如果存在边<span class="math inline">\(e=u,v\)</span>，那么<span class="math inline">\(u\)</span>可以被称作<span class="math inline">\(v\)</span>的邻居，可以说节点<span class="math inline">\(u\)</span>和<span class="math inline">\(v\)</span>是邻接的（adjacent）。</p>
<p>图有几种不同的代数表达形式：</p>
<ul>
<li>邻接矩阵（Adjacency matrix）：对于一个简单图<span class="math inline">\(G=(V,E)\)</span>，邻接矩阵<span class="math inline">\(A\in \mathcal{R}^{n\times n}\)</span>定义为：</li>
</ul>
<p><span class="math display">\[
A_{ij} =
\begin{cases}
1,  &amp; \mbox{if }\{ v_i, v_j \}\in E \mbox{ and } i \not= j \\
0, &amp; \mbox{if }\mbox{ otherwise}
\end{cases}
\]</span></p>
<ul>
<li>度矩阵（Degree matrix）：度矩阵<span class="math inline">\(D\in \mathcal{R}^{n\times n}\)</span>是一个对角矩阵s：</li>
</ul>
<p><span class="math display">\[
D_{ii}=d(v_i)
\]</span></p>
<ul>
<li>拉普拉斯矩阵（Laplacian matrix）：拉普拉斯矩阵定义为度矩阵减去邻接矩阵，<span class="math inline">\(L=D-A\)</span>：</li>
</ul>
<p><span class="math display">\[
L_{ij} =
\begin{cases}
d(v_i),  &amp; \mbox{if } i = j \\
-1, &amp; \mbox{if }\{ v_i, v_j \}\in E \mbox{ and } i\not=j \\
0, &amp; \mbox{otherwise}
\end{cases}
\]</span></p>
<ul>
<li>对称归一化拉普拉斯矩阵（Symmetric normalized Laplacian）：将上面的拉普拉斯矩阵归一化： <span class="math display">\[
\begin{align}
L^{sym}&amp;=D^{-\frac{1}{2}}LD^{-\frac{1}{2}} \\
&amp;=I-D^{-\frac{1}{2}}AD^{-\frac{1}{2}}
\end{align}
\]</span> 最终得到了归一化拉普拉斯矩阵，矩阵中的元素定义为： <span class="math display">\[
L_{ij}^{sym} =
\begin{cases}
1,  &amp; \mbox{if } i = j \mbox{ and } d(v_i)\not=0 \\
-\frac{1}{\sqrt{d(v_i)d(v_j)}}, &amp; \mbox{if }\{ v_i, v_j \}\in E \mbox{ and } i\not=j \\
0, &amp; \mbox{otherwise}
\end{cases}
\]</span></li>
</ul>
<p>接下来我们讨论的图是无向图，那么拉普拉斯矩阵是对称矩阵，归一化之后的图拉普拉斯矩阵是半正定对称矩阵。</p>
<p>基于归一化拉普拉斯矩阵，我们可以将它对角化，<span class="math inline">\(L^{sym}=U\Lambda U^T\)</span>，其中<span class="math inline">\(U=[\mathbf{u}_0,\mathbf{u}_1, \dots,\mathbf{u}_n]\in \mathcal{R}^{n\times n}\)</span>是特征向量矩阵，<span class="math inline">\(\Lambda_{ii}=\lambda_i\)</span>是特征值。这一对角化实对称矩阵的操作在线性代数中叫做谱分解，<span class="math inline">\(\Lambda\)</span>称作谱（spectrum）。实对称矩阵的特征向量一定是正交的（orthogonal），特征值一定是实数。特征向量构成了谱空间的基。在图的信号处理中，一个图信号（graph signal）定义为<span class="math inline">\(x\in \mathcal{R}^n\)</span>，每个节点都有一个对应的数值，这一图信号也叫做节点的特征，可以拥有多个特征，那么把多个图信号按列排序就得到了一个图的特征矩阵： <span class="math display">\[
X\in \mathcal{R}^{n\times D}
\]</span> <span class="math inline">\(X_i\)</span>表示第<span class="math inline">\(i\)</span>个节点的特征，<span class="math inline">\(X_{ij}\)</span>表示第<span class="math inline">\(i\)</span>个节点的第<span class="math inline">\(j\)</span>个特征。</p>
<p>在介绍GCN之前，需要介绍首个定义在图上进行的卷积操作原理。</p>
<p>在图信号处理中，模仿一般的傅里叶变换定义了图傅里叶变换（graph Fourier transform），就是将处于原来特征空间下的图信号投影转换到谱空间中， <span class="math display">\[
\mathcal{F}(x)=U^Tx
\]</span> 傅里叶逆变换定义为： <span class="math display">\[
\mathcal{F}^{-1}(x)=U\hat{x}
\]</span> 由于图不满足平移不变性，我们希望直接在特征空间下定义图的卷积算子<span class="math inline">\(f*g\)</span>比较困难，<span class="math inline">\(x\)</span>是输入的图信号（signal），<span class="math inline">\(g\)</span>是过滤器（filter）。但利用卷积定理，信号卷积的傅里叶变换等价于信号傅里叶变换的乘积。 <span class="math display">\[
\mathcal{F}({x*g})=\mathcal{F}(x)\cdot \mathcal{F}(g)
\]</span> 那么图卷积算子可以定义为： <span class="math display">\[
{x*g}=\mathcal{F}^{-1}(\mathcal{F}(x)\cdot \mathcal{F}(g))
\]</span> 这样我们无需考虑原特征空间中的卷积，只需要先将信号转换为谱空间中的信号，在谱空间中与谱空间中的过滤器做乘法，最后利用傅里叶逆变换转换到原来的空间中，就实现了图卷积。</p>
<p>更具体的图卷积算子定义为： <span class="math display">\[
\begin{align}
{x*g}&amp;=\mathcal{F}^{-1}(\mathcal{F}(x)\cdot \mathcal{F}(g)) \\
&amp;=U(U^Tx\cdot U^Tg) \\
\end{align}
\]</span> 其中，<span class="math inline">\(U^Tg\)</span>是一个向量，可以看做是对角矩阵<span class="math inline">\(g_{\theta}=diag(U^Tg)\)</span>，最后谱卷积算子定义为： <span class="math display">\[
{x*g}=Ug_{\theta}U^Tx
\]</span> 所有基于谱空间的图卷积方法都是在尝试寻找更合适的<span class="math inline">\(g_{\theta}\)</span>。</p>
<h3 id="fast-approximate-convolutions-on-graphs">FAST APPROXIMATE CONVOLUTIONS ON GRAPHS</h3>
<p>Spectral CNN（Spectral Convolutional Neural Network）直接将<span class="math inline">\(g_{\theta}\)</span>作为一系列可以学习的参数，得到了下面的卷积公式： <span class="math display">\[
H^{(l+1)}_{:,j}=\sigma(\sum_{i=1}^{f_{l}} U\Theta^{l}_{i,j}H^{(l)}_{:,i}) \ (j=1,2,3\dots,f_l)
\]</span> 这里任然需要计算特征向量，计算代价很大。</p>
<p>之后切比雪夫网络（Chebyshev Spectral CNN，ChebNet）对Spectral CNN进行简化，使用切比雪夫多项式简化<span class="math inline">\(g_{\theta}\)</span>，令<span class="math inline">\(g_{\theta}=\sum_{i=0}^K\theta_i T_i(\tilde{\Lambda})\)</span>，其中<span class="math inline">\(\tilde{\Lambda}=2\Lambda/\lambda_{max}-I_n\)</span>得到了下面的卷积公式： <span class="math display">\[
\begin{align}
{x*g} &amp;\approx U\sum_{i=0}^K \theta_i T_i(\tilde{\Lambda}) U^T x \\
&amp;= \sum_{i=0}^K \theta_i T_i(\tilde{L}) x
\end{align}
\]</span> 其中，<span class="math inline">\(\tilde{L}=2L/\lambda_{max}-I_n\)</span>。这样ChebNet不需要再计算特性向量<span class="math inline">\(U^T\)</span>。</p>
<h2 id="gcn">3 GCN</h2>
<p>GCN在ChebNet的基础上，进一步将K阶多项式限制到了1阶，假设<span class="math inline">\(\lambda_{max}=2\)</span>得到了新的卷积算子： <span class="math display">\[
{x*g} \approx \sum_{i=0}^K \theta_i T_i(\tilde{L}) \approx \theta_0x + \theta_1x(L-I_n)x=\theta_0x + \theta_1 D^{-\frac{1}{2}}AD^{-\frac{1}{2}} x
\]</span> 由于半监督图节点分类学习的数据量少，令0阶系数和1阶系数相同，减小学习的参数量。 <span class="math display">\[
\begin{align}
{x*g} &amp;\approx \theta_0x + \theta_1 D^{-\frac{1}{2}}AD^{-\frac{1}{2}} x \\
&amp;\approx \theta (I_n + D^{-\frac{1}{2}}AD^{-\frac{1}{2}})x
\end{align}
\]</span> 最终提出了具有多层结构的图卷积神经网络（GCN），每一层使用的卷积函数定义如下： <span class="math display">\[
H^{(l+1)}=\sigma (\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})
\]</span> 其中<span class="math inline">\(\tilde{D}\)</span>和<span class="math inline">\(\tilde{A}\)</span>是区别于之前的度矩阵和邻接矩阵， <span class="math display">\[
\tilde{A}=A+I_N\\
\tilde{D}_{ii}=\sum_j{\tilde{A}_{ij}}
\]</span> 原因是在实验中发现，如果使用原来的形式会导致训练的不稳定性以及梯度消失/爆炸的问题，因此重新归一化。</p>
<p>GCN用来做半监督的节点分类任务，在实现的时候使用了两层GCN，最后经过Softmax输出预测值。损失函数使用交叉熵。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201129220200051.png" /></p>
<h2 id="experiments">4 EXPERIMENTS</h2>
<p>使用以下四方面的实验：</p>
<ul>
<li>semi-supervised document classiﬁcation in citation networks</li>
<li>semi-supervised entity classiﬁcation in a bipartite graph extracted from a knowledge graph</li>
<li>an evaluation of various graph propagation models</li>
<li>a run-time analysis on random graphs</li>
</ul>
<p>使用的数据集：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201129220829777.png" /></p>
<p>需要注意的一点是对于知识图谱这种有向图，GCN将关系拆出来作为一个联通两个节点的新节点，这样知识图谱就转换为了无向图。</p>
<h3 id="semi-supervised-node-classification">4.1 SEMI-SUPERVISED NODE CLASSIFICATION</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201129222635232.png" /></p>
<h3 id="evaluation-of-propagation-model">4.2 EVALUATION OF PROPAGATION MODEL</h3>
<p>对于GCN机制的一个探究。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201129223242035.png" /></p>
<h3 id="training-timeper-epoch">4.3 TRAINING TIMEPER EPOCH</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201129223143658.png" /></p>
<h2 id="discussion">5 DISCUSSION</h2>
<p>切比雪夫网络是利用切比雪夫多项式对Spectra CNN进行的简化估计，无需再计算特征向量<span class="math inline">\(U\)</span>；GCN是对切比雪夫网络进一步的简化，将K阶多项式限制到了1阶，同时令0阶系数和1阶系数相同，得到了更简洁的图卷积形式。</p>
<p>优点：</p>
<ul>
<li>直接将图卷积算子简化到了一步线性计算的程度</li>
<li>形式上来看已经和一般的神经网络非常相似了，方便与已有的深度学习方法进行结合</li>
</ul>
<p>缺点：</p>
<ul>
<li>内存的限制，需要训练全图</li>
<li>无法学习有向图以及边的特征</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>GNN-1000-layers</title>
    <url>/gnn/GNN-1000-layers/</url>
    <content><![CDATA[<h1 id="training-graph-neural-networks-with-1000-layers">Training Graph Neural Networks with 1000 Layers</h1>
<p>ICML 2021</p>
<p>这篇文章通过在GNN中引入grouped reversible connections，实现了将GNN拓展到1000层，可能是当前最深的GNN之一。这篇文章的意义在于，实现了GNN的层数与模型所需的显存无关，使用较少的显存就可以在显存基本不增加的情况下，任意增加GNN深度。</p>
<p>下图是作者提出的Rev-GNN在ogbn-proteins数据集上的结果，很少的memory，达到了很好的效果。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323191910030.png" alt="image-20220323191910030" style="zoom:50%;" /></p>
<span id="more"></span>
<p>看一下作者的核心思路，在一层的GNN中的grouped reversible connections。首先，将输入划分的节点特征矩阵<span class="math inline">\(X\in \mathbb{R}^{N\times D}\)</span>随机划分为不同的group：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323192420194.png" alt="image-20220323192420194" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323192439309.png" alt="image-20220323192439309" style="zoom:50%;" /></p>
<p>然后作者基于划分好的group产生新的输出：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323192539787.png" alt="image-20220323192539787" style="zoom:50%;" /></p>
<p>上面的式子里，<span class="math inline">\(f_{w_i}\)</span>表示是图卷积操作。注意这里的输出<span class="math inline">\(X_i^\prime\)</span>，除了<span class="math inline">\(X_1^\prime\)</span>依赖于<span class="math inline">\(X_0^\prime\)</span>外，其它的<span class="math inline">\(X_i^\prime\)</span>都是由前一个的<span class="math inline">\(X_{i-1}^\prime\)</span>推出的。</p>
<p>这样做的好处是，可以通过输出直接推导出输入。比如用在backwards过程中：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323192914104.png" alt="image-20220323192914104" style="zoom:50%;" /></p>
<p>因此，在作者的RevGNN中，只需要保留最后一个GNN层的输出即可，前面所有层的中间状态都可以反向求出。从这里也可以看出来，<span class="math inline">\(X_0^\prime\)</span>之所以不从group 1开始累加，就是为了后续能够反向重构输入。否则的话，在后续重构<span class="math inline">\(X_1^\prime\)</span>，需要提前知道<span class="math inline">\(X_0^\prime\)</span>，但是想知道<span class="math inline">\(X_0^\prime\)</span>又需要知道<span class="math inline">\(X_1^\prime\)</span>，成为了死锁。</p>
<p>另外，作者提到了需要normalization layers和dropout layers：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323195400866.png" alt="image-20220323195400866" style="zoom:50%;" /></p>
<p>dropout操作会影响重构输入，如果每层dropout都不一样，backward的时候，每层都需要提前保存dropout，因此作者直接让所有层都是保持一样的dropout设置。</p>
<p>以上就是作者的核心思想，同时作者还做了两个拓展：</p>
<ol type="1">
<li>Weight-tied GNNs.</li>
</ol>
<p>意思是让每一层的参数量都固定一样，这样来减小模型参数量。实验结果发现性能并不如每层都有自己的参数的模型，训练速度也差不多一样，优点就是参数量减小。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323195848002.png" alt="image-20220323195848002" style="zoom:50%;" /></p>
<ol start="2" type="1">
<li>Deep Equilibrium GNNs</li>
</ol>
<p>使用implicit differentiation的方法来训练Weight-tied GNN，好处是训练比较快。这一部分没有特别理解，但是大概意思是通过不断的迭代，最终模型能够达到某个平衡点。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220323200027329.png" alt="image-20220323200027329" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>GraphSAGE</title>
    <url>/gnn/GraphSAGE/</url>
    <content><![CDATA[<h1 id="inductive-representation-learning-on-large-graphs">Inductive Representation Learning on Large Graphs</h1>
<p>NIPS 2017 GraphSAGE</p>
<p>主要贡献：</p>
<ul>
<li>提出了一种inductive学习图结构的方法，使用节点的特征（文本、度等）作为输入，进行无监督学习</li>
<li>构造了三个节点分类（node classification）的数据集</li>
</ul>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>从transductive到inductive 在GCN中训练需要训练整个图，所有节点的embedding，之后基于这些训练过的embedding进行测试，这叫做transductive； GraphSAGE计划设计一个inductive的方法，不训练所有的节点。在测试集中的节点在训练时是不可见的，使用节点的特征作为原始输入，然后使用训练好的网络在测试集中评估。</p>
<p>提出了GraphSAGE（SAmple and aggreGAte）</p>
<h2 id="method">2 Method</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201220093929039.png" alt="image-20201220104337756" /><figcaption>image-20201220104337756</figcaption>
</figure>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201220104337756.png" alt="image-20201220093929039" /><figcaption>image-20201220093929039</figcaption>
</figure>
<p>核心在于如何聚合邻居节点的信息：</p>
<ol type="1">
<li>首先使用节点特征（文本等）作为初始输入</li>
<li>之后均匀随机采样固定数量的直接相邻邻居节点，定义特定的聚合函数AGGREGATE，聚合邻居信息（不包括自身的特征）</li>
<li>拼接自身的特征与邻居的信息，过一层神经网络，得到获得一阶邻居后的输出</li>
<li>上面的过程重复K次，每个节点在k次聚和时，采样<span class="math inline">\(S_k\)</span>个邻居的k-1阶表示，得到k阶表示</li>
</ol>
<p>损失函数： <span class="math display">\[
J(\mathbf{z}_u) = -log(\sigma(\mathbf{z}_u^T \mathbf{z}_v))-Q\mathbb{E}_{v_n\sim P_n(v)}log(\sigma(-\mathbf{z}_u^T \mathbf{z}_{v_n}))
\]</span> <span class="math inline">\(v\)</span>是邻居节点；<span class="math inline">\(v_n\)</span>是负样本；<span class="math inline">\(P_n(v)\)</span>是负采样分布；<span class="math inline">\(Q\)</span>是负采样的数量。这个loss的含义是让邻居节点相似，增大不相关的节点差异。</p>
<p>下面是GraphSAGE的核心方法，聚合函数。</p>
<p>在论文里提出了四个聚合函数：</p>
<ol type="1">
<li>-GCN：<span class="math inline">\(\mathbf{h}_v^k = \sigma(W\cdot \mbox{Mean}(\{\mathbf{h}_v^{k-1}\} \cup \{\mathbf{h}_u^{k-1},\ u\in \forall N(v) \} ))\)</span></li>
<li>-Mean：先平均邻居表示，之后与中心节点表示拼接后过一层神经网络，<span class="math inline">\(\mbox{AGGREGATE}^{\mbox{mean}}_k=\mbox{Mean}(\{\mathbf{h}_u^{k-1},\ u\in \forall N(v) \})\)</span></li>
<li>-LSTM：使用LSTM聚合邻居信息，每次聚合时先随机打乱邻居节点的顺序</li>
<li>-Pooling：<span class="math inline">\(\mbox{AGGREGATE}^{\mbox{pool}}_k=\mbox{max}(\{\sigma(W_{pool}\mathbf{h}_u^{k-1}+\mathbf{b}),\ u\in \forall N(v) \})\)</span></li>
</ol>
<h2 id="experiments">3 Experiments</h2>
<p>三个实验：</p>
<ul>
<li>Web of Science引文网络分类任务，判断paper属于哪个subject。</li>
<li>Reddit中发送的post的分类任务，判断用户发送的post属于哪个community</li>
<li>protein-protein interaction (PPI)分类任务，判断蛋白质的功能</li>
</ul>
<p>对应的构造了三个数据集</p>
<ul>
<li>Wos Data：从Web of Science Core Collection中收集，2000-2005年6个生物领域的论文，标签就是这6个生物领域。使用2000-2004年数据作为训练，使用30%的2005年数据作为验证集，70%作为测试集。最终数据集包括了302,424节点，平均degree 9.15。在实验时，使用论文abstract的sentence embedding以及节点的degree作为初始特征输入。</li>
<li>Reddit Data：从Reddit 2014年9月中构造数据，选择了50个大的Reddit communities，如果用户在两个post下进行了评论，就把这两个post连接起来。20天训练，剩下的3天验证，7天测试。最终包含232,965节点，平均度492。实验时，post的title embedding，comment embedding，post的打分，comment的数量作为初始特征输入。</li>
<li>PPT Data：从Molecular Signatures Database中构造数据集，20个graph训练，2个graph验证，2个graph测试。每个graph来自不同的人体组织，平均graph有2373个节点，平均degree 28.8，一共121个标签。</li>
</ul>
<p>在验证集上寻找各个模型最好的参数，然后在测试集上评估。</p>
<p>实验时，还对比了监督学习（直接与标签进行cross-entropy）和无监督学习</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201221090604439.png" alt="image-20201220103317625" /><figcaption>image-20201220103317625</figcaption>
</figure>
<p>最终，作者发现K=2相对是比较好的选择，同时，采样s邻居数量<span class="math inline">\(S_1\cdot S_2 &lt; 500\)</span>较好，实验时使用的GraphSAGE都是K=2，<span class="math inline">\(S_1=25\)</span>，<span class="math inline">\(S_2=10\)</span>。</p>
<h2 id="minibatch-pseudocode">4 Minibatch pseudocode</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201220103317625.png" alt="mage-20201221090604439" /><figcaption>mage-20201221090604439</figcaption>
</figure>
<p>首先采样在对batch <span class="math inline">\(B\)</span>进行K阶训练，需要用到的所有节点。<span class="math inline">\(B^k\)</span>包括了所有在训练<span class="math inline">\(k+1\)</span>时需要用到的节点的<span class="math inline">\(k\)</span>阶表示。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>GNN-size-generalization</title>
    <url>/gnn/GNN-size-generalization/</url>
    <content><![CDATA[<h1 id="from-local-structures-to-size-generalization-in-graph-neural-networks">From Local Structures to Size Generalization in Graph Neural Networks</h1>
<p>ICML 2021</p>
<p>作者主要讨论了GNN对于graph size generalization问题的性质探究。具体一点是指GNN在一个small graph上训练，然后在一个更大的large graph上测试的场景。</p>
<p>主要贡献：</p>
<ul>
<li>提出了graph的local structure的一种定义，d-pattern。GNN在对于相同的d-pattern会产生相同的输出。因此使用d-pattern可以作为GNN表达能力的一种抽象。</li>
<li>理论上和实验上证明了GNN在size不同的graph上，不能保证学习到的模型是有足够size generalization能力的。</li>
<li>提出了一种基于自监督的方法（Self-Supervised Learning，SSL）来提升size generalization能力，分别有无监督（unsupervised）和半监督（semi-supervised）两种loss设置。训练过程采用了预训练和多任务学习两种不同的学习过程。</li>
</ul>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p>作者主要的研究场景：small graph训练+large graph测试</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328201522509.png" alt="image-20220328201522509" style="zoom:40%;" /></p>
<p>为什么要研究这个问题？作者的出发点：</p>
<ol type="1">
<li>理论上，graph的size的差异是很大的，虽然训练好一个graph可以让它在任意size的graph（保证是统一domain下的graph）上运行，但是效果好吗？什么情况下能够做到size泛化？这个问题很有趣（intriguing）但是还没被充分研究。</li>
<li>实际上，很多large graph想要获得准确的label是很困难的，想要获得large graph的label可能是非常困难的优化问题，也可能对于人来说想要准确的给复杂的graph打label也是很难的。因此，如果GNN能够做到在small graph上训练好，然后很好的泛化到large graph上，就是一个很有意义的研究。</li>
</ol>
<h2 id="overview">Overview</h2>
<p>几个作者希望声明的argument：</p>
<ol type="1">
<li><p>作者提出的d-pattern是研究GNN表达能力的一种合适的抽象表达（<strong>d-patterns are a correct notion for studying the expressivity of GNNs.</strong>）。依赖于d-pattern，GNN可以输出独立的任意值，对于具有一样d-pattern的node来说，GNN会输出一样的值。因此对于现有的GNN来说，d-pattern直接限制了它的表达能力。</p></li>
<li><p>small graph和large graph之间的d-pattern差异，暗示了可能存在某种糟糕的优化选择，导致GNN无法做到size generalization（<strong>d-pattern discrepancy implies the existence of bad global minima.</strong>）。</p></li>
<li>GNN在一般的情况下，会倾向于收敛到不泛化的解（<strong>GNNs converge to non-generalizing solutions.</strong>）。作者进行了实验上的证明，并且也发现，如果尝试不断改变small graph的分布，GNN泛化能力会有相应的提升</li>
<li>GNN的size generalization可以被提升（<strong>Size generalization can be improved.</strong>）。作者提出了新的SSL的训练方法，可以提升GNN的size generalization能力。</li>
<li><p>GNN的size泛化，不是简单的L1或L2防止过拟合问题，实际上，如果单纯的加入正则项，反而会让GNN的size generalization能力降低。</p></li>
</ol>
<h2 id="gnns-and-local-graph-patterns">GNNs and local graph patterns</h2>
<p>来看一下作者定义的d-pattern：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328203208523.png" alt="image-20220328203208523" style="zoom:50%;" /></p>
<p>这里的定义与WL-test类似。看看示例图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328203249132.png" alt="image-20220328203249132" style="zoom:40%;" /></p>
<p>作者提出的两个定理：</p>
<ol type="1">
<li>对于具有相同d-pattern的node，任意GNN都会输出相同的值。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328203453181.png" alt="image-20220328203453181" style="zoom:50%;" /></p>
<p>这个定理是说GNN能够表达的映射函数，如果节点的d-pattern一样，那么GNN输出也一样；如果d-pattern不一样，那么GNN输出可能一样，可能不一样。联想到GIN中提出的单射问题，和这个理论是能够联系的。GIN提出的单射问题是希望不同d-pattern能够对于不同的输出。</p>
<ol start="2" type="1">
<li>对于具有不同d-pattern的node，假设各自不同的d-pattern有不同的label，那么总存在一个GNN能够完美拟合。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328203635494.png" alt="image-20220328203635494" style="zoom:40%;" /></p>
<h2 id="bad-global-minima-exist">”Bad” global minima exist</h2>
<p>在这一部分，作者提出GNN可能学习到泛化能力弱的解。</p>
<p>同样，作者提出了两个定理：</p>
<ol type="1">
<li>存在一个GNN在small graph上效果很好，但是对于large graph（包含没有在small graph上出现过的d-pattern），可能有任意范围的error。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328204225483.png" alt="image-20220328204225483" style="zoom:40%;" /></p>
<ol start="2" type="1">
<li>一个和上面定理相似的定理，但是描述了small graph和large graph的d-pattern分布差异和可能导致的error。存在一个GNN在small graph上，表现好（指对于d-pattern集合A，<span class="math inline">\(error&lt;\epsilon\)</span>），但是在large graph上的error更大（指让large graph error最大的集合A的误差）。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328204906574.png" alt="image-20220328204906574" style="zoom:40%;" /></p>
<h2 id="towards-improving-size-generalization">Towards improving size generalization</h2>
<p>来看一下作者如果尝试解决size generalization问题。首先，作者同时从small graph和large graph上构造了pattern-tree，然后用这个pattern-tree进行学习任务。</p>
<p>pattern-tree：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328205133102.png" alt="image-20220328205133102" style="zoom:40%;" /></p>
<p>左上角是原来的graph，右上角是node对应的pattern-tree，底部是要预测的值（向量），也就是计算每一层的节点数量。</p>
<p>为什么要使用这个pattern-tree呢？作者在前面发现，GNN的size generalization做不好，就是因为在large graph上会有unseen d-pattern，那么如果提前想办法学习好small和large graph的d-pattern的信息，让两者的d-pattern表示有某种程度的对齐（通过一起训练的方法），是不是就能够提升模型效果？</p>
<p>如果构造pattern-tree：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328205701565.png" alt="image-20220328205701565" style="zoom:50%;" /></p>
<p>简单说，就是迭代的往叶子结点上添加它的邻居节点。</p>
<p>怎么使用？</p>
<p>两种训练策略：</p>
<ul>
<li>Pretraining：第一阶段，训练GNN，预测pattern-tree的descriptor；第二阶段，固定GNN值，预测目标task。</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328210257357.png" alt="image-20220328210257357" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328210309307.png" alt="image-20220328210309307" style="zoom:50%;" /></p>
<ul>
<li>Multitask training：同时训练pattern-tree task和main task。</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328210353315.png" alt="image-20220328210353315" style="zoom:50%;" /></p>
<p>两种设置的示意图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328210152599.png" alt="image-20220328210152599" style="zoom:50%;" /></p>
<p>实验发现，还是pretraining的方式更好一点。</p>
<p>作者还尝试了另外的semi-supervised setup，即加入一小部分large graph中有label的data，加入到前面的训练loss中。</p>
<h2 id="appendix">Appendix</h2>
<p>作者在附录提供了定理详细的证明过程，我只是粗略的看了一遍从直观上认识定理证明是否正确，没有严谨的推导。但是，有一个有意思的前人（Small relu networks are powerful memorizers: a tight analysis of memorization capacity.）提出的定理可以学习：</p>
<ul>
<li>对于各不相同的输入<span class="math inline">\(\mathbf{x}_i\)</span>，输出是<span class="math inline">\(y_i\in[-1,1]\)</span>，总存在一个三层的<span class="math inline">\(ReLU\)</span>网络可以完美拟合</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220328211224061.png" alt="image-20220328211224061" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>HAN</title>
    <url>/gnn/HAN/</url>
    <content><![CDATA[<h1 id="heterogeneous-graph-attention-network">Heterogeneous Graph Attention Network</h1>
<p>2019-4-13</p>
<h2 id="introduction">1 INTRODUCTION</h2>
<p>HAN设计了两个层次的attention机制，</p>
<ul>
<li>Semantic-level attention：在不同的meta-path中选择weight</li>
<li>Node-level attention：对于一个节点，它的邻居的weight</li>
</ul>
<span id="more"></span>
<h2 id="related-work">2 RELATED WORK</h2>
<blockquote>
<p>The graph convolutional neural work generally falls into two categories, namely spectral domain and non-spectral domain.</p>
</blockquote>
<h2 id="the-proposed-model">4 THE PROPOSED MODEL</h2>
<p>总的来说，HAN包括了两个层次的attention，node-level和semantic-level，node-level attention的输出作为semantic-level层次的输入。</p>
<h3 id="node-level-attention">4.1 Node-level Attention</h3>
<p>对于<span class="math inline">\((i,j,\Phi)\)</span>，<span class="math inline">\(i,j\)</span>表示节点，<span class="math inline">\(\Phi\)</span>表示meta-path。</p>
<p>node-level attention针对的目标是同一个meta-path下的nodes的weight。</p>
<p>首先根据node type确定投影embedding， <span class="math display">\[
h^{&#39;}_i=M_{\phi_i}h_i \\
\phi_i: node \ i \ type
\]</span> 计算attention value， <span class="math display">\[
\alpha_{ij}=\frac{exp(\sigma(a^T[h_i^{&#39;}||h_j^{&#39;}]))}{\sum_{k\in N_i^{\Phi}}  exp(\sigma(a^T[h_i^{&#39;}||h_k^{&#39;}]))}
\]</span> 把所有node的embedding结合起来， <span class="math display">\[
z_i^\Phi = \sigma(\sum_{j\in N_i^{\Phi}} \alpha_{ij}^\Phi h_{ij}^{&#39;} )
\]</span> 类似于GAT，采用multi-head attention， <span class="math display">\[
z_i^\Phi = ||_{k=1}^K \sigma(\sum_{j\in N_i^{\Phi}} \alpha_{ij}^\Phi h_{ij}^{&#39;} )
\]</span> 这是一种meta-path下一个节点<span class="math inline">\(i\)</span>的最终输出，对于所有的<span class="math inline">\(\Phi\)</span>与全部的node，产生<span class="math inline">\(\{z_i^{\Phi_0}, z_i^{\Phi_1},\dots z_i^{\Phi_p}\}\)</span>。</p>
<h2 id="semantic-level-attention">4.2 Semantic-level Attention</h2>
<p>要计算各种类型的meta-path的weight，就要在全局的情况下计算， <span class="math display">\[
\omega_{\Phi_p}=\frac{1}{|V|}\sum_{i\in V}q^T tanh(Wz_i^{\Phi_p}+b) \\
\beta_{\Phi_p}=softmax(\omega_{\Phi_p})
\]</span> 最后求和，得到最终的embedding， <span class="math display">\[
Z_i=\sum_{p=1}^P \beta_{\Phi_p}z_i^{\Phi_p}
\]</span> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200221215000895.png" alt="image-20200221215000895" style="zoom: 33%;" /></p>
<h2 id="experiments">5 EXPERIMENTS</h2>
<p>略</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>hypernetworks-collection</title>
    <url>/collection/hypernetworks-collection/</url>
    <content><![CDATA[<h1 id="collection-of-hypernetworks-papers">Collection of Hypernetworks Papers</h1>
<p>调研hypernetwork相关文章</p>
<ul>
<li>Dynamic Convlutional Layer（CVPR 2015）</li>
<li>SRCNN（ICCV 2015）</li>
<li>DFN（NIPS 2016）</li>
<li>HyperNetworks（ICLR 2017）</li>
<li>Nachmani et al. （arxiv 2020）</li>
<li>Hyper-CNN（arxiv 2021）</li>
<li>HyperSeg（CVPR 2021）</li>
<li>LGNN（IJCAI 2021）</li>
</ul>
<span id="more"></span>
<h2 id="dynamic-convlutional-layer">Dynamic Convlutional Layer</h2>
<p><strong>A Dynamic Convolutional Layer for Short Range Weather Prediction</strong> CVPR 2015</p>
<p>针对短时天气预测任务，这个任务会接收一个时序的图像数据，然后预测新的天气图像。构造了一个动态卷积层，对于当前的天气图像要使用的卷积参数，该参数由前面时序的图像输入生成。</p>
<p>模型的整体结构，DC表示动态卷积层，Network B就是用来生成卷积核的网络，同样是一个卷积网络。Network B的输出是两个，垂直卷积核V和水平卷积核H，经过softmax得到SV1和SH1。最后的CROP是一个裁剪层crop layer，只取DC2输出的中心patch。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210914164044854.png" alt="image-20210914164044854" /></p>
<p>产生卷积核的network B结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210914164712746.png" alt="image-20210914164712746" style="zoom:50%;" /></p>
<h2 id="srcnn">SRCNN</h2>
<p><strong>Conditioned Regression Models for Non-Blind Single Image Super-Resolution</strong> ICCV 2015</p>
<p>针对Single image super-resolution（SISR）任务，它接收一个低分率的图像<span class="math inline">\(l\)</span>，输出高分辨率图像<span class="math inline">\(h\)</span>。作者认为在还原为高分辨率的图片时，对于不同的图片，应该是有不同的blur kernel，而不是让blur kernel在训练和测试过程中一直固定。</p>
<p>作者为每个image都定义了一个额外的blur kernel，然后使用生成参数的方法生成新的blur 卷积核。SRCNN的示例图。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210914165618622.png" alt="image-20210914165618622" style="zoom:50%;" /></p>
<p>图片中的<span class="math inline">\(W_{1}(k,\theta)\)</span>就是生成的blur kernels，生成方式就是简单的全连接层。</p>
<h2 id="dfn">DFN</h2>
<p><a href="https://github.com/dbbert/dfn"><strong>Dynamic Filter Networks</strong></a> NIPS 2016</p>
<p>作者在video and stereo prediction任务上进行实验，使用一个ﬁlter-generating network生成参数，然后进行dynamic ﬁltering layer。作者除了让参数sample-specific，还产生了location-specific的参数。</p>
<p>概念图如下，其中input B依赖于之前的input A。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210914170121911.png" alt="image-20210914170121911" style="zoom:50%;" /></p>
<p>针对不同预测任务，作者设计了了不同的DFN。</p>
<p>在video prediction上，产生参数的网络是一个encoder-decoder的网络，输出是location-specific的卷积核。 <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210914170342132.png" alt="image-20210914170342132" style="zoom:50%;" /> 学习steerable ﬁlters，产生参数的网络是MLP。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210914170640801.png" alt="image-20210914170640801" style="zoom:50%;" /> ## HyperNetworks</p>
<p><strong>HyperNetworks</strong> ICLR 2017</p>
<a href="#">Post not found: HyperNetworks[个人详细博客]</a>
<p>核心贡献是将Hypernetwork扩展到了convolutional networks和long recurrent networks，证明其在使用更少的参数情况下，在序列模型和卷积网络的多个预测任务下都达到了不错的训练结果。</p>
<p>CNN：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111153567.png"  style="zoom:50%;" /></p>
<p>RNN：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111631387.png" alt="image-20210725111631387" style="zoom: 33%;" /></p>
<h2 id="nachmani-et-al.">Nachmani et al.</h2>
<p><strong>Molecule Property Prediction and Classiﬁcation with Graph Hypernetworks</strong> arxiv 2020</p>
<p>在molecule property prediction and classiﬁcation任务上，将hypernetwork引入GNN提升模型效果。为了解决hypernetwork存在的不稳定问题，作者发现拼接current message和first message来作为hypernetwork的输入能够解决这一问题。</p>
<p>作者针对NMP-Edge network, Invariant Graph Network和Graph Isomorphism Network都引入了hypernetwork。下面重点关注对GIN的改进。</p>
<p>GIN原来的形式</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210915103148269.png" alt="image-20210915103148269" style="zoom:50%;" /></p>
<p>改进后：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210915103214168.png" alt="image-20210915103214168" style="zoom:50%;" /></p>
<p><span class="math inline">\(f\)</span>和<span class="math inline">\(g\)</span>是3层和2层使用tanh的MLP。可以看到，它使用current message和first message作为hypernetwork输入，hypernetwork同样是一个GNN的形式，以节点为中心。</p>
<h2 id="hyper-cnn">Hyper-CNN</h2>
<p><strong>Hyper-Convolution Networks for Biomedical Image Segmentation</strong> arxiv 2021</p>
<p>作者将filter kernel的二维坐标作为输入，经过hypernetwork产生对应的kernel value。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210916103216333.png" alt="image-20210916103216333" style="zoom: 33%;" /></p>
<p>作者的hypernetwork是一个多层（四层）的1x1卷积网络，在实现的时候，主网络的每一层都有一个对应的hyper-CNN作为补充。</p>
<p>hypernetwork输入是表示x和y轴的两个channel输入，然后不断经过1x1卷积，不改变channel维度，最后输出weight。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210916103510440.png" alt="image-20210916103510440" style="zoom:50%;" /></p>
<h2 id="hyperseg">HyperSeg</h2>
<p><a href="https://nirkin.com/hyperseg"><strong>HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation</strong></a> CVPR 2021</p>
<p>这篇文章是针对Real-time Semantic Segmentation任务，不是很了解这个任务，看起来是针对实时拍摄的image进行scene understanding，划分图像边界。</p>
<p>作者引入了hypernetwork，动态产生卷积weight，进行patch-wise的卷积操作，最后输出预测。hypernetwork使用了U-Net的结构（同样不了解）。</p>
<p>整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210917180259574.png" alt="image-20210917180259574" style="zoom:50%;" /></p>
<p>这里hypernetwork就是context head，它接受backbone的输出。backbone会把原来的image划分为不同resolution的feature map，最后的一个feature map输出给hypernetwork。</p>
<p>hypernetwork的输出是一个大的signal map，提供给不同的meta-block使用，划分方式是作者设计了一个根据channel和不同meta-block需要的weights进行划分，划分方法在附录里，没有细看。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210917180815544.png" alt="image-20210917180815544" style="zoom:50%;" /></p>
<h2 id="lgnn">LGNN</h2>
<p><strong>Node-wise Localization of Graph Neural Networks</strong> IJCAI 2021</p>
<p>作者认为对于整个图学习同样的weight matrix，可能导致模型倾向于建模最常见的pattern，而不是针对不同node的不同的local context进行学习。作者让graph中不同node拥有不同的weight matrix。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195057584.png" alt="image-20210921195057584" style="zoom:50%;" /></p>
<p>具体有两个Node-level localization和Edge-level localization.</p>
<p><strong>Node-level localization</strong></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195215512.png" alt="image-20210921195215512" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195243176.png" alt="image-20210921195243176" style="zoom:50%;" /></p>
<p>注意，这里没有给不同node都定义新的vector，而是直接从上一层的邻居直接mean聚合，然后进行转换，生成的向量<span class="math inline">\(a_v\)</span>和<span class="math inline">\(b_v\)</span>之后用于生成node <span class="math inline">\(v\)</span>的weight matrix。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195358969.png" alt="image-20210921195358969" style="zoom:50%;" /></p>
<p>注意这里，是把<span class="math inline">\(a_v\)</span>和<span class="math inline">\(b_v\)</span>作为一行，然后复制，最后作用到graph global matrix<span class="math inline">\(W_l\)</span>上。</p>
<p><strong>Edge-level localization</strong></p>
<p>作者对node <span class="math inline">\(v\)</span>的不同邻居edge进一步建模：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195557949.png" alt="image-20210921195557949" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195613526.png" alt="image-20210921195613526" style="zoom:50%;" /></p>
<p>最后聚合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210921195641977.png" alt="image-20210921195641977" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title>HGSL</title>
    <url>/gnn/HGSL/</url>
    <content><![CDATA[<h1 id="heterogeneous-graph-structure-learning-for-graph-neural-networks">Heterogeneous Graph Structure Learning for Graph Neural Networks</h1>
<p>AAAI 2021</p>
<p>作者声称是首个尝试为异质图神经网络寻找最优的图结构进行学习的方法，提出了HGSL（Heterogeneous Graph Structure Learning）。核心方法有两个，异质图结构学习和图神经网络。 <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706213222126.png" style="zoom:40%;" /> <span id="more"></span></p>
<h2 id="introduction">Introduction</h2>
<p><strong>motivation</strong>：目前的异质图神经网络基于一个假设，学习使用的graph是足够好的。但是实际上这个假设不一定总能够满足。两个方面的原因，（1）在建模graph的时候，使用到的信息难免会包含错误的信息，导致最终的graph是不够好的（2）另一个原因是异质图结构本身与下游任务是独立的，不一定是有利于下游任务的最优解。为了解决上面的问题，图结构学习graph structure learning (GSL)被提出来，但是这些方法主要是在考虑同质图，无法很好的考虑异质图中的异质性以及异质图中存在的复杂的交互。</p>
<p><strong>method</strong>：提出HGSL，首先学习合适的graph structure，然后在这个graph structure上使用GCN进行学习。这种heterogeneous graph structure learning是核心创新点，包括三种graph的融合，<strong>feature similarity graph</strong>，<strong>feature propagation graph</strong>,和<strong>semantic graph</strong>。</p>
<blockquote>
<p>Heterogeneous Graph Neural Networks (HGNNs) have drawn increasing attention in recent years and achieved outstanding performance in many tasks. The success of the existing HGNNs relies on one fundamental assumption, i.e., the original heterogeneous graph structure is reliable. However, this assumption is usually unrealistic, since the heterogeneous graph in reality is inevitably noisy or incomplete. Therefore, it is vital to learn the heterogeneous graph structure for HGNNs rather than rely only on the raw graph structure. In light of this, we make the ﬁrst attempt towards learning an optimal heterogeneous graph structure for HGNNs and propose a novel framework HGSL, which jointly performs Heterogeneous Graph Structure Learning and GNN parameter learning for classiﬁcation. Different from traditional homogeneous graph structure learning, considering the heterogeneity of different relations in heterogeneous graph, HGSL generates each relation subgraph separately. Speciﬁcally, in each generated relation subgraph, HGSL not only considers the feature similarity by generating feature similarity graph, but also considers the complex heterogeneous interactions in features and semantics by generating feature propagation graph and semantic graph. Then, these graphs are fused to a learned heterogeneous graph and optimized together with a GNN towards classiﬁcation objective. Extensive experiments on real-world graphs demonstrate that the proposed framework signiﬁcantly outperforms the state-of-the-art methods.</p>
</blockquote>
<h2 id="method">Method</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706213222126.png" style="zoom:40%;" /></p>
<h3 id="feature-graph-generator">Feature Graph Generator</h3>
<p>基于node feature，通过计算相似度，学习node之间潜在的relationship。</p>
<p>对于边类型<span class="math inline">\(r\)</span>，首先，对于<span class="math inline">\(r\)</span>下的所有edge的头/尾node <span class="math inline">\(i\)</span>，根据node的类型对node feature进行转换</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706213656455.png" style="zoom:50%;" /></p>
<p>之后，计算利用余弦相似性计算两个节点的相似性</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706213845698.png" style="zoom:50%;" /></p>
<p>设计一个阈值，然后创建graph</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706213919202.png" style="zoom:50%;" /></p>
<p>这个graph，是边类型<span class="math inline">\(r\)</span>下的不同类型的头、尾实体的feature similarity graph <span class="math inline">\(\mathbf{S}^{FS}_r\)</span>。</p>
<h3 id="feature-propagation-graph">Feature Propagation Graph</h3>
<p>不同的关系<span class="math inline">\(r\)</span>，不同的node feature之间是存在complex的交互interaction的。为了建模这种复杂的交互，HGSL让node features和topology structure产生交互，然后构造一个feature propagation graph。核心思想是具有相似特征的节点可能具有相似的邻居。</p>
<p>关系r的邻接矩阵是<span class="math inline">\(\mathbf{A}_r\)</span>，头node和尾node可能具有不同的type。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706214453495.png" style="zoom:50%;" /></p>
<p>对于相同类型type的头结点<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>，构造一个头结点的相似特征图</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706215121910.png" style="zoom:50%;" /></p>
<p>之后，这些相似头结点可以通过拓扑结构传播，最终实现效果是相似头结点可以往相似头结点传播消息，获得了head feature propagation graph。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706215417582.png" style="zoom:50%;" /></p>
<p>类似的，构造相似尾结点图，然后传播，获得了tail feature propagation graph。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706215456493.png" style="zoom:50%;" /></p>
<p>之后，通过获得单纯的特征图、头实体的特征-拓扑结构交互图、尾实体的特征-拓扑结构交互图，进行融合，使用一个channel attention layer，学习一个<span class="math inline">\(1\times 1\times 3\)</span>的卷积核<span class="math inline">\(W^{Feat}_{\Psi,r}\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706215705310.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706215720881.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706215931644.png" style="zoom:50%;" /></p>
<h3 id="semantic-graph-generator">Semantic Graph Generator</h3>
<p>接下来，是学习多阶拓扑结构信息的合适图。在异质图中，不同阶的邻居信息当然是差异非常大的。</p>
<blockquote>
<p>The semantic graph is generated depending on the high-order topology structure in HIN, describing the multi-hop structural interactions between two nodes.</p>
</blockquote>
<p>HGSL使用MP2Vec去进行学习，定义了<span class="math inline">\(M\)</span>个元路径</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706220259483.png" style="zoom:50%;" /></p>
<p>对于所有的node，学习到<span class="math inline">\(M\)</span>个embedding集合，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706220338461.png" style="zoom:50%;" /></p>
<p>对于表示不同semantic的metapath信息，同样是构造一个相似图</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706220514947.png" style="zoom:50%;" /></p>
<p>使用channel attention layer融合semantic subgraph，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706220632763.png" style="zoom:50%;" /></p>
<h3 id="overall-generated-graph">Overall generated graph</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706220738042.png" style="zoom:50%;" /></p>
<h3 id="optimization">Optimization</h3>
<p>前面为每个关系都学习了一个融合的graph <span class="math inline">\(\mathbf{A}_r\)</span>，接下来作者直接使用GCN进行学习，通过直接认为只要有两个相连的node就可以认为是1，构造了<span class="math inline">\(\mathbf{A}^\prime\)</span>，推测就是直接所有的<span class="math inline">\(\mathbf{A}_r\)</span>相加。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210706221223318.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>HGT</title>
    <url>/gnn/HGT/</url>
    <content><![CDATA[<h1 id="heterogeneous-graph-transformer">Heterogeneous Graph Transformer</h1>
<p>本文的贡献主要有三点：</p>
<ol type="1">
<li>针对异质图设计了Heterogeneous Graph Transformer，HGT，用于处理Web-scale的异质网络。</li>
<li>为了能够训练大规模图，提出了HGSampling采样方法，在Open Academic Graph (OAG)上进行了验证。</li>
<li>针对动态异质图，引入relative temporal encoding，能够处理任意的动态信息</li>
</ol>
<span id="more"></span>
<p>WWW 2020</p>
<h2 id="introduction">Introduction</h2>
<p><strong>Motivation</strong> ：对于heterogeneous graph已有的处理方法有基于meta-path的方法，以及最近出现的GNN方法。但是这些方法都面临问题。</p>
<ol type="1">
<li>大多数的方法为不同的heterogeneous graph设计meta path，要求specific domain knowledge</li>
<li>很多方法要么忽略不同type的差异，直接使用共通的weight，要么直接认为不同type之间是完全独立的，为不同的方法定义各自独立的weight</li>
<li>它们大多数忽略了heterogeneous graph中存在的动态特性dynamic nature</li>
<li>它们intrinsic design无法modeling Web-scale heterogeneous graph</li>
</ol>
<blockquote>
<p>First, most of them involve the design of meta paths for each type of heterogeneous graphs, requiring specific domain knowledge;</p>
<p>Second, they either simply assume that different types of nodes/edges share the same feature and representation space or keep distinct non-sharing weights for either node type or edge type alone, making them insufficient to capture heterogeneous graphs’ properties;</p>
<p>Third, most of them ignore the dynamic nature of every (heterogeneous) graph;</p>
<p>Finally, their intrinsic design and implementation make them incapable of modeling Web-scale heterogeneous graphs.</p>
</blockquote>
<p><strong>Method</strong>：作者提出了HGT期望能够解决上面的四个问题。</p>
<ol type="1">
<li>To handle graph heterogeneity，引入node- and edge-type dependent attention mechanism. 在计算边<span class="math inline">\(&lt;s, t&gt;\)</span>的attention时，使用meta relation <span class="math inline">\(⟨node\ type\ of\ s,\ edge\ type\ of\ e\ between\ s\ \&amp;\ t,\ node\ type\ of\ t⟩\)</span>。给不同的type定义不同的weight matrix，然后组合起来成为这条边的weight matrix。这样子的话不同type的weight matrix就可以互相交互，互相影响。weight matrix被用来计算attention。另外，由于GNN的天性，聚合多阶邻居实际就是在被认为学习“soft” meta paths。另外根据attention，又能够更好的区分学习到的这些soft meta path。</li>
<li>To handle graph dynamics，类似于Transformer position encoding，定义了relative temporal encoding (RTE)。不是把不同timestamp的graph看做不同的图，而是直接把带有不同RTE的node一起聚合。</li>
<li>To handle Web-scale graph data，提出了HGSampling，采样的subgraph具有较为均匀的node type分布，同时还保证the sampled sub-graphs dense for minimizing the loss of information。</li>
</ol>
<p>先来看几个定义：</p>
<p>Heterogeneous Graph（a.k.a. heterogeneous information networks）</p>
<blockquote>
<p>Definition 1. Heterogeneous Graph: A heterogeneous graph is defined as a directed graph G = (V, E, A, R) where each node v ∈ V and each edge e ∈ E are associated with their type mapping functions τ(v) : V → A and ϕ(e) : E → R, respectively.</p>
</blockquote>
<p>“异质”的本质就是来源各不相同，type不同。</p>
<p>Meta Relation</p>
<blockquote>
<p>For an edge <span class="math inline">\(e = (s,t)\)</span> linked from source node s to target node t, its meta relation is denoted as <span class="math inline">\(⟨\tau (s),\phi (e),\tau (t)⟩\)</span>。</p>
</blockquote>
<p>常用的meta path可以看做是一系列这样的meta relation的组合</p>
<p>Dynamic Heterogeneous Graph.</p>
<blockquote>
<p>To model the dynamic nature of real-world (heterogeneous) graphs, we assign an edge <span class="math inline">\(e = (s,t)\)</span> a timestamp <span class="math inline">\(T\)</span>, when node <span class="math inline">\(s\)</span> connects to node <span class="math inline">\(t\)</span> at <span class="math inline">\(T\)</span>.</p>
</blockquote>
<p>当一个node <span class="math inline">\(s\)</span>在时间<span class="math inline">\(T\)</span>链接到<span class="math inline">\(t\)</span>的时候，认为这条边的timestamp就是<span class="math inline">\(T\)</span>，并且在以后不再更改。</p>
<h2 id="method">Method</h2>
<p>整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414163722393.png" /></p>
<p>注意这里，A-Linear是根据node <span class="math inline">\(t\)</span>的type决定的。同时使用了残差结构。</p>
<p>聚合函数就是直接相加。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414170116901.png" /></p>
<p>核心是两部分，产生消息，然后产生注意力。</p>
<p>产生消息：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414163415151.png" /></p>
<p>邻居node的type和邻居relation的type的weight相乘。</p>
<ul>
<li><p>邻居节点的type矩阵：用于转换node type独有的特征分布</p></li>
<li><p>邻居边的type矩阵：用于进行edge type的转换</p></li>
</ul>
<p>产生attention：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414170336206.png" /></p>
<p>这里在计算attention的时候就使用了meta relation。矩阵相乘的操作表示着parameter sharing。</p>
<p>与原始的transformer比较有三点不同：</p>
<ol type="1">
<li><p>考虑异质性，在计算Query和Key vector的时候使用不同类型的weight matrix。</p></li>
<li><p>在Q和K相乘时，中间加入了<span class="math inline">\(W_ϕ(e)^{ATT}\)</span>，加入它可以建模edge的信息</p></li>
<li><p>加入了μ∈R^{|A|×|R|×|A|} ，它是一个全局的meta relation weight，衡量全局意义上的元关系重要性</p></li>
</ol>
<p>除去vanilla Transformer中已经使用的K-Q计算注意力，值得注意的是加入了一个<span class="math inline">\(\mu \in \mathbb{R}^{|\mathcal{A}|\times |\mathcal{R}|\times |\mathcal{A}|}\)</span>。为所有的meta relation组合定义了一个全局范围的权重。这样导致的后果是除去单纯局部的attention，加入了global attention，能够更adaptively的学习attention。</p>
<h2 id="rte">RTE</h2>
<p>前面提到了RTE，它的核心思想是为不同timestamp的edge学习不同的表示，然后加到邻居node <span class="math inline">\(s\)</span>的表表示<span class="math inline">\(H[s]\)</span>上。</p>
<p>首先计算时间差，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414170312971.png" /></p>
<p>，然后编码，使用一个scalar生成一个embedding</p>
<p><span class="math inline">\(2i,\ 2i+1\)</span>应该是dim</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414180544283.png" /></p>
<p>最后加到邻居node <span class="math inline">\(s\)</span>的表表示<span class="math inline">\(H[s]\)</span>上。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414163541401.png" /></p>
<h2 id="hgsampling">HGSampling</h2>
<p>为了训练大规模的graph，必须进行采样，每次只训练一部分的graph，即采样subgraph。这一操作在graphSAGE中已经有相应的算法。但是问题在于，这样随机的采样导致后果是sub-graph在不同type下采样的数量非常imbalance。</p>
<blockquote>
<p>To address this issue, different sampling-based methods [1, 2, 7, 29] have been proposed to train GNNs on a subset of nodes. However, directly using them for heterogeneous graphs is prone to get sub-graphs that are extremely imbalanced regarding different node types, due to that the degree distribution and the total number of nodes for each type can vary dramatically.</p>
</blockquote>
<p>HGSampling算法能够保证两点：</p>
<ol type="1">
<li>不同类型的node和edge具有相近的数量</li>
<li>每次采样得到的sub-graph足够密集能够用于降低loss，同时减少sample variance</li>
</ol>
<p>核心思想是为不同的node type，根据重要程度，采样相同数量的node。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414180603410.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210414152012151.png" /></p>
<h2 id="experiment">Experiment</h2>
<p>核心数据集，Open Academic Graph (OAG)</p>
<blockquote>
<p>OAG consists of more than 178 million nodes and 2.236 billion edges—the largest publicly available heterogeneous academic dataset. In addition, all papers in OAG are associated with their publication dates, spanning from 1900 to 2019.</p>
</blockquote>
<p>为了验证模型的泛化性，同时从OAG中抽离出来两个不同的子集，Computer Science (CS) and Medicine (Med) academic graphs。</p>
<p>对于所有的edge，增加self和reverse relation。</p>
<p>prediction task有四个：</p>
<ul>
<li>the prediction of Paper–Field (L1)</li>
<li>Paper–Field (L2)</li>
<li>Paper–Venue</li>
<li>Author Disambiguation</li>
</ul>
<p>前三个实际是分类任务，最后一个是link prediction，使用了NTN。</p>
<blockquote>
<p>For author disambiguation, we select all the authors with the same name and their associated papers. The task is to conduct link prediction between these papers and candidate authors. After getting the paper and author node representations from GNNs, we use a Neural Tensor Network to get the probability of each author-paper pair to be linked.</p>
</blockquote>
<p>指标：</p>
<ul>
<li>NDCG</li>
<li>MRR</li>
</ul>
<p>使用2015年以前的数据作为训练集，2015-2016年的数据作为验证集，2016-2019年的数据作为测试集。</p>
<p>初始化的特征：</p>
<ul>
<li>paper：使用提前训练好的XLNet，然后根据title的word，使用attention平均，捕获语义特征</li>
<li>author：所有发表论文的特征，然后平均</li>
<li>field，venue和institute：使用metapath2vec，捕获结构特征</li>
</ul>
<p>为了公平比较，对于其它的baseline，在输入之前增加一层adaptation layer，把不同type的feature投影到同一分布下。</p>
<p>实现细节：</p>
<ul>
<li>256 dim</li>
<li>8 multi-head number</li>
<li>3 layer</li>
<li>All baselines are optimized via the AdamW optimizer</li>
<li>Cosine Annealing Learning Rate Scheduler</li>
<li>200 epoch</li>
<li>select the one with the lowest validation loss</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>HetSANN</title>
    <url>/gnn/HetSANN/</url>
    <content><![CDATA[<h1 id="an-attention-based-graph-neural-network-for-heterogeneous-structural-learning">An Attention-based Graph Neural Network for Heterogeneous Structural Learning</h1>
<p><a href="https://github.com/didi/hetsann">HetSANN</a>，AAAI 2020</p>
<p>提出了Heterogeneous Graph Structural Attention Neural Network (HetSANN），主要创新点有三个：</p>
<ul>
<li>对于预测标签任务，采用多任务学习，不同type的节点进行预测有不同的classifier（实际是全连接层+softmax）</li>
<li>针对edge和reversed edge，除了一般的基于拼接的方法计算attention外，提出了voice-sharing product的计算注意力方法。</li>
<li>在不同type的邻居信息转换中，提出了一个保持weight matrix的cycle consistent的方法。</li>
</ul>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p>作者认为如果使用基于meta-path的方法有以下缺点</p>
<ol type="1">
<li>meta-path的选择依赖于专家，并且需要手动设计</li>
<li>在meta-path中间的节点和边的信息被忽略。</li>
</ol>
<h2 id="method">Method</h2>
<p>看一下模型的整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193220627.png" alt="image-20210803193220627" style="zoom:50%;" /></p>
<h3 id="type-aware-attention-layer-tal">Type-aware Attention Layer (TAL)</h3>
<p>采用多头注意力（一般是8个头）</p>
<p>首先是基于type的邻居信息转化，node <span class="math inline">\(i\)</span> 提供给node <span class="math inline">\(j\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193433545.png" alt="image-20210803193433545" style="zoom:50%;" /></p>
<p>注意，这里的<span class="math inline">\(W\)</span>是根据中心node和邻居node的type同时区分的。</p>
<p>然后基于注意力聚合邻居信息，下面的是一般的GAT的方法，作者叫做<em>concat product</em>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193632456.png" alt="image-20210803193632456" style="zoom:50%;" /></p>
<p>需要注意的是，这里的注意力向量<span class="math inline">\(\alpha_r\)</span>，是每个edge type各有一个。然后就是基于softmax的attention聚合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193716164.png" alt="image-20210803193716164" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193733856.png" alt="image-20210803193733856" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803193750622.png" alt="image-20210803193750622" style="zoom:50%;" /></p>
<p>实际上，作者还提出了<em>voice-sharing</em>的注意力计算方法，主要是希望考虑关系和逆关系之间的对应联系。让注意力向量<span class="math inline">\(\alpha_r\)</span>互为负数，然后利用相加计算注意力。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803194003584.png" alt="image-20210803194003584" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803194127412.png" alt="image-20210803194127412" style="zoom:50%;" /></p>
<p>作者起名叫voice-sharing是因为以下的原因：</p>
<blockquote>
<p>The voice is the concept of English grammar including active voice and passive voice. Here we refer the active voice to the directed edge (cite, write, etc.) and refer the passive voice to the reversed edge (cited, written, etc.).</p>
</blockquote>
<p>最后的输出，就是多头注意力拼接+残差</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803194515638.png" alt="image-20210803194515638" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803194536089.png" alt="image-20210803194536089" style="zoom:50%;" /></p>
<p>整个TAL层如图所示。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803194602158.png" alt="image-20210803194602158" style="zoom:50%;" /></p>
<h3 id="multi-task-learning">Multi-task Learning</h3>
<p>对于不同type node的预测，定义了不同的output layer（一个全连接层）和softmax。但是gnn的参数是一样的。</p>
<h3 id="cycle-consistency-loss">Cycle-consistency Loss</h3>
<p>这一点很有意思，作者认为对于node的状态转化可以形成一个循环：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803194815041.png" alt="image-20210803194815041" style="zoom: 33%;" /></p>
<p>从中心节点node <span class="math inline">\(j\)</span>出发，有一个self-loop，作者认为self-loop之后的状态应该和从<span class="math inline">\(j\rightarrow i,\ i\rightarrow i,\ i\rightarrow j\)</span>的循环一样。即下面的式子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803195143924.png" alt="image-20210803195143924" style="zoom:50%;" /></p>
<p>由于matrix的逆矩阵比较难算，作者直接定义了一个新的逆矩阵</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803195313907.png" alt="image-20210803195313907" style="zoom:50%;" /></p>
<p>最后，上面的两个约束体现在loss中：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803195347065.png" alt="image-20210803195347065" style="zoom:50%;" /></p>
<p>最终的loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210803195411879.png" alt="image-20210803195411879" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>How-Powerful-of-GNN</title>
    <url>/gnn/How-Powerful-of-GNN/</url>
    <content><![CDATA[<h1 id="how-powerful-are-graph-neural-networks">HOW POWERFUL ARE GRAPH NEURAL NETWORKS?</h1>
<p>This paper:</p>
<ol type="1">
<li>characterize how expressive different GNN variants are in learning to represent and distinguish between different graph structures</li>
<li>show that GNNs are at most as powerful as the WL test in distinguishing graph structures.</li>
<li>identify graph structures that cannot be distinguished by popular GNN variants, such as GCN (Kipf &amp; Welling, 2017) and GraphSAGE (Hamilton et al., 2017a)</li>
<li>develop a simple neural architecture, Graph Isomorphism Network (GIN)</li>
</ol>
<span id="more"></span>
<div class="pdf-container" data-target="HOW-POWERFUL-ARE-GRAPH-NEURAL-NETWORKS.pdf" data-height="1000px"></div>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>InteratE</title>
    <url>/gnn/InteractE/</url>
    <content><![CDATA[<h1 id="interacte-improving-convolution-based-knowledge-graph-embeddings-by-increasing-feature-interactions">InteractE: Improving Convolution-based Knowledge Graph Embeddings by Increasing Feature Interactions</h1>
<p>2019-11-12</p>
<p>在ConvE的基础上，进行了特征dim随机排列，棋盘状的排列，以及多channel的卷积。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>由三元组表示的知识图谱在很多地方有广泛的应用：</p>
<ul>
<li>关系导出</li>
<li>问题回答</li>
<li>规范化</li>
<li>推荐系统</li>
<li>对话系统</li>
</ul>
<p>但是目前的知识图谱是imcomplete的，针对这个问题<em>link prediction</em>任务出现了。该任务的主要目标是根据已有知识图谱当中的事实(fact)来推测缺失的事实。常用的方法就是将所有的entity和relation转变为低维表示，然后利用这些低维表示通过一个得分函数（score function）来预测新的事实。</p>
<p>基于以上的思想，有几种不同类别的方法：</p>
<ul>
<li>基于翻译距离的方法：TransE、TransH</li>
<li>基于语义匹配的方法：HoleE、ANALOGY</li>
<li>神经网络方法：NTN、ConvE</li>
</ul>
<p>用CNN来学习KGE能够比一般的NN更有expressive，学习到非线性的信息；同时CNN本身就能保证参数效率，防止过度参数化。</p>
<h2 id="related-work">2 Related Work</h2>
<p>ConvE： <span class="math display">\[
\psi_r(e_s,e_o)=relu(vec(relu([\bar{e_s}; \bar{r_r}] \star \cal{w})) W)e_o
\]</span> 在2018年提出来的ConvE存在interaction被限制的缺点，因此提出了InteractE期望能够解决该问题。</p>
<h2 id="notation-and-deﬁnitions">3 Notation and Deﬁnitions</h2>
<p>实体<span class="math inline">\(s\)</span>和关系<span class="math inline">\(r\)</span>的<span class="math inline">\(d\)</span>维表示： <span class="math display">\[
e_s=(a_1,\dots,a_d) \\
e_r=(b_1,\dots,b_d)
\]</span> Reshaping Function： <span class="math display">\[
\phi: R^d\times R^d=R^{m\times n}
\]</span> <span class="math inline">\(\phi\)</span>函数有以下几种类型：<span class="math inline">\(\phi_{stk},\ \phi_{alt},\ \phi_{chk}\)</span></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405164138063.png" /></p>
<h2 id="interacte-details">4 InteractE Details</h2>
<p>总体结构</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405191734032.png" alt="image-20200405171149898" /><figcaption>image-20200405171149898</figcaption>
</figure>
<h3 id="feature-permutation">4.1 Feature Permutation</h3>
<p>拿到向量<span class="math inline">\(e_s,\ e_r\)</span>先进行特征随机排列，也就是对于<span class="math inline">\(e_s=(a_1,\dots,a_d)\  e_r=(b_1,\dots,b_d)\)</span>进行随机排序。一共可以进行<span class="math inline">\(t\)</span>次。得到， <span class="math display">\[
P_t=[(e_s^1,e_r^1),\cdots,(e_s^t,e_r^t)]
\]</span></p>
<h3 id="checkered-reshaping">4.2 Checkered Reshaping</h3>
<p>对于上一步的结果，使用格子/棋盘reshape成二维矩阵， <span class="math display">\[
\phi_{chk}(P_t)=[\phi(e_s^1,e_r^1),\cdots,\phi(e_s^t,e_r^t)]
\]</span></p>
<h3 id="circular-convolution">4.3 Circular Convolution</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405191900132.png" /></p>
<p>循环卷积， <span class="math display">\[
[x\star \omega]_{p,q}=\sum_{i=-\lfloor {k/2}\rfloor}^{\lfloor {k/2}\rfloor} \sum_{j=-\lfloor {k/2}\rfloor}^{\lfloor {k/2}\rfloor} x_{[p-i]_m,\ [q-j]_n} \omega_{i,j}
\]</span></p>
<h3 id="score-function">4.4 Score Function</h3>
<p><span class="math display">\[
\psi_r(e_s,e_o)=g(vec(f(\phi(P_t) \star \cal{w})) W)e_o
\]</span></p>
<h2 id="experimental-setup">5 Experimental Setup</h2>
<p>数据集</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405192616146.png" /></p>
<h3 id="performance-comparison">5.1 Performance Comparison</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405193118638.png" /></p>
<p>在整体性能的比较上来看，对于ConvE是有较明显的提升。同时在WN18RR数据集上的效果不显著。这一点和在ConvE里面发现的现象一致，因为这个数据集可能更适合于浅层的模型因为它的平均关联度就很低。</p>
<h3 id="effect-of-feature-reshaping-and-circular-convolution">5.2 Effect of Feature Reshaping and Circular Convolution</h3>
<p>探究重组方法以及循环卷积对于效果的影响。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405171149898.png" /></p>
<p>可以看出来：</p>
<ul>
<li>多数情况下，采用同样的reshape方式，循环卷积要优于标准卷积</li>
<li>随着interaction的增多，效果逐渐增强，而且循环卷积+棋盘式总能取得最好的结果</li>
</ul>
<h3 id="effect-of-feature-permutations">5.3 Effect of Feature Permutations</h3>
<p>探究特征随机排列的次数对于模型结果的影响</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405193453990.png" /></p>
<p>可以观察到，实际上较小的组合数量就能够取得较优的结果，1/2次随机的排列组合就能够取得不错的结果。再增加组合次数会造成过度参数化。</p>
<h3 id="evaluation-on-different-relation-types">5.4 Evaluation on different Relation Types</h3>
<p>对于不同类型的关系进行预测的结果。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200405171009766.png" /></p>
<p>可以看出来首先InteractE是全面优于ConvE的；另外，它更善于建模N-1和N-N的关系，而RotatE更擅长建模1-1的关系。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>Introduction-GNN</title>
    <url>/gnn/Introduction-GNN/</url>
    <content><![CDATA[<h1 id="introduction-to-graph-neural-networks">Introduction to Graph Neural Networks</h1>
<p>Note of book 《Introduction to Graph Neural Networks》</p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p>所谓的图graph就是一种数据结构，由节点集合与边集合组成。具有图结构的数据存在于众多的领域中，包括社交网络、化学分子、知识图谱等。最近图神经网络的出现使得在图上的深度学习成为了可能，图神经网络也受到了大量的研究关注。</p>
<p>图神经网络起源于两大部分，卷积神经网络（Convolutional Neural Network）与图嵌入（Graph Embedding）。</p>
<p>CNN在图像（image）上的成功在于它能够导出多尺度（multi-scale）局部化（localized）的空间特征。应用CNN的三个关键点在于局部连接（local connection）、共享参数（shared weight）以及多层结构（multi-layer）。这三个点对于图同样是很重要的，首先图中的绝大多数结构都是局部连接的；其次，共享参数能够帮助减少传统的基于谱图理论的图算法计算复杂度；最后，多层的结构能够用来捕获图中的层级结构信息。但是，由于图像是规则的欧几里得域（Euclidean domian）下的数据结构，而图是非欧几里得数据的（non-Euclidean），因此我们无法直接将传统的CNN应用到图上。我们需要一种新的模型，在保留CNN的三个关键特征的同时，能够处理非欧式空间下的图结构。</p>
<blockquote>
<p>简单辨析下欧几里得的数据以及非欧几里得下的数据：</p>
<p>在机器学习中处理的数据可以分为欧几里得和非欧几里得两类。两者的核心区别在于是否“排列整齐”，前者对于数据，可以使用<span class="math inline">\(\mathbb{R}^n\)</span>的空间进行描述，不丢失任何的原始信息。这一类数据的代表是图像、文字、一般的数值数据等。非欧几里得的数据实际广泛存在，主要有图（graph）和流型（mainfold）两类。对于这一类的数据，比如graph中的每个节点的邻居节点、邻居边都各不相同，数量不一，无法使用一个<span class="math inline">\(n\)</span>维的空间来完全描述此类数据。</p>
</blockquote>
<p>图嵌入的发展收到词嵌入（word embedding），Deepwalk被认为是首个学习图嵌入的方法，它将图中的每个节点都表示为了<span class="math inline">\(n\)</span>维的嵌入向量。Deepwalk首先在图上进行随机游走采样，之后应用SkipGram方法学习到合适的嵌入表示。在Deepwalk后，node2Vec，LINE，TADW这些方法逐步发展。但是这些方法存在两方面的缺点，一个是由于需要随机游走，学习到的方法很难直接用到新数据上，泛化性较差；另一方面是没有参数共享，导致随着图节点增多，模型参数也不断增加。</p>
<p>图神经网络在前两者的基础上，首先尝试将整个图都嵌入到欧式空间中，之后应用CNN的思想增强模型的表达能力，让嵌入能够表示更多的原始信息。</p>
<p>在这本书中，对于GNN的分类为：</p>
<ul>
<li>循环图神经网络（recurrent graph neural networks）</li>
<li>卷积图神经网络（convolutional graph neural networks）</li>
<li>图自编码器（graph auto-encoders）</li>
<li>时空图神经网络（spatial-temporal graph neural networks）</li>
</ul>
<h2 id="vanilla-graph-neural-networks">Vanilla Graph Neural Networks</h2>
<p>关于图神经网络GNN的概念实际上在2005年前后就已经有对应概念的提出[The graph neural network model; Graphical-based learning environments for pattern recognition]。</p>
<p>接下来介绍一个原始的模型vanilla GNN。它针对的是无向同质的图。</p>
<p>核心包括两个函数，局部转移函数（local transition function）以及局部输出函数（local output function）。 <span class="math display">\[
\mathbf{h}_v = f(\mathbf{x}_v,\mathbf{x}_{co[v]}, \mathbf{x}_{ne[v]}, \mathbf{h}_{ne[v]},) \\
\mathbf{o}_v = g(\mathbf{h}_v, \mathbf{x}_v)
\]</span> 其中，<span class="math inline">\(\mathbf{x}_{co[v]}\)</span>是邻居边的特征，<span class="math inline">\(\mathbf{x}_{ne[v]}\)</span>是邻居节点的特征，<span class="math inline">\(\mathbf{h}_{ne[v]}\)</span>是邻居节点的隐藏状态。</p>
<p>vanilla GNN不断迭代更新函数<span class="math inline">\(h\)</span> <span class="math inline">\(T\)</span>步，直到到达固定点，使得<span class="math inline">\(\mathbf{h}_v^T\approx \mathbf{h}_v^{T-1}\)</span>。这一操作的原理是Banach’s ﬁxed point theorem[An Introduction to Metric Spaces and Fixed Point Theory]。到达不动点之后，再进行梯度下降。</p>
<p>vanilla GNN的几个缺点：</p>
<ul>
<li>计算不够有效，每次都需要不断迭代T步之后才能进行梯度下降，实际上一般的神经网络是直接产生一个输出后就可进行梯度更新。</li>
<li>在T步的迭代中，vanilla GNN一直使用的是一样的参数，这就导致图的层级结构信息没有能够被显式的学习。实际上我们可以让模型的每次迭代都学习不同的参数。</li>
<li>vanilla GNN没有有效的建模边的信息。</li>
<li>如果图中的节点数量很多，使用不动点这种原理，可能会导致各个节点过平滑，差异性不够</li>
</ul>
<h2 id="graph-convolutional-networks">Graph Convolutional Networks</h2>
<p>主要有两类在图上进行卷积操作的GNN，一类是谱空间下卷积操作，一类是空间领域下的卷积操作。</p>
<h3 id="spectral-methods">Spectral Methods</h3>
<h4 id="spectral-gnn">Spectral GNN</h4>
<p>2014年。Spectral networks and locally connected networks on graphs</p>
<p>通过对图拉普拉斯矩阵进行特征分解，定义了在傅里叶域下的卷积操作。 <span class="math display">\[
\mathbf{g}_\theta \star \mathbf{x} = \mathbf{U} \mathbf{g}_\theta \mathbf{U}^T \mathbf{x}
\]</span> 详细的可以看之前的GCN笔记。</p>
<h4 id="chebnet">ChebNet</h4>
<p>2011年。Convolutional neural networks on graphs with fast localized spectral ﬁltering.</p>
<p>对上面公式中的<span class="math inline">\(\mathbf{g}_\theta\)</span>使用切比雪夫多项式进行估计，从而无需计算特征向量<span class="math inline">\(\mathbf{U}\)</span>。</p>
<h4 id="gcn">GCN</h4>
<p>2017年。Semi-supervised classiﬁcation with graph convolutional networks.</p>
<p>出现了著名的图卷积算子，它实际是在CheNet进一步的简化，约定了切比雪夫多项式只包括前两步。 <span class="math display">\[
\mathbf{Z}=\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} \mathbf{X} \Theta
\]</span></p>
<h4 id="agcn">AGCN</h4>
<p>2018年，Adaptive graph convolutional neural networks.</p>
<p>AGCN假设除了图的结构能够表现图中节点的关系外，它们之间应该还存在某种隐式的联系。</p>
<h3 id="spatial-methods">Spatial Methods</h3>
<p>基于空间域的方法是直接在graph上进行操作，不需要计算特征向量。</p>
<p>Spatial methods 和 Spectral methods的对比：</p>
<p>由于效率、通用性和灵活性问题，空间模型优于光谱模型。首先，光谱模型的效率低于空间模型。谱模型要么需要进行特征向量计算，要么需要同时处理整个图。由于空间模型通过信息传播直接在图域中执行卷积，因此空间模型更适合于大图形。计算可以在一批节点中进行，而不是整个图。其次，依赖于图Fourier基的谱模型很难推广到新的图。它们假设一个固定的图。对图的任何扰动都会导致特征基的变化。另一方面，基于空间的模型在每个节点上执行局部的图形卷积，在这些节点上可以很容易地在不同的位置和结构之间共享权重。第三，基于谱的模型仅适用于无向图。基于空间的模型更灵活地处理多源图形输入</p>
<h4 id="neural-fps">Neural FPS</h4>
<p>2015年，Convolutional networks on graphs for learning molecular ﬁngerprints</p>
<p>核心思想是对于具有不同度数的节点学习不同的权值矩阵。缺点是很难直接应用到大规模的图上。</p>
<h4 id="patchy-san">PATCHY-SAN</h4>
<p>2016年，Learning convolutional neural networks for graphs.</p>
<p>核心思想是对于图中的每个节点，基于广度优先搜索选择固定<span class="math inline">\(k\)</span>个邻居作为接受域，这样就将图处理问题转化为了传统的欧几里得数据问题，最后输入到CNN中进行处理。</p>
<h4 id="dcnn">DCNN</h4>
<p>2016年，Diﬀusion-convolutional neural networks.</p>
<p>扩散卷积神经网络</p>
<h4 id="dgcn">DGCN</h4>
<p>2018年，Dual graph convolutional networks for graph-based semisupervised classiﬁcation</p>
<p>重点读：双向卷积神经网络，既考虑了局部一致性，也考虑了全局一致性</p>
<h4 id="lgcn">LGCN</h4>
<p>2018年，Large-scale learnable graph convolutional networks.</p>
<h4 id="monet">MONET</h4>
<p>2017年，Geometric deep learning on graphs and manifolds using mixture model CNNs.</p>
<h4 id="graphsage">GraphSAGE</h4>
<p>2017年</p>
<h2 id="graph-attention-network">Graph Attention Network</h2>
<h3 id="gat">GAT</h3>
<p>2018年，Graph attention networks</p>
<p>使用多头注意力机制。</p>
<h3 id="gaan">GaAN</h3>
<p>2018年，GaAN: Gated attention networks for learning on large and spatiotemporal graphs.</p>
<p>同样使用多头注意力机制，但是使用了key-value的机制。</p>
<h2 id="graph-recurrent-networks">Graph Recurrent Networks</h2>
<p>融合了gate机制的模型，核心思想是提升图信息long term聚和的效果。</p>
<h3 id="ggnn">GGNN</h3>
<p>2016年，Gated graph sequence neural networks.</p>
<p>利用GRU，每次聚合<span class="math inline">\(T-1\)</span>步下的邻居信息，输入GRU，得到最后的输出</p>
<h3 id="tree-lstm">Tree-LSTM</h3>
<p>2015年，Improved semantic representations from treestructured long short-term memory networks.</p>
<p>利用LSTM</p>
<h3 id="graph-lstm">Graph LSTM</h3>
<p>2017年，Cross-sentence N-ary relation extraction with graph LSTMs.</p>
<h3 id="sentence-lstm">Sentence-LSTM</h3>
<p>2018年，Sentence-state LSTM for text representation.</p>
<p>将文本直接转换为graph，然后使用GNN进行学习，在很多NLP任务上表现出了很好的性能。</p>
<h2 id="graph-redidual-networks">Graph Redidual Networks</h2>
<p>使用残差链接，为了缓解在GCN中聚合多层信息效果反而下降的情况。</p>
<h3 id="highway-gcn">Highway GCN</h3>
<p>2018年，Semi-supervised user geolocation via graph convolutional networks.</p>
<p>在更新节点状态时，使用了门机制。</p>
<h3 id="jump-knowledge-network">Jump Knowledge Network</h3>
<p>2018年，Representation learning on graphs with jumping knowledge networks.</p>
<p>每一层都会直接连接向最后一层。</p>
<h3 id="deepgcns">DEEPGCNS</h3>
<p>2019年，DeepGCNs: Can GCNs go as deep as CNNs?</p>
<p>使用skip connection和dense connection解决两个问题：GNN中的梯度消失以及过度平滑。</p>
<h2 id="heterogeneous-graph">Heterogeneous Graph</h2>
<ul>
<li>HAN：</li>
<li>PP-GCN：Fine-grained event categorization with heterogeneous graph convolutional networks.</li>
<li>ActiveHNE：Activehne: Active heterogeneous network embedding.</li>
</ul>
<h2 id="multi-dimensional-graph">Multi-Dimensional Graph</h2>
<ul>
<li>Multi-dimensional graph convolutional networks</li>
</ul>
<h2 id="sampling">Sampling</h2>
<ul>
<li>GraphSAGE（2017）: 邻居节点随机采样</li>
<li>PinSage（2018）: 基于邻居节点重要性采样，Graph convolutional neural networks for web-scale recommender systems.</li>
<li>FastGCN：FastGCN: Fast learning with graph convolutional networks via importance sampling</li>
<li>Adaptive sampling towards fast graph representation learning：参数化，可训练的采样器</li>
<li>SSE：Learning steady-states of iterative algorithms over graphs.</li>
</ul>
<h2 id="graph-auto-encoder">Graph Auto Encoder</h2>
<ul>
<li>GAE: Variational graph auto-encoders.</li>
<li>ARGA: Adversarially regularized graph autoencoder for graph embedding.</li>
<li>DGI: Deep graph infomax.</li>
</ul>
<h2 id="general-framework">General Framework</h2>
<ul>
<li>MPNN：</li>
<li>NLNN：Non-local neural networks.</li>
<li>GN：Relational inductive biases, deep learning, and graph networks.</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>M-GNN</title>
    <url>/gnn/M-GNN/</url>
    <content><![CDATA[<h1 id="robust-embedding-with-multi-level-structures-for-link-prediction">Robust Embedding with Multi-Level Structures for Link Prediction</h1>
<p>这篇文章提出了一种multi-level graph neural network，M-GNN。使用GIN中的MLP学习结构信息，然后提出了一种基于KG中图的不同粒度进行建模的方法。它会从原始的KG出发，不断合并邻居节点，合并边，构造出一系列不同粒度的graph，在这些graph上进行图卷积操作，得到最后的输出。除了一般的链路预测实验，作者还进行了在不同稀疏度以及加入noising edges的实验。</p>
<span id="more"></span>
<h2 id="graph-coarsening">Graph Coarsening</h2>
<p>和一般的GNN消息聚合方式不同，M-GNN希望能够建模KG中不同尺度中的信息。</p>
<p>首先构造k个Coarsened graph：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826143747570.png" alt="image-20210826143747570" style="zoom:50%;" /></p>
<p>核心是两种合并结构的方法：<strong>edge coarsening</strong>和<strong>neighbor coarsening</strong>。</p>
<p>M-GNN考虑在图中的不同relation包括不同的结构信息：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826144601695.png" alt="image-20210826144601695" style="zoom:50%;" /></p>
<p>对于1-1 structure，使用<strong>edge coarsening</strong>，1-1 structure是指两个edge没有相连的相同实体。edge coarsening直接把这样的edge分别看做是新的super node，对edge进行了coarsening。如下图a所示。edge coarsening使得节点包括了更多阶邻居的信息。</p>
<p>对于1-n或者n-1 structure，同一关系下的不同邻居实体共享某种相同的信息，可以进行聚合，把两个邻居实体合并为新的super node，叫做<strong>neighbor coarsening</strong>。如下图b, c所示。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826145202651.png" alt="image-20210826145202651" style="zoom:50%;" /></p>
<p>对于n-n structure，可以看做是多个1-n或者n-1结构，不需要单独处理。</p>
<p>通过先neighbor coarsening压缩实体，然后edge coarsening进一步压缩graph中实体和关系数量。</p>
<h2 id="multi-level-gnn">Multi-Level GNN</h2>
<p>与产生不同粒度的graph的顺序相反，在进行GNN的消息传递时，先从最粗粒度的graph进行学习，然后到更细粒度的graph，每个graph对应一层GNN。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826150307208.png" alt="image-20210826150307208" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826150339407.png" alt="image-20210826150339407" style="zoom:50%;" /></p>
<p>公式中的<span class="math inline">\(S\)</span>是指实体到实体的对应矩阵。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210826150505564.png" alt="image-20210826150505564" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>KGE</tag>
      </tags>
  </entry>
  <entry>
    <title>MAGNN</title>
    <url>/gnn/MAGNN/</url>
    <content><![CDATA[<h1 id="magnn-metapath-aggregated-graph-neural-network-for-heterogeneous-graph-embedding">MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding</h1>
<p>看一下整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210425135447705.png" style="zoom:50%;" /></p>
<span id="more"></span>
<p><strong>Motivation</strong>：</p>
<p>对于GNN，大部分的GNN假设graph是同质图，但是很多实际的graph都是异质图。</p>
<p>对于处理异质图的传统方法，是基于meta path的方法。但是这些基于meta path的方法存在几个缺点：</p>
<ul>
<li>The model does not leverage node content features, so it rarely performs well on heterogeneous graphs with rich node content features</li>
<li>The model discards all intermediate nodes along the metapath by only considering two end nodes，模型不考虑meta path中的中间节点</li>
<li>模型只依赖于单个meta path，The model relies on a single metapath to embed the heterogeneous graph.</li>
</ul>
<p><strong>Method</strong>：</p>
<p>提出MAGNN。对于不同type的node，先是linear projection到统一feature space中。之后，经过下面几个步骤：</p>
<p>对于同一metapath下的节点，编码单个邻居信息：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220309182244290.png" alt="image-20220309182244290" style="zoom:50%;" /></p>
<p>实验了三个具体的方法</p>
<ul>
<li>Mean：</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210425135012239.png" style="zoom:67%;" /></p>
<ul>
<li>Linear Mean：</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220309182100917.png" alt="image-20220309182100917" style="zoom:50%;" /></p>
<ul>
<li>Relational rotation encoder：</li>
</ul>
<p>模仿RotatE，可以建模metapath下的节点的序列信息，这一点区别于上面的方法。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210425135214910.png" style="zoom: 67%;" /></p>
<h2 id="intra-metapath-aggregation">Intra-metapath Aggregation</h2>
<p>对于同一metapath下的节点，基于注意力聚合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220309182403668.png" alt="image-20220309182403668" style="zoom:50%;" /></p>
<p>这里需要注意的是就是在计算注意力加入了target node embedding。</p>
<p>并且使用了多头注意力。</p>
<h2 id="inter-metapath-aggregation">Inter-metapath Aggregation</h2>
<p>计算在全局下，所有metapath的weight。首先对于不同type的node，相加相同mepath的embedding。需要注意的是，不是计算单个node的不同metapath。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210425140032603.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210425140219668.png" style="zoom:50%;" /></p>
<p>计算注意力：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210425134123312.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>MPNN</title>
    <url>/gnn/MPNN/</url>
    <content><![CDATA[<h1 id="neural-message-passing-for-quantum-chemistry">Neural Message Passing for Quantum Chemistry</h1>
<p>ICML 2017</p>
<p>Google Brain, Google DeepMind</p>
<p>本文就提出了一种图上进行监督学习的泛化框架Message Passing Neural Networks (MPNNs)</p>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>虽然化学家们已经尝试将机器学习应用到化学任务上，但是之前的很多工作还是在围绕特征工程打交道。虽然神经网络在其它很多领域已经很成功，但是在化学领域还处在很初始的阶段。</p>
<p>最近，随着high throughput experiments的进步，量子化学计算与分子动态模拟产生了大量的数据，导致之前的经典方法无法再处理这样数据量的数据，需要一种新的更灵活的方法。</p>
<p>而在化学分子上设计的神经网络需要满足图同构的情况下不变：</p>
<blockquote>
<p>The symmetries of atomic systems suggest neural networks that operate on graph structured data and are invariant to graph isomorphism might also be appropriate for molecules.</p>
</blockquote>
<p>本文就提出了一种图上进行监督学习的泛化框架Message Passing Neural Networks (MPNNs)</p>
<p>预测任务是预测小型有机分子化学属性。</p>
<p>使用QM9数据集。</p>
<h2 id="message-passing-neural-networks">2. Message Passing Neural Networks</h2>
<p>MPNN，泛化了至少之前的8种方法。分为两大阶段，message passing phase和readout phase。</p>
<h3 id="message-passing-phase">message passing phase</h3>
<p>包括两个函数，消息函数Message Function和Update Function。</p>
<p>Message Function：用来产生消息，<span class="math inline">\(M_t(h_v^t, h_w^t, e_{v,w})\)</span> <span class="math display">\[
m_v^{t+1}=\sum_{w\in N(v)} M_t(h_v^t, h_w^t, e_{vw})
\]</span> Update Function: 更新节点状态 <span class="math display">\[
h_v^{t+1}=U_t(h_v^t, m_v^{t+1})
\]</span></p>
<h3 id="readout-phase">readout phase</h3>
<p>这一阶段是针对图级别的任务。 <span class="math display">\[
y^\prime=R(\{ h_v^T | v\in G \})
\]</span></p>
<h2 id="mpnn-variants">3 MPNN Variants</h2>
<p>接下来描述MPNN中具体实现的时候使用的结构。</p>
<p>基于GG-NN进行探究，</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>node2vec</title>
    <url>/gnn/node2vec/</url>
    <content><![CDATA[<p>本文就提出了一种无监督的方法。核心思想：通过特定的游走方式进行采样，对于每个点都会生成 对应的序列。再将这些序列视为文本导入skip-gram模型，即可得 到每个节点的向量</p>
<span id="more"></span>
<div class="pdf-container" data-target="node2vec-Scalable-Feature-Learning-for-Networks.pdf" data-height="1000px"></div>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Graph Embedding</category>
      </categories>
  </entry>
  <entry>
    <title>revisting-GCN</title>
    <url>/gnn/revisting-GCN/</url>
    <content><![CDATA[<h1 id="revisiting-graph-neural-networks-all-we-have-is-low-pass-filters">Revisiting Graph Neural Networks: All We Have is Low-Pass Filters</h1>
<p>这篇文章中，作者从图信号处理GSP的角度出发，有三方面的贡献：</p>
<ul>
<li>首先实验发现大多数的信息隐藏在邻居信息的低频特征中，并且低频特征的信息以及足够丰富；提出了假设1：输入特征包括低频真实特征和噪声。真实特征为机器学习任务提供了足够的信息。</li>
<li>将图信号与传播矩阵相乘对应于低通滤波（low-pass filters），并且提出了gfNN(graph filter neural network)用于分析GCN和SGC</li>
<li>在假设1下，认为SGC、GCN 和 gfNN 的结果与使用真实特征的相应神经网络的结果相似。</li>
</ul>
<span id="more"></span>
<p>作者首先做了一个实验，通过图傅里叶变化，使用不同的频率的信息经过mlp进行预测。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210628205446190.png" style="zoom:50%;" /></p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210628205516246.png" style="zoom:50%;" /></p>
<p>结果分析：高频的邻居信息与中心节点差异较大，可能是噪声；低频的意思是变化不剧烈，中心节点的信号与邻居节点的信号差值不大。虽然人工增加了噪声，但是在低频下没有太多变化。低频特征足以提供足够的信息。</p>
<p>之后，作者证明了将特征矩阵<span class="math inline">\(X\)</span>与邻居矩阵相乘就是作为低通滤波器。</p>
<p>证明过程来自<a href="https://www.zhihu.com/question/427800721/answer/1547978404">知乎回答</a>，不是论文本身的内容。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210628205850099.png" style="zoom:50%;" /></p>
<p>也就是说，与正则化的邻接矩阵相乘时，由于所有的特征都是大于等于0的，因此低频特征对应的<span class="math inline">\(p(\lambda)\)</span>大，而高频特征对应的<span class="math inline">\(p(\lambda)\)</span>小，即起到了一个低通滤波的作用。降低高频特征中的噪声，加强低频特征中的信息。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT-2</title>
    <url>/llm/GPT-2/</url>
    <content><![CDATA[<h1 id="language-models-are-unsupervised-multitask-learners">Language Models are Unsupervised Multitask Learners</h1>
<p>GPT-2 OpenAI，15亿参数量，2019-02</p>
<blockquote>
<p>Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. <strong>We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText.</strong> When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts WebText. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.</p>
</blockquote>
<p>遗憾的是尽管比BERT-large的3.5亿参数量还要大，但是效果并没有超过BERT。因此在GPT-2主要在zero-shot设置下进行探究。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p><strong>问题</strong>：之前出现的在大规模数据集上训练大模型的方法，对数据集的分布以及特定的任务很敏感。这些系统的适应面积还比较狭窄。作者希望能够进一步推动这些大模型的泛化性，往最终的理想目标更进一步：不需要给每个任务都创建和人工标注数据集。</p>
<p><strong>假设</strong>：作者认为在特定领域下进行task相关的训练，是造成目前众多系统泛化性受到约束的原因。比如目前出现的利用多任务学习提升模型泛化性的方法，即在训练的时候可以同时看到不同任务相关的数据集，从元学习的角度看，每个任务(dataset, objective)可以看做是一个training sample。如果要让一个ML系统的泛化性足够好，可能需要成百上千的多任务。当然这是很难一直拓展的下去的。</p>
<p>另外，对于已有的预训练+微调的模式，对于不同的任务仍然需要有标注好的数据。</p>
<blockquote>
<p>Our suspicion is that the prevalence of single task training on single domain datasets is a major contributor to the lack of generalization observed in current systems.</p>
</blockquote>
<p><strong>方法</strong>：作者直接让训练好的语言模型能够在下游的zero-shot的任务下进行预测，不需要任何结构和参数上的调整。核心在于两点：（1）足够大、足够多样化、质量较可靠的大规模数据集WebText（2）整体参数量达到了15亿的基于Transformer的模型（和GPT-1整体架构一样，只不过是层数更多，并且采用了一些新的训练trick）。</p>
<h2 id="approach">2 Approach</h2>
<p>在GPT-1里，对于要预测的任务加入了词元（START、EXTRACT和delimiter），这些词元是在无监督的时候没有见过的词元，但是因为会进行task-specific的微调，所以这些词元回去尝试学到合适的表示。但是现在GPT-2要做zero-shot的设置，那么就不能在不同task下，加入没见过的词元。因此在GPT-1中的词元的引入就不再合适了。</p>
<p>也就是说要让输入的序列，变得更像自然语言。</p>
<p>比如做机器翻译：(translate to french, english text, french text)。第一个输入<em>translate to french</em>，就叫做提示prompt。</p>
<p>为什么加入这样自然语言描述的prompt就能够让机器执行相应的任务？作者认为训练好的大模型应该有能力学习到这样的推理能力。</p>
<blockquote>
<p>Our speculation is that a language model with sufficient capacity will begin to learn to infer and perform the tasks demonstrated in natural language sequences in order to better predict them, regardless of their method of procurement.</p>
</blockquote>
<p>比如下面在数据集里关于法语翻译成英语的例子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220513151520436.png" style="zoom:30%;" /></p>
<p>可以猜想，如果语料库确实质量好，数据量足够大，那么对于不同的任务应该可以理解到不同的含义。</p>
<h3 id="training-dataset">2.1 Training Dataset</h3>
<p>作者构建了尽可能大，尽可能包括更多领域的数据。</p>
<blockquote>
<p>Our approach motivates building as large and diverse a dataset as possible in order to collect natural language demonstrations of tasks in as varied of domains and contexts as possible.</p>
</blockquote>
<p>作者自己从Reddit上导出了网页内容，为了保证数据质量，人工的过滤/审核抓取的网页内容是不实际的。因此作者从Reddit上爬取的数据是至少有3个karma的帖子（karma是佛教里业力、报应值的意思，在用户对Reddit的帖子进行点赞投票的时候，会获得相应的karma），表明至少这些内容是有意义或者是有趣的。最后的WebText，在2017年12月之后，经过了数据清洗，去重之后，包括了超过800万的文档，总共40G的数据。</p>
<h3 id="input-representation">2.2 Input Representation</h3>
<p>模型对输入文本的要求会限制模型的泛化性。</p>
<p>作者采用了Byte Pair Encoding (BPE)的方法在word-level和byte-level上进行平衡。word-level的编码效果比较好，而byte-level的泛化性强。</p>
<p><em>这一部分没看懂</em>。</p>
<h3 id="model">2.3 Model</h3>
<p>继续沿着OpenAI GPT model的架构，但是做了几个稍稍的改进：</p>
<ul>
<li>把layer normalization移到每个block的输入部分；并且在最后的self-attention block输出加了一个额外的layer normalization、</li>
<li>残差层的参数初始化值考虑到了网络的深度，乘以系数<span class="math inline">\(1/\sqrt{N}\)</span>，<span class="math inline">\(N\)</span>代表残差层的深度。</li>
</ul>
<p>根据网络的深度，设计了四个大小不同的模型：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220511193814757.png" style="zoom:50%;" /></p>
<p>最大的模型参数量比GPT-2大了14倍。</p>
<h2 id="experiments">3 Experiments</h2>
<p>涉及到的方面很多，很多任务具体不是很了解，看一下总体的情况：</p>
<p>在zero-shot设置下，不需要经过有监督的训练，直接在8个数据集中的7个数据集获得了SOTA：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220511194124158.png" style="zoom:50%;" /></p>
<p>GPT-2在Children’s Book Test（类似于完形填空）、LAMBADA（文本长依赖建模能力，预测长句子的最后一个单词）、Winograd Schema challenge（对含糊不清的文本进行常识推理）等task都取得了SOTA的结果。</p>
<p>但是在一些其它的task表现不太好，特别是翻译和QA，表现出来的效果并没有比之前非常粗浅的方法效果好，距离已有的SOTA方法差距很远。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220513151837927.png" style="zoom:40%;" /></p>
<p>需要注意的是，即便是这么大的模型，作者认为仍然是欠拟合（underfit）WebText的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220511195003857.png" style="zoom:30%;" /></p>
<p>随着模型增大，在WebText上的效果一直在变好，如果继续增大模型，效果应该会进一步增加。纵轴是困惑度（perplexity），越小越好，下面的它的常用的对数形式（来自<a href="https://www.zhihu.com/question/58482430">知乎</a>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220511195728092.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Pretrain</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>ConvRe-LLM</title>
    <url>/llm/ConvRe-LLM/</url>
    <content><![CDATA[<h1 id="convre">ConvRe</h1>
<p>An Investigation of LLMs’ Inefficacy in Understanding Converse Relations. 北航. EMNLP 2023. <a href="https://github.com/3B-Group/ConvRe">代码</a>.</p>
<blockquote>
<p>Large Language Models (LLMs) have achieved remarkable success in many formal language oriented tasks, such as structural data-to-text and semantic parsing. However current benchmarks mostly follow the data distribution of the pre-training data of LLMs. Therefore, <strong>a natural question rises that do LLMs really understand the structured semantics of formal languages.</strong> In this paper, we investigate this problem on a special case, converse binary relation.** We introduce a new benchmark ConvRe focusing on converse relations, which contains 17 relations and 1240 triples extracted from popular knowledge graph completion datasets.** Our ConvRE features two tasks, Re2Text and Text2Re, which are formulated as multi-choice question answering to evaluate LLMs’ ability to determine the matching between relations and associated text. For the evaluation protocol, apart from different prompting methods, we further introduce variants to the test text and few-shot example text. We conduct experiments on three popular LLM families and have observed various scaling trends. The results suggest that LLMs often resort to shortcut learning and still face challenges on our proposed benchmark.</p>
</blockquote>
<p>在这篇论文里，作者探究了LLM对于逆关系converse relations理解的问题，为此，创建了一个benchmark ConvRe。作者发现LLM能够更好的理解normal relation，而不能很好的理解逆关系。并且随着model size增大，反而理解效果越差。作者推测是由于LLM在预训练阶段学习到了很多特征，在推理时，习惯于利用这些预训练特征走捷径shortcut。</p>
<span id="more"></span>
<p>尽管LLM已经在data-to-text和semantic parsing等任务上已经表现出了很好的结果，但是仍然有个关键问题需要探究：</p>
<blockquote>
<p>do these LLMs genuinely understand the nuanced semantics of formal languages, or are they merely exploiting statistical patterns inherent in their pre-training data?</p>
</blockquote>
<p>是否是真正的理解了语言，还是说仅仅在利用预训练阶段的统计特征。作者将这种倾向看做是shortcut learning：</p>
<blockquote>
<p>Geirhos illustrated et al. (2020), highlighted a phenomenon in deep learning known as <em>shortcut learning</em>. These deep variations learning on the known test as text shortcut bring different effects are decision rules that achieve high performance on standard benchmarks but fail to generalize under more challenging testing conditions such as real-world scenarios. This issue is particularly significant in language processing tasks, where a language model may show an ability to reason that is learned from the training data, but its performance can drop drastically—sometimes to levels equivalent to random guessing—when superficial correlations are removed from the dataset (Niven and Kao, 2019).</p>
</blockquote>
<p>shortcut learning就是指在benchmark里起到作用的有bias的映射规则，但是在实际中可能并不存在</p>
<p>作者特别针对逆关系的理解问题进行了探究：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017201512542.png"  style="zoom:50%;" /></p>
<p>从WN18RR (Dettmers et al., 2018), FB15K-237 (Toutanova and Chen, 2015), Wikidata5M (only transductive settings) (Wang et al., 2021), NELL-ONE (Xiong et al., 2018), ICEWS14 (García-Durán et al., 2018), ConceptNet5 (Speer et al., 2017)等数据集中，人工选择了<span class="math inline">\(17\)</span>种relation和对应的triples。</p>
<p>然后，作者设计了两类任务：Re2Text任务将relation 三元组（无头实体）转化为句子；Text2Re将句子，转化为无头实体的三元组。两个任务都是做选择的形式。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017201758518.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017201822598.png"  style="zoom:50%;" /></p>
<p>在这两个任务里的关键设置是对text句子进行改写，将其转化为更不常在LLM预训练语料中出现的形式。利用这个句子去控制可能存在的捷径。</p>
<p>作者对于OpenAI GPT-3 (Brown et al., 2020), Anthropic Claude (Anthropic, 2023), and Google FLAN-T5 (Chung et al., 2022)三类LLM进行了实验。实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017202942704.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231017203004101.png" style="zoom:50%;" /></p>
<p>可以看出来，目前最优的GPT-4等模型，对于逆关系的理解甚至不如小模型。更大的model，学习预训练数据效果更好，也更有可能潜在的更倾向于利用捷径。</p>
<blockquote>
<p>We conjecture that larger models have stronger priors, causing them to rely more heavily on memorized patterns from training data, which can conflict with the given task.</p>
</blockquote>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Capacity</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Capacity</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT-4</title>
    <url>/llm/GPT-4/</url>
    <content><![CDATA[<h1 id="gpt-4-technical-report">GPT-4 Technical Report</h1>
<p>2023-03-14日OpenAI发布的多模态GPT-4，下面是关于它技术报告的一个总结。大多是简单的high-level的描述和输入输出cases，具体模型细节、部署架构等等都没有说。</p>
<blockquote>
<p>We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformerbased model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>GPT-4是一个能够输入text和image输出text的大模型。GPT-4在很多测试上取得了很好的效果，比如在simulated bar exam（模拟律师资格考试）中超越了90%的人类测试者。</p>
<p>下面是它的一些新特点和技术介绍。</p>
<h2 id="predictable-scaling">2. Predictable Scaling</h2>
<p>Openai开发出了一套能够提前预测不同规模下模型性能的方法，这使得他们能够在使用1000倍到10000倍更少的计算资源的情况下提前预测模型的效果。</p>
<p>（<em>可惜没有提到到底是如何用小模型预测大模型性能的，不过这个肯定是非常重要的大模型将来发展方向</em>）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320160230598.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320160424977.png" /></p>
<p>从上面两个图可以看到，对于GPT-4在不同scale下的性能表现，还是预测的很准的。</p>
<p>另外GPT-4表现出来的比较好的一点是，之前研究者发现在某些任务下随着规模增大，大模型的效果反而可能下降。但是GPT-4奇怪的逆反了这一趋势：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320160627535.png" /></p>
<h2 id="capabilities">3. Capabilities</h2>
<p>接下来是对于GPT-4各种任务表现的说明。OpenAI试验了两个测试版本，一个是在训练集中移除了可能覆盖的测试集内容，然后进行训练；一个是使用完全的原始版本的训练集。最后在两个版本中选择最低的值进行report。下图中小括号里是指超过了多少的人类测试者。部分小括号里是区间因为这些测试是划分等级的，同一分数的人很多。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320161854080.png" /></p>
<p>总体来看很强大了，比如LeetCode easy题能够通过75%，然后中等题和困难题通过数量比GPT-3.5要高很多，不过不清楚这个原因是不是因为网上很多人们问LeetCode题导致本身数据就比较多。</p>
<p>GPT-4比GPT-3.5更强大的是在复杂任务上表现效果好了很多：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320162156850.png" /></p>
<p>和其它大模型进行比较，当然是SOTA了，而且是不需要fine tuning只需要few-shot prompting：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320162434080.png" /></p>
<p>GPT-4在MMLU数据集上对多语言场景的效果（<em>不知为何，没有汉语</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320162624510.png" /></p>
<p>GPT-4可以输入图像，理解笑话：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320163055557.png" /></p>
<p>GPT-4对于图像还有更多强大的应用场景，比如直接识别图表：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320234549698.png" /></p>
<p>直接回答试卷题目：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320234631303.png" /></p>
<p>识别图片上异常的地方：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320234743020.png" /></p>
<p>直接理解论文……</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320234827672.png" /></p>
<p>理解幽默图片……</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320234859940.png" /></p>
<p>甚至是进一步理解包含了领域知识的幽默图片：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320234952378.png" /></p>
<p>一句话总结，强的离谱。各种通用领域，特别是公开数据比较容易获得的任务已经被GPT-4以端到端的统一方式很好的完成了。接下来可能需要更多关注公开数据少、可信度和可解释性要求高的场景。最近这一年大量的NLP和多模态小任务会直接被GPT-4终结（除非在证明了GPT-4真的做不好的场景中继续研究），继续投入资源研究无意义了<span class="github-emoji" data-alias="broken_heart" style="" data-fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f494.png?v8">💔</span> 。</p>
<h2 id="limitations">4. Limitations</h2>
<p>GPT-4仍然会产生错误的事实输出，不过通过RLHF比GPT-3.5产生错误事实的概率要小很多。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320232202499.png" /></p>
<h2 id="risks-mitigations">5. Risks &amp; mitigations</h2>
<p><strong>Adversarial Testing via Domain Experts</strong>：邀请了50位各领域专家来帮助评估GPT-4可能产生的risk。通过采集领域专家的建议来进一步提升模型的可信性和安全性。比如说能够帮助GPT-4拒绝提供生产危险化学品方法的请求：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320232550517.png" /></p>
<p><strong>Model-Assisted Safety Pipeline</strong>：关于GPT-4的一个重要问题是如何让它知道什么样的问题是应该回答的。GPT-4对于输入安全性过于“放松”或者过于“谨慎”都不合适。</p>
<p>为了让模型能够更好的识别可回答的问题，OpenAI使用包括下面两个组件的方法：</p>
<ul>
<li>an additional set of safety-relevant RLHF training prompts</li>
<li>rule-based reward models (RBRMs)</li>
</ul>
<p>RBPM是一系列的zero-shot GPT-4分类器，能够为GPT-4 policy model提供额外的采取正确action的信号。比如下面是一个用来判断是否要拒绝的RBPM说明：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320233419511.png" /></p>
<p>最后的回答应该是A-R的选项，并且提供这样做的原因：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320233613256.png" /></p>
<p>通过采用上面的安全性控制策略，GPT-4能够更好的选择是否要回答用户的提问，比如下面不应该回答的问题：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320233748641.png" /></p>
<p>应该回答，但是回答应该更加谨慎：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320233829118.png" /></p>
<p>总体上，在OpenAI的评估中，通过使用RLHF，GPT-4能够更好地采取合适的反应：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230320234025037.png" /></p>
<p>尽管GPT-4对于危险输入的限制能力已经获得了很大提升，但是输入危险prompt依然是非常可能的。因此在部署后进行持续的安全性检测与更新是非常必要的。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Pretrained</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>Multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT-1</title>
    <url>/llm/GPT-1/</url>
    <content><![CDATA[<h1 id="improving-language-understanding-by-generative-pre-training">Improving Language Understanding by Generative Pre-Training</h1>
<p>2018-06年，OpenAI，GPT-1</p>
<blockquote>
<p>Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. <strong>We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task.</strong> In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).</p>
</blockquote>
<span id="more"></span>
<p>参考：</p>
<ul>
<li>原论文《<em>Improving Language Understanding by Generative Pre-Training</em>》</li>
<li><a href="https://www.bilibili.com/video/BV1AF411b7xQ/?spm_id_from=333.788">沐神的GPT讲解视频</a></li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220513101404397.png" style="zoom:25%;" /></p>
<p>GPT把Transformer的解码器拿出来在大规模数据集上进行预训练；BERT把transformer的编码器拿过来。BERT-base维度和结构层数和GPT-1是一样的，并且也使用了BooksCorpus数据集进行预训练。</p>
<h2 id="introduction">1 Introduction</h2>
<p>作者希望解决什么问题？</p>
<p>深度学习的模型往往需要足够的标注数据进行训练，但是这往往代表着高昂的人工代价和成本。同时在很多领域没有这么多的标注数据。但是直接利用无标签数据进行信息捕获的方法，是一直以来期望能够实现的方向。即便是有足够标注数据的领域，如果引入通过无监督方式学习到的表示，也可能进一步提升模型效果，比如使用预训练好的word embedding来提升NLP任务结果。</p>
<p>但是目前在如何利用无标签数据这个方向上的方法存在两个问题：</p>
<ol type="1">
<li>从无标签文本当中学习什么样的优化目标是最适合之后进行task transfer的，没有明确的答案。</li>
<li>对如何把学习到的表示转化到特定的任务，没有统一的方法/共识，很多方法往往会针对特定任务进一步改造模型架构，引入更多的参数。</li>
</ol>
<p>作者是用什么方法/思路解决上面的问题的？</p>
<p><strong>思路</strong>：半监督预训练+有监督的任务相关的微调，unsupervised pre-training+supervised ﬁne-tuning</p>
<blockquote>
<p>In this paper, we explore a semi-supervised approach for language understanding tasks using a combination of unsupervised pre-training and supervised ﬁne-tuning.</p>
</blockquote>
<p>最终期望能够在大规模语料上训练好，对于不同的任务（甚至是和语料表示的领域不相关的任务）只需要很小的改动即可。</p>
<blockquote>
<p>Our goal is to learn a universal representation that transfers with little adaptation to a wide range of tasks.</p>
</blockquote>
<p><strong>设计</strong>：预训练（Transformer decoder）+微调（把输入采用traversal-style approaches，变为序列化token的输入，输出在Transformer后加一个线性层和softmax）</p>
<p>使用transformer作为总体的架构，因为它更能够处理长期依赖（想想它是所有token都一起经过attention的），因此在不同的task之间，提供了较好的鲁棒性（设想下不同的task需要的信息是不同的，可能存在于语料的不同地方，那么当然需要预训练的模型尽量把所有的信息都能够记住）。</p>
<p><em>有研究者认为预训练实际上是一个regularization scheme，因此能够让深度学习有更好的泛化性</em>，这里如有兴趣，可以参考paper《Why does unsupervised pre-training help deep learning?》</p>
<h2 id="framework">2 Framework</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154323724.png" style="zoom:50%;" /></p>
<p>从上图可以看到，GPT会把各个子任务变为序列的形式，在开始加入一个<span class="math inline">\(Start\)</span>词元，在最后加入一个抽取<span class="math inline">\(Extract\)</span>词元。整个序列输入transformer解码器，然后使用抽取词元的表示经过线性层，作为具体的预测目标。</p>
<ul>
<li>Entailment：指在premise中是不是支持hypothesis，三分类问题</li>
<li>Similarity：两段文本是不是相似，构造两个序列</li>
<li>Multiple Choice：n个答案，构造n个序列输入</li>
</ul>
<h3 id="unsupervised-pre-training">2.1 Unsupervised pre-training</h3>
<p>优化目标，标准的语言模型优化目标，已知前<span class="math inline">\(k\)</span>个token，尝试预测当前token <span class="math inline">\(i\)</span>，<span class="math inline">\(k\)</span>就是窗口大小：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154617674.png" style="zoom:50%;" /></p>
<p>已知前面几个token的情况下，预测第i个token出现的概率；这点和BERT中的不太一样；BERT的预训练是采用了带掩码的语言模型，会mask掉任意的word然后进行了预测，做完形填空，这样来看BERT的预训练的语义方向是双向的。</p>
<p>优化目标<span class="math inline">\(L_1\)</span>是整个语料<span class="math inline">\(U\)</span>各个token出现的概率，一般情况下概率之间应该是相乘的，这里使用<span class="math inline">\(log\)</span>之后，就变成了多个概率相加。相加的操作比相乘更容易并行，计算也更简单。<span class="math inline">\(k\)</span>越大的话，整个模型会月倾向于使用更长的文本中寻找信息。</p>
<p>输入是context token（不太清楚具体指什么vector，难道就是简单的token编码，比如one-hot？）。</p>
<p>使用的模型是transformer的解码器，因为transformer的编码器是可以看到整个文本的，而解码器是只会看到前面的词，因此在GPT里还是使用了transformer的解码器。结构是12层+768 dimensional states+12 attention heads，输出是预测是哪个token的概率：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510154934018.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(W_e\)</span>是指token embedding组成的矩阵。</p>
<h3 id="supervised-ﬁne-tuning">2.2 Supervised ﬁne-tuning</h3>
<p>输入是token，对于某些任务，比如问题-回答等，需要把原来结构化的输入变为与序列化的输入。</p>
<p>对于输入<span class="math inline">\(&lt;x^1,\cdots,x^m&gt;\)</span>，放入transformer里，获得最后一层的位置<span class="math inline">\(m\)</span>输出的表示。</p>
<p>参数就是前一步train好的Transformer，后面再加一线性层，最后经过softmax获得预测的标签<span class="math inline">\(y\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510155720266.png"  style="zoom:50%;" /></p>
<p>优化的目标函数：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510155835380.png"  style="zoom:50%;" /></p>
<p>作者同样是有了辅助目标函数来增加有监督模型泛化性（让有监督模型不仅仅是只看重一个优化目标），加速收敛（不仅仅依赖于微调对于pre-train model的updating）。但是作者在后面的实验部分发现，辅助函数主要是对规模比较大的有监督的数据集效果比较好，而对于规模比较小的数据集效果不如移除辅助目标函数。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160042465.png" style="zoom:50%;" /></p>
<p>在优化task相关的目标loss的同时，也进一步优化之前pretrain的目标loss。</p>
<h2 id="experiments">3 Experiments</h2>
<p>在BooksCorpus数据集上进行了预训练，7000篇没有被发表的书。</p>
<p>作者用到了大量的训练上的trick，这里不提。有一部分是我不了解的，也没有使用过。</p>
<p>总的来说，在4个任务atural language inference，question answering，semantic similarity， text classiﬁcation，一共12个数据集上的9个数据集取得了最好的结果。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160500198.png" style="zoom:50%;" /></p>
<p>具体的结果也不粘贴了，参考论文。</p>
<p>主要看一下消融实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220510160616495.png" style="zoom:50%;" /></p>
<p>证明了：</p>
<ul>
<li>加入辅助目标函数，帮助模型在规模更大的数据集上取得了更好的效果</li>
<li>使用Transformer而不是LSTM，帮助模型取得了更好的效果（除了在MRPC数据集上）</li>
<li>如果不使用预训练，在所有数据集下都出现了严重的效果下降</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p><strong>Our work suggests that achieving signiﬁcant performance gains is indeed possible, and offers hints as to what models (Transformers) and data sets (text with long range dependencies) work best with this approach.</strong> We hope that this will help enable new research into unsupervised learning, for both natural language understanding and other domains, further improving our understanding of how and when unsupervised learning works</p>
</blockquote>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Pretrain</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Head-to-Tail-Knowledgeable-LLM</title>
    <url>/llm/Head-to-Tail-Knowledgeable-LLM/</url>
    <content><![CDATA[<h1 id="head-to-tail-how-knowledgeable-are-large-language-models-llm-a.k.a.-will-llms-replace-knowledge-graphs">Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? A.K.A. Will LLMs Replace Knowledge Graphs?</h1>
<p>Meta Reality Labs，arXiv 2023-08</p>
<blockquote>
<p>Since the recent prosperity of Large Language Models (LLMs), there have been interleaved discussions regarding how to reduce hallucinations from LLM responses, how to increase the factuality of LLMs, and whether Knowledge Graphs (KGs), which store the world knowledge in a symbolic form, will be replaced with LLMs. In this paper, <strong>we try to answer these questions from a new angle: How knowledgeable are LLMs?</strong></p>
<p>To answer this question, <strong>we constructed Headto-Tail, a benchmark that consists of 18K question-answer (QA) pairs regarding head, torso, and tail facts in terms of popularity.</strong> We designed an automated evaluation method and a set of metrics that closely approximate the knowledge an LLM confidently internalizes. Through a comprehensive evaluation of 14 publicly available LLMs, we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities.</p>
</blockquote>
<p>这篇工作是探究LLM在记忆knowledge问题上的又一篇工作。与前面的PopQA数据集有点类似，都是分析entity-related knowledge随着entity popularity变化的趋势。这篇工作分析了更多的开源LLM和不同领域下不同popularity的knowledge的回答准确性。</p>
<span id="more"></span>
<h2 id="the-head-to-tail-benchmark">The Head-to-Tail Benchmark</h2>
<h3 id="qa-pair-generation">QA pair generation</h3>
<p>先来看作者的benchmark是如何构造的。</p>
<p>作者的数据源来自下面四个方面：</p>
<ul>
<li>Open domain: DBpedia knowledge graph，English snapshot from December 1, 2022</li>
<li>Movie domain: IMDb from May 21, 2023</li>
<li>Book domain: Goodreads scraped in 2017</li>
<li>Academics domain: MAG from September 13, 2021 and DBLP from May 10, 2023</li>
</ul>
<p>然后是如何定义popularity。作者从traffic和density两个维度评估popularity。如果有traffic信息，比如votes次数/浏览次数等，就使用traffic作为popularity；如果没有traffic相关信息，就使用density信息，比如一个entity有多少相关事实/工作。具体来说各个数据集的评估依据如下：</p>
<ul>
<li>IMDb (traffic): The number of votes (i.e., numVotes)</li>
<li>Goodreads (traffic): The count of ratings (i.e., ratings_count)</li>
<li>MAG (traffic): The number of citations (i.e., CitationCount)</li>
<li>DBLP (density): The number of works the scholar has authored.</li>
<li>DBpedia (density): The number of relational triples in DBPedia that contain the entity.</li>
</ul>
<p>接下来，作者按照流行程度把不同的knowledge划分为3个部分：head、torso和tail。注意这里的head/tail不要和一般KG三元组描述常用的head/tail混淆。这篇paper中的head/tail只是表示流行程度。</p>
<p>具体的实体划分方法：计算top-1流行实体的累积popularity score，然后popularity score能够达到这个最大得分1/3的实体作为head实体，以此类推划分出torso entity和tail entity。</p>
<p>这种划分方法同样可以用在划分三元组的predicates上。作者将DBpedia中包括了对应predicate的三元组数量看做是predicate的popularity，然后按照相同的流程进行划分。</p>
<p>然后作者为了避免最新的knowledge对于LLM的影响，只截取了比较靠前年份的知识：</p>
<blockquote>
<p>For IMDb, MAG, DBLP, and Goodreads, we kept only entities by the years 2020, 2020, 2020, and 2015, respectively.</p>
</blockquote>
<p>这样保证了保留的knowledge都在LLM预训练数据的涉及时间范围之内。</p>
<p>下面的表格是作者构造的各类entity分布：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828211635764.png"   style="zoom:50%;" /></p>
<p>可以看到大部分的entity都是在tail分组中。</p>
<p>然后为了能够prompt LLM去回答相应的knowledge，需要构造prompt模板。For each specific domain (Movie, Book, Academics), we manually designed the question template for each attribute. DBpedia contains a large set of attributes, so we first employed ChatGPT to draft the templates (using Prompt 1 in Appendix A.1), then proofread them manually and made necessary edits.</p>
<p>让ChatGPT去生成prompt template的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828211817649.png"   style="zoom:30%;" /></p>
<p>用entity去填充prompt模板就能够得到相应的问题，作者最后构造出来的数据集question的分布如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828211928286.png"   style="zoom:30%;" /></p>
<p>最终，作者构造的整个数据集都是形式简单的关于事实的问题。无法探究LLM的理解能力、推理能力等。</p>
<h3 id="metrics">Metrics</h3>
<p>使用什么指标？作者定义了3类指标：</p>
<blockquote>
<p>accuracy (A), hallucination rate (H), and missing rate (M), measuring the percentage of questions that an LLM gives the correct answer, gives a wrong or partially incorrect answer, or admits it cannot answer, respectively; by definition, A + H + M = 100%.</p>
</blockquote>
<p>这里出现了一个missing rate指标，是因为作者允许LLM回答不知道/不确定。</p>
<p>如何计算指标？</p>
<p>LLM-Based. <span class="math inline">\(A_{LM}\)</span>, <span class="math inline">\(H_{LM}\)</span>判断回答的答案到底是否正确，由于缩写等原因，通过完全匹配的评价方式不一定合适。因此作者给定ground truth和prediction，让LLM判断这两个是否一致。根据LLM的判断结果来计算指标。作者发现，这种方法，98%的情况下LLM的判断是可靠的。下面是作者用LLM判断结果是否和正确答案匹配的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828212407043.png"   style="zoom:30%;" /></p>
<p>Rule-Based. 就是最常见的直接计算指标，作者用了3种具体指标，exact match (EM) <span class="math inline">\(A_{EM}\)</span>, token F1 (F1) <span class="math inline">\(A_{F1}\)</span>, and ROUGE-L (RL) <span class="math inline">\(A_{RL}\)</span>。</p>
<p>作者发现上面两种计算指标方法的评估结果在很大程度上是一致的。</p>
<h3 id="evaluation-methodology">Evaluation methodology</h3>
<p>作者使用few-shot in-context learning去查询LLM。下面是具体：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828212850775.png"   style="zoom:30%;" /></p>
<p>few-shot的设置应该是搞了两个固定的不在数据集中的example，一个回答正确的答案；一个回答不确定。让LLM学会follow。</p>
<p>上面的prompt有两点可以借鉴：</p>
<ul>
<li>让LLM的回复进行可能简洁，能够降低不确定性</li>
<li>让LLM回复不知道/不确定，能够减小LLM捏造事实的概率</li>
</ul>
<h2 id="experimental-analysis">Experimental Analysis</h2>
<h3 id="rq1-how-reliable-are-llms-in-answering-factual-questions">RQ1: How reliable are LLMs in answering factual questions?</h3>
<p>下面是部分的LLM回答准确率，全部统计可以参考paper的附录A.3：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828213445040.png"  style="zoom:50%;" /></p>
<p>下面是ChatGPT和开源LLM表现相对最好的LLaMA 33B的对比：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828213324020.png"   style="zoom:50%;" /></p>
<p>有下面的观察：</p>
<ul>
<li>对于GPT-3.5和各类开源LLM，表现最好的GPT-3.5总体上只有20%左右的问题能够被准确回答</li>
<li>LLaMA的幻觉率<span class="math inline">\(H_{LM}\)</span>很高，这表明LLaMA更喜欢强硬的给出答案，即使是错误的答案，也不愿意承认自己不知道/不会。ChatGPT就好很多，更加习惯承认自己不知道。这可能是因为ChatGPT的人类对齐/指令微调过程的效果。经过了指令微调Vicuna会比原始的LLaMA更愿意承认自己不知道，但是回答准确性同样下降了</li>
<li>LLaMA和ChatGPT在open domain（DBpedia knowledge）的回答准确率比较接近，在不同领域下的回答效果不同。在不太常见的领域如Academics的回答准确率只有个位数</li>
</ul>
<h3 id="rq2-do-llms-perform-equally-well-on-head-torso-and-tail-facts">RQ2: Do LLMs perform equally well on head, torso, and tail facts?</h3>
<p>下面是不同popularity entity的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828214146540.png"  style="zoom:30%;" /></p>
<p>有以下的观察：</p>
<ul>
<li>很明显的，随着popularity的降低，回答准确率也降低了</li>
<li>在head entity里，能够被正确回答的比例即使是GPT-3.5也只有30%左右，在比较不常见的domain里可能回答的准确率只有不到10%。而即使是在popular domain里的popular entity回答准确性也就在50%左右（如Movie domain的head entity）。不过，一个好的迹象是，ChatGPT出现幻觉hallucination的比例并没有随着popularity降低而提升。说明ChatGPT还是比较清楚自己不知道什么知识的</li>
</ul>
<p>下面的实验结果是针对不同popularity的predicates：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828214612131.png"   style="zoom:30%;" /></p>
<p>有如下的观察：</p>
<ul>
<li>对于predicates的预测没有明显的随着popularity变化的趋势</li>
<li>不同LLM对于predicates的回答准确率没有特别显著的差别</li>
</ul>
<h3 id="rq3-does-normal-methods-that-improve-llms-increase-the-factuality">RQ3: Does normal methods that improve LLMs increase the factuality?</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828214743175.png"   style="zoom:50%;" /></p>
<p>有下面的观察：</p>
<ul>
<li>增大model参数量可以在一定程度上增加记忆效果，但在参数量到达一定程度时，继续增加参数量不一定总是能够带来更好的记忆效果，比如LLaMA-65B没有比LLaMA-33B表现更好</li>
<li>经过了指令微调的LLM回答更加保守，因此幻觉率会下降，同时回答的准确率也下降了</li>
</ul>
<h3 id="robustness-of-our-evaluation-methodology">Robustness of our evaluation methodology</h3>
<p>首先是LLM-based和rule-based的metric计算方法的对比：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828215126675.png"   style="zoom:30%;" /></p>
<p>能够看出两种计算方法的相关性是很强的，rule-based metrics are good alternatives for lower-cost or faster evaluation。</p>
<p>然后是作者设计的prompt的robustness。作者让LLM对相同的问题重复产生答案，发现</p>
<ul>
<li>如果不要求回答尽可能的简洁，18%的问题会有新答案</li>
<li>如果不允许LLM回答unsure，幻觉率会增大13%</li>
</ul>
<p>这说明prompt LLM去尽可能回答简单的回复可能能够减小LLM重复回答的不确定性。 prompt LLM去回答不知道/不确定，能够有效的减低答案里存在hallucination。 在两个措施都使用的情况下，ChatGPT只对1%的问题重复回答有不同的结果。</p>
<h2 id="the-future-of-knowledge-graphs">The future of knowledge graphs</h2>
<p>尽管LLM不能够准确的回答很多事实问题，但是它已经改革了人们寻找信息的方式。因此有必要仔细考虑knowledge的表示/表达/存储方法。显式表示知识的三元组形式（KG）和隐式表示知识的参数化形式（LLM）应该可以协作。</p>
<blockquote>
<p>The symbolic form caters to human understanding and explainability</p>
<p>The neural form benefits machine comprehension and seamless conversations</p>
</blockquote>
<p>同一knowledge可能同时在两者中都存在，但是哪一种形式是最合理的，可能没有最优解，依赖于任务场景/需求（个人见解）。</p>
<p>作者指出两个研究方向的必要性：</p>
<ul>
<li>尽管popular entity/knowledge的预训练数据应该比较充分，但是LLM仍然不能够很好的记忆。有必要考虑如何提升LLM对于knowledge的记忆能力。比如knowledge infusion技术[<em>A survey on knowledge-enhanced pre-trained language models</em>]。</li>
<li>对于less popular的knowledge，可能用triple这种形式化的方法储存比较合理。然后把这种形式化的知识想办法增强LLM的回答。比如knowledge-augmented LLMs [<em>Retrieval-based language models and applications</em>]。</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Knowledge</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Knowledge</tag>
      </tags>
  </entry>
  <entry>
    <title>GenRead</title>
    <url>/llm/GenRead/</url>
    <content><![CDATA[<h1 id="generate-rather-than-retrieve-large-language-models-are-strong-context-generators">Generate rather than Retrieve: Large Language Models are Strong Context Generators</h1>
<p>University of Notre Dame和Microsoft，ICLR 2023，<a href="https://github.com/wyu97/GenRead">代码</a>。</p>
<blockquote>
<p>Knowledge-intensive tasks, such as open-domain question answering (QA), require access to a large amount of world or domain knowledge. A common approach for knowledge-intensive tasks is to employ a retrieve-then-read pipeline that first retrieves a handful of relevant contextual documents from an external corpus such as Wikipedia and then predicts an answer conditioned on the retrieved documents. <strong>In this paper, we present a novel perspective for solving knowledge-intensive tasks by replacing document retrievers with large language model generators.</strong> We call our method generate-then-read (GenRead), which first prompts a large language model to generate contextual documents based on a given question, and then reads the generated documents to produce the final answer. Furthermore, <strong>we propose a novel clustering-based prompting method that selects distinct prompts, in order to generate diverse documents that cover different perspectives, leading to better recall over acceptable answers.</strong> We conduct extensive experiments on three different knowledge-intensive tasks, including open-domain QA, fact checking, and dialogue system. Notably, GenRead achieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantly outperforming the state-of-the-art retrieve-thenread pipeline DPR-FiD by +4.0 and +3.9, without retrieving any documents from any external knowledge source. Lastly, we demonstrate the model performance can be further improved by combining retrieval and generation. Our code and generated documents can be found at https://github.com/wyu97/GenRead.</p>
</blockquote>
<p>作者提出了使用LLM生成的question的documents，作为question的background来回答问题，<em>generate-then-read</em>。</p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p>knowledge-intensive tasks如开放域QA任务等，常常需要大量的word knowledge / domain knowledge。之前的常常通过检索外部知识源Wikipedia等来获得relevant contextual documents。</p>
<p><em>retrieve-then-read</em>来解决knowledge-intensive tasks存在的问题：</p>
<ul>
<li>First, candidate documents for retrieval are chunked (e.g., 100 words) and fixed, so the retrieved documents might contain noisy information that is irrelevant to the question.</li>
<li>Second, the representations of questions and documents are typically obtained independently in modern two-tower dense retrieval models (Karpukhin et al., 2020), leading to only shallow interactions captured between them (Khattab et al., 2021).</li>
<li>Third, document retrieval over a large corpus requires the retriever model to first encode all candidate documents and store representations for each document.</li>
</ul>
<p>而作者认为，LLM生成的document比传统的检索结果更加和query question更加相关，原因是：LLM的生成结果是通过基于question的token，然后经过attention等机制生成的，而一般的检索只是利用question和document的embedding相似度去检索的。显然LLM的生成结果会和question更加相关。</p>
<blockquote>
<p>We believe this is because large language models generate contextual documents by performing deep token-level cross-attention between all the question and document contents, resulting in generated documents that are more specific to the question than retrieved documents.</p>
</blockquote>
<p>在检索方法中，检索的答案越多，能够提供更多的不同角度/方面的knowledge，从而增加最后回答答案的准确率。</p>
<p>但是如果是相同的prompt，LLM会倾向不断输出重复的内容。因此作者提出从不同的聚类中选择上下文样例，从而产生更多样的输出documents。</p>
<h2 id="method">Method</h2>
<p>作者尝试了两种不同的设置，一种是zero-shot setting，也就是一直使用LLM来回答问题。另一种是supervised setting，用LLM来生成documents，因为目前有监督的方法效果还是更好，并且效率更高。</p>
<p>有一种生成不同结果的思路是直接修改解码策略。但如果保持input一样，即使是修改解码策略，也很难生成covering different perspectives的documents，虽然内容可能改变，但是表达的knowledge总是倾向于重复。更多样documents，更大的相关信息召回率。</p>
<p>因此作者提出clustering-based prompt方法，提取不同的上下文样例，构造不同的prompt，生成的多个结果文档，一起再来辅助回答问题。核心包括3步：</p>
<ol type="1">
<li>初始化：先用LLM给训练集中的每个question生成一个document。也可以使用检索的方法，为每个question从外部知识源中检索一个相关document；</li>
<li>编码document，基于K-means无监督聚类：作者使用GPT-3这类LLM为每个question-document进行编码，然后进行K-means聚类。聚类的数量K，和要生成的documents数量一致</li>
<li>采样并且生成K个documents：对每一个聚类，采样n个样例作为上下文，然后生成query question的一个document，最终生成的K个documents。这些documents作为background，和query question组合成一个prompt，获得最终的答案。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230915160124104.png"   style="zoom:50%;" /></p>
<p>除去基于聚类的prompt方法，作者还尝试了让人工写不同的prompt。人类写的prompt效果不错，但是有两个问题： 1. 人工写的prompt，难以泛化到不同的task上 2. 人工写的prompt对于不同LLM来说不一定还是好的prompt</p>
<h2 id="experiments">Experiments</h2>
<p>总体实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230915160418898.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230915160434685.png"  style="zoom:50%;" /></p>
<p>作者还尝试把检索的文档和生成的文档结合起来，发现效果进一步提升。简单的说就是用生成的文档替换一部分检索的文档，作为回答question的背景知识：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230915160549438.png"   style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>QA</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>QA</tag>
      </tags>
  </entry>
  <entry>
    <title>GPT-3</title>
    <url>/llm/GPT-3/</url>
    <content><![CDATA[<h1 id="language-models-are-few-shot-learners">Language Models are Few-Shot Learners</h1>
<p>GPT-3，NIPS 2020 技术报告63页，不是投稿的论文，OpenAI，2020-05</p>
<blockquote>
<p>Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by ﬁne-tuning on a speciﬁc task. While typically task-agnostic in architecture, this method still requires task-speciﬁc ﬁne-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions – something which current NLP systems still largely struggle to do. <strong>Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art ﬁne-tuning approaches.</strong> Speciﬁcally, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or ﬁne-tuning, with tasks and few-shot demonstrations speciﬁed purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-ﬂy reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we ﬁnd that GPT-3 can generate samples of news articles which human evaluators have difﬁculty distinguishing from articles written by humans. We discuss broader societal impacts of this ﬁnding and of GPT-3 in general.</p>
</blockquote>
<p>GPT-3比GPT-2强调的zero-shot的设置，稍微回退了一点，变为强调few-shot的设置。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>最近NLP领域热衷于研究pre-trained的语言表示，寻找能够实现task-agnostic的方法。</p>
<p>一开始研究者学习word的表示，然后作为task-specific的模型的输入。</p>
<p>最近出现了预训练+fine-tunning的模式，取得了很大的进展。</p>
<p><strong>问题</strong>：进行任务相关的微调，可能带来下面几个缺点：</p>
<ol type="1">
<li><p>fine-tuning需要为不同的任务收集有监督的数据。每一个新任务都需要收集新的数据，这当然限制了模型的表达能力</p></li>
<li><p>fine-tuning的操作，会使得之前pre-training好的model向着一个狭隘的训练分布拟合，导致实际上更大的模型不一定会在训练分布之外表现出更好的泛化性，也就没有办法真正的评估出预训练模型的好坏</p></li>
<li><p>从人类的角度来看，学习特定的语言任务并不需要太多的数据，比如一个简单的描述就可以让人类进行对应的行为。这使得人类可以很快的学会大量不同的任务，并且同时无缝的执行不同的语言任务。我们期望语言模型也能够拥有这样的易变性（ﬂuidity）和普遍性（generality）</p></li>
</ol>
<p><strong>解决思路</strong>：</p>
<p>一方面近期出现了一些在NLP上进行元学习的方法，比如“in-context learning”，把预训练模型的输入，构造出不同task的形式，让模型能够在训练的时候学习到广泛的模式识别能力。</p>
<blockquote>
<p>Recent work [RWC +19] attempts to do this via what we call “in-context learning”, using the text input of a pretrained language model as a form of task speciﬁcation: the model is conditioned on a natural language instruction and/or a few demonstrations of the task and is then expected to complete further instances of the task simply by predicting what comes next.</p>
</blockquote>
<p>下面这张图是对于语言模型可能在进行潜在的元学习的说明，并不是GPT-3真正的训练过程。比如不同的document有不同的context，是在讨论不同的领域。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220512194903403.png" style="zoom:50%;" /></p>
<p>但是这一方向的元学习方法效果还远远不够好。</p>
<p>另一方面，最近出现了一系列基于transformer的大模型，随着规模增大，效果逐渐提升。</p>
<p>那么作者的思路就是结合两者：</p>
<p>如果也将元学习的模型规模扩大，可能它的能力也会得到提高。</p>
<blockquote>
<p>Since in-context learning involves absorbing many skills and tasks within the parameters of the model, it is plausible that in-context learning abilities might show similarly strong gains with scale.</p>
</blockquote>
<p>虽然作者提到了元学习的概念，但是这里的n-shot的example，并不会像一般的元学习方法一样去更新参数，在GPT-3的n-shot的example仅仅是作为输入，用来提示必要的信息。</p>
<p>这篇文章作者进行了以下的探究和贡献：</p>
<ul>
<li>提出了拥有1750亿参数量的GPT-3，重点在于探究它的元学习能力。参数量是GPT-2的116倍；GPT-1的1600倍左右。</li>
<li>对GPT-3的性能，分别在zero-shot、one-shot和few-shot的设置下进行了大量的实验。讨论了GPT-3表现优越的地方，和表现不好的情况。</li>
<li>研究了在大规模语料中出现的数据污染问题（data contamination），即测试集中的内容可能在训练集中出现，特别是因为很多数据是收集于web上。发展出一套评估数据污染情况和后果的工具。</li>
</ul>
<h2 id="approach">2 Approach</h2>
<p>GPT-3使用的几种不同的实验设置：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220512193531024.png" style="zoom:40%;" /></p>
<p>最终效果显示，GPT-3在少次任务下表现相对最好，甚至在某些情况下超过了SOTA的模型；在one-shot和zero-shot的情况下，很多的任务表示promising，没有达到SOTA。</p>
<blockquote>
<p>Broadly, on NLP tasks GPT-3 achieves promising results in the zero-shot and one-shot settings, and in the the few-shot setting is sometimes competitive with or even occasionally surpasses state-of-the-art (despite state-of-the-art being held by ﬁne-tuned models).</p>
</blockquote>
<p>在一个移除随机符号的NLP任务下，不同设置的GPT-3的性能：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220512195107205.png" style="zoom:40%;" /></p>
<p>作者也发现，GPT-3在一些任务，比如自然语言推理以及阅读理解的部分数据集下表现不好。</p>
<blockquote>
<p>At the same time, we also ﬁnd some tasks on which few-shot performance struggles, even at the scale of GPT-3. This includes natural language inference tasks like the ANLI dataset, and some reading comprehension datasets like RACE or QuAC.</p>
</blockquote>
<h3 id="model-and-architectures">2.1 Model and Architectures</h3>
<p>沿用GPT-2的架构。区别是使用了Sparse Transformer中的一些机制：</p>
<blockquote>
<p>we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer.</p>
</blockquote>
<p>实现的不同大小的模型：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220512194115923.png" style="zoom:50%;" /></p>
<p>更大的模型，使用了更大的batch size和更小的学习率。猜测是大模型拟合能力更强，容量更大，因此扩大batch size、减小learning rate都是避免模型拟合太快</p>
<h3 id="training-dataset">2.2 Training Dataset</h3>
<p>大规模语料，来自多个不同的数据集，由于规模大，整个语料基本上一个sequence只需要训练一次即可。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220512194411891.png" style="zoom:50%;" /></p>
<p>这里需要特别注意Common Crawl，原始版本包括了万亿级别单词，但是数据质量比较低。因此作者对它进行了一系列的数据清洗，最后得到了大概4100亿token，大小570 GB。</p>
<ol type="1">
<li>把Common Crawl数据集下载下来，然后使用一个简单的线性回归分类器，正类是高质量的数据集，比如GPT-2的WebText里的数据；负类是Common Crawl中原始的数据。然后对所有的Common Crawl中数据进行预测，如果分类到了正，就认为质量还可以，否则的话就过滤掉。</li>
<li>去重，使用LSH算法判断两个document是不是重合的。</li>
<li>把多个高质量的数据集加进去</li>
</ol>
<p>在训练的时候，根据数据集的质量来采样，而不是根据数据集的大小。</p>
<p>在训练大规模model的时候，大规模语料可能在无意间包含了下游任务的测试信息，因此作者根据所有测试任务的验证和测试集，对训练语料进行了数据清洗。</p>
<blockquote>
<p>To reduce such contamination, we searched for and attempted to remove any overlaps with the development and test sets of all benchmarks studied in this paper.</p>
</blockquote>
<p>但是GPT-3的初始版本训练的数据集没有完全过滤掉污染的数据，并且由于训练代价，没法再次进行训练。</p>
<blockquote>
<p>Unfortunately, a bug in the ﬁltering caused us to ignore some overlaps, and due to the cost of training it was not feasible to retrain the model.</p>
</blockquote>
<h2 id="results">3 Results</h2>
<p>不同大小的模型，计算量和验证集上的损失下降的趋势。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220513160142526.png" style="zoom:50%;" /></p>
<p>可以看到，对于单个模型，最好的方案是在每个loss和计算量相对平衡的点，继续进行运算，loss基本处于收敛的情况。如果把各个模型的平衡点相连，大致上是一个power-law的分布。也就是说，找到一个合适的模型，不过度训练的情况下，随着计算量呈指数增长，模型精度大概是线性下降的趋势。</p>
<h2 id="limitations">5 Limitations</h2>
<ol type="1">
<li>虽然效果比GPT-2要好很多，但是在文本生成任务上还是较弱。GPT-3擅长描述一段的文本，但是不擅长写更多、更长的文本。</li>
<li>结构和算法上的局限性，比如只能从前向后看。然后比如是在预测的时候，对于每一个token都是一样的处理，没有提取最重要的token。并且也只能学习文本的信息，并没有对物理世界的各种其它信息的感知。</li>
<li>样本有效性不够，使用了过多过大的语料。</li>
<li>不确定性，不确定GPT-3到底是在推理的时候真的从头学习到了怎么进行新的任务，还是说只是识别出了之前在预训练的时候见过的模式。</li>
<li>训练代价昂贵。</li>
<li>无法解释。</li>
</ol>
<h2 id="broader-impacts">6 Broader Impacts</h2>
<ol type="1">
<li>可能会被用来做坏事，假新闻造谣、论文造假等等</li>
<li>公平、偏见（性别、种族、宗教等等）。比如GPT-3更可能认为某个角色是男性</li>
<li>能耗</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p>We presented a 175 billion parameter language model which shows strong performance on many NLP tasks and benchmarks in the zero-shot, one-shot, and few-shot settings, in some cases nearly matching the performance of state-of-the-art ﬁne-tuned systems, as well as generating high-quality samples and strong qualitative performance at tasks deﬁned on-the-ﬂy. We documented roughly predictable trends of scaling in performance without using ﬁne-tuning. We also discussed the social impacts of this class of model. Despite many limitations and weaknesses, these results suggest that very large language models may be an important ingredient in the development of adaptable, general language systems.</p>
</blockquote>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Pretrain</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Increasing-Diver-Acc-Data-Gen-LLM</title>
    <url>/llm/Increasing-Diver-Acc-Data-Gen-LLM/</url>
    <content><![CDATA[<h1 id="increasing-diversity-while-maintaining-accuracy-text-data-generation-with-large-language-models-and-human-interventions">Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions</h1>
<p>密歇根大学与Microsoft，ACL 2023</p>
<blockquote>
<p>Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging. <strong>In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation.</strong> We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user’s domain of interest or to which no considered label applies. With oracle studies, we found that LR increases the absolute accuracy of models trained with diversified datasets by 14.4%. Moreover, we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification. In contrast, OOSF was not effective in increasing model accuracy, implying the need for future work in human-in-the-loop text data generation.</p>
</blockquote>
<p>利用LLM生成训练数据，考虑生成数据的多样性与准确性。</p>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>训练深度模型总是需要训练数据，而训练数据的获得一直是老大难问题。LLM的出现为这一个问题提供了新的解决思路，让LLM根据用户的去求直接生成domain text data。</p>
<p>虽然LLM通过ICL可以直接执行各类NLP任务，但是我们可能仍然需要小模型的几点理由：</p>
<ul>
<li>some might not have enough resources (e.g., GPUs) or budget (e.g., credit for GPT-3) to run expensive models. 资源</li>
<li>Others might be concerned about privacy or security issues when they use LLMs from external APIs (e.g., OpenAI API). 隐私与安全</li>
<li>Moreover, if we share generated datasets within the community, we can also benefit those who do not have access to LLMs. 生成的data可以帮助无法直接访问LLM的研究者</li>
<li>Lastly, we can also use generated datasets to test models. 生成的数据集可以用来测试SLM</li>
</ul>
<p>这篇文章就旨在讨论利用人机协作的方法创建高质量数据集，Ideal classification datasets need to have the following characteristics:</p>
<ol type="1">
<li><strong>Scoped</strong>: fall in the model builder’s domain of interest while classifiable with labels of interest,</li>
<li><strong>Label accurate</strong>: accompany accurate labels</li>
</ol>
<ol start="3" type="1">
<li><strong>Diverse</strong>: cover cases the model would encounter during test time.</li>
</ol>
<h2 id="diversified-text-data-generation">2. Diversified Text Data Generation</h2>
<h3 id="method">2.1 Method</h3>
<p>第一大部分，作者主要讨论了2种在解码阶段增加多样性的方法：</p>
<ul>
<li><p>Logit Suppression：decreases the probability of high-frequency tokens。之前生成的tokens，根据频率，降低它在下一次采样中的概率。这里叫做logit的原因应该是，作者通过调用OpenAI的logit bias API来实现这一点。</p></li>
<li><p>High Temperature：增大temperature <span class="math inline">\(T\)</span>，更大的temperature意味着最终的概率分布更加平滑flat：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914230956172.png"   style="zoom:40%;" /></p></li>
</ul>
<p>示意图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914231021977.png"   style="zoom:50%;" /></p>
<p>作者调用GPT生成数据的时候，考虑的是短文本分类任务，构造的prompt主要考虑text type和label：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914231203885.png"   style="zoom:40%;" /></p>
<p>下面是各个task用到的text type和label：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914231253525.png"   style="zoom:50%;" /></p>
<p>text type应该是用来控制输出符合task特点的文本。</p>
<h3 id="experiments">2.2 Experiments</h3>
<p>一些实验设置：</p>
<ul>
<li>作者一共用了8个短文本分类数据集</li>
<li>调用<code>text-davinci-002</code>，每次调用生成20个新data</li>
<li>微调用的model是<code>BERT-base</code>+Linear classifier</li>
<li>原始的training data用来训练<em>oracle model</em> （很重要，后续在计算指标和提高质量的时候被用到）；生成的新data用来训练各个实验model，保持两者样本数量一样；用原始的test set进行测试</li>
<li>作者实验了一个额外的example seeding设置，也就是初始第一次迭代，有没有个样例池。样例池中的样例被按照每个label对应1个样例的设置被随机选择，作为prompt上下文。如果一开始没有一个上下文样例池，作者第一次迭代就是使用zero-shot ICL的形式，在第二次迭代才开始从样例池中随机采样</li>
</ul>
<p>实验指标：</p>
<ul>
<li>Diversity: We also measured the diversity of the dataset using Remote-Clique metric (Rhys Cox et al., 2021), which is the average mean pairwise distances.</li>
<li>Label Accuracy: We also evaluated label accuracy, which is the accuracy of the alignment between the generated texts and the specified labels. 使用oracle model作为评估工具</li>
<li>Model Accuracy: 微调的BERT在测试集上的准确率</li>
<li>Similarity: We also measured the similarity of the generated dataset to the oracle dataset with the average mean pairwise distances between the two.</li>
</ul>
<p>8个短文本分类数据集平均结果（原paper附录中有详细的结果）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914232216415.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>一开始使用一个上下文样例池有助于提高生成数据多样性和最终的SLM性能；</li>
<li>增加多样性，可能会降低accuracy；两种解码策略都会降低accuracy，但是High temperature降低的稍微轻一点；</li>
<li>一味的增加生成数据的多样性，不一定能够对fine-tuned的SLM性能有提升作用，甚至会降低模型效果；</li>
<li>To evaluate how diversity, label accuracy, and similarity impact model accuracy, we performed a linear regression analysis. <strong>The analysis showed that label accuracy, diversity, and similarity are positively correlated with model accuracy, with significance</strong> (coef=<span class="math inline">\(.4797\)</span> and <span class="math inline">\(p&lt;0.001\)</span> for label accuracy, coef=<span class="math inline">\(.2260\)</span> and <span class="math inline">\(p&lt;0.001\)</span> for diversity, and coef=<span class="math inline">\(0.1980\)</span> and <span class="math inline">\(p&lt;0.005\)</span> for similarity). 生成数据的三种因素和最终fine-tuned之后的model有很强的相关系数；</li>
</ul>
<h2 id="human-interventions-to-fix-inaccurate-text-generation">3. Human Interventions to Fix Inaccurate Text Generation</h2>
<h3 id="method-1">3.1 Method</h3>
<p>上面的实验揭露了单纯增加生成数据多样性不行，作者进一步考虑引入人类智能来缓解这一问题。简单的说，就是利用人去标注了小规模的分类器，用这个分类器去重新标注或过滤生成的数据。</p>
<p>作者考虑两种简单的方法：</p>
<ol type="1">
<li>label replacement (LR)：switching the misaligned label to the correct one. 修正label
<ul>
<li>作者考虑训练一个proxy model来重新标注生成的text</li>
<li>作者考虑了两种方法，一种是直接用oracle model来重新标注所有生成的text；一种是少量的采样，用oracle model标注，然后训练支持向量分类器来判断label正确与否</li>
</ul></li>
<li>out-of-scope data filtering (OOSF)：removes instances that are outside the domain of interest and do not match any labels. 移除不符合task的生成数据
<ul>
<li>人工判断采样一小部分数据，然后判断句子是否outside the task，标注数据。用这个标注数据来训练一个支持向量分类器。最终用这个支持向量分类器去过滤掉不符合要求的句子</li>
</ul></li>
</ol>
<h3 id="experiments-1">3.2 Experiments</h3>
<p>第一种标签替换LR的策略：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914233552594.png"   style="zoom:30%;" /></p>
<p>能够极大的提高最终的训练出来model的效果。由于只是修改label，因此不会影响多样性指标。</p>
<p>第二种OOSF过滤策略：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230914233641751.png"   style="zoom:50%;" /></p>
<p>作者是在LR方法的基础上，继续加上OOSF（图中的<code>+OOS</code>）。实验发现OOSF不能够总是带来一致的效果提升，并且由于会移除生成数据，还会同时影响多样性指标。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Data Augment</category>
      </categories>
      <tags>
        <tag>Data Augment</tag>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-ICL-survey-pku</title>
    <url>/llm/LLM-ICL-survey-pku/</url>
    <content><![CDATA[<h1 id="a-survey-on-in-context-learning">A Survey on In-context Learning</h1>
<p>arXiv 2023.05，北大。ICL首个survey。</p>
<blockquote>
<p>With the increasing ability of large language models (LLMs), in-context learning (ICL) has become a new paradigm for natural language processing (NLP), where LLMs make predictions only based on contexts augmented with a few examples. It has been a new trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, demonstration designing strategies, as well as related analysis. Finally, we discuss the challenges of ICL and provide potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>这篇survey中对于in-context learning的定义和在GPT-3中给出的正式定义有所区别。这篇survey认为ICL必须要有demonstrations，但是GPT-3的原始定义则不是：</p>
<blockquote>
<p>Recent work [GPT-2] attempts to do this via what we call “in-context learning”, using the text input of a pretrained language model as a form of task specification: the model is conditioned on a natural language instruction and/or a few demonstrations of the task and is then expected to complete further instances of the task simply by predicting what comes next.</p>
</blockquote>
<p>下面图是作者划分的一个分类：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531231352388.png" alt="image-20230531231352388" /><figcaption>image-20230531231352388</figcaption>
</figure>
<p>ICL最吸引人的点就在于在inference的时候，完全无需训练，并且在某些task下已经达到了SOTA的结果 （当然在很多任务下还有差距）。作者指出了三个ICL优势点：</p>
<ol type="1">
<li>since the demonstration is written in natural language, it provides an interpretable interface to communicate with LLMs</li>
<li>in-context learning is similar to the decision process of human beings by learning from analogy</li>
<li>compared with supervised training, ICL is a training-free learning framework.</li>
</ol>
<h2 id="model-warmup">2. Model Warmup</h2>
<p>在LLM的预训练任务是语言建模，这和ICL的任务形式是有gap的。因此很多研究讨论通过在pre-training和ICL之间加入一个额外的训练过程以进一步提升ICL的效果。作者称为warmup training。</p>
<p>比如MetaICL就是在一系列加入了demonstrations的ICL的训练数据中进行Supervised In-context Training。</p>
<p>另一个能够提升ICL的训练方法是instruction tuning。</p>
<blockquote>
<p>Compared to MetaICL, which constructs several demonstration examples for each task, instruction tuning mainly considers an explanation of the task and is more easier to scale up.</p>
</blockquote>
<p>instruction tuning对于构造训练数据的要求更小，更容易构造一系列不同task的训练数据。</p>
<p>加入一个额外的训练过程已经在很多研究中发现效果提升很明显，并且发现一直增加相应的训练数据不会带来持续的性能提升，可能数据的分布、task的覆盖范围和差异性这些因素是更关键的。</p>
<h2 id="demonstration-designing">3. Demonstration Designing</h2>
<h3 id="demonstration-organization">3.1 Demonstration Organization</h3>
<p>Demonstration Organization指如何选择合适的examples和排序？</p>
<p><strong>Demonstration Selection</strong>. 又可以分为无监督和有监督的方法。无监督的方法比如使用kNN这些方法，选择和当前测试的instance最相似的demonstrations；比如使用互信息，perplexity等；比如选择的时候还要考虑demonstrations的差异性；还有的直接使用LLM自己生成的demonstrations。</p>
<p>有监督的选择方法比如先无监督的检索，再用一个打分函数进行选择；比如可以使用强化学习不断更新检索的模型。</p>
<p><strong>Demonstration Ordering</strong>. 已经有研究发现demonstrations的顺序对于结果有影响。比如可能LLM倾向于输出最靠近测试样例的demonstration一样的结果。如果有<span class="math inline">\(k\)</span>个demonstrations，会有<span class="math inline">\(k!\)</span>种排列组合。（个人认为这种情况属于LLM的一个不稳定、不鲁棒的缺陷。需要想办法去解决，而不是利用…）</p>
<h3 id="demonstration-formatting">3.2 Demonstration Formatting</h3>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531233847239.png" alt="image-20230531233847239" /><figcaption>image-20230531233847239</figcaption>
</figure>
<p>怎么样设计具体的输入模板。</p>
<p><strong>Instruction Formatting</strong>. instruction需要准确的描述任务，依赖于人工设计。</p>
<ul>
<li>Instruction induction: From few examples to natural language task descriptions. 使用LLM自动从几个demonstrations中生成task instruction。</li>
<li>Large language models are human-level prompt engineers. 提出自动生成和选择instruction。</li>
</ul>
<p><strong>Reasoning Steps Formatting</strong>. survey这里提到的是将CoT加入到ICL进一步提升LLM对于复杂task的推理能力。</p>
<h2 id="scoring-function">4. Scoring Function</h2>
<p>是指怎么样将LLM的输出转化为一个恰当的概率估计。</p>
<blockquote>
<p>The scoring function decides how we can transform the predictions of a language model into an estimation of the likelihood of a specific answer.</p>
</blockquote>
<p>作者提及了三种方法：</p>
<ol type="1">
<li>A direct estimation method (Direct) adopts the conditional probability of candidate answers that can be represented by tokens in the vocabulary of language models. 直接使用预测的答案在LLM中的条件概率，但是这要求预测的答案出现在模板的最后，作为要续写的token进行输出。</li>
<li>Perplexity (PPL) is another commonly-used metric, which computes the sentence perplexity of the whole input sequence. 对模板没有要求</li>
<li>Min et al. (2022a) proposed to utilize channel models (Channel) to compute the conditional probability in a reversed direction, i.e., estimating the likelihood of input query given the label. 反过来让模型decode加入了label之后的query。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531234701083.png"   style="zoom:50%;" /></p>
<h2 id="analysis">5. Analysis</h2>
<h3 id="what-influences-icl-performance">5.1 What Influences ICL Performance</h3>
<p>有哪些因素会影响ICL的效果？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531234752644.png"   style="zoom:40%;" /></p>
<p><strong>Pre-training Stage</strong>：</p>
<ul>
<li>Putting multiple corpora together may give rise to emergent ICL ability, pretraining on corpora related to the downstream tasks does not always improve the ICL performance.</li>
<li>a pretrained model suddenly acquires some emergent ICL abilities when it achieves a large scale of pre-training steps or model parameters.</li>
</ul>
<p><strong>Inference Stage</strong>:</p>
<ul>
<li>Min et al. (2022c) investigated that the inﬂuence of demonstration samples comes from four aspects: the input-label pairing format, the label space, the input distribution, and the input-label mapping. They prove that all of the input-label pairing formats, the exposure of label space, and the input distribution contribute substantially to the ICL performance.</li>
<li>Lu et al. (2022) indicated that the demonstration sample order is also an important factor.</li>
</ul>
<h3 id="understanding-why-icl-works">5.2 Understanding Why ICL Works</h3>
<p>ICL原理分析</p>
<ul>
<li>Distribution of Training Data. Chan et al. (2022) showed that the ICL ability is driven by data distributional properties. They found that the ICL ability emerges when the training data have examples appearing in clusters and have enough rare classes. 发现ICL能力的出现需要训练数据的分布多样性足够。</li>
<li>Learning Mechanism.
<ul>
<li>Garg et al. (2022) proved that Transformers could encode effective learning algorithms to learn unseen linear functions according to the demonstration samples. 认为Transformer能够从demonstration samples学习没有见过的linear functions。</li>
<li>Dai et al. (2022) figured out a dual form between Transformer attention and gradient descent and further proposed to understand ICL as implicit fine tuning. 将ICL和梯度下降对齐，认为ICL是在进行一种隐式的梯度下降。</li>
</ul></li>
<li>Functional Modules. Olsson et al. (2022) found that there exist some induction heads in Transformers that copy previous patterns to complete the next token. 发现Transformer中可能有可以实现归纳功能的induction head。</li>
</ul>
<h2 id="evaluation-and-resources">6. Evaluation and Resources</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230531235353921.png"   style="zoom:50%;" /></p>
<h2 id="challenges-and-future-directions">7. Challenges and Future Directions</h2>
<p>一些新的挑战：</p>
<ul>
<li>New Pre-training Strategies. 比如instruction-tuning</li>
<li>Distill the ICL Ability to Smaller Models. Transferring the ICL ability to smaller models could facilitate the model deployment greatly.</li>
<li>Knowledge Augmentation and Updating
<ul>
<li>Knowledge Augmentation. Retrieving correct knowledge and integrating the correct knowledge with the context in a lightweight manner is possibly promising for ICL.</li>
<li>Knowledge Updating. Updating the wrong or out-of-date knowledge for ICL is worth further exploration.</li>
<li>Robustness to Demonstration. Previous studies have shown that ICL performance is extremely unstable, from random guess to SOTA, and can be sensitive to many factors.</li>
<li>ICL for Data Engineering. How to use ICL for data annotation remains an open question. For example, Ding et al. (2022) performed a comprehensive analysis and found that generation-based methods are more cost-effective in using GPT-3 than annotating unlabeled data via ICL.</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>ICL</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>ICL</tag>
        <tag>Survey</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-know-what-they-dont-know</title>
    <url>/llm/LLM-know-what-they-dont-know/</url>
    <content><![CDATA[<h1 id="do-large-language-models-know-what-they-dont-know">Do Large Language Models Know What They Don’t Know?</h1>
<p>复旦大学，ACL 2023 Findings，<a href="https://github.com/yinzhangyue/SelfAware">代码</a>。</p>
<blockquote>
<p>Large language models (LLMs) have a wealth of knowledge that allows them to excel in various Natural Language Processing (NLP) tasks. Current research focuses on enhancing their performance within their existing knowledge. Despite their vast knowledge, LLMs are still limited by the amount of information they can accommodate and comprehend. Therefore, the ability to understand their own limitations on the unknows, referred to as self-knowledge, is of paramount importance. <strong>This study aims to evaluate LLMs’ self-knowledge by assessing their ability to identify unanswerable or unknowable questions.</strong> We introduce an automated methodology to detect uncertainty in the responses of these models, providing a novel measure of their self-knowledge. <strong>We further introduce a unique dataset, SelfAware, consisting of unanswerable questions from five diverse categories and their answerable counterparts.</strong> Our extensive analysis, involving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an intrinsic capacity for self-knowledge within these models. Moreover, we demonstrate that in-context learning and instruction tuning can further enhance this self-knowledge. Despite this promising insight, our findings also highlight a considerable gap between the capabilities of these models and human proficiency in recognizing the limits of their knowledge.</p>
</blockquote>
<p>这篇论文主要讨论了LLM是否知道一个question是否有准确的答案？或者说LLM是否knowing what you don’t know，作者把这种能力成为LLM的self-knowledge。</p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p>LLM的参数里可能蕴含了很多的knowledge，但是LLM能够知道自己已知哪些知识，知道自己不知道哪些知识吗？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903210129000.png"   style="zoom:40%;" /></p>
<p>让LLM给出不确定的回答，让LLM承认自己不知道是很重要的。这种能力是能够提高LLM可信度的一种重要度量。</p>
<p>这篇工作作者主要讨论上面图中的”Known Unknows”和“Unknown Unknows“之间的比值，作者将这种判断问题是否有准确回答的判别能力来看做评估LLM的self-knowledge的手段。</p>
<h2 id="dataset">Dataset</h2>
<p>作者创建了一个新的数据集，SelfAware，包括1,032 unanswerable questions和2,337 questions that are classified as answerable。在这篇工作前是有其它类似数据集的，如KnowUnknowns。作者的SelfAware数据集包括了更多的问题数量和更多的问题类型：</p>
<ul>
<li>unanswerable questions：来源于online platforms like Quora and HowStuffWorks。经过人工标注后判断不可回答</li>
<li>answerable questions：we opted for answerable questions drawn from three datasets: SQuAD (Rajpurkar et al., 2016), HotpotQA (Yang et al., 2018), and TriviaQA (Joshi et al., 2017).</li>
</ul>
<p>下面Table是作者随机从数据集中找了100个样例分析后得到的，不能够完全准确的描述数据集全体的情况：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903210715891.png"   style="zoom:50%;" /></p>
<h2 id="experiment">Experiment</h2>
<p>然后是如何判断LLM的回答是不知道呢？作者通过SimCSE方法计算LLM的回答和作者提前定义好的uncertain sentences的相似度，只要相似度大于一定阈值（实验中取<span class="math inline">\(0.75\)</span>），就认为LLM的回答是不确定。下面是uncertain sentences的示例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903210908826.png"   style="zoom:20%;" /></p>
<p>这些句子的创建就是随机选择100个样例让GPT回答；然后人工挑选出那些表达不清楚/不知道的句子。 （个人认为是否可以让LLM自己评估回答是不是不确定/不知道的？）</p>
<p>GPT-4的评估样例用了100个；其它LLM是用了整个SelfAware dataset。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903211006720.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>model size越大，越知道自己不知道什么</li>
<li>上下文学习最能够激发LLM的潜力</li>
</ul>
<p>下面是作者在使用中使用的三种输入形式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903211333112.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903211345050.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903211418667.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903211048028.png"  style="zoom:30%;" /> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903211107183.png"  style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>指令微调能够让模型更好的知道自己不知道；也就是回答不确定/不清楚</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903211149108.png"   style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>最好的GPT-4和人类仍有差距，但是结果仍然是非常promising的</li>
</ul>
<p>下面是作者</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
      </categories>
      <tags>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-reason-survey-zju</title>
    <url>/llm/LLM-reason-survey-zju/</url>
    <content><![CDATA[<h1 id="reasoning-with-language-model-prompting-a-survey">Reasoning with Language Model Prompting: A Survey</h1>
<p>浙大zjunlp，<a href="https://github.com/%20zjunlp/Prompt4ReasoningPapers">paper仓库</a>。回顾并总结了使用LLM进行推理的各种现有方法。</p>
<blockquote>
<p>Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions.</p>
</blockquote>
<span id="more"></span>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526152650228.png"   style="zoom:40%;" /></p>
<p>作者提出的分类如图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526152918290.png" alt="image-20230526152918290" /><figcaption>image-20230526152918290</figcaption>
</figure>
<h2 id="taxonomy-of-methods">Taxonomy of Methods</h2>
<p>作者主要划分为两个大类：</p>
<ul>
<li>Strategy Enhanced Reasoning</li>
<li>Knowledge Enhanced Reasoning</li>
</ul>
<h3 id="strategy-enhanced-reasoning">Strategy Enhanced Reasoning</h3>
<h4 id="prompt-engineering">Prompt Engineering</h4>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526154004528.png" alt="image-20230526154004528" /><figcaption>image-20230526154004528</figcaption>
</figure>
<p>单步prompt早期的方法是基于模板，后来人们通过往ICL中加入更多的推理中间步骤（也就是CoT）来能够进一步的提升模型的推理能力。</p>
<p>后来的方法进一步把复杂的问题分解为几个步骤，进行multi-stage的prompting。</p>
<h4 id="process-optimization">Process Optimization</h4>
<p>prompt engineering仅仅是在修改输入，进一步的有工作探究怎么样优化推理步骤（叫做Natural language rationales，在有些paper中也叫做explanations）。作者简单介绍了三种过程优化方法：</p>
<ul>
<li>Self-Optimization：通过引入额外的module来矫正过程</li>
<li>Ensemble-Optimization：集成多个不同的推理步骤的推理结果，获得更加鲁棒的推理能力</li>
<li>Iterative-Optimization：迭代的重复推理过程，把推理答案加入到训练数据进一步fine tune模型</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526154854026.png"   style="zoom:40%;" /></p>
<h4 id="external-engine">External Engine</h4>
<p>LLM模型本身的能力是有局限的，但是通过结合外部的推理引擎能够进一步提升LLM的推理能力。作者也同样简单介绍了三种：</p>
<ul>
<li>Physical Simulator：对物理过程的理解通过一个物理引擎进行模拟，然后再作为prompt输入到LLM</li>
<li>Code Interpreter：将LLM和代码结合起来，利用程序语言更加鲁棒，能够更好的说明复杂结构和计算过程的优点</li>
<li>Tool Learning：有些很简单的任务，LLM不一定能够超过非常简单的方法，因此有工作探究如何让LLM学习调用各种工具。</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526155347585.png"   style="zoom:40%;" /></p>
<h3 id="knowledge-enhanced-reasoning">Knowledge Enhanced Reasoning</h3>
<h4 id="implicit-knowledge">Implicit Knowledge</h4>
<p>有研究发现LM内部学习到了隐式的知识（“modeledge”），因此一个自然的想法是使用这样的隐式知识来增强prompts。比如有人使用GPT-3生成知识和prompt来指导下游任务的LM。</p>
<h4 id="explicit-knowledge">Explicit Knowledge</h4>
<p>LM generated knowledge缺点是不稳定与不可靠，因此有人考虑通过从已有的可信赖的外部资源（例如Wikipedia）去检索合适的知识来增强prompt。</p>
<h2 id="comparison-and-discussion">Comparison and Discussion</h2>
<p><strong>Comparison of Language Models</strong></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526164451578.png"  style="zoom:35%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526164530981.png"   style="zoom:35%;" /></p>
<p>Codex加入CoT进行推理比单纯的GPT-3效果要好。CoT的出现表现在model size大于100B的时候，有研究发现，CoT和model size的关系之所以会表现出“涌现”，也可能是因为评估策略的问题，可能model size增大，CoT的中间步骤的效果是在逐渐变好的，只不过只有到了一定的大小，最终的答案才会变好。</p>
<p>下图是不同构造prompt方法应用的总结：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230526164708229.png" alt="image-20230526164708229" /><figcaption>image-20230526164708229</figcaption>
</figure>
<h2 id="future-directions">Future Directions</h2>
<ul>
<li>Theoretical Principle of Reasoning：探究涌现能力、推理能力等出现的原因（decipher the dark matter of intelligence）</li>
<li><p>Efficient Reasoning：使用大模型本身就有很大的代价，如何减小使用大模型的代价。一个方向是研究更加通用的大模型；一个方向是把LLM的推理能力迁移到小模型上。</p></li>
<li>Robust, Faithful and Interpretable Reasoning：如何保证推理可靠</li>
<li>Multimodal (Interactive) Reasoning：使用不同模态的交互式的推理</li>
<li><p>Generalizable (True) Reasoning：对于LLM没有在训练过程中见过的任务进行推理</p></li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Survey</tag>
        <tag>Reasoning</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-survey-renmin</title>
    <url>/llm/LLM-survey-renmin/</url>
    <content><![CDATA[<h1 id="a-survey-of-large-language-models">A Survey of Large Language Models</h1>
<p>人大，arXiv 2023.05，<a href="https://github.com/RUCAIBox/LLMSurvey">代码</a>。</p>
<blockquote>
<p>Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine. Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable artificial intelligence (AI) algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pretraining Transformer models over large-scale corpora, showing strong capabilities in solving various natural language processing (NLP) tasks. Since the researchers have found that model scaling can lead to an improved model capacity, they further investigate the scaling effect by increasing the parameter scale to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement, but also exhibit some special abilities (e.g., incontext learning) that are not present in small-scale language models (e.g., BERT). To discriminate the language models in different parameter scales, the research community has coined the term large language models (LLM) for the PLMs of significant size (e.g., containing tens or hundreds of billions of parameters). Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT (a powerful AI chatbot developed based on LLMs), which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. Considering this rapid technical progress, in this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Furthermore, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions. This survey provides an up-to-date review of the literature on LLMs, which can be a useful resource for both researchers and engineers.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>语言是人类从小开始学习，终身都在使用的工具。让机器能够像人一样的读、写和交流是人工智能领域一直以来的追求。</p>
<p>语言建模language modeling（LM）是指能够生成词序列概率似然的技术手段，能够实现预测下一个或者确实的token。其对应模型的发展经历了四个阶段：</p>
<ol type="1">
<li>Statistical language models (SLM). 根据固定范围的context来预测下一个词，比如n-gram models。需要注意下，这里的SLM的缩写，和某些论文中出现的Small Language Model是两个含义。</li>
<li>Neural language models (NLM). 利用神经网络来预测word sequence probabilities。每一个word被建模为distributed representations [<em>A neural probabilistic language model 2003</em>]，最出名的有word2vec方法。</li>
<li>Pre-trained language models (PLM). 先在语料上预训练，之后在具体任务上微调。早期的尝试包括ELMo（基于biLSTM），后续出现了BERT，GPT1,2（基于Transformer）等方法。</li>
<li>Large language models (LLM). 简单的讲LLM就是large-scaled PLM，比如GPT-3，PaLM等。</li>
</ol>
<p>LLM和PLM（之前看到也有研究把PLM对应的方法叫做SLM）的区别，作者分出3点：</p>
<ul>
<li>LLM比起SLM涌现出了新的能力（emergent abilities [<em>Emergent abilities of large language models 2022</em>]），比如GPT-3比起GPT-2，能够通过in-context learning进行few-shot任务。</li>
<li>LLM改变了人们使用和发展AI算法的方式。对LLM的应用更多的是通过改变输入，然后利用API进行访问。</li>
<li>LLM使得科研和工程之间的界限变得模糊。预训练LLM可能模型架构本身不再是问题，问题是工程实践（如何处理和选择数据、如何并行训练、如何细微地调整模型的细节）</li>
</ul>
<p>由于现在对于LLM模型最小scale并没有统一的认识（特别是LLM的性能和训练数据以及模型本身的大小有关），因此在这篇论文里，作者简单的把10B以上参数量的PLM叫做LLM。</p>
<p>发展LLM面临的问题，作者总结了3个大的方面：</p>
<ul>
<li>LLM出现能力涌现的原因到底是什么？</li>
<li>学术界较难从头训练一个LLM，特别是很多LLM由大公司开发，实现细节不公开（这就是为什么我们要发展open LLM）</li>
<li>如何让LLM和人类偏好对齐？特别是如何阻止生成有毒的、虚假编造的输出。</li>
</ul>
<h2 id="overview">2. Overview</h2>
<h3 id="background-for-llms">2.1 Background for LLMs</h3>
<p>scaling law是指随着模型大小，数据集大小以及计算次数等的增加，LLM性能变化的形式化的变化趋势。作者介绍了两个有代表性的scaling law：</p>
<ol type="1">
<li>KM scaling law：2020年OpenAI提出的[<em>Scaling laws for neural language models 2020</em>]，表示模型的性能和三个因素成power-law：model size（模型大小），dataset size（训练数据大小）和training compute（训练计算FP）。KM scaling law更强调在一定的计算负担情况下，增大model size而不是dataset size。</li>
<li>Chinchilla scaling law：2022年Google DeepMind提出的，强调在一定的计算负担情况下，更好的选择是同时增加dataset size和model size。</li>
</ol>
<p>利用scaling law可以帮助我们选择预训练模型大小和数据集大小。</p>
<p>但是，存在一些LLM能力不符合scaling law，当模型大小较小的情况下无法显示，然而在大模型中突然表现出来的能力，这就是LLM的涌现能力（Emergent Abilities）。下面是3个典型的涌现能力：</p>
<ul>
<li>In-context learning：在GPT-3中正式提出（虽然在GPT-2中实际已经使用），是指模型在提供了自然语言描述的指令instruction和几个demonstrations之后，无需训练和梯度更新，就能够生成期望的输出的能力。</li>
<li>Instruction following：通过在预训练数据集中加入指令instruction，进行instruction tuning，模型能够学会仅仅通过指令，不需要demonstration，就能够准确执行任务的能力。</li>
<li>Step-by-step reasoning：通过chain-of-thought (CoT) prompting，LLM模型能够一步步的解决复杂任务，这一点在之前的PLM是无法做到的。</li>
</ul>
<h3 id="technical-evolution-of-gpt-series-models">2.2 Technical Evolution of GPT-series Models</h3>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230522220527055.png" alt="image-20230522220527055" /><figcaption>image-20230522220527055</figcaption>
</figure>
<p>作者简要的介绍了GPT家族的发展过程。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230820154803236.png" alt="image-20230820154803236" /><figcaption>image-20230820154803236</figcaption>
</figure>
<ol type="1">
<li>Early Explorations. GPT-1和GPT-2。GPT-1（Generative Pre-Training）2017年提出，follow了Transformer的工作，使用Transformer的decoder部分进行单向的next word预测。GPT-2在2019年提出，参数量达到了1.5B，在更大的数据集上进行训练，通过把各类NLP任务建模为word prediction任务，实现无需训练的通用多任务学习器。</li>
<li>Capacity Leap. GPT-3在2020年提出，是OpenAI的里程碑，参数量达到了175B。GPT-3不仅仅能够适用于很多NLP任务，还能够适用于很多复杂的需要推理的任务上。</li>
<li>Capacity Enhancement. 对GPT-3能力的增强，主要包括代码预训练（Training on code data）和人类对齐（Human alignment）。通过加入代码数据，增强GPT-3的推理能力，代表工作是2021年7月提出的Codex。人类对齐Human alignment是指从人类偏好中进行学习，代表工作是2022年1月提出的InstructGPT，利用了RLHF人类反馈强化学习（reinforcement learning from human feedback）。RLHF不仅能够提升LLM对于人类指令的理解，更能够用来缓解有害输出的生成（比如询问GPT怎么样制作爆炸物）。这些对于GPT-3的提升产生了GPT-3.5系列模型。</li>
<li>The Milestones of Language Models. ChatGPT在2022年11月推出，ChatGPT和InstructGPT可以看做是双胞胎，只不过ChatGPT的预训练数据集中加入了对话数据，让ChatGPT格外擅长和人类交互。随后在2023年3月推出了多模态GPT-4。</li>
</ol>
<h2 id="resources-of-llms">3. Resources of LLMs</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230821234601704.png" alt="image-20230821234601704" /><figcaption>image-20230821234601704</figcaption>
</figure>
<h3 id="publicly-available-model-checkpoints-or-apis">3.1 Publicly Available Model Checkpoints or APIs</h3>
<p>目前可以获取的开源参数的模型：</p>
<ul>
<li><p>Models with Tens of Billions of Parameters. 这个量级的LLM大致参数是在100B以下。作者推荐了以下几个可以考虑的模型：</p>
<ul>
<li>Flan-T5（11B version），可以用来研究指令微调的效果，它从指令训练task的数量、model size和加入CoT的数据三个方面进行了训练。</li>
<li>CodeGen（11B version）：可以作为探究LLM生成代码的base。它还额外的引入了MTPB这个benchmark，包括了115个专家生成的编程问题。</li>
<li>mT0（13B version）：可以作为多语言任务的base。</li>
<li>PanGu-<span class="math inline">\(\alpha\)</span>（largest public version 13B）：可以作为中文zero-shot或者few-shot任务的base。</li>
<li>LLaMA（largest version 65B）：目前被应用研究最多的开源LLM，下面有具体的介绍。</li>
<li>Falcon：通过更加精心准备的预训练数据达到更好效果的最新开源LLM。</li>
</ul></li>
<li><p>Models with Hundreds of Billions of Parameters. 100B以上的LLM。这一级别的开源模型就比较少了，包括OPT，OPT-IML，BLOOM，BLOOMZ，GLM等。</p>
<ul>
<li>OPT（175B version）有个对应的加入了指令微调的版本OPT-IML。</li>
<li>BLOOM（176B version）和BLOOMZ（176B version）主要可用于跨语言任务。</li>
<li>GLM（130B version）：一个中英双语LLM。额外提供了一个很流行的更小size的中文模型ChatGLM2-6B（是之前ChatGLM-6B的升级版），其加入了量化、32K上下文size和快速推理等特征/技术。</li>
</ul></li>
<li><p>LLaMA Model Family. 由Meta AI在2023年2月推出的开源LLM，可能是目前被改造应用最多的模型。</p>
<ul>
<li><p>Alpaca：是首个基于LLaMA-7B进行指令微调的模型。指令微调的数据是使用了52k个利用self-instruct基于<code>text-davinci-003</code>生成的指令。该指令微调数据集叫做Alpaca-52K，并且被后续的Alpaca-LoRA，Koala，BELLE等LLM使用。</p></li>
<li><p>Vicuna：在LLaMA基础上加入了从ShareGPT平台上导出的用户对话数据。Vicuna是目前很多multimodal LLM常用的base language model，比如LLaVA，MiniGPT-4，InstructBLIP和PandaGPT。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230821163623231.png" alt="image-20230821163623231" /><figcaption>image-20230821163623231</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="commonly-used-corpora">3.2 Commonly Used Corpora</h3>
<p>常见的预训练LLM的数据来源：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230821172255121.png" style="zoom:45%;" /></p>
<ul>
<li>Books：
<ul>
<li>BookCorpus：小规模的书籍数据集，11000本书，GPT和GPT-2中使用了。</li>
<li>Project Gutenberg：目前最大的公开书籍数据集，70000本书，在MT-NLP和LLaMA预训练中使用了。</li>
<li>Books1和Books2：更大的book数据集，在GPT-3的训练中使用了，但是未开源。</li>
</ul></li>
<li>CommonCrawl. CommonCrawl.是目前互联网中最大的开源爬取网页的数据集，千万亿字节/千T级别的数据。但是数据质量较低，有以下的数据清洗的版本：
<ul>
<li>C4：Colossal Clean Crawled Corpus，有5个版本，en (806G), en.noclean (6T), realnewslike (36G), webtextlike (17G), and multilingual (38T)。</li>
<li>CC-Stories (31G)：CommonCrawl.的一个子集，其中的内容是story-like的样式。可以通过CC-Stories-R访问其的复现版本。</li>
<li>REALNEWS (120G)</li>
<li>CC-News (76G)</li>
</ul></li>
<li>Reddit Links. 从Reddit上爬取的数据
<ul>
<li>WebText：包括了Reddit上点赞数/赞同数高的post，未开源。有个开源的替代OpenWebText。</li>
<li>PushShift.io：一个不断更新的Reddit的dump数据集，还有提供了一套查询，总结等功能的接口。</li>
</ul></li>
<li>Wikipedia. 维基百科，很多LLM都会使用的数据源。GPT-3，LaMDA，LLaMA都使用了。</li>
<li>Code：包括代码和代码相关的QA平台
<ul>
<li>BigQuery：Google开源的大规模代码数据</li>
</ul></li>
<li>Others
<ul>
<li>Pile（800G）：book，code，website，paper等各类数据混杂的数据集。GPT-J (6B), CodeGen (16B) 和 Megatron-Turing NLG (530B)等LLM使用。</li>
<li>ROOTS（1.61T）：各类小数据集的混合，59种语言，包括自然语言和编程语言。BLOOM预训练使用。</li>
</ul></li>
</ul>
<h3 id="library-resource">3.3 Library Resource</h3>
<p>作者总结了几个可以用来训练LLM的库</p>
<ul>
<li>Transformers：Hugging Face的开源仓库</li>
<li>DeepSpeed：Microsoft开发的优化库，可以用来训练LLM，比如MT-NLG，BLOOM就是基于此库</li>
<li>Megatron-LM：英伟达开发的用于训练LLM的库，支持各类并行算法、分布式训练等</li>
<li>JAX：Google提供的开发高性能ML算法的库</li>
<li>Colossal-AI：HPC-AI Tech提供的开发大规模AI模型的库，ColossalChat就是基于此开发</li>
<li>BMTrain：OpenBMB开发的支持分布式训练大规模参数量AI模型的库，目前可以通过它的ModelCenter直接访问Flan-T5、GLM。</li>
<li>FastMoE：支持训练MoE模型，基于PyTorch。</li>
</ul>
<h2 id="pre-training">4. Pre-Training</h2>
<h3 id="data-collection-and-preparation">4.3 Data Collection and Preparation</h3>
<p>略，参见论文</p>
<h3 id="architecture">4.2 Architecture</h3>
<p>现有的主流LLM架构：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240229110120857.png" alt="image-20240229110120857" /><figcaption>image-20240229110120857</figcaption>
</figure>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20240229111009405.png"  style="zoom:50%;" /></p>
<p>首先是基于Transformer的3种架构：</p>
<ul>
<li>Encoder-Decoder：原始的Transformer架构，双向mask的encoder+单向mask的decoder，在当前的LLM中用的比较少，比如Flan-T5</li>
<li>Causal Decoder：单向mask的decoder，也是当前使用最多的架构，只能够看到前面的token，不断的预测下一个token</li>
<li>Prefix Decoder：在给定的prefix tokens之间使用双向attention，对于要生成的tokens使用单向mask。常用的实践策略是在casual decoder基础上继续训练以加速收敛，得到prefix decoder，例如U-PaLM就是在PaLM基础上发展来的。</li>
</ul>
<p>至于上面这3中架构到底各有什么优劣，现在没有定论，只不过大家现在主要都是follow OpenAI的casual decoder。不过现在有少数的研究发现，casual decoder似乎表现出了更好的zero-shot和few-shot能力。</p>
<p>然后是其它新兴的架构，主要目的是缓解Transformer的二次方计算效率问题：</p>
<ul>
<li>parameterized state space models：比如S4、GSS、H3</li>
<li>long convolutions：比如Hyena</li>
<li>Transformer-like architectures that incorporate recursive update mechanisms：比如RWKV，RetNet。一方面继续保持了Transformer便于并行训练的优点，一方面还不需要关注全部的序列，可以像RNN一样只关注前一个输入。</li>
</ul>
<p>另外，LLM还常常结合Mixture-of-Experts，通过部分激活策略实现在保持计算效率的情况下增大模型参数。训练MoE常见的问题是不稳定。</p>
<h2 id="adaption-tuning-of-llms">5. Adaption Tuning of LLMs</h2>
<p>作者主要介绍了instruction tuning、alignment tuning和efficient tuning。</p>
<h3 id="instruction-tuning">5.1 Instruction Tuning</h3>
<p>指令微调主要用来激发/加强LLM对于人类指令的执行能力（个人感觉像是LLM本身经过预训练后已经拥有了解决各种任务的能力，只不过还没有学会到底怎么样按照人类的指令去输出人类期望的结果。指令微调就是告诉LLM人类到底是期望各种task以什么样的结果输出的）。</p>
<p>指令微调就是一种有监督的训练，和多任务学习等都是相关的。</p>
<p>首先是怎么样构造带有指令的数据集。来源有三种：</p>
<ul>
<li>现有的数据集（Formatting Existing Datasets）：将已有的各种任务的数据集收集起来，加入人工的任务描述。PromptSource是一个可以为不同数据集构造合适的描述的众包平台。</li>
<li>基于人类输入构造的数据（Formatting Human Needs）：现有的NLP数据集不能够全面的、准确的满足实际的人类需要。InstructGPT就将真实用户的查询作为instruction。GPT-4进一步人工构造危险的有毒的指令，让模型学会拒绝这样的指令。</li>
<li>自动构造的数据：类似于Self-instruct，一些半自动的方法被提出来以减小人类标注指令的负担。</li>
</ul>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230604175331744.png" alt="image-20230604175331744" /><figcaption>image-20230604175331744</figcaption>
</figure>
<p>构造的指令数据集有以下几个关键因素</p>
<ul>
<li>task的数量。效果的提升在task数量增加到一定数量时会逐渐达到一个确定的层级。</li>
<li>task descriptions的差异性（长度、结构、创新性等）。</li>
<li>每个task不需要有很多对应的instance，通常较少数量的instances就足够了。</li>
<li>具体输入到LLM的prompt格式，比如要不要加入推理步骤、要不要加入demonstrations等。</li>
</ul>
<p>总体上来说，似乎指令的多样性要比数量更重要。</p>
<p>在训练的时候，由于指令数据集要远远小于预训练的语料，因此训练起来更快。除了一般的要关注的有监督训练的各种超参设置外，还有几个额外需要关注的策略：</p>
<ul>
<li>Balancing the Data Distribution.
<ul>
<li>直接混合不同task dataset的数据，然后随机选择；</li>
<li>增大高质量dataset数据的被采样的概率；</li>
<li>设置单个dataset最大采样的次数，避免过大的dataset过于影响instruction tuning效果；</li>
</ul></li>
<li>Combining Instruction Tuning and Pre-Training.
<ul>
<li>在instruction tuning加入pre-training的数据，让模型在指令微调过程中保持在预训练过程中学习到的能力和知识。OPT-IML incorporates pre-training data during instruction tuning, which can be regarded as regularization for model tuning.</li>
<li>使用多任务学习同时预训练和指令微调。some studies attempt to train a model from scratch with a mixture of pre-training data (i.e., plain texts) and instruction tuning data (i.e., formatted datasets) using multi-task learning.</li>
<li>将指令微调数据集直接作为预训练数据中的一部分。GLM-130B [83] and Galactica [35] integrate instruction-formatted datasets as a small proportion of the pre-training corpora to pre-train LLMs, which potentially achieves the advantages of pre-training and instruction tuning at the same time.</li>
</ul></li>
</ul>
<p>经过instruction tuning之后，模型一般会取得性能提升：</p>
<ul>
<li>the models of different scales can all beneﬁt from instruction tuning [64, 217], yielding improved performance as the parameter scale increases [84].</li>
<li>instruction tuning demonstrates consistent improvements in various model architectures, pre-training objectives, and model adaptation methods [64].</li>
</ul>
<p>并且会获得更好的任务泛化性：</p>
<ul>
<li>A large number of studies have conﬁrmed the effectiveness of instruction tuning to achieve superior performance on both seen and unseen tasks [85, 217].</li>
<li>instruction tuning has been shown to be useful in alleviating several weaknesses of LLMs (e.g., repetitive generation or complementing the input without accomplishing a certain task) [61, 64].</li>
<li>LLMs trained with instruction tuning can generalize to related tasks across languages.</li>
</ul>
<h3 id="alignment-tuning">5.2 Alignment Tuning</h3>
<h3 id="efficient-tuning">5.3 Efficient Tuning</h3>
<h2 id="utilization">6. Utilization</h2>
<p>作者主要简单介绍了两种利用LLM进行下游任务的prompt方法：ICL（in-context learning）和CoT（chain-of-thought）。CoT可看做是ICL的拓展，在ICL的输入中加入了中间推理步骤。下图是ICL和CoT的示意：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230522211632104.png" alt="image-20230522211632104" /><figcaption>image-20230522211632104</figcaption>
</figure>
<h3 id="in-context-learning">6.1 In-Context Learning</h3>
<p>ICL的prompt主要有3部分：task description <span class="math inline">\(I\)</span>, demonstrations <span class="math inline">\(D_k = \{ f(x_1,y_1),\dots,f(x_k,y_k) \}\)</span>和query <span class="math inline">\(x_{k+1}\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230522211913510.png"   style="zoom:50%;" /></p>
<p>如果按照GPT-3中的定义，demonstrations不是必须的（尽管常常可以提升性能），只有任务描述的prompt也可以叫做ICL。</p>
<p>ICL和instruction tuning有很深的联系，只不过instruction tuning需要在有instruction的数据集上进行微调，而ICL只是改变LLM的输入。通过instruction tuning能够有效提升LLM的ICL能力。</p>
<p>在ICL中，怎么样选择合适的demonstrations是很关键的，有下面几种思路可以参考：</p>
<ul>
<li>Heuristic approaches. 有些研究通过利用k-NN算法选择和当前样本相似的demonstrations [<em>Does GPT-3 generate empathetic dialogues? A novel in-context example selection method and automatic evaluation metric for empathetic dialogue generation. COLING 2022</em>]。还有的研究进一步考虑了demonstrations内部的差异性[<em>Complementary explanations for effective in-context learning. 2022</em>]。</li>
<li>LLM-based approaches. 还有的研究使用LLM来选择合适的demonstrations [<em>Learning to retrieve prompts for in-context learning. NAACL 2022</em>]。还有的研究直接使用LLM来生成对应的demonstrations，无需人工干预 [<em>What can transformers learn in-context? A case study of simple function classes. 2022</em>]。</li>
</ul>
<p>另外，demonstration的顺序也可能是一个影响性能的因素。有研究发现LLM有时候会倾向于重复demonstrations最后一个例子的答案 [<em>Calibrate before use: Improving few-shot performance of language models. ICML 2021</em>]。</p>
<p>对ICL背后的原理，作者主要介绍了两个问题：</p>
<ul>
<li>How Pre-Training Affects ICL?
<ul>
<li>在预训练的时候，预训练任务可能会影响ICL。有研究者发现通过设计合适的预训练任务可以让SLM也获得ICL能力 [<em>Metaicl: Learning to learn in context. NAACL 2022</em>]。</li>
<li>ICL还可能和预训练语料的来源有关 [<em>On the effect of pretraining corpora on in-context learning by a largescale language model. NAACL 2022</em>]。有研究者发现ICL出现在预训练语料聚类出现很多不频繁类的情况下 [<em>Data distributional properties drive emergent in-context learning in transformers. 2022</em>]。</li>
</ul></li>
<li>How LLMs Perform ICL?
<ul>
<li>部分研究者将ICL看做是隐式的梯度下降，将demonstrations在前馈过程中对应的计算看做是产生meta-gradient [<em>Transformers learn in-context by gradient descent. 2022</em>]。</li>
<li>还有的人将ICL抽象为算法学习过程。有研究发现LLM在预训练过程中实际上编码了隐式的模型 [<em>What learning algorithm is in-context learning? investigations with linear models. 2022</em>]。</li>
</ul></li>
</ul>
<h3 id="chain-of-thought-prompting">6.2 Chain-of-Thought Prompting</h3>
<p>研究者发现，如果能够利用多个不同的推理路径能够提升LLM推理能力 [<em>On the advance of making language models better reasoners. 2022</em>]。同时，如果涉及更加复杂的推理步骤，似乎能够进一步激发LLM的推理潜力 [<em>Complexity-based prompting for multi-step reasoning. 2022</em>]。</p>
<p>CoT的不同推理路径可能提供了不同的答案，self-consistency方法就是通过集成多个推理路径的答案取得更好的效果 [<em>Self-consistency improves chain of thought reasoning in language models. 2022</em>]。</p>
<p>另一个关键的CoT工作是AuToCoT [<em>Automatic chain of thought prompting in large language models. 2022</em>]，它通过利用Zero-shot-CoT [<em>Large language models are zero-shot reasoners. 2022</em>]来自动选择合适的CoT。</p>
<p>对于CoT，作者也介绍了两个原理性问题：</p>
<ul>
<li>When CoT works for LLMs?
<ul>
<li>CoT能力通常出现在模型参数量大于10B的情况下 [<em>Chain of thought prompting elicits reasoning in large language models. 2022</em>]。</li>
<li>CoT通常是对于一般的ICL无法很好的完成的复杂推理任务能够起到提升作用。对于不需要复杂推理的任务，甚至可能会带来性能下降 [<em>Rationale-augmented ensembles in language. 2022</em>]。</li>
</ul></li>
<li>Why LLMs Can Perform CoT Reasoning?
<ul>
<li>CoT能力的来源常常被广泛认为是在code data上进行了训练（尽管现在缺乏具体的实验验证这一点）。instruction tuning似乎对LLM的CoT能力没有提升。</li>
<li>CoT中，patterns (equations in arithmetic reasoning)和text (the rest of tokens that are not symbols or patterns)是更加关键的要素，消融掉这两个部分都会导致性能的下降，甚至patterns是否正确都没有特别大的影响。</li>
</ul></li>
</ul>
<p>除去上面两点外，作者还简单提及了利用LLM的另一个思路模型定制（model specialization）[<em>Specializing smaller language models towards multistep reasoning. 2023</em>]。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Survey</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM-too-positive-negative-comm-know</title>
    <url>/llm/LLM-too-positive-negative-comm-know/</url>
    <content><![CDATA[<h1 id="say-what-you-mean-large-language-models-speak-too-positively-about-negative-commonsense-knowledge">Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge</h1>
<p>复旦，ACL 2023，<a href="https://github.com/jiangjiechen/uncommongen">代码</a>。</p>
<blockquote>
<p>Large language models (LLMs) have been widely studied for their ability to store and utilize positive knowledge. However, negative knowledge, such as “lions don’t live in the ocean”, is also ubiquitous in the world but rarely mentioned explicitly in the text. <strong>What do LLMs know about negative knowledge? This work examines the ability of LLMs to negative commonsense knowledge.</strong> We design a constrained keywords-to-sentence generation task (CG) and a Boolean question-answering task (QA) to probe LLMs. <strong>Our experiments reveal that LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge, yet they can correctly answer polar yes-or-no questions. We term this phenomenon the belief conflict of LLMs.</strong> Our further analysis shows that statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict.</p>
</blockquote>
<p>作者主要讨论了LLM对于negative commonsense knowledge在判断和生成两个角度有明显差别的问题。LLM擅长判断某个knowledge是否成立，但是在生成对应的negative knowledge cases的时候又常常发生错误。</p>
<span id="more"></span>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905225314340.png"   style="zoom:40%;" /></p>
<h2 id="probing-protocol">Probing Protocol</h2>
<h3 id="the-csk-pn-dataset">The CSK-PN Dataset</h3>
<p>作者基于前人的工作[<em>NegatER: Unsupervised Discovery of Negatives in Commonsense Knowledge Bases.</em>]创建了一个新的探测LLM对于negative commonsense knowledge的数据集CKS-PN，一共有4,000个三元组，其中positive and negative分别相同的数量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905225527781.png"   style="zoom:40%;" /></p>
<h3 id="probing-task-formulation">Probing Task Formulation</h3>
<p>作者设计了两个task去探测：Boolean Question Answering (QA)和Constrained Sentence Generation (CG)。</p>
<p>Boolean Question Answering (QA)：回答yes/no，用来探测LLM对于commonsense knowledge的belief：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905225633688.png"   style="zoom:50%;" /></p>
<p>Constrained Sentence Generation (CG)是一个<em>keyword-to-sentence task</em>，给定原始的三元组，模型需要生成一个完整的句子，自己判断是否在句子中添加negation cues，如not，unable等：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905225658875.png"  style="zoom:50%;" /></p>
<p>最后在探测的时候，作者使用了<span class="math inline">\(k\)</span>-shot上下文学习。作者自己编写了<span class="math inline">\(32\)</span>个正负样例examples，然后随机选择从正负样例中选择，初始默认正负样例各占一半。</p>
<h3 id="evaluation-metrics">Evaluation Metrics</h3>
<p>三种指标：</p>
<ul>
<li>TP：accuracy on the positive cases</li>
<li>TN：accuracy on the negative cases</li>
<li>Acc：accuracy on the whole dataset</li>
</ul>
<h2 id="do-llms-have-negative-commonsense-knowledge">Do LLMs have negative commonsense knowledge?</h2>
<h3 id="the-belief-conflict">The Belief Conflict</h3>
<p>先看总体结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905230246234.png"   style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li><strong>belief conflict</strong> manifests itself in two ways: the gap between TP and TN on the CG task, and the gap of TN between the QA and CG tasks</li>
<li>对于QA task，大多数LLM的TP和TN指标差距不大；但是对于CG task，大多数LLM的TP要远好于TN</li>
<li>InstructGPT-003和ChatGPT表现比较好，作者推测是因为在RLHF过程中，human feedback常常包含一些negative knowledge和rebuttal statements，比如admitting errors or instructing the model not to do something</li>
</ul>
<h3 id="sensitivity-to-the-number-of-in-context-examples">Sensitivity to the Number of In-Context Examples</h3>
<p>增大上下文样例数量，保持正负样例比例不变：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905230638557.png"  style="zoom:30%;" /></p>
<p>增大上下文样例数量对CG任务影响更大。</p>
<h2 id="analysis-on-the-belief-conflict">Analysis on the Belief Conflict</h2>
<h3 id="could-keywords-as-task-input-hinder-the-manifestation-of-llms-belief">Could keywords as task input hinder the manifestation of LLMs’ belief?</h3>
<p>作者首先检测是否是CG任务的使用keywords作为输入的prompting方式影响了negative knowledge的生成，因此作者设计了额外的两种task：</p>
<ul>
<li><p>keywords-to-answer task</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905230853242.png"   style="zoom:50%;" /></p></li>
<li><p>question-to-sentence task</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905230930041.png"   style="zoom:50%;" /></p></li>
</ul>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905231003210.png"   style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>Figure a证明了使用keywords作为输入，LLM仍然能够在QA任务中判断出negative knowledge是否成立；这说明keywords作为输入不会太影响对于knowledge的belief</li>
<li>Figure b证明了如果把keywords换为一个完整的question，TP和TN的指标差异消失了。作者推测尽管回答的还是个完整的sentence，但是由于在预训练语料中有很多的negated texts following a Boolean question，比如&quot;...? No, lions do not live in the ocean.&quot;这种格式的句子。LLM对于这种问题question已经将其退化为了一个回答yes/no的判别问题了。为了验证这一点判断，作者移除了上下文的样例，直接让LLM回答，然后发现此时80%以上的回答都以Yes/No开头，然后再生成sentence。</li>
<li>上面这点的发现，让人怀疑commonsense knowledge在LLM的encoding方式，它是否仅仅擅长类比在语料中见过的表达，而很难泛化为其它的表达？LLM是否真正的理解了knowledge？According to this experiment, commonsense knowledge seems to be stored in LLMs in the same manner as it is in the corpus. LLMs struggle to generalize them, as evidenced by the keyword inputs for negative knowledge that do not have a statistical shortcut from pre-training.</li>
</ul>
<h3 id="will-the-keyword-co-occurrence-within-corpus-affect-llms-generation">Will the keyword co-occurrence within corpus affect LLMs’ generation?</h3>
<p>作者探究这种negative knowledge和positive knowledge之间的差异，是否和预训练语料中实体之间的共现频率相关。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905232121301.png"  style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>We conclude that the hard-to-generate negative knowledge for LLMs tend to be those in which they have seen many subjects and objects appear together. 越倾向于一起出现的头尾entity，LLM越倾向于产生positive的描述，越难以正确的描述negative knowledge</li>
</ul>
<h3 id="how-does-the-balance-of-positive-and-negative-examples-affect-negation-bias">How does the balance of positive and negative examples affect negation bias?</h3>
<p>作者发现通过增加上下文中负样例的数量/占比，可以一定程度缓解难以正确产生negative cases的问题：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905232258148.png"   style="zoom:30%;" /></p>
<h3 id="do-chain-of-thought-help-generate-texts-with-negative-commonsense-knowledge">Do Chain-of-Thought help generate texts with negative commonsense knowledge?</h3>
<p>作者讨论了是否能够通过CoT来缓解对negative knowledge的生成问题：</p>
<ul>
<li>Deductive Reasoning Prompting：演绎推理，prompting中的上下文样例被修改为<code>&lt;input, “Let’s think step by step: ...”, output&gt;</code>的格式。
<ul>
<li>对于positive propositions，采用<em>modus ponens logic</em>，<code>if P then Q. P. Therefore, Q.</code>，举例：<em>Things with lightweight bodies and strong wing muscles (P) can usually fly (Q). Birds have these physical characteristics (P). Therefore, birds can fly. (Q)</em>。</li>
<li>对于negative propositions，采用modus tollens，<code>If P then Q. Not Q. Therefore, Not P.</code>，举例：<em>If something is a intelligent being (P), then it must have the ability to think (Q). Computers cannot think (Not Q). Therefore, computers are not intelligent beings (Not P).</em></li>
</ul></li>
<li>Fact Comparison Prompting：和已有的related fact保持一致，prompting中的上下文样例被修改为<code>&lt;input, “Related fact: ...”, output&gt;</code>，举例：对于<em>lions do not live in the ocean</em>的Related fact举例是<em>lions live in the land</em>。</li>
</ul>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905232801375.png"   style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>加入中间的推理步骤能够缓解对negative knowledge的生成问题</li>
<li>演绎推理Deductive Reasoning的方法比Fact Comparison的方法在TP上效果下降；作者认为这是因为演绎推理会倾向于关心特殊情况，而在判断commonsense的时候比较保守。commonsense knowledge不是在所有情况下都成立的，它只是common情况下成立，就比如常识上鸟都会飞；但是企鹅是鸟，然后企鹅不会飞。这种特点导致演绎推理常常认为一般的knowledge不成立，降低了TP指标。这一点应该是commonsense和fact knowledge的区别之一</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Capacity</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Capacity</tag>
      </tags>
  </entry>
  <entry>
    <title>LM-as-KB-Survey</title>
    <url>/llm/LM-as-KB-Survey/</url>
    <content><![CDATA[<h1 id="a-review-on-language-models-as-knowledge-bases">A Review on Language Models as Knowledge Bases</h1>
<p>arxiv 2022，Meta AI的一篇关于把预训练语言模型看做是知识库KB的综述。</p>
<blockquote>
<p>Recently, there has been a surge of interest in the NLP community on the use of pretrained Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs trained on a sufﬁciently large (web) corpus will encode a signiﬁcant amount of knowledge implicitly in its parameters. The resulting LM can be probed for different kinds of knowledge and thus acting as a KB. This has a major advantage over traditional KBs in that this method requires no human supervision. In this paper, we present a set of aspects that we deem an LM should have to fully act as a KB, and review the recent literature with respect to those aspects.1</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>在大规模语料上训练得到的语言模型LM已经展现出了拥有以下几种知识：</p>
<ul>
<li>world knowledge</li>
<li>relational knowledge</li>
<li>commonsense knowledge</li>
<li>linguistic knowledge</li>
<li>actionable knowledge</li>
</ul>
<p>但是LM的知识是隐式的，导致它的知识可访问性和可解释性都比较差。和之相对的，知识库knowledge base使用显式的符号知识表达现实世界，它的知识访问、更新和可解释性都更强。因此，研究者开始探究怎么样能够像KB一样控制LM中学习到的知识呢？该问题在论文《Language Models as Knowledge Bases? 》（EMNLP 2019）中首次提出。</p>
<p>这篇survey从LM-as-KBs的6个角度进行了综述：Access, Edit, Consistency, Reasoning, and Explainability and Interpretability。</p>
<h2 id="accessing-knowledge">2. Accessing Knowledge</h2>
<p>KB可以使用查询语言或者查询工具很简单的找到对应的knowledge，但是对于LM来说要找到对应的knowledge更难。有两种主要的方式访问LM中的知识：finetuning和prompting。</p>
<h3 id="finetuning">2.1 Finetuning</h3>
<p>在下游任务上直接微调预训练模型的参数，当然是最直接使用预训练隐式知识的方法。有研究者发现，大多数的知识还是在预训练过程中学习到的，而finetuning仅仅是学习到了一个访问该知识的接口（<em>Analyzing commonsense emergence in few-shot knowledge models. 21</em>）。</p>
<h3 id="prompting">2.2 Prompting</h3>
<p>prompting是一种让任务来适应模型的方法，不需要改变LM的模型参数，只需要找到合适的任务提示。作者把prompting分为discrete prompt和soft prompt两种。</p>
<p>discrete prompting是指直接使用自然语言/token进行描述；</p>
<p>soft prompting是指使用词向量进行提示；有研究者发现soft prompts的表达能力比discrete prompting更强（<em>Learning how to ask: Querying lms with mixtures of soft prompts. 21</em>）。<em>之前没有仔细了解过prompting，此结论不确定是否正确</em>。</p>
<h2 id="consistency">3. Consistency</h2>
<p>一致性是LM作为KB要面临的重要挑战之一。在下面三个情况下都需要考虑一致性：</p>
<h3 id="paraphrase">3.1 Paraphrase</h3>
<p>改写paraphrase，相同的意思使用不同句子/词去表达。LM对于不同paraphrase prompt的输出结果应该是一致的。</p>
<blockquote>
<p>Bhagat and Hovy (2013) [<em>What Is a Paraphrase? 13</em>] deﬁne the term quasi-paraphrases as ‘sentences or phrases that convey approximately the same meaning using different words’.</p>
</blockquote>
<h3 id="commonsense">3.2 Commonsense</h3>
<p>LM的另一个一致性体现在对于学习到的知识的一致性。研究者发现LM可能对于negation词（如not）是不鲁棒的。比如一个LM能够同时学习到“Birds can fly”和“Birds cannot fly”两个矛盾知识（<em>Negated and misprimed probes for pretrained language models: Birds can talk, but cannot ﬂy. 20</em>）。</p>
<p>LM对于蕴含entailment知识也应该是一致的（个人理解，entailment就是指当我们提到了一个知识成立的时候，它内部包括的知识也应该都成立），比如蛇是脊椎动物“A viper is a vertebrate”蕴含了另一个知识蛇有大脑“A viper has a brain”。（<em>Do Language Models Have Beliefs? Methods for Detecting, Updating, and Visualizing Model Beliefs. 21</em>）</p>
<h3 id="multilingual">3.3 Multilingual</h3>
<p>LM对于不同语言描述的同一个查询，应该给出相同的输出。</p>
<h2 id="model-editing">4. Model Editing</h2>
<p>知识库中的知识很简单的就可以被修改和更新，但是LM学习到的知识要更新/编辑就比较困难了。De Cao等人提出一个editing方法应该满足以下三点：</p>
<ul>
<li>Generality：editing方法不应该局限在某个具体的LM模型</li>
<li>Reliability：editing方法应该只影响要修改的知识，不能影响其它的知识。</li>
<li>Consistency：editing方法修改之后，应该保证对于各种语义相同的输入给出相同的输出，也就是要保证前面说的一致性要求。这就要求editing方法既要修改不正确的隐式知识，和修改的事实关联的所有事实也需要被修改，同时其它的事实保持不变。</li>
</ul>
<p>现在的editing方法主要有三类：</p>
<ul>
<li>finetuning：最粗暴的方法是直接让模型针对新的知识进行从头学习，但这由于LM的训练成本基本上是不现实的。另外一种方法是构造一个支持新知识的evidence collection，让模型进行学习。但是这种持续学习的方法，要特别注意灾难性遗忘的问题，也就是会迅速忘记之前的旧知识（由于所有的参数都要更新，也不知道哪个参数需要修改，修改幅度有多大）。</li>
<li>hyper networks：另一种方法是通过训练一个外部网络，让它输出要修改知识所需要的weight shift，从而能够编辑知识（<em>Editing Factual Knowledge in Language Models. 21</em>）。</li>
<li>direct editing：Meng等人提出可以直接把Transformer block看做是key-value对，通过追踪相关的weight，直接修改对应的weight即可（<em>Locating and editing factual knowledge in gpt. 22</em>）。</li>
</ul>
<h2 id="reasoning">5. Reasoning</h2>
<p>LM模型已经表现出了一定的推理能力，比如常识推理、自然语言推理、数学推理、归纳推理等等。并且如果输入些推理过程的提示，LM模型也可以模仿着给出推理过程。</p>
<p>但是LM到底有没有推理能力，还没有定论（<em>Chain of thought prompting elicits reasoning in large language models. 22</em>）。</p>
<h2 id="interpretability">6. Interpretability</h2>
<p>作者区分了两个“可解释”：</p>
<ul>
<li>interpretability指对模型内部机理的探究；</li>
<li>explainability指模型的输出是否可解释，比如让模型自己给出输出答案的原因，属于事后解释。</li>
</ul>
<p>可解释性可能是影响大规模语言模型真正落地到实际应用中最大的问题了。研究者从不同的角度进行了探究，但是个人认为目前的进展还不能充分解释LM内部机理。</p>
<ul>
<li>Probing：研究者将LM内部的表示和外部属性进行关联，从而辅助理解LM到底学习到了什么信息。</li>
<li>Attention：自注意力是Transformer中的重要组成，研究者对attention进行了许多探究，包括不同层attention学习到的模式有什么区别、同一层不同attention head学习到的模式有什么区别、attention在不同情况下会更加关注什么样的token输入等等。</li>
<li>Mechanistic Interpretability：Elhage等人提出了一个解释Transformer的数学视角（<em>A mathematical framework for transformer circuits. 21</em>）。</li>
<li>Causal tracing：Meng等人尝试追踪模型输出和参数之间的路径关联（<em>Locating and editing factual knowledge in gpt. 22</em>）。</li>
</ul>
<h2 id="explainability">7. Explainability</h2>
<p>作者提到，有人使用influence function来尝试提高输出的可解释性，对此方法不了解（<em>Explaining black box predictions and unveiling data artifacts through inﬂuence functions. 20</em>）。</p>
<p>注意力本身的结果也常常被用来提供可解释输出。有研究者认为attention可以提供必要的explainability，但是有研究者认为attention不能够提供真正的explainability（<em>Is attention interpretable? 19</em>，<em>Attention is not Explanation 19</em>）。另外有研究者认为这个和具体模型相关（<em>Attention is not not explanation. 19</em>）。 所以attention能否被用来作为输出解释的一部分，目前在学术界还有争议。</p>
<p>另外一种方式是直接让LM给出它们做决策的解释，比如可以让它指出输入文本中支持输出的fragment（<em>Probing across time: What does roberta know and when? 16</em>）。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>Survey</tag>
        <tag>Language Model</tag>
      </tags>
  </entry>
  <entry>
    <title>Opportunities-and-Risks-of-Foundation-models</title>
    <url>/llm/Opportunities-and-Risks-of-Foundation-models/</url>
    <content><![CDATA[<h1 id="on-the-opportunities-and-risks-of-foundation-models">On the Opportunities and Risks of Foundation Models</h1>
<p>2021 斯坦福大学 arxiv</p>
<p>在这篇论文里，斯坦福大学的研究者提出了一个概念“foundation models”用来指代在大规模数据上进行训练，可以用于大范围应用的模型。</p>
<p>下面仅仅是基础概念和发展的笔记，具体请参考论文。</p>
<blockquote>
<p>AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that <strong>are trained on broad data at scale and are adaptable to a wide range of downstream tasks</strong>. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles (e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities, and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.</p>
</blockquote>
<span id="more"></span>
<p>论文中定义的foundation model：</p>
<blockquote>
<p>A foundation model is any model that is trained on broad data at scale and can be adapted (e.g., fine-tuned) to a wide range of downstream tasks; current examples include BERT [Devlin et al. 2019], GPT-3 [Brown et al. 2020], and CLIP [Radford et al. 2021].</p>
</blockquote>
<p>foundation的命名（没有使用大语言模型、预训练模型等名字）主要是想强调模型的影响范围，并且想强调这些model不是能够直接进行各种下游任务，而是需要adaptation（fine-tuning、prompt、 architecture reusing、 embedding reusing等等）。这些模型的一点点改进，几乎可以推进所有NLP领域的进展，甚至是跨研究社区的领域进展，对于社会的法律和道德等方面也有影响，作者在论文称之为“强杠杆作用”（high leverage）。foundation模型的好的方面和坏的方面会被所有采用它的下游任务方法所集成，同时它还具有可解释性弱、可能产生不可预计的错误预测场景等问题。</p>
<p>作者提出，foundation models的出现使得AI的发展进入了新的阶段：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230208111627037.png" alt="image-20230208111627037" /><figcaption>image-20230208111627037</figcaption>
</figure>
<ul>
<li>machine learning：20世纪90年代开始到2015年，机器学习的算法/模型可以在不同应用通用，但是特征的导出依赖于领域专家的特征工程。机器学习取代了之前的专家知识库等概念，开始引领AI的发展。</li>
<li>deep learning：2015年左右，Yann LeCun提倡的深度学习“deep learning”[Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep Learning. Nature 521, 7553 (2015).] 让模型架构能够在不同应用通用，用来实现自动特征导出，极大的降低了对领域专家特征工程的需求。只需要很少的数据预处理，深度学习模型就可以自动学习high level的feature。</li>
<li>foundation model：2019年开始，随着BERT，GPT-2，T5等模型的出现，证明了模型在大规模数据集上进行训练，可以通过很小的改变适应到一系列和预训练任务独立的下游任务。不仅仅是deep learning模型的架构通用，而是model本身（参数、输出等）就可以在不同任务中通用。同时，跨研究社区、跨模态等应用也开始出现。</li>
</ul>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230208112855998.png" alt="image-20230208112855998" /><figcaption>image-20230208112855998</figcaption>
</figure>
<p>foundation models的出现依赖于模型结构（Transformer）、大规模在线数据的产生和收集、计算资源的指数级增加、训练方法（自监督学习）等多方面的进展。foundation model体现出的另一个不一样的点是，会直接面向社会公开/部署，让各个领域研究者/公司/个人/政府都可以尝试，因而对社会也产生了影响（环境/偏见/歧视/不可解释等）。</p>
<p>后面更多的论文内容没有记录，前面对于foundation model的探讨讲的不错。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Self-Instruct</title>
    <url>/llm/Self-Instruct/</url>
    <content><![CDATA[<h1 id="self-instruct-aligning-language-models-with-self-generated-instructions">SELF-INSTRUCT: Aligning Language Models with Self-Generated Instructions</h1>
<p>使用LLM自动从已有的task instructions生成一系列新的task instructions进行instruction</p>
<p>-tuning。ACL 2023，华盛顿大学，<a href="https://github.com/%20yizhongw/self-instruct">代码</a>。</p>
<blockquote>
<p>Large “instruction-tuned” language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. <strong>Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity,</strong> therefore hindering the generality of the tuned model. We introduce SELF-INSTRUCT, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on SUPER-NATURALINSTRUCTIONS, on par with the performance of InstructGPT 001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT 001 . SELF-INSTRUCT provides an almost annotation-free method for aligning pretrained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>人工生成instructions一方面代价很大，另一方面人工生成的instructions难以保证quantity, diversity, and creativity。</p>
<p>作者提出使用LLM从已有的task instruction出发，自动生成新的task instruction和对应的input-output，然后过滤掉不符合规则的新task instructions，再加入到已有的task instructions集合中。作者在这个自动构造的instruction data上fine-tuning GPT3，发现效果提升了33%，非常接近InstructGPT001的效果。</p>
<h2 id="method">2. Method</h2>
<p>作者提出的方法：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150047353.png" alt="image-20230603150047353" /><figcaption>image-20230603150047353</figcaption>
</figure>
<p>首先，作者拥有一个task pool，包括175 tasks (1 instruction and 1 instance for each task)。这175个初始的task instructions都是由本文作者自己创建的。</p>
<p>然后，作者从task pool中随机抽取8个task instructions（6 are from the human-written tasks, and 2 are from the model-generated tasks）。下面是产生新task instruction的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150335100.png" style="zoom:50%;" /></p>
<p>之后，作者使用LLM判断新产生的instruction是否是一个classification task（using 12 classification instructions and 19 non-classification instructions）：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150505630.png" alt="image-20230603150505630" /><figcaption>image-20230603150505630</figcaption>
</figure>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150518579.png" alt="image-20230603150518579" /><figcaption>image-20230603150518579</figcaption>
</figure>
<p>随后，对于新产生的task instruction，用LLM生成新的对应的instance。对于生成任务，作者先生成input，再生成output，作者称为Input-first Approach：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150903068.png" alt="image-20230603150903068" /><figcaption>image-20230603150903068</figcaption>
</figure>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603150941339.png" alt="image-20230603150941339" /><figcaption>image-20230603150941339</figcaption>
</figure>
<p>对于分类任务，作者发现如果是先生成input，LLM总是会倾向于生成某一个label的输入。因此作者使用LLM先生成output label，再让LLM生成input，作者称为Output-first Approach：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151018452.png" alt="image-20230603151018452" /><figcaption>image-20230603151018452</figcaption>
</figure>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151030519.png" alt="image-20230603151030519" /><figcaption>image-20230603151030519</figcaption>
</figure>
<p>对于LLM生成的task instruction、input和output，需要通过一些规则过滤，比如：</p>
<ul>
<li>只有当和已有的task instruction相似度全部比较低（<span class="math inline">\(\mbox{ROUGE-L}&lt; 0.7\)</span>）的时候，一个新task instruction会被添加到task pool里</li>
<li>We also exclude instructions that contain some specific keywords (e.g., image, picture, graph) that usually can not be processed by LMs.</li>
<li>When generating new instances for each instruction, we filter out instances that are exactly the same or those with the same input but different outputs.</li>
<li>Invalid generations are identified and filtered out based on heuristics (e.g., instruction is too long or too short, instance output is a repetition of the input).</li>
</ul>
<h2 id="experiment">3. Experiment</h2>
<p>作者从原始的175个task出发，最后构造了5万多的task，并且差异性也比较大：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603151912820.png"   style="zoom:40%;" /></p>
<p>不同task instructions的相似度和各种分布统计：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603152004847.png"   style="zoom:40%;" /></p>
<p>为了进一步确认自动生成的数据的质量，作者随机选择了200个生成的task instruction和对应的1个input-output让作者之一进行人工评估：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603152211702.png"   style="zoom:40%;" /></p>
<p>可以看出来，自动生成的数据尽管有噪音，还是可以用的，特别是生成的task instructions基本上是现实中成立的说得通的任务。并且那些有错误的样例大多格式是正确的，或者有部分是正确的。</p>
<p>在SuperNI数据集上的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603152723289.png"   style="zoom:40%;" /></p>
<p>SuperNI数据集大多是已有的NLP任务，为了进一步评估模型在实际使用场景下的价值，作者人工创建了一个包括252 task的新数据集。</p>
<blockquote>
<p>We first brainstorm various domains where large LMs may be useful (e.g., email writing, social media, productivity tools, entertainment, programming), then craft instructions related to each domain along with an input-output instance.</p>
</blockquote>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603153203667.png" alt="image-20230603153203667" /><figcaption>image-20230603153203667</figcaption>
</figure>
<p>从效果上来看，作者加入self-instruct效果确实好于vanilla GPT-3（davinci），效果接近InstructGPT001（text-davinci-001）。</p>
<p>最后，作者评估了不断加入instructions进行fine-tuning的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230603154016697.png"   style="zoom:40%;" /></p>
<p>图上红色的点是很有趣的，那个红色的结果是作者使用text-davinci-003重新针对每个生成的task instructions重新生成input-output的结果，说明了持续提高instruction-tuning数据质量的效果。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Instruct-tuning</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Instruct-tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>Trustworthy-LLM-survey-bytedance</title>
    <url>/llm/Trustworthy-LLM-survey-bytedance/</url>
    <content><![CDATA[<h1 id="trustworthy-llms-a-survey-and-guideline-for-evaluating-large-language-models-alignment">Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment</h1>
<p>2023-08 字节的关于可信LLM的survey。</p>
<blockquote>
<p>Ensuring alignment, which refers to making models behave in accordance with human intentions [1, 2], has become a critical task before deploying large language models (LLMs) in real-world applications. For instance, OpenAI devoted six months to iteratively aligning GPT-4 before its release [3]. However, a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms, values, and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue, this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. <strong>The survey covers seven major categories of LLM trustworthiness: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness.</strong> Each major category is further divided into several sub-categories, resulting in a total of 29 sub-categories. Additionally, a subset of 8 sub-categories is selected for further investigation, where corresponding measurement studies are designed and conducted on several widely-used LLMs. The measurement results indicate that, in general, more aligned models tend to perform better in terms of overall trustworthiness. However, the effectiveness of alignment varies across the different trustworthiness categories considered. This highlights the importance of conducting more fine-grained analyses, testing, and making continuous improvements on LLM alignment. By shedding light on these key dimensions of LLM trustworthiness, this paper aims to provide valuable insights and guidance to practitioners in the field. Understanding and addressing these concerns will be crucial in achieving reliable and ethically sound deployment of LLMs in various applications.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>LLM已经引起了学界和企业界的深刻变革。ChatGPT是目前历史上用户数量增长速度最快的应用，超过了TikTok和instagram。</p>
<p>妨碍LLM进一步得到应用的关键是LLM可能产生不可信的输出，比如有毒的、歧视性的、虚假的、不符合人类道德观的输出。</p>
<p>LLM无法保证生成可信的结果的最重要的原因可能是预训练数据本身就包含了大量的噪音。大多数LLM的数据都要依赖从Internet上爬取，无论如何这些大规模的数据中会包含各种和人类主流价值观不符的数据。同时，在预训练过程中，并没有针对这些有害数据进行额外的设计。</p>
<p>通过想办法让LLM和人类价值对齐，可以促使LLM的输出更加reliable, safe, and attuned to human values：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230822162550709.png"  style="zoom:30%;" /></p>
<p>之前的研究工作提出了一个针对LLM对齐任务的3H原则：Helpful, Honest, and Harmless [<em>A general language assistant as a laboratory for alignment.</em>]。</p>
<p>目前主流的将LLM对齐的技术：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230822162756249.png"   style="zoom:40%;" /></p>
<p>两个关键方法是SFT (supervised fine-tune)和RLHF (reinforcement learning from human feedback)。SFT首先用来训练经过预训练的原始LLM，让其在一定程度上能够和人类价值观对齐。之后训练过的LLM对于同一问题产生不同的输出，让人类去排序，训练一个reward model。最后就是利用RLHF结合LLM和reward model进行迭代的更新。</p>
<p>当然，目前也有很多研究讨论RLHF算法是否合适。</p>
<p>除去LLM对齐技术本身外，用来对齐的数据可能需要重点关注。比如在Anthropic发布的对齐数据中，各种有害情况的分布是不平衡的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230822163345545.png"   style="zoom:20%;" /></p>
<p>作者在这篇论文了提出了关于可信LLM的7个方面，包括29个小方面：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230822165425971.png" alt="image-20230822165425971" /><figcaption>image-20230822165425971</figcaption>
</figure>
<p>划分的依据主要是根据不同方面所关系的问题和目标：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230822165445056.png" alt="image-20230822165445056" /><figcaption>image-20230822165445056</figcaption>
</figure>
<h2 id="reliability">2. Reliability</h2>
<p>可靠性作者进一步细分了5个方面，misinformation、hallucination、inconsistency、miscalibration、sycophancy。</p>
<h3 id="misinformation">2.1 Misinformation</h3>
<p>作者认为的misinformation是非用户本意的，由LLM生成的错误信息。</p>
<blockquote>
<p>We define misinformation here as wrong information not intentionally generated by malicious users to cause harm, but unintentionally generated by LLMs because they lack the ability to provide factually correct information.</p>
</blockquote>
<p>下图是ChatGPT生成错误事实的例子：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823161352142.png" alt="image-20230823161352142" /><figcaption>image-20230823161352142</figcaption>
</figure>
<p>错误信息产生的几个可能原因：</p>
<ul>
<li><p>训练数据（特别是从网络上爬取的数据）就存在错误事实。这些错误事实被LLM记录。</p></li>
<li><p>Elazar et al. 发现常常共同出现的实体对，可能会导致LLM产生错误的输出。[<em>Measuring causal effects of data statistics on language model’sfactual’predictions.</em>]</p>
<blockquote>
<p>Elazar et al. [55] find that a large number of co-occurrences of entities (e.g. , Obama and Chicago) is one reason for incorrect knowledge (e.g. Obama was born in Chicago) extracted from LLMs</p>
</blockquote></li>
<li><p>LLM对于不常见的知识可能更会生成错误信息，有研究人员认为不对不常见的事实应该从其它类型的非参数化外部知识库中获取。[<em>When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories.</em>]</p>
<blockquote>
<p>Mallen et al. [56] discover that LLMs are less precise in memorizing the facts that include unpopular entities and relations. They propose to leverage retrieved external non-parametric knowledge for predictions regarding unpopular facts as retrieval models.</p>
</blockquote></li>
<li><p>有研究人员发现，当在prompt中提供了新的信息时，不是所有的LLM都能够利用prompt中的新信息更新自己的答案。[<em>Prompting gpt-3 to be reliable</em>]</p>
<blockquote>
<p>Si et al. [58] evaluate whether LLMs can update their memorized facts by information provided in prompts. They find that, while code-davinci-002 can update its knowledge around 85% of the time for two knowledge-intensive QA datasets, other models including T5 [59] and text-davinci-001 have much lower capability to update their knowledge to ensure factualness.</p>
</blockquote></li>
</ul>
<h3 id="hallucination">2.2 Hallucination</h3>
<p>幻觉（Hallucination）属于misinformation的一种，但是有自己独特的特点。misinformation可能是由于输入的信息错误引起的。而hallucination是指生成完全虚构的答案，并且通常还非常自信。</p>
<blockquote>
<p>LLMs can generate content that is nonsensical or unfaithful to the provided source content with appeared great confidence, known as hallucinations in LLMs.</p>
</blockquote>
<p>Hallucination对应在心理学上的概念叫做虚构（confabulation），是指非故意的虚假记忆。</p>
<p>作者提出有两类的幻觉：</p>
<ul>
<li><p>intrinsic hallucination: hallucination may consist of fabricated contents that conflict with the source content. 和用户输入的信息矛盾，LLM内部就存在的虚构事实。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823162053377.png" alt="image-20230823162053377" /><figcaption>image-20230823162053377</figcaption>
</figure></li>
<li><p>extrinsic hallucination: hallucination may consist of fabricated contents cannot be verified from the existing sources. 对于用户输入的虚构事实，进一步进行虚构。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823162133936.png" alt="image-20230823162133936" /><figcaption>image-20230823162133936</figcaption>
</figure></li>
</ul>
<p>产生幻觉的可能原因：</p>
<ul>
<li>训练数据和测试数据之间的偏移</li>
<li>LLM相关技术，比如生成next token的随机性、在编码和解码阶段的错误、不平衡分布的training bias</li>
</ul>
<p>探测幻觉的几种手段：</p>
<ul>
<li>常用的评测任务是text summarization，比较LLM输出和reference text之间的差异</li>
<li>QA任务，比如TruthfulQA数据</li>
<li>训练能够评估truthfulness的分类器来评估LLM的输出</li>
<li>人工</li>
</ul>
<p>目前消除幻觉的方法还比较少：</p>
<ul>
<li>数据清洗，提高训练数据质量</li>
<li>The other aspect is using different rewards in RLHF. 通过改进RLHF的奖励过程，让LLM的输出更加和输入相符，而不是自己虚构事实。</li>
</ul>
<h3 id="inconsistency">2.3 Inconsistency</h3>
<p>对于相同的/实质上一样的问题，有不同的回答，特别是考虑到对于本质上没有区别的提问方式，仅仅是简单的改变提问格式，就会输出正确/错误的回答。</p>
<blockquote>
<p>It is shown that the models could fail to provide the same and consistent answers to different users, to the same user but in different sessions, and even in chats within the sessions of the same conversation.</p>
</blockquote>
<p>示例：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823163522465.png" alt="image-20230823163522465" /><figcaption>image-20230823163522465</figcaption>
</figure>
<p>不一致性的原因还不清楚：</p>
<ul>
<li>和LLM本身的随机性有关（randomness in sampling tokens, model updates, hidden operations within the platform, or hardware specs）</li>
<li>预训练数据中存在的令人疑惑的和互相矛盾的事实可能是一个原因。The confusing and conflicting information in training data can certainly be one cause.</li>
</ul>
<p>可能改善不一致性的技术：</p>
<ul>
<li>consistency loss [<em>Measuring and improving consistency in pretrained language models.</em>]。[91] regulates the model training using a consistency loss defined by the model’s outputs across different input representations.</li>
<li>Another technique of enforcing the LLMs to self-improve consistency is via “chain-of-thought&quot; (COT) [29], which encourages the LLM to offer step-by-step explanations for its final answer.</li>
</ul>
<h3 id="miscalibration">2.4 Miscalibration</h3>
<p>LLM对于输出的过度自信。</p>
<blockquote>
<p>LLMs have been identified to exhibit over-confidence in topics where objective answers are lacking, as well as in areas where their inherent limitations should caution against LLMs’ uncertainty (e.g. not as accurate as experts)</p>
</blockquote>
<p>过度自信的原因：</p>
<ul>
<li>训练数据中存在很极端的观点，可能会导致LLM过度自信。This problem of overconfidence partially stems from the nature of the training data, which often encapsulates polarized opinions inherent in Internet data [95].</li>
</ul>
<p>示例：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823164215662.png" alt="image-20230823164215662" /><figcaption>image-20230823164215662</figcaption>
</figure>
<p>有两种方法获取LLM的自信/不确定性。一个是直接让LLM输出confidence；一个是获取LLM的下一个token的logits，这要求LLM提供了获取logits的渠道。这两种方法获得的confidence之间是可能存在差异的。</p>
<p>下面是让LLM直接输出confidence的例子：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823164648913.png" alt="image-20230823164648913" /><figcaption>image-20230823164648913</figcaption>
</figure>
<p>目前缓解LLM过度自信的研究相对多一点：</p>
<ul>
<li>Mielke et al. [96] proposed a calibration method for “chit-chat&quot; models, encouraging these models to express lower confidence when they provide incorrect responses.</li>
<li>Guo et al. [97] offered a method for rescaling the softmax output in standard neural networks to counter overconfidence.</li>
<li>LLM的对齐阶段可能会导致over-confidence。有研究提出让模型能够学会进行不确定性的表达，如“Answers contain uncertainty. Option A is preferred 80% of the time, and B 20%.&quot;。但是这需要人工能够构造出更加smooth的训练数据。</li>
<li>另一类方法是让LLM尝试回避回答不确定的问题，如让LLM生成答案：“I do not know the answer&quot; or “As an AI model, I am not able to answer&quot;。</li>
</ul>
<h3 id="sycophancy">2.5 Sycophancy</h3>
<p>阿谀奉承，拍马屁（Sycophancy）指LLM会承认用户输入的错误信息。</p>
<blockquote>
<p>LLM might tend to flatter users by reconfirming their misconceptions and stated beliefs [24, 122, 123]. This is a particularly evident phenomenon when users challenge the model’s outputs or repeatedly force the model to comply.</p>
</blockquote>
<p>示例：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823165632655.png" alt="image-20230823165632655" /><figcaption>image-20230823165632655</figcaption>
</figure>
<p>Sycophancy和前面的inconsistency是不一样的，Sycophancy是指强迫LLM承认/顺从用户的错误指令。而inconsistency通常是由于LLM内部存在缺陷，无法对于同样的问题给出一致的回答。</p>
<p>Sycophancy出现的可能原因：</p>
<ul>
<li>It is possibly due to existing sycophantic comments and statements in the training data.</li>
<li>It can also be attributed to sometimes excessive instructions for the LLM to be helpful and not offend human users.</li>
<li>It is possible that the RLHF stage could promote and enforce confirmation with human users.</li>
</ul>
<p>因此，在对齐阶段，可能要在LLM顺从人类指令和坚持自身的回答之间做权衡。过于服从人类指令会导致LLM拍马屁；过于不服从人类指令，那么LLM的存在意义都没有了。</p>
<h2 id="explainability-and-reasoning">6. Explainability and Reasoning</h2>
<p>对某些高风险场景来说，能够解释输出背后的原因，是必要且核心的。比如在金融、教育、健康等领域。</p>
<h3 id="lack-of-interpretability">6.1 Lack of Interpretability</h3>
<p>对于ML的可解释性已经受到了很多的关注，比如下面的几种提供解释的方法：</p>
<ul>
<li>removal-based explanations</li>
<li>counterfactual explanations</li>
<li>concept-based explanations</li>
<li>saliency maps</li>
</ul>
<p>而针对LLM的可解释，存在了集中新的思路：</p>
<ul>
<li>retrieval-augmented models。通过提供LLM进行归纳信息来源，让用户选择是否相信LLM的输出结果。比如用在web browser、search engine等场景中。</li>
<li>Bills et al.提出可以使用LLM来解释LLM [<em>Language models can explain neurons in language models.</em>]。</li>
<li>让LLM提供结果的解释，也就是提供自己的thought step。chain-of-thought (CoT)方法。这可能是目前讨论的让LLM提供结果的解释最多的研究，下面的两个部分都是在讨论CoT [<em>Chain of thought prompting elicits reasoning in large language models.</em>]。</li>
</ul>
<h3 id="limited-general-reasoning">6.2 Limited General Reasoning</h3>
<p>一般的逻辑推理能力。</p>
<blockquote>
<p>Reasoning is an essential skill for various NLP tasks including question answering, natural language inference (NLI), and commonsense reasoning.</p>
</blockquote>
<p>让LLM自己生成解释，是属于LLM出现后的全新研究领域。在很多任务中，利用prompt让LLM生成解释能够提高任务的性能。目前已经有了很多的关于CoT的工作，比如self-consistent CoT，tree-of-thoughts等方法。</p>
<p>然而LLM到底是不是依据它自己给出的解释进行推理的？这个问题目前看来不一定。</p>
<ul>
<li>研究人员发现LLM有时候给出的解释，并不是它自己真正进行推理决策的过程。他们在上下文的样例中将正确答案总是放在option A的位置上，然后让LLM对于新的样例为什么选择A给出解释，然后发现LLM没有回答这种明显的bias。[<em>Language models don’t always say what they think: Unfaithful explanations in chain-of-thought prompting.</em>]</li>
<li>有工作指出，LLM在给出不正确的推理过程情况下，也可以生成最终正确的答案。[<em>Mathematical capabilities of chatgpt.</em>]</li>
</ul>
<p>下面是几个对LLM在需要逻辑推理能力任务上的研究，进一步讨论了LLM推理能力的缺陷：</p>
<ul>
<li>[384] found performance of ChatGPT and GPT-4 dropped significantly on new datasets requiring logical reasoning, even though they performed relatively well on most existing benchmarks. This suggests current success may rely on exploiting dataset-specific quirks rather than robust human-like reasoning.</li>
<li>LLMs are known to exploit superficial spurious patterns in logical reasoning tasks rather than meaningful logic [385].</li>
</ul>
<p>目前的提高LLM推理能力的技术：</p>
<ul>
<li>prompt engineering: 各种不涉及参数更新的方法。prompt engineering techniques such as CoT, instruction tuning, and in-context learning can enhance LLMs’ reasoning abilities. For example, Zhou et al. [389] propose Least-to-most prompting that results in improved reasoning capabilities.</li>
<li>pretraining: 从头预训练LLM，设计更加需要推理能力的预训练任务。[392, 393] show the effectiveness of pretraining an LLM from scratch with data curated for tasks that require complex reasoning abilities.</li>
<li>continual training: 对于经过了预训练的LLM，进一步在新的数据上进行训练。In [390, 391], results show that continuing to train pretrained LLMs on the same objective function using high-quality data from specific domains (e.g., Arxiv papers and code data) can improve their performance on down-stream tasks for these domains.</li>
<li>supervised fine-tuning: Chung et al. [30] propose to add data augmented by human-annotated CoT in multi-task fine-tuning. Fu et al. [394] show that LLMs’ improvement of reasoning ability can be distilled to smaller models by model specialization, which utilizes specialization data partially generated by larger models (e.g. code-davinci-002) to fine-tune smaller models. [<em>Specializing Smaller Language Models towards Multi-Step Reasoning</em>]</li>
<li>reinforcement learning: 利用强化学习提升LLM的推理能力，比如让LLM不仅仅关注最后推理结果是否正确，也让LLM去关注中间步骤是否正确。</li>
</ul>
<h3 id="limited-causal-reasoning">6.3 Limited Causal Reasoning</h3>
<p>LLM的因果推理能力。和前面的逻辑推理能力比较起来，因果推理能力强调捕获状态/时间的cause-effect relationship。</p>
<blockquote>
<p>Unlike logical reasoning, which derives conclusions based on premises, causal reasoning makes inferences about the relationships between events or states of the world, mostly by identifying cause-effect relationships.</p>
<p>Causal reasoning tasks specifically examine various aspects regarding LLMs’ understanding of causality, including inferring causal relationships among random variables (e.g. temperature and latitude) [399] and events (e.g. a person bumped against a table and a beer fell to the group) [358], answering counterfactual questions, and understanding rules of structural causal models [400] (e.g. d-separation).</p>
</blockquote>
<p>有研究工作发现，GPT-4擅长推理必要条件，不擅长找充分条件。研究者认为可能的一个原因是寻找充分条件需要考虑更大范围的情况。[<em>Causal reasoning and large language models: Opening a new frontier for causality.</em>]</p>
<p>Jin et al.提出了一个新的因果推理数据集，CORR2CAUSE。在给定了一些变量和变量之间的correlation之后，让LLM判断假设的因果关系是否成立。作者发现LLM对于这种因果推理的能力还是比较弱的。[<em>Can large language models infer causation from correlation?</em>]</p>
<p>作者进行了一个case study，测试LLM是否理解了必要条件（Necessary Cause）这个概念：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230823235141549.png"   style="zoom:50%;" /></p>
<p>在这个case study中的task 1中，GPT-3.5给出的情感和event之间的因果关系是正确的。“fans feeling disappointed” ← “canceled baseball game” ← “storm”. 然后LLM也能够识别出是哪个event引起了对应的情感的。但是它修改event来改变情感的时候，修改的event和最后的sentiment是不匹配的。</p>
<h2 id="robustness">8. Robustness</h2>
<p>验证LLM的性能是很重要的，而保证在部署前/运行中评估LLM的robustness也同等重要。</p>
<h3 id="prompt-attacks">8.1 Prompt Attacks</h3>
<p>LLMs are sensitive to the engineering of prompts. 前面的2.3的inconsistency已经证明了对于同一个question，不同的提法可能会导致完全不同的答案。更糟糕的是，一些小的偏差比如语法/拼写错误，也可以导致LLM有不同的答案：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903170720715.png"   style="zoom:50%;" /></p>
<p>prompt attacks，通过修改prompt，可以诱导LLM回答原本不应该回答的问题，比如：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903170810152.png"   style="zoom:50%;" /></p>
<p>不过这种prompt也可以被反过来用于增强LLM的训练数据，构造更加安全的LLM，这叫做adversarial prompt engineering。</p>
<h3 id="paradigm-and-distribution-shifts">8.2 Paradigm and Distribution Shifts</h3>
<p>Paradigm and Distribution Shifts是指knowledge会随着时间而改变。LLM如果无法及时的学习到这种改变的话，它的回答也是不可信的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230903171003813.png"   style="zoom:50%;" /></p>
<h3 id="interventional-effect">8.3 Interventional Effect</h3>
<p>干预效应是指算法的算法可能会导致data distribution发生变化。</p>
<p>举例：对于LLM来说，由于训练数据中的分布不一样。如果LLM使用用户的个人反馈/信息，来为不同用户提供差异化服务，这可能进一步导致未来的数据分布发生变化。比如说某个用户群体由于LLM提供的服务不好，选择不再使用LLM，那么LLM在未来就更不能够收集到足够的信息，导致未来LLM对于该特定用户群体的服务进一步变差。</p>
<p>再比如如果用户总是对某些不道德的输出选择赞同，那么这部分反馈可能会被用到将来的预训练/微调，导致LLM输出的bias进一步增强。</p>
<h3 id="poisoning-attacks">8.4 Poisoning Attacks</h3>
<p>Poisoning Attacks通常是指通过修改训练数据，让模型特别是判别/分类模型的行为产生偏差。</p>
<blockquote>
<p>Traditional poisoning attacks on general machine learning models aim to fool the model by manipulating the training data, usually performed on classification models. One of the most common ways of data poisoning is to alter the label of training samples.</p>
</blockquote>
<p>比如有研究发现污染极少一部分的training data（0.1%），就可以让model完全丧失判别能力[<em>Poisoning the unlabeled dataset of semi-supervised learning.</em>]。</p>
<p>对于LLM来说，由于大多数训练数据来源于Internet，要污染training data更加容易。比如有研究发现通过构造域名/众包，可以污染LAION-400M [455], COYO-700M [456], and Wikipedia这些大规模数据集[<em>Poisoning web-scale training datasets is practical.</em>]。</p>
<p>更糟糕的威胁是，如果污染code LLM，那么这些LLM在自动生成代码的时候也会生成错误/有风险的代码，如果这些code LLM被广泛的应用于代码补全/代码建议，那么这些有风险的代码会不断传播。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Survey</tag>
        <tag>Trustworthy</tag>
      </tags>
  </entry>
  <entry>
    <title>When-not-to-trust-LLM-entity-knowledge</title>
    <url>/llm/When-not-to-trust-LLM-entity-knowledge/</url>
    <content><![CDATA[<h1 id="when-not-to-trust-language-models-investigating-effectiveness-of-parametric-and-non-parametric-memories">When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories</h1>
<p>华盛顿大学，ACL 2023，<a href="https://github.com/AlexTMallen/adaptive-retrieval">代码</a>。</p>
<blockquote>
<p>Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the difficulty of encoding a wealth of world knowledge in their parameters. <strong>This paper aims to understand LMs’ strengths and limitations in memorizing factual knowledge,</strong> by conducting large-scale knowledge probing experiments on two open-domain entity-centric QA datasets: <strong>PopQA, our new dataset with 14k questions about long-tail entities</strong>, and EntityQuestions, a widely used open-domain QA dataset. <strong>We find that LMs struggle with less popular factual knowledge, and that retrieval augmentation helps significantly in these cases. Scaling, on the other hand, mainly improves memorization of popular knowledge, and fails to appreciably improve memorization of factual knowledge in the long tail.</strong> Based on those findings, we devise a new method for retrieval augmentation that improves performance and reduces inference costs by only retrieving non-parametric memories when necessary.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>之前已经有工作讨论过LM对于less frequent entities的记忆能力并不好[<em>Large language models struggle to learn long-tail knowledge. 2022</em>]。有后续的研究提出可以通过引入non-parametric knowledge来缓解这一问题[<em>Few-shot learning with retrieval augmented language models</em>]。但是Understanding when we should not trust LMs’ outputs is also crucial to safely deploying them in real-world applications。</p>
<p>这篇文章的目的就在于搞清楚什么时候应该trust LLM输出的factual knowledge，什么时候不应该trust LLM的输出factual knowledge。</p>
<p>为了探究这个问题，作者构造了一个新的知识探测数据集PopQA，主要是由各类less popular的实体相关知识构成。</p>
<p>主要发现如下：</p>
<ol type="1">
<li>factual knowledge frequently discussed on the web is easily memorized by LMs, while the knowledge that is less discussed may not be well captured and thus they require retrieving external non-parametric memories.</li>
<li>scaling up models does not significantly improve the performance for less popular questions.</li>
<li>we found that retrieval-augmented LMs are particularly competitive when subject entities are not popular.</li>
<li>we also find that retrieval augmentation can hurt the performance of large LMs on questions about popular entities as the retrieved context can be misleading.</li>
</ol>
<h2 id="evaluation-setup">2. Evaluation Setup</h2>
<p>作者从Wikidata中构造了自己的数据集，entity的popularity用维基百科相关页面的点击次数Wikipedia monthly page views来评估，PopQA数据集构造流程如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827214908873.png"   style="zoom:40%;" /></p>
<p>实体的popularity统计分布：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827215004300.png"   style="zoom:35%;" /></p>
<p>在询问LLM的时候，使用下面的句子模板：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827215051326.png"   style="zoom:35%;" /></p>
<p>已知头实体和关系，预测尾实体。除了自己构造的数据集外，还使用了EntityQuestions数据集[<em>Simple entity-centric questions challenge dense retrievers. EMNLP 2021</em>]。</p>
<p>具体在查询LLM是使用了few-shot的in-context learning方法。</p>
<h2 id="memorization-depends-on-popularity-and-relationship-type">3. Memorization Depends on Popularity and Relationship Type</h2>
<p>先看总体上的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827215549720.png"  style="zoom:50%;" /></p>
<p>有以下的observation：</p>
<ul>
<li>总体上，更大的LLM记忆的knowledge更多，表现效果更好</li>
<li>图4底部是entity popularity和回答的准确率accuracy之间的相关性correlation。可以看到这种相关性是正的，并且这种相关性随着LLM参数量的增加，总体上进一步增强</li>
<li>图4上半部分能看出来，不同relationship下的实体，LLM的回答准确率有很大差异。并且对于有些relation，popularity和准确性之间没有很强的相关性（如country、sport），但是准确性却很高。这可能是因为这些问题是LLM可以简单的通过一些特征surface-level artifacts就判断出来进行回答的。比如可以根据一个person entity的名字拼写，猜出他/她是来自那个国家</li>
</ul>
<p>尽管上面的实验结果发现，更大的LLM似乎记忆效果更好，下面的实验进一步分析对不同popularity问题的回答准确度和LLM参数量大小之间的关系：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827220422168.png"   style="zoom:35%;" /></p>
<p>能够看出来，Figure 5 shows that on both P OP QA and EntityQuestions, most of scaling’s positive effect on parametric knowledge comes from questions with high popularity.</p>
<p>而less popular的问题，随着model参数量增加，增长很慢（尽管是有增长的）。因此作者推测，不断扩大LLM参数量，会进一步降低能够被可靠记忆的entity popularity的阈值。但是估计很难真正的抵达long tail entity的popularity范围。</p>
<h2 id="non-parametric-memory-complements-parametric-memory">4. Non-parametric Memory Complements Parametric Memory</h2>
<p>作者对比了2个开箱即用的基于检索的方法：BM25和Contriever。同时还对比了一个GenRead的方法，该方法是直接让LM生成上下文，而不是通过检索。</p>
<p>利用现有的检索技术，从Wikipedia dump中直接检索到top-1相关的paragraph，然后与要探测的question拼接，作为输入到LLM的prompt。</p>
<p>下面的实验结果可以看出来，通过检索增强之后，几乎所有的LLM都能够获得总体效果的提升：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827221203413.png"   style="zoom:35%;" /></p>
<p>上图还有一个有意思的发现，直接让LLM生成额外的文本辅助增强prompt的GenRead方法，在更大的LLM中，效果是逐渐提升的。在GPT-3中已经靠近了纯检索的Contriever方法。</p>
<p>进一步实验发现，这种增强的效果提升主要是由于对less popular问题效果的提高：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827221438146.png"   style="zoom:35%;" /></p>
<p>而在比较popular的问题上，检索增强甚至会降低效果。检索到的额外文本也不能够保证一定是有意义的，可能会误导LLM的输出。下图也佐证了这一点：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827221559929.png"   style="zoom:35%;" /></p>
<p>table 1中，本来LLM回答正确的问题，在检索增强后，可能会被误导（表格中10%的问题占比）。</p>
<p>下面是几个检索结果对原始LLM生成结果的影响实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828150533816.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230828150513838.png"  style="zoom:50%;" /></p>
<h2 id="adaptive-retrieval-using-retrieval-only-where-it-helps">5. Adaptive Retrieval: Using Retrieval Only Where It Helps</h2>
<p>基于以上的实验观察，作者提出了一种Adaptive Retrieval的简单方法，就是给不同relationship设定不同的popularity阈值，只有小于阈值的问题才会进行检索增强，而大于阈值的问题就认为是比较popular的问题，只需要让LLM自己回答即可。</p>
<p>阈值的选择是通过在development set上，选择能够让不同relationship回答准确率最高的threshold。下面是作者的示意图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827223427458.png"  style="zoom:35%;" /></p>
<p>在应用了作者的adaptive检索方法之后，效果都是有提升的，并且是越大的LLM提升越明显：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827222121112.png"   style="zoom:35%;" /></p>
<p>具体原因是因为，对于小LLM来说，几乎总是需要检索，而越大的LLM，越不太依赖检索：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827222247441.png"   style="zoom:35%;" /></p>
<p>上面图10的实验结果表明，小LLM的检索阈值几乎是1，而越大的LLM，检索阈值越小。</p>
<p>这种自适应的检索增强方法另一个好处是，减小了时延（不需要检索以及更短的input length）和调用GPT的花费（更少的处理token，所需要的money更少），实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230827222537489.png"  style="zoom:35%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Knowledge</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Knowledge</tag>
      </tags>
  </entry>
  <entry>
    <title>is-gpt3-good-data-annotator</title>
    <url>/llm/is-gpt3-good-data-annotator/</url>
    <content><![CDATA[<h1 id="is-gpt-3-a-good-data-annotator">Is GPT-3 a Good Data Annotator?</h1>
<p>南洋理工与阿里达摩，ACL 2023，<a href="https://github.com/DAMO-NLP-SG/LLM-Data-Annotator">代码</a>。</p>
<blockquote>
<p>Data annotation is the process of labeling data that could be used to train machine learning models. Having high-quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output. GPT-3, a large-scale language model developed by OpenAI, has demonstrated impressive zero- and few-shot performance on a wide range of NLP tasks. It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks. <strong>In this paper, we evaluate the performance of GPT-3 as a data annotator by comparing it with traditional data annotation methods and analyzing its output on a range of tasks.</strong> Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP.</p>
</blockquote>
<p>作者探讨了利用GPT-3生成sentiment analysis (SA)，relation extraction (RE)，named entity recognition (NER)和aspect sentiment triplet extraction (ASTE)等任务的数据方法。</p>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>为什么要讨论数据标注问题？因为从大的方面讲，AI技术应该面向社会各界提供服务（论文中称为The democratization of artificial intelligence）。但是一个AI model往往需要大量的标注数据。</p>
<blockquote>
<p>The democratization of artificial intelligence (AI) (Garvey, 2018; Rubeis et al., 2022) aims to provide access to AI technologies to all members of society, including individuals, small- and medium-sized enterprises (SMEs), academic research labs, and nonprofit organizations.</p>
</blockquote>
<p>标注数据的获得需要很高成本：</p>
<ul>
<li>labor costs associated with the labeling process</li>
<li>the time and resources required to hire, train and manage annotators.</li>
<li>Additionally, there may be costs associated with the annotation tools and infrastructure needed to support the annotation process.</li>
</ul>
<p>对于个人和小公司来说这种成本往往是不可接受的。</p>
<p>另一方面，GPT-3等大模型有很多knowledge，可以执行广泛的NLP任务；但是在production环境中，使用BERT-base等small的model可能是更加合理的（个人认为这种small model在极端情况下，需要高响应的场景中也不实用）。</p>
<p>所以，论文作者就关注利用GPT-3生成/标注训练数据，去更好的训练small model以降低标注数据获取成本。</p>
<p>用GPT生成训练数据/标注数据，然后训练small model，可以看做是一种蒸馏技术。（那么人类标注，然后训练model，是不是能够看做一种人类到model的蒸馏？）</p>
<h2 id="methodology">2. Methodology</h2>
<p>作者的标注数据获取方法有三种：</p>
<ul>
<li>prompt-guided unlabeled data annotation (PGDA)：<strong>tagging-based</strong> approach，让LLM直接对in-domain unlabelled data进行标注</li>
<li>prompt-guided training data generation (PGDG)：<strong>generation-based</strong> approach，让LLM生成带有label的数据</li>
<li>dictionary-assisted training data generation (DADG)：<strong>generation-based</strong> approach，利用external knowledge source去辅助生成带有label的数据。先在Wikidata中查询相关的样例，然后让GPT模仿生成数据。这样做的好处是对于一些LLM的预训练数据没有包括/占比较少，学习效果不好的domain，更能够生成可信的结果。</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905163214676.png"   style="zoom:40%;" /></p>
<p>三种思路对于不同的任务有不同的prompt，但是都采用了in-context learning的形式。</p>
<h2 id="experiments">3. Experiments</h2>
<h3 id="experiment-settings">3.1 Experiment Settings</h3>
<p>一些设置：</p>
<ul>
<li>GPT-3使用<code>text-davinci-003</code>，使用其生成的data去训练small model</li>
<li>small model是<code>BERT-base</code></li>
<li>DADG利用到的外部知识源是Wikidata</li>
</ul>
<p>下面主要记录了在RE和NER任务上的表现，其它任务请参见论文原文。</p>
<h3 id="fewrel">3.2 FewRel</h3>
<p>FewRel数据集有64种relation。</p>
<p>下面是三种方法分别用到的prompt示例：</p>
<p>PGDA方法用到的unlabeled data是原始数据集中的样例移除人工标注之后的data。然后再使用GPT新标注的结果去训练BERT。</p>
<p>作者设计了5种PGDA方法用到的prompt，但由于这个数据集label space很大，这种标注方法效果并不好：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905164325630.png"   style="zoom:40%;" /> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905164203625.png" style="zoom:40%;" /></p>
<p>PGDG生成方法，第一步让GPT生成特定relation的head/tail entity；第二步让GPT根据head/tail entity去创造包含这两个实体的sentence；从论文描述中看，应该是随机找的demonstrations。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905164544743.png"   style="zoom:30%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905164602059.png"   style="zoom:30%;" /></p>
<p>DADG方法第一步在Wikidata中查询对应relation的entity pairs；第二步用查询到的entity pairs作为上下文生成新的sentence。与上面的PGDG类似。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905164752260.png"  style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>由于这个数据集有很多relation label，GPT不能够准确的标注label，因此PGDA方法效果最差</li>
<li>基于生成的方法PGDG和DADG效果比PGDA要好很多。最重要的是，标注代价要远远小于人工标注</li>
</ul>
<h3 id="crossner">3.3 CrossNER</h3>
<p>作者使用CrossNER数据集中的AI数据集（14种entity label）。</p>
<p>PGDA方法，作者发现GPT标注entity的时候：</p>
<ul>
<li>it may also identify entities that are not of the specified entity type, resulting in incorrect labeling</li>
<li>GPT-3 may not accurately identify the boundaries of the entities</li>
</ul>
<p>因此，作者除了直接让GPT标注实体外，还让加了额外的一个确认entity type的步骤：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905165424041.png"   style="zoom:30%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905165440312.png"   style="zoom:30%;" /></p>
<p>首先，让GPT标注对应entity type的entity；然后再次确认，让GPT对于识别出的entity重新决定属于哪一类entity。（尽管经过这么两步，PGDA方法效果仍然是最差的）</p>
<p>基于生成的PGDG是两步，第一步让GPT生成不同entity type下的可能entity；第二步让GPT利用生成的entity去生成对应的sentence：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905165740644.png"   style="zoom:30%;" /></p>
<p>基于生成的DADG第一步是从Wikidata中查询属于entity type的entities；第二步和PGDG第二步一致。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905165900707.png"   style="zoom:30%;" /></p>
<p>PGDG和DADG方法甚至超过了完全使用人类标注的效果，不过人类标注的实验只用了100个样例，这个比较结果不够公平。但还是非常promising的。</p>
<h2 id="further-analysis">4. Further Analysis</h2>
<h3 id="impact-of-label-space">4.1 Impact of Label Space</h3>
<p>两种类型的生成训练数据的思路各有优缺点：</p>
<ul>
<li>The tagging-based approach (PGDA) is more appropriate for tasks with smaller label spaces and clearly defined labels，比如SE和ASTE方法中label只有2-3种，这种情况下PGDA方法效果更好。</li>
<li>In contrast, the generation-based approaches (PGDG and DADG) are better suited for tasks with larger label spaces or labels that possess a certain degree of ambiguity，对于实验中的FewRel和CrossNER数据集，让GPT准确的理解label是很难的，因此直接标注的效果反而不好</li>
<li>The tagging-based approach (PGDA) 能够直接利用in-domain unlabeled data；然而the generation-based approaches may generate data that contains information that was &quot;learned&quot; during pre-training and may not align with the distribution of in-domain data. 也就是说生成的数据特征分布不能够保证和真实世界的数据特征是一致的</li>
</ul>
<h3 id="comparison-with-human-annotators">4.2 Comparison with Human Annotators</h3>
<p>与人类标注的比较：</p>
<ul>
<li>For human annotators, it usually takes longer time to train them for domain-specific data annotation, and their annotation speed is not comparable with machines in most cases</li>
<li>Moreover, it is often more challenging for humans to construct training data without unlabeled data, or when the size of label space is very large.</li>
<li>If we limit the number of data samples for model training, the per-instance quality of the data annotated by humans is still higher in most cases.</li>
</ul>
<h3 id="impact-of-number-of-shots">4.3 Impact of Number of Shots</h3>
<p>不同任务中，增加上下文的样例数量来提升生成数据的效果，影响是不一样的，可能效果提升也可能效果下降：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905171146027.png"   style="zoom:40%;" /></p>
<p>对于FewRel数据集，增加样例数量能够生成更加diverse的数据：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905171046363.png"   style="zoom:30%;" /></p>
<p>对于SST2数据集，增加样例数量，生成的数据越来越接近真实数据集中特点，反而会逐渐减少信息：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905171431462.png"   style="zoom:30%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Capacity</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Data Augmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>linear-algorithm-in-ICL</title>
    <url>/llm/linear-algorithm-in-ICL/</url>
    <content><![CDATA[<h1 id="what-learning-algorithm-is-in-context-learning-investigations-with-linear-models">What learning algorithm is in-context learning? Investigations with linear models</h1>
<p>ICLR 2023, Google Research and MIT, <a href="https://github.com/ekinakyurek/google-research/tree/master/incontext">地址</a>。</p>
<blockquote>
<p>Neural sequence models, especially transformers, exhibit a remarkable capacity for in-context learning. They can construct new predictors from sequences of labeled examples (x, f(x)) presented in the input without further parameter updates. <strong>We investigate the hypothesis that transformer-based in-context learners implement standard learning algorithms implicitly, by encoding smaller models in their activations, and updating these implicit models as new examples appear in the context.</strong> Using linear regression as a prototypical problem, we offer three sources of evidence for this hypothesis. First, we prove by construction that transformers can implement learning algorithms for linear models based on gradient descent and closed-form ridge regression. Second, we show that trained in-context learners closely match the predictors computed by gradient descent, ridge regression, and exact least-squares regression, transitioning between different predictors as transformer depth and dataset noise vary, and converging to Bayesian estimators for large widths and depths. Third, we present preliminary evidence that in-context learners share algorithmic features with these predictors: learners’ late layers non-linearly encode weight vectors and moment matrices. These results suggest that in-context learning is understandable in algorithmic terms, and that (at least in the linear case) learners may rediscover standard estimation algorithms.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>这篇工作的研究问题：How can a neural network with fixed parameters to learn a new function from a new dataset on the ﬂy?</p>
<p>作者做了这样的假设，上下文学习过程中，Transformer潜在的学习到了一个映射函数，并且上下文中的样例起到了对这样的潜在函数进行训练的作用。</p>
<blockquote>
<p>This paper investigates the hypothesis that some instances of ICL can be understood as implicit implementation of known learning algorithms: in-context learners encode an implicit, context-dependent model in their hidden activations, and train this model on in-context examples in the course of computing these internal activations.</p>
</blockquote>
<h2 id="preliminary">2. Preliminary</h2>
<h3 id="the-transformer-architecture">The Transformer architecture</h3>
<p>作者研究的是Transformer的decoder，下面是self-attention定义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904233831897.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904233844389.png"   style="zoom:50%;" /></p>
<p>下面是feed-forward transformation的定义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904233900476.png"   style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(\lambda\)</span>是layer normalization，<span class="math inline">\(\sigma\)</span>是GeLU等激活函数。</p>
<p>Transformer的computational capacity与depth，hidden size <span class="math inline">\(h\)</span>, number of heads <span class="math inline">\(m\)</span>有关。</p>
<h3 id="training-for-in-context-learning">Training for in-context learning</h3>
<p>作者在论文中讨论的Transformer，是针对ICL objective进行优化的模型。不是目前更多的单纯优化language objective的LM：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904234304259.png"   style="zoom:50%;" /></p>
<p>单纯的看这个loss，感觉是先输入上下文exemplar 1，预测exemplar 1，计算loss；然后输入exemplar 1和exemplar 2，预测exemplar 2，计算loss。</p>
<h3 id="linear-regression">Linear regression</h3>
<p>作者对比的learning algorithm是linear regression，原因之一是linear regression相对简单，人们对于它的理解比较充分。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904234627050.png"   style="zoom:50%;" /></p>
<p>当<span class="math inline">\(\lambda=0\)</span>，上面的回归称为ordinary least squares regression (OLS)；</p>
<p>当<span class="math inline">\(\lambda&gt;0\)</span>，上面的回归称为ridge regression岭回归。</p>
<p>其中的<span class="math inline">\(w^*\)</span>表示线性回归的最优解。</p>
<h2 id="what-learning-algorithms-can-a-transformer-implement">3. What learning algorithms can a transformer implement?</h2>
<p>这一部分，作者证明从理论上，通过固定Transformer中self-attention层和FFN层的一些参数，可以让Transformer实现linear regression。</p>
<blockquote>
<p>for <span class="math inline">\(d\)</span>-dimensional regression problems, with <span class="math inline">\(O(d)\)</span> hidden size and constant depth, a transformer can implement a single step of gradient descent; and with <span class="math inline">\(O(d^2)\)</span> hidden size and constant depth, a transformer can update a ridge regression solution to include a single new observation. Intuitively, <span class="math inline">\(n\)</span> steps of these algorithms can be implemented with <span class="math inline">\(n\)</span> times more layers.</p>
</blockquote>
<h3 id="preliminaries">3.1 preliminaries</h3>
<p>作者定义了下面的几种变化操作，然后证明Transformer可以实现这些操作：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904235141390.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904235157113.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904235213253.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904235226816.png"   style="zoom:50%;" /></p>
<p>证明过程在附录。</p>
<p>下面是作者的引理：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904235306938.png"   style="zoom:50%;" /></p>
<p>下面两个部分，是作者讨论的两种学习linear model参数的方法。作者从理论上证明Transformer能够学习这样的映射函数。</p>
<h3 id="gradient-descent">3.2 Gradient descent</h3>
<p>通过梯度下降的形式学习linear model的参数：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904235543973.png"   style="zoom:50%;" /></p>
<p>然后，作者证明从理论上，在最后输出的对应<span class="math inline">\(x_n\)</span>（测试样例）的结果，某一个元素可以等于线性回归的计算结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230904235613542.png"   style="zoom:50%;" /></p>
<h3 id="closed-form-regression">3.3 Closed-form regression</h3>
<p>直接计算最优解<span class="math inline">\(w^*\)</span>需要计算<span class="math inline">\(X^TX+\lambda I\)</span>的逆矩阵，这种计算比较复杂。</p>
<p>然后作者利用Sherman–Morrison formula [<em>Adjustment of an inverse matrix corresponding to a change in one element of a given matrix. 1950</em>]可以将这种求方阵<span class="math inline">\(A\)</span>的逆矩阵转换为迭代的和rank-one的example进行运算的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905000053236.png"   style="zoom:50%;" /></p>
<p>最后，被转化的求<span class="math inline">\(w^*\)</span>的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905000131555.png"   style="zoom:50%;" /></p>
<h2 id="what-computation-does-an-in-context-learner-perform">4. What computation does an in-context learner perform?</h2>
<p>这一部分是从实验中评估，Transformer对于上下文的处理和linear model在多大程度上是相近的。</p>
<h3 id="behavioral-metrics">4.1 Behavioral metrics</h3>
<p>首先是要定义度量指标，作者定义了两个metric，Squared prediction difference（SPD）和Implicit linear weight difference（ILWD）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905000359930.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905000413623.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905000457521.png"   style="zoom:50%;" /></p>
<p>SPD指标比较两种mapping function在预测输出的差异；ILWD比较两种mapping function的参数的差异。</p>
<h3 id="experimental-setup">4.2 Experimental Setup</h3>
<p>作者讨论的Transformer不是特别大：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905000636258.png"   style="zoom:50%;" /></p>
<p>训练数据是生成的，For the main experiments we generate data according to <span class="math inline">\(p(w) = N(0, I)\)</span> and <span class="math inline">\(p(x) = N(0, I)\)</span>.</p>
<h3 id="results">4.3 Results</h3>
<p>作者对比了下面几种学习算法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905000930170.png"   style="zoom:50%;" /></p>
<p>包括使用欧式距离的k-NN算法、一个样本的随机梯度下降、batch随机梯度下降和直接计算最优参数<span class="math inline">\(w^*\)</span>的方法。</p>
<blockquote>
<p>ICL matches ordinary least squares predictions on noiseless datasets.</p>
</blockquote>
<p>对比结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905001044377.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>ICL的行为和k-NN最不相似</li>
<li>ICL的行为和没有正则项的线性回归最相似</li>
<li>虽然上下文样例数增多，基于梯度下降的线性回归算法也越来越靠近ICL的行为</li>
</ul>
<blockquote>
<p>ICL matches the minimum Bayes risk predictor on noisy datasets.</p>
</blockquote>
<p>在前面的实验结果中，作者发现，Transformer的输出总是和最小二乘算法的输出一致；作者认为原因是在构造训练数据的时候，是以0位平均数的高斯分布进行采样的。Transformer通过ICL学习到了这样的规律，总是试图输出minimum Bayes risk的solution。</p>
<p>因此，作者构造了另外一个带有噪音的数据：</p>
<blockquote>
<p>To more closely examine the behavior of ICL algorithms under uncertainty, we add noise to the training data: now we present the in-context dataset as a sequence: <span class="math inline">\([x_1 , f(x_1) + \epsilon_1 , \dots, x_n , f(x_n ) + \epsilon_n ]\)</span> where each <span class="math inline">\(i ∼ N(0, \sigma^2)\)</span>.</p>
</blockquote>
<p>最小Bayes risk的solution应该是：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905001639044.png"   style="zoom:50%;" /></p>
<p>此时的最优参数应该是：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905001659159.png"   style="zoom:50%;" /></p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905001725225.png"   style="zoom:50%;" /></p>
<blockquote>
<p>ICL exhibits algorithmic phase transitions as model depth increases.</p>
</blockquote>
<p>作者进一步探究model size是如何影响这种内在的学习机制的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905001907105.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<blockquote>
<p>When we vary the depth, learners occupy three distinct regimes: very shallow models (1L) are best approximated by a single step of gradient descent (though not wellapproximated in an absolute sense). Slightly deeper models (2L-4L) are best approximated by ridge regression, while the deepest (+8L) models match OLS</p>
</blockquote>
<h2 id="does-icl-encode-meaningful-intermediate-quantities">5. Does ICL encode meaningful intermediate quantities?</h2>
<p>最后，作者探测下Transformer的中间状态到底在编码什么样的信息？asking what information is encoded in these states, and where. 也就是希望能够理解Transformer是如何最终逐步学习到前面讨论的linear model的？</p>
<p>作者选择了优化linear model中要用的两个中间量作为期望被编码的信息：</p>
<ul>
<li>the moment vector <span class="math inline">\(X^T Y\)</span> (gradient descent variant)</li>
<li>the (min-norm) least-square estimated weight vector <span class="math inline">\(w_{OLS}\)</span> (ridge-regression variant)</li>
</ul>
<p>作者认为中间变量会Transformer逐步的进行编码。</p>
<p>为了验证这一点，训练了一个额外的an auxiliary probing model [<em>Understanding intermediate layers using linear classiﬁer probes. 2016</em>]，：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905002812516.png"  style="zoom:50%;" /></p>
<p>输入是前面训练的参数固定的Transformer。期望输出的<span class="math inline">\(\hat{v}\)</span>能够逼近中间量： <span class="math display">\[
L(v, \hat{v} ) = |v - \hat{v} |^2
\]</span> 实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230905002221813.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li><p>For both targets, a 2-layer MLP probe outperforms a linear probe, meaning that these targets are encoded nonlinearly 中间量需要非线性编码</p></li>
<li><p>Both targets are decoded accurately deep in the network (but inaccurately in the input layer, indicating that probe success is non-trivial.) 只有深度网络才能越来越好的学习中间量</p></li>
</ul>
]]></content>
      <categories>
        <category>LLM</category>
        <category>ICL</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>ICL</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>rethinking-role-of-demonstrations</title>
    <url>/llm/rethinking-role-of-demonstrations/</url>
    <content><![CDATA[<h1 id="rethinking-the-role-of-demonstrations-what-makes-in-context-learning-work">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</h1>
<p>华盛顿大学与Meta，EMNLP 2022，<a href="github.com/Alrope123/rethinking-demonstrations">代码</a>。</p>
<blockquote>
<p>Large language models (LMs) are able to incontext learn—perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. <strong>In this paper, we show that ground truth demonstrations are in fact not required—randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choice tasks</strong>, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of end task performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.</p>
</blockquote>
<p>作者对于上下文学习中，什么样的signal是对LLM进行task learning有帮助的进行了实验探究。</p>
<span id="more"></span>
<h2 id="experimental-setup">Experimental Setup</h2>
<p>作者实验用model：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920160808581.png"   style="zoom:40%;" /></p>
<p>用的prompt实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920160835959.png"   style="zoom:40%;" /></p>
<p>作者主要针对4个ICL中的demonstrations可能提供的learning signal进行了实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161615499.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920160935727.png"   style="zoom:40%;" /></p>
<h2 id="ground-truth-matters-little">Ground Truth Matters Little</h2>
<p>作者的第一个重要发现是ICL中demonstrations的input-label是否正确匹配，对模型效果的影响不大。作者用随机的label来替换demonstrations的ground truth label，发现效果下降不是很多：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161132344.png"   style="zoom:50%;" /></p>
<p>上面的结果说明给定demonstrations很重要；但是demonstrations中input-label的对应关系没有那么重要。似乎LLM能够自己根据demonstrations的input去恢复映射关系。</p>
<p>额外的实验同样证明了相同的变化趋势，作者随机替换一部分的ground truth label：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161421023.png"   style="zoom:50%;" /></p>
<p>不同demonstrations数量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161457497.png"   style="zoom:40%;" /></p>
<p>不同prompt template（换为人工设计的prompt）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161548069.png"  style="zoom:50%;" /></p>
<h2 id="why-does-in-context-learning-work">Why does In-Context Learning work?</h2>
<h3 id="impact-of-the-distribution-of-the-input-text">Impact of the distribution of the input text</h3>
<p>然后，作者进一步探究了其它3个可能影响ICL效果的因素。对于input text的distributions，作者实验用外部语料库找到的句子，随机替换一些demonstrations的input，引入out-of-distribution text：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920161931114.png"   style="zoom:50%;" /></p>
<p>发现结果出了Direct MetaICL外，都出现了明显的效果下降。</p>
<h3 id="impact-of-the-label-space">Impact of the label space</h3>
<p>作者实验用随机英文单词，替换ground truth label，发现效果下降：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920162506223.png"   style="zoom:50%;" /></p>
<h3 id="impact-of-input-label-pairing">Impact of input-label pairing</h3>
<p>作者实验了demonstrations的input-label这种format对效果的影响，包括No labels和labels only：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230920162622374.png"   style="zoom:50%;" /></p>
<h2 id="discussion">Discussion</h2>
<p><strong>Does the model learn at test time?</strong> 如何理解ICL是否进行了学习learning？要依据如何定义learning这个概念：</p>
<blockquote>
<p>If we take a strict definition of learning: capturing the inputlabel correspondence given in the training data, then our findings suggest that LMs do not learn new tasks at test time. Our analysis shows that the model may ignore the task defined by the demonstrations and instead use prior from pretraining.</p>
<p>However, learning a new task can be interpreted more broadly: it may include adapting to specific input and label distributions and the format suggested by the demonstrations, and ultimately getting to make a prediction more accurately. With this definition of learning, the model does learn the task from the demonstrations.</p>
</blockquote>
<p>如果认为learning是要利用demonstrations中input-label的mapping依赖来学会新task的映射关系，那么不能认为ICL进行了学习；如果认为learning是能够适应某种input和label的分布，并且按照一定的format进行输出，这种更加general的定义，那么可以认为ICL进行了学习。</p>
<p><strong>Capacity of LMs.</strong> ICL的能力从哪里来？如果LLM不是主要根据样例中的input-label的mapping关系来学习的，那么它是从哪里学习映射关系的？作者认为可能是从language modeling的角度，判断input text和label text之间关联的。这种能力的获得可能是在预训练阶段。如之前有研究者认为，demonstrations的作用是<em>task location</em>，真正能力实在pre-training阶段获得的。</p>
<blockquote>
<p>Reynolds and McDonell (2021) who claim that the demonstrations are for task location and the intrinsic ability to perform the task is obtained at pretraining time</p>
</blockquote>
<p><strong>Significantly improved zero-shot performance.</strong> 作者的工作启发了一种zero-shot模式，只需要提供给LLM无ground truth label的random label的样例，LLM或许就能够更好的执行zero-shot任务。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>ICL</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>ICL</tag>
      </tags>
  </entry>
  <entry>
    <title>synthetic-data-llm-sub</title>
    <url>/llm/synthetic-data-llm-sub/</url>
    <content><![CDATA[<h1 id="synthetic-data-generation-with-large-language-models-for-text-classification-potential-and-limitations">Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations</h1>
<p>Purdue University, 作者评论接收至EMNLP 2023。</p>
<blockquote>
<p>The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment. Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, <strong>the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks.</strong> To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the subjectivity of classification. Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data. We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM for synthetic data generation.</p>
</blockquote>
<p><strong>Issue</strong>: 目前在不同的task里，对于使用LLM生成的data是否能够和真实人工标注的data相比，没有定论。</p>
<p><strong>Solution</strong>: 作者认为出现这种现象的原因之一和具体text classification任务的主观程度subjectivity有关，实验发现主观性越强的分类任务，LLM生成数据的效果也会越差。</p>
<span id="more"></span>
<h2 id="methodolgy">Methodolgy</h2>
<p>作者采用了zero-shot和few-shot ICL两种设置。</p>
<p>对于zero-shot ICL prompt：</p>
<ul>
<li>“context prompt” relevant to the targeted domain of interest is used to set the context. 与具体task context相关的prompt</li>
<li>the “data generation prompt”, is provided to the LLM, instructing the model to generate texts with a specific style, label (with respect to the classification task of interest), and word limit. 提供具体的label、生成字数限制等要求的prompt</li>
<li>a “diversity prompt” to the LLM—“Can you provide something more diverse compared to the previously generated data?”—aiming to increase the diversity of the synthetic data generated. 生成具体的几个text data后，提示LLM生成更多不同的text data</li>
</ul>
<p>对于few-shot ICL prompt：</p>
<ul>
<li>“context prompt”与前面zero-shot ICL一样</li>
<li>随机采样的几个demonstrations，其中说明了对应的label</li>
<li>还强制限制了不允许仅仅是修改原来的句子，而是期望生成更多的具体data，比如<code>You should imitate the example I have provided, but you cannot simply modify or rewrite the example I have given</code></li>
</ul>
<p>下面是不同task用到的具体prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021225717858.png"  style="zoom:50%;" /></p>
<p>更多具体task的prompt参考paper附录。</p>
<h2 id="evaluation-i-comparison-across-different-types-of-tasks">Evaluation I: Comparison Across Different Types of Tasks</h2>
<p>一些实验设置：</p>
<ul>
<li><p>10个不同task，AG’s news (Zhang et al., 2015), IMDB reviews (Maas et al., 2011), SMS spam (Almeida et al., 2011), Financial phrase bank (Malo et al., 2014), Reddit emotion (Demszky et al., 2020), Relation classification (Gao et al., 2019) <strong>FewRel 2.0</strong>, Tweet irony speech (Van Hee et al., 2018), Tweet emotions (Mohammad et al., 2018), Sarcasm news (Misra and Arora, 2023, Misra and Grover, 2021), and Humor speech (Annamoradnejad and Zoghi, 2020).</p></li>
<li><p>对于关系分类任务，只讨论了FewRel 2.0数据集中‘country’, ‘league’, ‘screenwriter’, and ‘tributary’的4种relation</p></li>
<li><p>主要基于<code>GPT-3.5-Turbo</code>进行数据生成，但是在附录里提供了关于<code>GPT2-large (774M)</code>和<code>Llama2 (7B)</code>的对比实验</p></li>
<li><p>对于每个label生成<span class="math inline">\(3000\)</span>条数据用于实验，微调BERT和RoBERTa进行实验</p></li>
<li><p>具体task的主观程度，是通过众包人工打分得出的，每个worker会被要求判断随机的从两个task里找到的句子，哪个更加客观。具体的众包过程可以参考论文。在众包时，提示worker的对于任务客观性的定义：</p>
<blockquote>
<p>the classification of a piece of text is based on clear, identifiable features in the text (e.g., keywords or phrases), and can be done without being affected by any personal interpretation of the text resulted from personal biases, emotions or beliefs.</p>
</blockquote></li>
</ul>
<p>分类结果可以根据text很清楚的判断出来，并且不会受到个人的偏好、情感、信仰等发生变化。</p>
<h3 id="evaluation-results">Evaluation Results</h3>
<p>分别独立的在真实数据、生成数据上进行训练的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021230350077.png"  style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>直接使用真实数据训练的效果最好</li>
<li>few-shot ICL生成数据效果比zero-shot ICL效果好</li>
<li>LLM在生成带有更多人类主观性的数据上，效果更差</li>
</ul>
<p>为什么任务的主观程度会增大LLM生成数据的效果？作者提供了两个解释：</p>
<ol type="1">
<li>highly subjective tasks often require a deep understanding of nuanced human emotions and contextual subtleties, as well as the ability to discern and accurately interpret different perspectives. 越主观，越要求对于人类情感等有非常微妙的理解</li>
<li>it may be challenging for LLMs to generate synthetic data to recover such potentially biased “majority view,” especially if the LLMs are trained to maintain neutrality. 大多数的任务实例是利用众包标注的，也就是说在数据集里的gold label可能只反映了多个人的主要投票意见。对于LLM来说，要生成反映这种majority view的句子可能比较难。</li>
</ol>
<p>使用一小部分真实数据进行训练，然后拿这一小部分真实数据作为demonstrations进行数据增强的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021230653949.png" style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>在关系抽取任务上，作者的这种比较简单的生成数据的方法，没有明显提升效果</li>
</ul>
<p>不同LLM生成数据的对比：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021231834682.png"  style="zoom:50%;" /></p>
<h3 id="diversity-and-similarity-between-the-synthetic-data-and-the-real-data">Diversity and Similarity between the Synthetic Data and the Real Data</h3>
<p>对于生成的数据，作者从多样性和原有数据的相似性两个角度进行了分析。</p>
<p>对于多样性，follow前人的工作[<em>Directed diversity: Leveraging language embedding distances for collective creativity in crowd ideation. 2021</em>]，采用<em>Remote Clique Score</em>和<em>Chamfer Distance Score</em>两个metric计算多样性：</p>
<ul>
<li>Remote Clique Score (i.e., the average mean distance of a data instance to other instances)</li>
<li>Chamfer Distance Score (i.e., the average minimum distance of a data instance to other instances)</li>
</ul>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021231603375.png"  style="zoom:50%;" /></p>
<p>可以看到真实数据多样性更强；而few-shot ICL生成数据的多样性比zero-shot ICL生成数据的多样性更强。</p>
<p>相似度是衡量生成数据与真实数据的相似程度，具体来说，对于真实的text，利用Sentence Transformer（<em>all MiniLM-L6-v2</em>）转化为embedding，然后计算和各个生成数据embedding的余弦相似度，取前5个最大的相似度的值来计算平均相似性。实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021231307005.png"  style="zoom:40%;" /></p>
<p>可以看到，用few-shot ICL生成的数据比zero-shot ICL生成的数据，和原有真实数据更加一致。</p>
<h2 id="evaluation-ii-comparison-across-different-task-instances">Evaluation II: Comparison Across Different Task Instances</h2>
<p>作者进一步探究了，利用LLM生成的data训练的模型，是否对于同一任务下，不同主观程度的instance也会有不同的表现？</p>
<p>instance的主观程度同样是利用众包人工标记，多个worker对于某种instance分类结果，判断越不一致，越认为instance的主观性越强。利用多个worker的投票分类结果，可以计算最多的投票分类在所有投票中的占比，作为主观程度的度量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021232135959.png"  style="zoom:50%;" /></p>
<p>上面的度量论文里称作annotation agreement。下面是不同task的annotation agreement平均值：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021232350439.png"  style="zoom:50%;" /></p>
<p>作者在实验时，设定了阈值<span class="math inline">\(\gamma\)</span>，instance的annotation agreement <span class="math inline">\(\alpha_i\)</span>超过一定阈值后，才会被评估。因此阈值gamma越大，代表着剩下的测试实例主观性越弱。实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231021232516131.png"  style="zoom:50%;" /></p>
<p>可以看到，instance的主观性越弱，训练好的model越有可能分类正确。</p>
<p>只在real data上训练的model，也会表现出类似的趋势，但是没有单纯在生成数据上训练的model表现出来的趋势强。这证明了，生成数据的加入，可能要考虑给model带来的bias的影响。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>LLM</category>
        <category>Data Augmentation</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Data Augmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>CapsE</title>
    <url>/kge/CapsE/</url>
    <content><![CDATA[<h1 id="a-capsule-network-based-embedding-model-for-knowledge-graph-completion-and-search-personalization">A Capsule Network-based Embedding Model for Knowledge Graph Completion and Search Personalization</h1>
<p>2019-6-2s</p>
<h2 id="introduction">1 Introduction</h2>
<p>常用的KE模型，比如TransE，Complex，DISTMULT等模型，它们只捕获了三元实体之间的线性联系，没有捕获非线性的联系。</p>
<p>本论文的基础是在capsule networks（CapsNet）Dynamic routing between capsules的基础上，直接应用到knowledge graph triplet上。CPasNet原来是作用于图片上。</p>
<p>论文的理论是处在相同维度下的triplet，同一纬度下的embedding可以通过capsule（each capsule is a group of neurons） network捕获不同的变体。</p>
<span id="more"></span>
<h2 id="the-proposed-capse">2 The proposed CapsE</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200217182118840.png" style="zoom:50%;" /></p>
<p>特点：</p>
<ol type="1">
<li>三元组直接作为一个矩阵进行训练</li>
<li>最后的score function是向量的长度</li>
</ol>
<p>具体请看论文描述</p>
<h2 id="knowledge-graph-completion-evaluation">3 Knowledge graph completion evaluation</h2>
<p>数据集：</p>
<ul>
<li>WN18RR</li>
<li>FB15k-237</li>
</ul>
<p>评估指标：</p>
<ul>
<li>Mean rank（MR）</li>
<li>Mean reciprocal rank (MRR)</li>
<li>Hits@10</li>
</ul>
<p>Embedding 初始化：</p>
<ul>
<li>ConvKB和CapsE都使用了TransE训练好之后的embedding来初始化</li>
<li>对于TransE，在WN18RR数据集下，使用了100-dimensional Glove word embeddings初始化</li>
</ul>
<p>参数设置：</p>
<ul>
<li>初始的KE维度为100</li>
<li>过滤器filter数量的设置在{50，100, 200, 400}</li>
</ul>
<p>关于关系r的分类：</p>
<blockquote>
<p>Following Bordes et al. (2013), for each relation r in FB15k-237, we calculate the averaged number <span class="math inline">\(\eta_s\)</span> of head entities per tail entity and the averaged number <span class="math inline">\(\eta_o\)</span> of tail entities per head entity. If <span class="math inline">\(\eta_s\)</span> &lt;1.5 and <span class="math inline">\(\eta_o\)</span> &lt;1.5, r is categorized one-to-one (1-1). If <span class="math inline">\(\eta_s\)</span> &lt;1.5 and <span class="math inline">\(\eta_o\)</span> ≥ 1.5, r is categorized one-to-many (1-M). If <span class="math inline">\(\eta_s\)</span> ≥ 1.5 and <span class="math inline">\(\eta_o\)</span> &lt;1.5, r is categorized many-to-one (M-1). If <span class="math inline">\(\eta_s\)</span> ≥ 1.5 and <span class="math inline">\(\eta_o\)</span> ≥ 1.5, r is categorized many-to-many (M-M)</p>
</blockquote>
<p>最后得到的结果显示M-M的关系总是最多的</p>
<p>使用filtered设置进行训练</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>CoPER</title>
    <url>/kge/CoPER/</url>
    <content><![CDATA[<h1 id="coper">CoPER</h1>
<p>认为之前的KGE方法将entity embedding和relation embedding之间的交互都局限在additive上。 这篇文章使用relation embedding产生参数，转化entity embedding。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/Screen-Shot-2020-09-25-at-4.22.16-PM.png" /></p>
<span id="more"></span>
<p>首先它指出了之前很多方法对于entity embedding和relation embedding的学习是受限的，比如<span class="math inline">\(w[h;r]\)</span>，这样的方式，无法建模下面的例子。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/Screen-Shot-2020-09-25-at-4.22.09-PM.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/Screen-Shot-2020-09-25-at-4.16.00-PM.png" /></p>
<p>属于additive的方式，无法很好的区分<span class="math inline">\(e_0\)</span>，<span class="math inline">\(e_1\)</span>，<span class="math inline">\(e_2\)</span>，<span class="math inline">\(e_3\)</span></p>
<p>在实现的方法中，它设计了三个不同的产生参数的module，contextual parameter generator (CPG).</p>
<p>Parameter Lookup Table：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/Screen-Shot-2020-09-25-at-4.21.05-PM.png" /></p>
<p>Linear Projection.：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/Screen-Shot-2020-09-25-at-4.22.25-PM.png" /></p>
<p>Multi-Layer Perceptron. ：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/Screen-Shot-2020-09-25-at-4.21.33-PM.png" /></p>
<p>实验中发现，第一种方法效果s都不太好，容易过拟合，而且relation之间没有information sharing。第二中方法和第三种方法更合适，第二中方法适合于更大size的dataset，第三种更适合小一点的dataset。 在ConvE和MINERVA方法的基础上加入了CPG模块，具体看图</p>
<p>需要注意的一点是它使用了新的训练方式，导致ConvE和DISTMULT这些方法的效果远远好于原来的效果，以后可以详细看一下。 优点：和ParamE类似，都是将relation embedding转换到了parameter space中，但是ParamE是完全将模型参数都作为relation embedding，而CoPER是使用某种结构转换relation embedding到参数中，还需要选择在什么地方使用由relation embedding转换过来的parameter。 可以利用或改进的点：可以利用这样的思想，将relation embedding转换为参数，然后和entity embedding进行交互。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>CompGCN</title>
    <url>/kge/CompGCN/</url>
    <content><![CDATA[<h1 id="composition-based-multi-relational-graph-convolutional-networks">COMPOSITION-BASED MULTI-RELATIONAL GRAPH CONVOLUTIONAL NETWORKS</h1>
<h2 id="introduction">1 INTRODUCTION</h2>
<p>原来的CNN, RNN等方法不能直接应用到graph上，因此最近GCN被提出来了。</p>
<p>但是初始的GCN方法主要集中与无向图，最近的针对有向图的方法类如R-GCN，存在over-parameterization问题。</p>
<blockquote>
<p>there is a need for a framework which can utilize KG embedding techniques for learning task-speciﬁc node and relation embeddings.</p>
<p>COMPGCN addresses the shortcomings of previously proposed GCN models by jointly learning vector representations for both nodes and relations in the graph</p>
</blockquote>
<span id="more"></span>
<h2 id="related-work">2 RELATED WORK</h2>
<p>两个方面叙述</p>
<ul>
<li>GCN: 原始的GCN，之后的各种拓展，都在MPNN框架下，本论文提出的也是这样，但是专门为relational data设计过</li>
<li>KE: translational、semantic matching based、neural network based</li>
</ul>
<h2 id="background">3 BACKGROUND</h2>
<h3 id="gcn-on-undirected-graph">GCN on undirected graph</h3>
<p>图的表示形式： <span class="math display">\[
G=(\cal{V},\cal{E},\cal{X})
\]</span> 其中<span class="math inline">\(\cal{X}\)</span>表示所有entity的初始feature，<span class="math inline">\(\cal{X}\in \cal{R}^{ |\cal{V}|\times d_0 }\)</span>。</p>
<p>获取归一化后的self-connection邻接矩阵： <span class="math display">\[
\hat{A}=\tilde{D}^{-\frac{1}{2}}(A+I)\tilde{D}^{-\frac{1}{2}} \\
\tilde{D}_{ii}=\sum_j{(A+I)_{ij}}
\]</span> 某一层的GCN： <span class="math display">\[
H^{k+1}=f(\hat{A}H^kW^k) \\
H^0=\cal{X}
\]</span></p>
<h3 id="gcn-on-directed-graph">GCN on directed graph</h3>
<p>图的表示形式： <span class="math display">\[
G=(\cal{V},\cal{R},\cal{E},\cal{X})
\]</span> <span class="math inline">\(\cal{R}\)</span>表示relation的集合。</p>
<p>这种情况下对于关系数据的处理就存在区别了，基于Encoding sentences with graph convolutional networks for semantic role labeling 中提出的假设，</p>
<blockquote>
<p>information in a directed edge ﬂows along both directions</p>
</blockquote>
<p>因此构造出反向关系inverse relation: <span class="math display">\[
(u,v,r)\in \cal{E}\ \ and\ \ (v,u,r^{-1})\in \cal{E^{-1}}
\]</span> 此时的GCN： <span class="math display">\[
H^{k+1}=f(\hat{A} H^k W^k_r) \\
H^0=\cal{X}
\]</span></p>
<h2 id="compgcn-details">4 CompGCN DETAILS</h2>
<p>图： <span class="math display">\[
G=(\cal{V},\cal{R},\cal{E},\cal{X},\cal{Z}) \\
\cal{X}\in \cal{R}^{ |\cal{V}|\times d_0 } \\
\cal{Z}\in \cal{R}^{ |\cal{R}|\times d_0 }
\]</span> 构造关系： <span class="math display">\[
\cal{E^{&#39;}} = \cal{E}\ \cup\ \{ (v,u,r^{-1}) | (u,v,r)\in \cal{E}\ \}\ \cup\ \{ (u,u,T) | u\in \cal{V} \}
\]</span> embedding更新方式： <span class="math display">\[
h_v^{k+1}=f(\sum_{(u,r)\in \cal{N}_v} W_{\lambda(x)^k}\phi(x_u^k, z_r^k))
\]</span> 其中<span class="math inline">\(\phi\)</span>函数，为了减少参数，可以为下面的三种方式，当然可以拓展为更多的方式： <span class="math display">\[
Sub: \ \phi(x_u, z_r) = x_u - z_r \\
Mult:\ \phi(x_u, z_r) = x_u * z_r \\
Circular-correlation:\ \phi(x_u, z_r) = x_u \star z_r
\]</span> 其中的关系权值矩阵： <span class="math display">\[
W_{dir(r)}= \begin{cases} W_o,\ r\in \cal{R} \\ W_i,\ r\in \cal{R}_{inv} \\ W_S\ r\in \cal{T}(self-loop) \end{cases}
\]</span> 对于关系relation的处理，与KBGAT一样： <span class="math display">\[
z_r^{k+1} = W_{rel}z_r^k \\
W_{rel}\in R^{d_1\times d_0}
\]</span> 在第一层初始的时候，对于relation的定义是bias-vector。 <span class="math display">\[
Z_r = \sum_b^B \alpha_{br}\bold{v}_b \\
\{ \bold{v}_1, \bold{v}_2,\cdots \bold{v}_B \}
\]</span></p>
<h2 id="experimental-setup">5 EXPERIMENTAL SETUP</h2>
<p>进行了下面三个任务：</p>
<ul>
<li>Link Prediction：FB15k-237，WN18RR</li>
<li>Node Classiﬁcation：MUTAG (Node) ， AM</li>
<li>Graph Classiﬁcation：bioinformatics dataset：MUTAG (Graph) ， PTC</li>
</ul>
<h2 id="results">6 RESULTS</h2>
<p>研究了下面四个方面的问题：</p>
<ol type="1">
<li>在link prediction上的效果</li>
<li>选择不同的composite operation效果</li>
<li>模型对于不同数量的relation的数据集的效果</li>
<li>在node和graph classiﬁcation的效果</li>
</ol>
<blockquote>
<p>We ﬁnd that with DistMult score function, multiplication operator (Mult) gives the best performance while with ConvE, circular-correlation surpasses all other operators.</p>
</blockquote>
<p>具体结果略</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>ConvE</title>
    <url>/kge/ConvE/</url>
    <content><![CDATA[<h1 id="convolutional-2d-knowledge-graph-embeddings">Convolutional 2D Knowledge Graph Embeddings</h1>
<p>2018-7-4</p>
<h2 id="introduction">1 Introduction</h2>
<p>第一个利用CNN学习KGE的方法。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200314161529853.png" /></p>
<span id="more"></span>
<p>现在的knowledge graph会存在很多missing links，比如在Freebase和DBpedia中，超过66%的person实体没有到出生地的link。由于在知识图谱当中存在上百万的facts，所以模型的效率和计算代价就需要特别的考虑。</p>
<p>CNN具有能够快速计算的特性，因此可以应用与knowledge graph embedding。</p>
<h2 id="convolutional-2d-knowledge-graphs-embeddings">2 Convolutional 2D Knowledge Graphs Embeddings</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200314161529853.png" /></p>
<p>首先对<span class="math inline">\(e_1\in R^k\)</span>和<span class="math inline">\(r_r\in R^k\)</span>的一维的embedding进行转换为2维的形式： <span class="math display">\[
[\bar{e_s}; \bar{r_r}] \\
\bar{e_s},\ \bar{r_r}\in R^{k_w\times k_h} \\
k=k_w\times k_h
\]</span> 即： <span class="math display">\[
\begin{pmatrix} 
a &amp; a &amp; a\\ 
b &amp; b &amp; b\\
a &amp; a &amp; a\\
b &amp; b &amp; b\\
\end{pmatrix}
\]</span> 改变为这种两个embedding相间的格式。</p>
<p>之后进行卷积操作： <span class="math display">\[
relu([\bar{e_s}; \bar{r_r}] \star \cal{w})
\]</span> 然后变回一维矩阵 <span class="math display">\[
vec(relu([\bar{e_s}; \bar{r_r}] \star \cal{w}))
\]</span> 过一个全连接层， <span class="math display">\[
relu(vec(relu([\bar{e_s}; \bar{r_r}] \star \cal{w}))W)
\]</span> 最后和目标embedding相乘，就得到了score。 <span class="math display">\[
\psi_r(e_s,e_o)=relu(vec(relu([\bar{e_s}; \bar{r_r}] \star \cal{w})) W)e_o
\]</span> 训练loss $$</p>
<p>$$</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>ConvKB</title>
    <url>/kge/ConvKB/</url>
    <content><![CDATA[<h1 id="a-novel-embedding-model-for-knowledge-base-completion-based-on-convolutional-neural-network">A Novel Embedding Model for Knowledge Base Completion Based on Convolutional Neural Network</h1>
<p>2018-3-13 ConvKB</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200219181643488.png" /></p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>知识图谱可以为knowledge base/knowledge graph</p>
<p>知识图谱在很多领域都有重要的作用，但是在open world assumion下，知识图谱本身是不完整的，不能包含所有实际存在的三元组。</p>
<p>在这种情况下，预测(h,r,t)是否valid就有意义了，这就是link prediction或者叫做knowledge completion。</p>
<p>之前有人提出过ConvE（2018），首个将CNN应用到knowledge completion中的model。</p>
<p>ConvKB就是在其基础上发展起来的。</p>
<p>CNN的意义：</p>
<blockquote>
<p>CNN learns non-linear features to capture complex relationships with a remarkably less number of parameters compared to fully connected neural networks.</p>
</blockquote>
<p>总结一下CNN相比fully connected neural network优势：</p>
<ul>
<li>更少的参数</li>
<li>能够捕获复杂的，非线性的关系</li>
</ul>
<h2 id="proposed-convkb-model">2 Proposed ConvKB model</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200219181643488.png" /></p>
<p>首先三元组组成矩阵 <span class="math display">\[
A=[v_h,v_r,v_t]\in R^{k\times 3}
\]</span> 之后经过一个简单的CNN层， <span class="math display">\[
v_i=g(w\cdot A_{i;}+b) \\
w\in R^{1\times k}
\]</span> 一个filter <span class="math inline">\(w\)</span>得到一个<span class="math inline">\(k\times 1\)</span>维的feature map</p>
<p>共有<span class="math inline">\(\Gamma\)</span>个filter，通过concat得到<span class="math inline">\(R^{\Gamma k\times 1}\)</span>维的向量，</p>
<p>最后与一个权值矩阵<span class="math inline">\(W\in R^{\Gamma k\times 1}\)</span>相乘，得到最终的结果score。score function衡量不相似的程度，越小越相似。</p>
<p>训练时候的损失函数是log-likehood损失函数。</p>
<h2 id="experiments">3 Experiments</h2>
<p>实验数据集：</p>
<ul>
<li>WN18RR</li>
<li>FB15k237</li>
</ul>
<p>都是对于WN18和FB15k去除可逆关系之后的结果</p>
<p>sample corrupt triplets的时候采用了Bernoulli trick</p>
<p>embedding初始化使用TransE训练出来的结果</p>
<p>filter情况下的数据集进行训练</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>ConvR</title>
    <url>/kge/ConvR/</url>
    <content><![CDATA[<h1 id="adaptive-convolution-for-multi-relational-learning">Adaptive Convolution for Multi-Relational Learning</h1>
<p>2019-6</p>
<h2 id="introduction">1 Introduction</h2>
<blockquote>
<p>Learning with multi-relational data plays a pivotal role in many application domains, ranging from social networks or recommender systems to large-scale knowledge bases (KBs)</p>
</blockquote>
<p>ConvR的思想是从relation中构造filter，然后卷积于subject embedding，最后投影，与object embedding做点积。</p>
<p>这样的做法就导致了ConvR的另一个优势，减少了参数的数量。</p>
<span id="more"></span>
<h2 id="adaptive-convolution-on-multi-relational-data">3 Adaptive Convolution on Multi-relational Data</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200330213550962.png" /></p>
<p>对于三元组<span class="math inline">\((s, r, o)\)</span>，首先将<span class="math inline">\(e_s\)</span> reshape为2D矩阵， <span class="math display">\[
e_s\in R^{d_e}\Rightarrow S\in R^{d_e^h,\ d_e^w}
\]</span> 对于关系<span class="math inline">\(r\)</span>，先分割为<span class="math inline">\(c\)</span>段： <span class="math display">\[
r^{(1)},\cdots,r^{(c)}
\]</span> 然后每个<span class="math inline">\(r^{(l)}\)</span> reshape为2D的矩阵作为filter <span class="math display">\[
R^{l}\in R^{h,\ w}
\]</span> 对于<span class="math inline">\(c\)</span>个filter，在<span class="math inline">\(S\)</span>上卷积，得到<span class="math inline">\(c\)</span>个feature map。</p>
<p>将<span class="math inline">\(c\)</span>个feature map先展开为一维，然后stack到一起，得到单向量<span class="math inline">\(e_c\)</span>。</p>
<p>最后过一个全连接层，和尾结点计算点积 <span class="math display">\[
\psi(s,r,o)=f(We_c+b)e_o
\]</span> 训练方式与ConvE保持一致。</p>
<p>比起ConvE的好处就是结果更好，参数更少，空间复杂度降低。</p>
<p>ConvR使用三个dropout防过拟合：</p>
<ul>
<li>在reshape subject representation时</li>
<li>在卷积得到feature map之后</li>
<li>在经过全连接之后</li>
</ul>
<h2 id="experiments">4 Experiments</h2>
<p>使用了四个数据集：</p>
<ul>
<li>FB15k</li>
<li>WN18</li>
<li>FB15K-237</li>
<li>WN18RR</li>
</ul>
<p>实现的超参：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200330213445418.png" /></p>
]]></content>
  </entry>
  <entry>
    <title>GRL</title>
    <url>/kge/GRL/</url>
    <content><![CDATA[<h1 id="generalized-relation-learning-with-semantic-correlation-awareness-for-link-prediction">Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction</h1>
<p>AAAI 2021</p>
<p>作者提出了一种能够捕获KG中relation的semantic correlations的方法，叫做GRL（Generalized Relation Learning）。这个方法在一般的embedding方法之后，利用输出的embedding评估relation之间的相似程度。</p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p><strong>motivation</strong>：作者认为目前用于link prediction的基于embedding方法存在两个问题：</p>
<ol type="1">
<li>忽略了对于few-shot relation的学习，大多数方法假设不同relation有足够的实例进行学习</li>
<li>无法学习zero-shot relation</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629162808164.png" style="zoom:50%;" /></p>
<p>根据调研的情况来看，大多数的relation是few-shot relation。</p>
<p><strong>method</strong>：作者利用many-shot relation来为相似的few-shot和zero-shot relation提供信息。主要做法是提出GRL，学习relation之间的相关性correlation。</p>
<h2 id="method">Method</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629163143120-20210629200856777.png" style="zoom:50%;" /></p>
<p>首先，通过一个base model获取embedding，比如利用ConvE或者DistMult。</p>
<p>GRL详细的说有三个module，</p>
<p>在Attention module中，首先捕获头实体与尾实体之间可能存在的潜在relation信息，即学习一个头尾实体的联合表示joint vector <span class="math inline">\(\mathbf{j}\)</span></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629163754371.png" style="zoom:50%;" /></p>
<p>然后，作者使用了一个Relation Memory Block保存所有的relation信息，<span class="math inline">\(K\)</span>就是所有relation的数量。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629163911233.png" style="zoom:50%;" /></p>
<p>之后，作者希望从这个Relation Memory Block导出能够丰富<span class="math inline">\(\mathbf{j}\)</span>的信息，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629164240642.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629164355894.png" style="zoom:50%;" /></p>
<p>这一步实际就是捕获了不同relation之间的correlation，需要注意的是对于在<span class="math inline">\(\mathbf{M}\)</span>中的预测目标<span class="math inline">\(\mathbf{r}\)</span>，会被mask为0。<span class="math inline">\(\alpha_{sim}\)</span>就是joint vector <span class="math inline">\(\mathbf{j}\)</span>和不同relation之间的相似程度。这样，利用<span class="math inline">\(\alpha_{sim}\)</span>，在遭遇zero-shot relation时，可以选择最相似的relation来替代zero-shot relation。</p>
<p>在Fusion module中，为了确定如何自适应的混合<span class="math inline">\(\mathbf{j}\)</span>和<span class="math inline">\(\mathbf{rk}\)</span>，使用了一个类似GRU的方法，计算一个weight scalar。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629164658959.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629164715132.png" style="zoom:50%;" /></p>
<p>最后，在classifier module，预测真实的relation：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629165004731.png" style="zoom:50%;" /></p>
<p>其中，<span class="math inline">\(W_c\in \mathbb{R}^{dim\times K}\)</span>，计算loss</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629165133409.png" style="zoom:50%;" /></p>
<p>最终，这个loss和base model的loss混合到一起</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210629165254620.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KRL</category>
      </categories>
      <tags>
        <tag>KG</tag>
      </tags>
  </entry>
  <entry>
    <title>CrossE</title>
    <url>/kge/CrossE/</url>
    <content><![CDATA[<h1 id="interaction-embeddings-for-prediction-and-explanation-in-knowledge-graphs">Interaction Embeddings for Prediction and Explanation in Knowledge Graphs</h1>
<p>2019-3-12日发表</p>
<p>设计了一种有效的，浅层的KGE方法CrossE，能够让entity embedding和relation embedding进行更多的交互。</p>
<span id="more"></span>
<h2 id="abstract">Abstract</h2>
<p>在知识图谱embedding的现有技术当中，Crossover interactions信息没有被利用过，本文提出的CrossE就是利用这种信息，并且进行了link prediction和prediction explanation的实验。</p>
<h2 id="introduction">1. INTRODUCTION</h2>
<p>几个出名的知识图谱Yago，WordNet，Freebase都是以<span class="math inline">\((h, r, t)\)</span>表示的三元组。</p>
<blockquote>
<p>Knowledge graph embedding (KGE) learns distributed representations [11] for entities and relations, called entity embeddings and relation embeddings.</p>
</blockquote>
<p>三种知识图谱embedding类型，</p>
<ul>
<li>tensor factorization based RESCAL ,</li>
<li>translation-based TransE ,</li>
<li>neural tensor network NTN</li>
</ul>
<p>但是这些模型都没有使用过Crossover interactions。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200213103537464.png" alt="image-20200213103537464" /><figcaption>image-20200213103537464</figcaption>
</figure>
<p>Crossover interactions包括interaction from relations to entities和interactions from entities to relations.</p>
<p>例如在上图中预测(X, isFatherOf, ? )</p>
<p>那么，与关系isFatherOf有关的实体只有Y，S这些与X是家庭关系的实体，与Q，T实体无关，这就叫做interaction from relations to entities，根据关系选择实体</p>
<p>同时，关系isFatherOf有两条途径，但头结点实体是X，所以只能选择X作为头结点的关系，这叫做interactions from entities to relations.</p>
<p>因此提出了CrossE：</p>
<ol type="1">
<li>generate interaction embeddings <span class="math inline">\(h_I\)</span> for head entity <span class="math inline">\(h\)</span></li>
<li>generate interaction embeddings <span class="math inline">\(r_I\)</span> for relation <span class="math inline">\(r\)</span></li>
<li>combine interaction embeddings <span class="math inline">\(h_I\)</span> and <span class="math inline">\(r_I\)</span> together</li>
<li>compare the similarity of combined embedding with tail entity embedding<span class="math inline">\(t\)</span></li>
</ol>
<h2 id="related-work">2. Related work</h2>
<p>不考虑利用了额外信息进行embedding的模型，剩下的模型从entity是否表示为统一的形式划分，</p>
<ul>
<li><p>KGEs with general embeddings：</p>
<blockquote>
<p>Existing embedding methods with general embeddings all represent entities as low-dimensional vectors and relations as operations that combine the representation of head entity and tail entity.</p>
</blockquote>
<p>典型模型包括：TransE, RESCAL，DistMult，ComplEx</p>
<p>这些模型都没有考虑在不同情况下embedding应该是不同的，没有考虑crossover interaction</p></li>
<li><p>KGEs with multiple embeddings：</p>
<blockquote>
<p>Some KGEs learn multiple embeddings for entities or relations under various considerations.</p>
</blockquote>
<p>比如：Structured Embedding (SE)（每个关系有两个矩阵），ORC（每个entity有head embedding和tail embedding），TransH，TransR等</p>
<p>这些模型，relation的embedding是general的，只考虑了relation-&gt;entity的interaction</p></li>
</ul>
<h2 id="crosse-model-description">3. CrossE: MODEL DESCRIPTION</h2>
<p>CrossE最大的创新就在于考虑了新的embedding内容，同时没有增加过多的参数。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200213173128411.png" alt="image-20200213173128411" /><figcaption>image-20200213173128411</figcaption>
</figure>
<p>初始定义：</p>
<ul>
<li><span class="math inline">\(E \in R^{n_e \times d}, R \in R^{n_r \times d}, C \in R^{n_r \times d}\)</span>分别表示所有实体，关系和interaction matrix</li>
<li><span class="math inline">\(x_h, x_r, x_t\)</span>分别表示(h, r, t)的one-hot形式</li>
</ul>
<p>对于一个三元组(h, r, t)进行预测的顺序如下：</p>
<h3 id="获取general-embedding">3.1 获取general embedding</h3>
<p><span class="math display">\[
h=x_h^T E,\ r=x_r^T R,\ t=x_t^T E
\]</span></p>
<h3 id="interaction-embedding-for-entities.">3.2 Interaction Embedding for Entities.</h3>
<p>对于头结点h， <span class="math display">\[
h_I = c_r \circ h \\
c_r = x_r^TC
\]</span> 其中的<span class="math inline">\(\circ\)</span>是Hadamard product, an element-wise operator</p>
<h3 id="interaction-embedding-for-relations">3.3 Interaction Embedding for Relations</h3>
<p>对于关系r，模型来自头结点的信息， <span class="math display">\[
r_I = h_I \circ r
\]</span></p>
<h3 id="combination-operator">3.4 Combination Operator</h3>
<p>将前面的两个基于interaction的embedding联合起来， <span class="math display">\[
q_{hr}=tanh(h_I+r_I+b)
\]</span></p>
<h3 id="similarity-operator">3.5 Similarity Operator</h3>
<p>计算最终的相似度， <span class="math display">\[
f(h, r, t)=\sigma(q_{hr}t^T)=\sigma(tanh(c_r\circ h+c_r\circ h \circ r+b )t^T)
\]</span> 最终的loss function使用交叉熵。</p>
<h2 id="explanations-for-predictions">4 EXPLANATIONS FOR PREDICTIONS</h2>
<p>在知识图谱的explanation：</p>
<ul>
<li><p>在知识图谱中对于(h, r, t)可以成立的explanation是指从h-&gt;t的路径</p></li>
<li><p>对于一个explanation，应该有对应的一个或多个support，在这篇论文当中，explanation的support就是现存的知识图谱中相似结构，如下图所示。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200213203729321.png" alt="image-20200213203729321" /><figcaption>image-20200213203729321</figcaption>
</figure></li>
</ul>
<p>寻找explanation的步骤：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200213204130795.png" alt="image-20200213204130795" /><figcaption>image-20200213204130795</figcaption>
</figure>
<p>详细的请参考论文</p>
<h2 id="experimental-evaluation">5 EXPERIMENTAL EVALUATION</h2>
<p>略</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>HAKE</title>
    <url>/kge/HAKE/</url>
    <content><![CDATA[<h1 id="learning-hierarchy-aware-knowledge-graph-embeddings-for-link-prediction">Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction</h1>
<p>2019-12-15 AAAI 2020</p>
<p>Hierarchy-Aware Knowledge Graph Embeddings（HAKE）就是不增加额外的信息，利用知识图谱的语义层级建模。</p>
<p>HAKE为了区分所有的实体，将实体嵌入分为两部分：</p>
<ul>
<li>不同的语义层级下的实体，使用极坐标的模长/极径（modulus）表示</li>
<li>同一语义层级下的不同实体，使用极坐标的相位/极角（phase）表示</li>
</ul>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>问题：目前的模型大多没有对于语义层级关系（semantic hierarchy）进行建模</p>
<p>解决方案：引入极坐标系（polar coordinate system），</p>
<ul>
<li>具有更高语义层级的实体具有更小的半径</li>
<li>同一语义层级的实体具有不同的角度</li>
</ul>
<p>知识图谱在是一系列的事实的集合，是语义网络的拓展。</p>
<p>现在的知识图谱可以包含数以亿计的事实（fact），但是知识图谱不可能包含所有实际中存在的事实。因此，链路预测（link prediction）/知识图谱补全（knowledge base completion）成为了研究的一个方向。即如何根据已有的事实，预测可能存在的事实。</p>
<p>受到词嵌入的启发，知识图谱嵌入（knowgraph graph embedding）——将知识图谱映射到离散的表示形式，就成为了研究热点。</p>
<blockquote>
<ul>
<li>知识图谱嵌入的应用方向很多，不只是链路预测，还包括实体分类等等。</li>
<li>知识图谱嵌入也只是图嵌入的一个方向</li>
<li>链路预测对于其它的图（社交网络等），同样成立</li>
</ul>
</blockquote>
<p>之前的知识图嵌入的工作主要集中在建模关系的特性：</p>
<ul>
<li>对称/不对称</li>
<li>可逆/不可逆</li>
<li>组合</li>
</ul>
<p>在知识图谱当中存在语义的层级，比如在wordnet知识图谱里，[arbor/cassia/palm, hypernym, tree]，tree的语义层级要高于[hypernym, tree]。对于如何利用知识图谱的语义特性的工作较少，并且很多要求要增加额外的信息，例如额外的文本描述，来建模知识图谱的层级关系。</p>
<p>Hierarchy-Aware Knowledge Graph Embeddings（HAKE）就是不增加额外的信息，利用知识图谱的语义层级建模。</p>
<p>HAKE为了区分所有的实体，将实体嵌入分为两部分：</p>
<ul>
<li>不同的语义层级下的实体，使用极坐标的模长/极径（modulus）表示</li>
<li>同一语义层级下的不同实体，使用极坐标的相位/极角（phase）表示</li>
</ul>
<h2 id="the-proposed-hake">2 The Proposed HAKE</h2>
<p>HAKE的模型图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200614173832367.png" alt="image-20200614173832367" /><figcaption>image-20200614173832367</figcaption>
</figure>
<h3 id="the-modulus-part">2.1 The modulus part</h3>
<p>极坐标的极径建模实体的语义层级。</p>
<p>知识图谱中的实体可以组成一棵树，越往上的实体语义层级越高，越往下的语义层级越低。使用模量/极径表示实体在语义树中的深度，具有越高的语义层级的实体有更小的深度，更小的模量。</p>
<p>使用<span class="math inline">\(e_m\)</span>表示嵌入的模量部分modulus part，则有： <span class="math display">\[
h_m\circ r_m=t_m,\  where\ h_m,\ t_m\in R^k,\ r_m \in R^k_{+}
\]</span> 距离函数为： <span class="math display">\[
d_{r,m}(h_m, t_m)=||h_m\circ r_m - t_m||_2
\]</span> 要注意这里限制了<span class="math inline">\(r_m\)</span>必须在正数域下，这是因为正数的<span class="math inline">\(r_m\)</span>不会改变<span class="math inline">\(h_m\)</span>的符号，这是因为对于正样本<span class="math inline">\((h,r,t)\)</span>，<span class="math inline">\(h_m\)</span>与<span class="math inline">\(t_m\)</span>倾向于有相同的符号，<span class="math display">\[d_{r,m}(h_m,t_m)\]</span>更小，而负样本<span class="math inline">\((h,r,t^{&#39;})\)</span>更难保证同一纬度下的<span class="math inline">\(h_m\)</span>与<span class="math inline">\(t_m\)</span>倾向有相同的符号，导致<span class="math inline">\(d_{r,m}(h_m,t_m^{&#39;})\)</span>更大。</p>
<p>这样的<span class="math inline">\(r_m\)</span>成为了一个缩放操作，对于<span class="math inline">\((h,r,t)\)</span>，</p>
<ol type="1">
<li>如果h的层级比t更大，r倾向于&gt;1</li>
<li>如果h的层级与t一样，r倾向于=1</li>
<li>如果h的层级比t更小，r倾向于&lt;1</li>
</ol>
<h3 id="the-phase-part">2.2 The phase part</h3>
<p>进一步区分同一层级下的不同实体。</p>
<p>使用<span class="math inline">\(e_p\)</span>表示相位部分， <span class="math display">\[
(h_p+r_p)\ mod\ 2\pi = t_p,\ where\ h_p,t_p,r_p\in [0, 2\pi)^k
\]</span> 距离函数： <span class="math display">\[
d_{r,p}(h_p,t_p)=|| \sin{((h_p + r_p - t_p)/2)} ||_1
\]</span> 除以2是保证<span class="math inline">\((h_p + r_p - t_p)/2\in [0, 2\pi)^k\)</span>，上面的式子和pRotatE中的一样。</p>
<h3 id="loss-function">2.3 Loss Function</h3>
<p>经过上面的两部分，获得总的嵌入： <span class="math display">\[
e=[e_m;e_p]
\]</span> 之后计算<span class="math inline">\((h,r,t)\)</span>存在概率的得分： <span class="math display">\[
f_r(h,t)=-(d_{r,m}(h,t)+\lambda d_{r,p}(h,t))
\]</span> 使用负采样的损失函数： <span class="math display">\[
L=-log\sigma(\gamma-f_r(h,t))-\sum_{i=1}^n p(h^{&#39;}_i, r, t^{&#39;}_i) log\sigma(f_r(h^{&#39;}_i,t^{&#39;}_i)-\gamma) \\
p(h^{&#39;}_j, r, t^{&#39;}_j) =\frac{exp\alpha f_r(h^{&#39;}_j, t^{&#39;}_j)}{\sum_i f_r(h^{&#39;}_i, t^{&#39;}_i)}
\]</span></p>
<h2 id="experiments-and-analysis">3 Experiments and Analysis</h2>
<h3 id="main-results">3.1 Main Results</h3>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200614173938559.png" alt="image-20200614173938559" /><figcaption>image-20200614173938559</figcaption>
</figure>
<p>三个数据集：WN18RR, FB15k-237, YAGO3-10</p>
<p>为了说明phase part部分的作用，只保留modulus part，作为模型<strong>ModE</strong>： <span class="math display">\[
d_{r,m}(h_m, t_m)=||h_m\circ r_m - t_m||_2\  where\ h_m,\ t_m\ r_m \in R^k
\]</span></p>
<h3 id="analysis-on-relation-embeddings">3.2 Analysis on Relation Embeddings</h3>
<p>首先，说明HAKE能否捕获不同语义层级的信息。</p>
<p>只使用modulus part，下图是表示不同语义层级的关系embedding的直方图，横轴是大小，纵轴是密度</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200614174230314.png" /></p>
<p>其中，</p>
<ul>
<li>a和b是尾实体比头实体的关系语义层级高，结果显示关系embedding大部分元素&lt;1</li>
<li>c和d是尾实体比头实体的关系语义层级一样，结果显示关系embedding大部分元素=1</li>
<li>e和f是尾实体比头实体的关系语义层级低，结果显示关系embedding大部分元素&gt;1</li>
</ul>
<p>同样可以看出HAKE比ModE的方差更小，说明HAKE的建模更准确。</p>
<p>之后，说明phase part的作用，比较c和d的关系embedding的phase part</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200614175049088.png" /></p>
<p>上述结果说明有很多关系嵌入的phase part元素分布在<span class="math inline">\(\pi\)</span>，导致<span class="math inline">\(h_p\)</span>和<span class="math inline">\(t_p\)</span>不一样，可以区分同一语义层级的不同实体。</p>
<h3 id="analysis-on-entity-embeddings">3.3 Analysis on Entity Embeddings</h3>
<p>因为是使用极坐标来表示语义层级，可以把实体embedding在极坐标中可视化。</p>
<p>实体embedding大小为1000，选500个维度画在二维极坐标中，对原始的极径使用对数函数，来更好的展示结果。由于所有模的值都小于1，因此在图中，更大的直径表示更小的模值，即更高的语义层级。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200614181125392.png" /></p>
<p>图中显示的结果说明HAKE比RotatE能够更好的捕获层级关系。</p>
<h3 id="ablation-studies">3.4 Ablation Studies</h3>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200614180811928.png" alt="image-20200614181125392" /><figcaption>image-20200614181125392</figcaption>
</figure>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>HoLE</title>
    <url>/kge/HoLE/</url>
    <content><![CDATA[<h1 id="hole-holographic-embeddings-of-knowledge-graphs">HoLE: Holographic Embeddings of Knowledge Graphs</h1>
<p>AAAI 2016</p>
<p>这篇文章提出了holographic embeddings (HOLE)，来学习KG的compositional vector space representations。</p>
<span id="more"></span>
<p><strong>motivation</strong>：However, existing embedding models that can capture rich interactions in relational data are often limited in their scalability. Vice versa, models that can be computed efﬁciently are often considerably less expressive.</p>
<p><strong>methods</strong>：直接从subject entity embedding和object entity embedding中，使用circular correlation获得新的embedding，称作holograph embedding，然后使用这个holograph embedding与relation embedding做点积，得到预测概率。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210418181121701.png" style="zoom:50%;" /></p>
<p><strong>理解circular correlation</strong>：</p>
<p>它是一种捕获feature interaction的方法，首先我们来看以下几个不同的捕获特征交互的方法。</p>
<ol type="1">
<li>Tensor Product</li>
</ol>
<p><span class="math display">\[
[\mathbf{a}\ \otimes\ \mathbf{b}]_{ij} = \mathbf{a}_{i}\mathbf{b}_j \in \mathbb{R}^{d^2}
\]</span></p>
<p>形成了一个矩阵。这样捕获的feature的特点是获得了所有的pairwise multiplicative interactions between the features of <span class="math inline">\(\mathbf{a}\)</span> and <span class="math inline">\(\mathbf{b}\)</span>。</p>
<p>从直观上来看，如果是来自<span class="math inline">\(\mathbf{a}\)</span> 和<span class="math inline">\(\mathbf{b}\)</span>的同时起作用时，这样的方法比较好。它能够用来捕获<em>通用，共有</em>的特征，例如a和b是自由人和自由党，<em>liberal persons are typically members of liberal parties</em>，这样的事实。</p>
<blockquote>
<p>Intuitively, a feature in the tuple representation a ⊗ b is “on” (has a high absolute magnitude), if and only if the corresponding features of both entities are “on”</p>
</blockquote>
<p>这样的方法在RESCAL和NTN，DistMult中都得到了使用。</p>
<p>缺点在于（1）计算量相对较大（2）无法捕获独立的特征</p>
<ol start="2" type="1">
<li>Concatenation, Projection, and Non-Linearity</li>
</ol>
<p>这是最常见的方法，对于向量输入<span class="math inline">\(\mathbf{a}\)</span> 和<span class="math inline">\(\mathbf{b}\)</span>，先拼接，然后linear projection，最后经过一层non-linearity function。 <span class="math display">\[
f(W[\mathbf{a};\mathbf{b}])
\]</span> 这种方法捕获的特征是如果有特征至少在<span class="math inline">\(\mathbf{a}\)</span> 和<span class="math inline">\(\mathbf{b}\)</span>中起到作用。</p>
<blockquote>
<p>Intuitively, a feature in the tuple representation W(a ⊕ b) is “on” if at least one of the corresponding features is “on”.</p>
</blockquote>
<p>缺点是对于<span class="math inline">\(\mathbf{a}\)</span> 和<span class="math inline">\(\mathbf{b}\)</span>没有直接的交互。</p>
<ol start="3" type="1">
<li>Circular Convolution</li>
</ol>
<p><span class="math display">\[
[\mathbf{a}\ *\ \mathbf{b}]_{k} = \sum_{i=0}^{d-1} a_i b_{k-i\ mod\ d}
\]</span></p>
<p>将<span class="math inline">\(\mathbf{b}\)</span>反转，然后与<span class="math inline">\(\mathbf{a}\)</span>进行卷积。</p>
<ol start="4" type="1">
<li>Circular Correlation</li>
</ol>
<p><span class="math display">\[
[\mathbf{a}\ \star\ \mathbf{b}]_{k} = \sum_{i=0}^{d-1} a_i b_{k+i\ mod\ d}
\]</span></p>
<p><span class="math inline">\(\mathbf{b}\)</span>不需要反转，然后与<span class="math inline">\(\mathbf{a}\)</span>进行卷积。</p>
<p>一个图示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210418184909978.png" style="zoom:50%;" /></p>
<p>从这个图能够看出来，Circular Correlation可以看做是tensor dot的一种压缩方式，它的输出结果的每一维都是tensor dot结果的一部分。</p>
<p>它与Circular Convolution的区别：</p>
<ul>
<li>Non Commutative：对于Circular Convolution，<span class="math inline">\(\mathbf{a}\ *\ \mathbf{b} = \mathbf{b}\ *\ \mathbf{a}\)</span>，但是对于Circular Correlation，<span class="math inline">\(\mathbf{a}\ \star\ \mathbf{b} \not= \mathbf{b}\ \star\ \mathbf{a}\)</span>。</li>
<li>Similiarity Component：在计算Circular Correlation的0维输出的时候，实际是在计算<span class="math inline">\(\mathbf{a}\)</span> 和<span class="math inline">\(\mathbf{b}\)</span>的相似程度。</li>
</ul>
<p>它与Circular Convolution的联系： <span class="math display">\[
\mathbf{a}\ \star\ \mathbf{b} = \tilde{\mathbf{a}}\ *\ \mathbf{b}
\]</span> 其中，<span class="math inline">\(\tilde{\mathbf{a}}\)</span>是<span class="math inline">\(\mathbf{a}\)</span>的involution，<span class="math inline">\(\tilde{\mathbf{a}}_i=\mathbf{a}_{-i\ mod\ d}\)</span></p>
<p>为什么会想到使用Circular Correlation？</p>
<p>这个问题需要回归到题目 Holographic，作者受到基于Associative Memory的holographic models的启发。</p>
<p>在holographic reduced representations方法中，使用circular convolution来store <span class="math inline">\(\mathbf{a}\)</span> 和<span class="math inline">\(\mathbf{b}\)</span>的关联信息： <span class="math display">\[
\mathbf{m} = \mathbf{a}\ *\ \mathbf{b}
\]</span> <span class="math inline">\(\mathbf{m}\)</span>保存了memory，然后，使用circular correlation来retrieve和 <span class="math inline">\(\mathbf{a}\)</span> 相关的信息： <span class="math display">\[
\mathbf{b}^\prime = \mathbf{a}\ \star\ \mathbf{m} = \mathbf{a}\ \star\  (\mathbf{a}\ *\ \mathbf{b} )= \mathbf{b} * (\mathbf{a}\ \star\ \mathbf{a})
\]</span> 使用<span class="math inline">\(\mathbf{b}^\prime\)</span>可以与所有的候选<span class="math inline">\(\mathbf{b}\)</span>求相似度。</p>
<p>因此，这个问题作者类比到了KGE，<span class="math inline">\(\mathbf{m}\)</span>类比到<span class="math inline">\(\mathbf{e}_o\)</span>，<span class="math inline">\(\mathbf{a}\)</span>类比到<span class="math inline">\(\mathbf{e}_s\)</span>，<span class="math inline">\(\mathbf{b}\)</span>类比到<span class="math inline">\(\mathbf{r}_p\)</span>。</p>
<p>对于HoLE，Circular Correlation就是用来retrieve stored in <span class="math inline">\(\mathbf{e}_o\)</span>，然后与所有的候选<span class="math inline">\(\mathbf{r}_p\)</span>求相似度。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
      <tags>
        <tag>KGE</tag>
      </tags>
  </entry>
  <entry>
    <title>KBGAT</title>
    <url>/kge/KBGAT/</url>
    <content><![CDATA[<h1 id="learning-attention-based-embeddings-for-relation-prediction-in-knowledge-graphs">Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</h1>
<p>2019-6-4</p>
<p>将GAT应用到KG上。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<blockquote>
<p>Our architecture is an encoder-decoder model where our generalized graph attention model and ConvKB (Nguyen et al., 2018) play the roles of an encoder and decoder, respectively.</p>
</blockquote>
<p>CNN-based和translational-based的模型单独的处理triplet，没有考虑到KG当中某个entity附近的丰富的语义信息。</p>
<p>本论文在GAT的基础上改进。</p>
<blockquote>
<p>To the best of our knowledge, we are the ﬁrst to learn new graph attention based embeddings that speciﬁcally target relation prediction on KGs.</p>
</blockquote>
<h2 id="our-approach">3 Our Approach</h2>
<p>和之前的GAT模型比较起来，用于知识图谱的话需要考虑relation。</p>
<p>假设每一层的输入包括两个矩阵，entity matrix和relation matrix <span class="math display">\[
H\in N_e\times T \\
G\in N_r\times P
\]</span> 每一层的输出为： <span class="math display">\[
H^{&#39;}\in N_e\times T^{&#39;} \\
G^{&#39;}\in N_r\times P^{&#39;}
\]</span></p>
<h3 id="attention">3.1 Attention</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200220112116226.png" style="zoom:50%;" /></p>
<p>对于一个以<span class="math inline">\(e_i\)</span>为顶点的edge (i, j, k)，应该能够传播给<span class="math inline">\(e_i\)</span>一个embedding： <span class="math display">\[
c_{ijk}=W_1[h_i][h_k][g_j]
\]</span> 接下来计算对应的attention value。 <span class="math display">\[
b_{ijk}=LeakRelu(W_2c_{ijk}) \\
\alpha_{ijk}=softmax(b_{ijk})
\]</span> 之后进行weighted sum就可以了，neighbour指的是某个的状态 <span class="math display">\[
h_i^{&#39;}=\sigma(\sum_{j\in N_i}\sum_{k\in R_{ij}}\alpha_{ijk}c_{ijk})
\]</span></p>
<p>但类似与GAT中，使用multihead attention机制，在实现的时候作者并不是使用了<span class="math inline">\(\sigma\)</span>，而是使用<span class="math inline">\(elu\)</span>函数。 <span class="math display">\[
h_i^{&#39;}=\lVert_{m=1}^{M} \sigma(\sum_{j\in N_i}\sum_{k\in R_{ij}}\alpha_{ijk}^{m} c_{ijk}^{m})
\]</span> 在这一层传入下一层的时候，作者实现中加了一个dropout层，防止过拟合。</p>
<p>但是在最后一层，就不使用concate操作了， <span class="math display">\[
h_i^{&#39;}=\sigma(\frac{1}{M} \sum_{m=1}^M \sum_{j\in N_i} \sum_{k\in R_{ij}} \alpha_{ijk}^{m} c_{ijk}^{m})
\]</span> 最后一层的输出记作<span class="math inline">\(H^f \in N_e \times T^{f}\)</span></p>
<h3 id="对于关系的处理">3.2 对于关系的处理</h3>
<p>对于输入的<span class="math inline">\(G\)</span>，前面获得的<span class="math inline">\(h_i^{&#39;}\)</span>只是针对实体i的，所以关系<span class="math inline">\(G\)</span>的变换是直接进行线性转换。 <span class="math display">\[
G^{&#39;}=GW^R \\
W^R\in R^{P\times P^{&#39;}}
\]</span></p>
<h3 id="保留原来的entity-embedding">3.3 保留原来的entity embedding</h3>
<p>在最后一层，加上原来的entity embedding。 <span class="math display">\[
H^{&#39;&#39;}=W^EH + H^f
\]</span></p>
<h3 id="training-objective">3.4 Training Objective</h3>
<p>hinge-loss： <span class="math display">\[
L(\Omega)=\sum_{t_{ij\in S}}\sum_{t_{ij}^{&#39;}\in S^{&#39;}} max(d_{ij}-d_{ij}^{&#39;}+\gamma,\ 0)
\]</span></p>
<h3 id="decoder">3.5 Decoder</h3>
<p>使用ConVKB作为decoder</p>
<h2 id="experiments-and-results">4 Experiments and Results</h2>
<p>数据集：</p>
<ul>
<li>WN18RR (Dettmers et al., 2018),</li>
<li>FB15k-237 (Toutanova et al., 2015),</li>
<li>NELL-995 (Xiong et al., 2017),</li>
<li>Uniﬁed Medical Language Systems (UMLS) (Kok and Domingos, 2007)<br />
</li>
<li>Alyawarra Kinship (Lin et al., 2018).</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>KE-GCN</title>
    <url>/kge/KE-GCN/</url>
    <content><![CDATA[<h1 id="knowledge-embedding-based-graph-convolutional-network">Knowledge Embedding Based Graph Convolutional Network</h1>
<p>WWW 2021, <a href="https://github.com/PlusRoss/KE-GCN">KE-GCN</a>，提出了一个泛化的框架，将GCN和KGE的传统方法结合起来，认为在GCN中的信息传播过程是传播计算edge是否存在的得分函数<span class="math inline">\(f(u,r,v)\)</span>对<span class="math inline">\(v\)</span>的梯度，并且提出了对于relation的传播过程，在knowledge graph alignment和entity classification上进行了实验。</p>
<span id="more"></span>
<blockquote>
<p>Recently, a considerable literature has grown up around the theme of Graph Convolutional Network (GCN). How to effectively leverage the rich structural information in complex graphs, such as knowledge graphs with heterogeneous types of entities and relations, is a primary open challenge in the field. Most GCN methods are either restricted to graphs with a homogeneous type of edges (e.g., citation links only), or focusing on representation learning for nodes only instead of jointly propagating and updating the embeddings of both nodes and edges for target-driven objectives. This paper addresses these limitations by proposing a novel framework, namely the Knowledge Embedding based Graph Convolutional Network (KE-GCN), which combines the power of GCNs in graphbased belief propagation and the strengths of advanced knowledge embedding (a.k.a. knowledge graph embedding) methods, and goes beyond. Our theoretical analysis shows that KE-GCN offers an elegant unification of several well-known GCN methods as specific cases, with a new perspective of graph convolution. Experimental results on benchmark datasets show the advantageous performance of KE-GCN over strong baseline methods in the tasks of knowledge graph alignment and entity classification .</p>
</blockquote>
<h2 id="introduction">1 Introduction</h2>
<p><strong>motivation</strong>：</p>
<ul>
<li>传统的GCN方法主要假设在同质图上进行学习，忽略了KG中的relation蕴含的丰富的信息。</li>
<li>传统的KGE方法没有考虑graph的结构信息</li>
<li>将GCN和KGE结合的方法比如VR-GCN，COMPGCN等，在学习relation embedding的时候没有考虑entity embedding对relation embedding的影响</li>
</ul>
<p><strong>method</strong>：</p>
<p>为了解决上面的问题，提出了KE-GCN（Knowledge Embedding based Graph Convolution Network），能够结合KGE的方法，基于图卷积操作同时学习entity和relation embedding。</p>
<h2 id="method">2 Method</h2>
<h3 id="reformulation-of-vanilla-gcn">2.1 Reformulation of Vanilla GCN</h3>
<p>作者首先从新的角度看原始GCN的公式：</p>
<p>原来GCN的公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517192759415.png" style="zoom:50%;" /></p>
<p>通过引入一个得分函数，重新定义GCN，假设引入得分函数<span class="math inline">\(f\)</span>，该得分函数计算edge存在的score，对于已经存在的edge输出较大的值；对于不存在的边输出较小的值。假设<span class="math inline">\(f\)</span>为求内积： <span class="math display">\[
f(h_u,h_v)=h_u^T h_v
\]</span> 那么计算的消息<span class="math inline">\(h_u\)</span>能够看做是<span class="math inline">\(f\)</span>对<span class="math inline">\(v\)</span>的梯度，那么所有的<span class="math inline">\(h_u\)</span>加起来就成为下面的形式</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517191155431.png" style="zoom:50%;" /></p>
<p>此时对于<span class="math inline">\(h_v+m_v\)</span>看做是learning rate为1，对<span class="math inline">\(h_v\)</span>的梯度提升；目的是使scoring function<span class="math inline">\(f\)</span>的值最大。</p>
<p>通过修改为上面的形式，能够看到，它从新的角度说明了GCN做了什么，邻居信息是如何提供给中心节点的，是如何帮助中心节点获得更好的表示的。</p>
<blockquote>
<p>The above reformulation provides an explicit view about what the vanilla GCN is optimizing, instead of how the updates are executed procedurally.</p>
</blockquote>
<h3 id="the-new-framework">2.2 The New Framework</h3>
<p>新的framework有两个核心部分，更新实体表示以及更新关系表示：</p>
<p>更新实体表示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517195223629.png" style="zoom:50%;" /></p>
<p>更新关系表示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517192820729.png" style="zoom:50%;" /></p>
<p>更新的关系表示实际提供了一种global的view。</p>
<p>整体结构：</p>
<p>消息传递过程：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517190645145.png" style="zoom:50%;" /></p>
<p>消息聚合过程：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517190907479.png" style="zoom:50%;" /></p>
<p>它能够泛化COMPGCN、R-GCN以及W-GCN。实际上COMPGCN本身就已经泛化了R-GCN和W-GCN，这部分泛化参考论文原文。</p>
<h2 id="experiments">3 EXPERIMENTS</h2>
<p>在实验的时候，对于KE-GCN，主要是引入不同的得分函数<span class="math inline">\(f\)</span>，该得分函数使用不同的KGE方法，并且为了简化模型，对于in，out，self-loop都使用了相同的<span class="math inline">\(W\)</span>和相同的得分函数<span class="math inline">\(f\)</span>。</p>
<p>使用了一系列的KGE方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517195011713.png" style="zoom:50%;" /></p>
<h3 id="knowledge-graph-alignment">3.1 Knowledge Graph Alignment</h3>
<p>匹配不同KG中的实体和关系，在实验中直接计算embedding之间的L1-distance，</p>
<p>在这种情况下的loss function</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517200018220.png" style="zoom:50%;" /></p>
<p>数据集，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517200444629.png" style="zoom:50%;" /></p>
<p>结果，这里只贴了KE-GCN的比较：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517200123514.png" style="zoom:50%;" /></p>
<h3 id="knowledge-graph-entity-classification">3.2 Knowledge Graph Entity Classification</h3>
<p>在这种情况下的loss function</p>
<p>multi-class classification</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517200315774.png" style="zoom:50%;" /></p>
<p>multi-label classification</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517200151721.png" style="zoom:50%;" /></p>
<p>数据集，AM和WN是multi-class，FB15K是multi-label</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517200250204.png" style="zoom:50%;" /></p>
<p>结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210517200606660.png" style="zoom:50%;" /></p>
<div class="pdf-container" data-target="KE-GCN.pdf" data-height="1000px"></div>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>KGE</tag>
      </tags>
  </entry>
  <entry>
    <title>Knowledge-Graphs</title>
    <url>/kge/Knowledge-Graphs/</url>
    <content><![CDATA[<h1 id="knowledge-graphs">Knowledge Graphs</h1>
<p>Introduction of Knowledge Graphs.</p>
<span id="more"></span>
<blockquote>
<ol type="1">
<li>HOGAN A, BLOMQVIST E, COCHEZ M, et.al. Knowledge Graphs[J]. arXiv:2003.02320 [cs], 2020.</li>
<li>Knowledge Graph Embedding: A Survey of Approaches and Applications</li>
<li>东南大学知识图谱课程笔记，<a href="https://github.com/npubird/KnowledgeGraphCourse">原项目地址</a>。</li>
<li><a href="https://mp.weixin.qq.com/s/RK0bymmcXloxzCBYOPk6wg">从知识图谱到认知图谱： 历史、发展与展望</a></li>
<li><a href="https://web.stanford.edu/class/cs520/">StandFord的课程《knowledge graph》2020</a></li>
</ol>
</blockquote>
<h2 id="introduction">1. INTRODUCTION</h2>
<p>Knowledge graph这个词的现代含义是从2012年谷歌知识图谱（Google knowledge graph）提出后才具备的。谷歌使用知识图谱增强搜索引擎检索效果。</p>
<p>首先需要搞清楚几个重要的概念。</p>
<p>一、什么是知识？</p>
<p>有很多的定义</p>
<blockquote>
<ol type="1">
<li>Knowledge is a familiarity, awareness, or understanding of someone or something, such as facts, information, descriptions, or skills, which is acquired through experience or education by perceiving, discovering, or learning.——维基百科</li>
<li>知识包括两部分：已知的和未知的，实际对于所有涉及知识都是这两方面的研究</li>
</ol>
</blockquote>
<p>简单理解知识的例子：110，110本身是没有意义的，它只是计算机表示的符号。但是我们知道，认识到110可以是一百一十，可以是2进制，可以是中国的报警电话。它在不同的情景下有不同的具体含义，表达了除去110符号之外的现实含义。这就是知识。</p>
<p>二、什么是语义？</p>
<p>根据它原本的定义，语义就是语言包含的意义。语义可以简单地看作是数据所对应的现实世界中的事物所代表的概念的含义，以及这些含义之间的关系，是数据在某个领域上的解释和逻辑表示。</p>
<p>三、什么是本体？</p>
<p><strong>Ontology</strong>的定义，据维基百科</p>
<blockquote>
<p>In computer science and information science, an ontology is a <strong>formal naming and definition of the types, properties, and interrelationships of the entities</strong> that really or fundamentally exist for <strong>a particular domain</strong> of discourse. It is thus a practical application of philosophical ontology, with a taxonomy.</p>
</blockquote>
<p>具体的理解，引用知乎的<a href="https://www.zhihu.com/question/34835422/answer/60367501">答案</a></p>
<blockquote>
<p>我浅显的理解，本体就是这个知识库本身的<strong>存在，</strong>也就是知识库中对知识的一个定义，定义这个知识库中具体的每一个知识到底是什么。【本体论（英语：Ontology），又译存在论、存有论，它是形而上学的一个基本分支，本体论主要探讨存有本身，即一切现实事物的基本特征。】就好像有一匹马叫赤兔，那么马这个概念才是本体，赤兔红兔什么的无所谓；有一个美女叫貂蝉，那么美女这个概念才是本体，貂蝉西施啊什么的也无所谓。</p>
</blockquote>
<p>一句话概括本体，形式化、正式的概念定义。</p>
<p>四、本体、知识库（knowledge base）、知识图谱（knowledge graph）之间的关系？</p>
<p>还是引用知乎的<a href="https://www.zhihu.com/question/34835422/answer/144387604">答案</a></p>
<blockquote>
<p>从抽象层面看，本体最抽象，其次是知识库，最后才是知识图谱。举个例子，如果我们要做图书领域的知识库或者知识图谱，首先要对图书进行分类，这个分类就是本体，比如说，图书分为计算机类和电子类，计算机类有分为网络、人工智能；有了这个分类后，我们就可以把图书都分到每个类别，比如说《Zero to One》是一本进口原版书，然后这本书有各种属性－属性值，比如说书的作者是Peter Thiel，这些数据就构成了一个图书知识图谱（前面讲的分类可以认为不是这个知识图谱的一部分），而这里分类和知识图谱一起可以看成是一个图书知识库。也就是说，<strong>本体是强调概念关系</strong>，<strong>知识图谱强调实体关系和实体属性值</strong>，<strong>知识库则是所有知识的集合。但是知识库不局限于分类和图谱，知识库可以包括规则，包括过程性知识等</strong>。而本体也可以定义得很抽象，任何概念的内涵和外延可以定义本体。</p>
</blockquote>
<p>知识图谱获得了很多的研究关注，核心是在于使用图表示数据，进而使用图表示知识的思想。使用图表示知识的好处，和关系型的数据结构比较起来，有以下的优点：</p>
<ul>
<li>图能够提供很多领域下一种准确、直观的抽象。使用图描述数据的时候，可以一开始不确立一个准确的定义，而是随着发展慢慢的定义。</li>
<li>在图上也有查询语言，不仅能够支持传统的查询操作（join、unions、 projections），也能够在图上递归的查询。</li>
<li>标准的知识表示形式，比如ontologies和rule，都可以被用来描述和推理图中的节点</li>
</ul>
<p>knowledge graph的一个归纳的定义：</p>
<blockquote>
<p>A graph of data intended to accumulate and convey knowledge of the real world, whose nodes represent entities of interest and whose edges represent relations between these entities.</p>
</blockquote>
<p>在认识论里，对于知识已经有了很多的讨论。这里粗略的理解knowledge就是something that is known。知识图谱中的知识可以从外部累积，也可以从内部导出。使用Deductive methods/Inductive methods都可以导出新的知识。</p>
<blockquote>
<p>演绎Deductive是从一般到个别</p>
<p>归纳Inductive是从个别到一般</p>
</blockquote>
<p>知识图谱的构造可以用到很多数据来源，这些数据来源的结构、粒度各不相同。因此，构造知识图谱需要定义三方面的内容。</p>
<ol type="1">
<li>schema：知识图谱的高层次的结构定义</li>
<li>identity：确定知识图谱或不同来源的描述对象是否指向现实世界中相同的实体</li>
<li>context：context may indicate a specific setting in which some unit of knowledge is held true</li>
</ol>
<p>知识图谱不断成长和提升需要涉及的方面有：</p>
<ul>
<li>extraction</li>
<li>enrichment</li>
<li>quality assessment</li>
<li>refinement</li>
</ul>
<p>实践当中，按照知识图谱的开放程度，分为open knowledge graph和enterprise knowledge graphs两类。前者对公众开放，比如：DBpedia, Freebase, Wikidata, YAGO。后者主要是公司内部使用，Bing, Google, Airbnb, Amazon, eBay</p>
<p>实际上本质的，知识图谱获得成功要得益于它的特点——弱语义，多实例</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200826100711774.png" style="zoom:50%;" /></p>
<p>不需要多强的语义，因为现实世界是如此的复杂，以至于我们不可能概括一个通用的、泛化性强的规则/语义去描述全部的现实世界。但语义又是必须的，没有语义的话，就没有知识，知识图谱的本身就不成立了。所以，知识图谱着眼于弱语义，同时看重实例的堆积，反而取得了成功，并且在快速的发展。</p>
<p>知识图谱的研究热点逐渐出现重数量轻结构化的倾向，</p>
<p>知识图谱怎么用？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200826153137057.png" style="zoom:50%;" /></p>
<p>宏观角度看知识图谱</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200829195712010.png" style="zoom:50%;" /></p>
<p>知识图谱的缺点：</p>
<p>知识图谱的缺点本质上都是“⼆元⼀阶谓词逻辑”作为知识表示本身的缺陷带来的。词逻辑”作为知识表示本身的缺陷带来的。⻓久以来，知识 表示是研究者孜孜不倦追寻探索的话题，完全依靠（头实体，关系，尾实体）这样的命题，尽管能表示⼤部分简单事件或实体属性，但对于复杂知识却束手无策。</p>
<p>比如“克隆⽺的各项属性都与本体相同”，这个知识就无法被现有的知识图谱结构很好的记录。</p>
<p>另一方面，在构建知识图谱的过程中，从原始的语音、图像等的信息约减带来的实体链接困难。知识的最终来源是我们所处的世界，从原始的语⾳、图像等数据到⽂本再到知识图谱，信息量不断被约减，只有最核⼼的内容被保留下来。然⽽，忽略了原始⽂本中⼈物的具体经历等信息后，会导致同名⼈物难以消歧。</p>
<p>因此，现在有出现认知图谱，动力在于自然语言处理的进步，核心在于保持知识图谱的图结构带来的可解释性与精准稳定的推理能力的同时，带来推理能力的改变。</p>
<h2 id="data-graphs">2 DATA GRAPHS</h2>
<p>在这个部分我们讨论几种常见的知识图谱类型。</p>
<h3 id="directed-edge-labelled-graphs">2.1 Directed edge-labelled graphs</h3>
<p>是最常见，也是我们默认讨论知识图谱时具备的结构。它由节点集合与有向边集合组成。关系都是二元关系。一般使用RDF定义，可以进行各种查询操作。</p>
<h3 id="graph-dataset">2.2 Graph dataset</h3>
<p>A graph dataset then consists of a set of named graphs and a default graph.</p>
<p>即多个知识图的集合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200826105530023.png" style="zoom:50%;" /></p>
<h3 id="property-graphs">2.3 Property graphs</h3>
<p>属性图谱是在一般的知识图谱基础上改进的，A property graph allows a set of property–value pairs and a label to be associated with both nodes and edges.在边上添加了属性和标签。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200829204546266.png" style="zoom:50%;" /></p>
<h3 id="other-graph-data-models">2.4 Other graph data models</h3>
<p>例如hypergraph：complex edges that connect sets rather than pairs of nodes</p>
<h2 id="deductive-knowledge">3 DEDUCTIVE KNOWLEDGE</h2>
<p>给予一些先验的知识，一些规则等，就可以在知识图谱上进行对于新知识的演绎。一些通用的规则，很多人都了解的知识被称为<em>commonsense knowledge</em>，相反的，只被相关领域的专家了解的知识叫做<em>domain knowledge</em>。</p>
<p>为了能够准确的构建知识图谱，我们必须首先确定涉及的term的准确定义，这就是本体<em>Ontologies</em>。描述本体的形式化语言是OWL（Web Ontology Language）。</p>
<p>在知识图谱中，普遍存在四种假设</p>
<ul>
<li>Closed World Assumption (CWA)：未知的知识一定不成立</li>
<li>Open World Assumption (OWA)：未知的知识有可能成立</li>
<li>Unique Name Assumption (UNA)：不同的实体一定对应现实世界的不同事物</li>
<li>No Unique Name Assumption (NUNA)：不同的实体可以对应现实世界的同一事物</li>
</ul>
<p>OWL是基于OWA，NUMA假设的。</p>
<p>演绎知识主要集中在推理方面，比如利用构建知识图谱时用到的本体，本体中的各种概念会构成一张图。利用预先知道的规则/逻辑，演绎推理出新的知识。这样得到的知识是很精确的。集中的表现是预先知道规则rule/描述逻辑Description Logics (DLs)，然后在graph中寻找能够匹配的现实。rule的一般表现是if-then类型的类似路径的序列。DL一般采用一阶逻辑FOL。</p>
<blockquote>
<p>A rule is composed of a body (if) and a head (then). Both the body and head are given as graph patterns. A rule indicates that if we can replace the variables of the body with terms from the data graph and form a subgraph of a given data graph, then using the same replacement of variables in the head</p>
</blockquote>
<blockquote>
<p>Description Logics (DLs) were initially introduced as a way to formalise the meaning of frames and semantic networks. Initially, DLs were restricted fragments of First Order Logic (FOL) that permit decidable reasoning tasks.</p>
</blockquote>
<h2 id="inductive-knowledge">4 INDUCTIVE KNOWLEDGE</h2>
<blockquote>
<p>inductively acquiring knowledge involves generalising patterns from a given set of input observations, which can then be used to generate novel but potentially imprecise predictions. Graph analytics is then the application of analytical processes to (typically large) graph data.</p>
</blockquote>
<p>由于一般归纳的知识再用于预测无法得到绝对正确的预测，因此一般提供<em>confidence</em>。</p>
<h3 id="graph-analytics">4.1 Graph analytics</h3>
<blockquote>
<p>Analytics is the process of discovering, interpreting, and communicating meaningful patterns inherent to (typically large) data collections</p>
</blockquote>
<p>各种的图分析技术：</p>
<ol type="1">
<li>Centrality：衡量节点的重要程度。to identify the most important (aka central) nodes or edges of a graph.</li>
<li>Community detection：探测节点之间的聚类。to identify communities in a graph, i.e., sub-graphs that are more densely connected internally than to the rest of the graph.</li>
<li>Connectivity：评估图的连通性。to estimate how well-connected the graph is, revealing, for instance, the resilience and (un)reachability of elements of the graph.</li>
<li>Node similarity：发现节点的相似程度。to find nodes that are similar to other nodes by virtue of how they are connected within their neighbourhood.</li>
<li>Path finding: 一般是发现两个节点之间的可能路径。to find paths in a graph, typically between pairs of nodes given as input.</li>
</ol>
<p>上述的图分析技术已经在图领域当中进行了深入的研究，存在很多的图框架适合于分析图，比如Apache Spark (GraphX), GraphLab, Pregel, Signal–Collect, Shark。</p>
<p>但是还不能直接把上面的图分析技术应用到知识图谱上，因为知识图谱是有向带标签的图。因此，有几种不同的方案处理这一问题。</p>
<ol type="1">
<li>Projection：移除边的类型得到一个无向或者有向图</li>
<li>Weighting：设计某些方法，将边的元数据转化为数字</li>
<li>Transformation：将原来的图进行转换——lossy/lossless，前者表示转化后的图无法复原原来的图；后者表示可以复原原来的图，比如把原来的边的标签表示为新的节点，新的边变为无标签的</li>
<li>Customisation：改变之前的图分析技术，加入对边的考虑</li>
</ol>
<p>具体选择哪种方法没有特定的方式，依赖于具体的技术。</p>
<p>一个可能的研究方向是结合语义和图分析技术，研究<em>semantically-invariant analytics</em>，因为之前的图分析技术无法利用具体的语义信息，比如逆关系/不可逆关系。</p>
<h3 id="knowledge-graph-embeddingskrl">4.2 Knowledge Graph Embeddings/KRL</h3>
<p>知识图谱嵌入的核心目的是创建出knowledge graph在低维、连续空间下的稠密表示。</p>
<p>它实际上是知识图谱表示学习目前的主流思想，都是把表示转化为embedding。基本可以划等号。</p>
<p><strong>表示学习</strong>：将研究对象的语义信息表示为稠密低维的实值向量，举例：文字、图片、语音</p>
<p><strong>知识表示学习</strong>：将知识库/知识图谱中的实体和关系表示为稠密低维的实值向量</p>
<p><strong>知识</strong>：知识图谱中的知识通常就是三元组（head, relation, tail）</p>
<p>知识表示中存在的问题，设想怎么样能够表示三元组？</p>
<ol type="1">
<li><p>0-1的onehot编码，每个实体/关系有唯一的编码，信息基本全丢失，不可用</p></li>
<li><p>直接使用图结构的图算法复杂度高</p></li>
<li><p>数据稀疏问题：长尾/重尾分布（大量的实体处在长尾上）</p></li>
</ol>
<p>研究知识图谱嵌入的意义：</p>
<ol type="1">
<li><p>低维向量提高计算效率</p></li>
<li><p>稠密的向量缓解数据稀疏问题</p></li>
<li><p>多源的异质信息表示形式统一，便于迁移和融合</p></li>
</ol>
<p>一般的评测任务</p>
<ul>
<li>链路预测</li>
<li>实体分类</li>
<li>图分类</li>
</ul>
<p>知识图谱嵌入一般的应用：</p>
<ul>
<li>知识融合，如Cross-lingual Entity Alignment via Joint Attribute-Preserving Embedding</li>
<li>人机交互，如Commonsense Knowledge Aware Conversation Generation with Graph Attention</li>
</ul>
<p>根据经典的survey，中所有的KGE从利用信息的角度分为两类：KG embedding with facts alone（仅使用facts）和Incoprorating additional information（多源信息融合）。从使用的模型核心方法的角度讲，根据[1]又可以划分为Translational models、Tensor decomposition models、Neural models。实际上人们也经常根据得分函数scoring function，直接分为Translational Model和Semantic Matching Models，前者的scoring计算entity embedding之间基于关系的距离，后者的scoring function基于相似度计算事实成立的得分。</p>
<blockquote>
<p><em>Translational distance models</em> exploit distance-based scoring functions. They measure the plausibility of a fact as the distance between the two entities, usually after a translation carried out by the relation.</p>
<p><em>Semantic matching models</em> exploit similarity-based scoring functions. They measure plausibility of facts by matching latent semantics of entities and relations embodied in their vector space representations.</p>
</blockquote>
<p>在这里，我们主要关心方法本身，根据模型进行分类。</p>
<h4 id="基于翻译的模型">4.2.1 基于翻译的模型</h4>
<p>起始于TransE，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200826152742454.png" style="zoom:50%;" /></p>
<p>TransE的不足：</p>
<ul>
<li>首先，TransE严格要求有效的三元组满足头实体加关系在向量空间中与尾实体足够靠近，可以很好地处理一对一关系，但在处理多映射属性关系时，存在多个实体竞争一个点的现象．例如在一对多关系中，同一个头实体<span class="math inline">\(h\)</span>与多个尾实体<span class="math inline">\(\{t_1,t_2\cdots\}\)</span>存在关系<span class="math inline">\(r\)</span>，由于<span class="math inline">\(h+r=t_i,f=\{1,2,\cdots\}\)</span>的约束，这些尾实体将竞争空间中的同一个点，即使它们语义差别很大，因而会造成向量空间的拥挤和误差；</li>
<li>其次，TransE只专注于满足知识图谱中的三元组约束，然而知识图谱中存在大量层级关系，例如在知识图谱WordNet的子集WN18中，大约有50%的层级关系，孩子关系就是一种层级关系，对应的实体和关系形成树结构．Li等人也指出，考虑层级结构有助于推理：</li>
<li>然后，TransE没有考虑丰富的语义信息，缺乏对空间中向量分布位置的进一步调整；</li>
<li>再者，TransE在单个知识图谱上进行学习推理，而单个知识图谱知识量有限；</li>
<li>此外，TransE参数的选取与知识图谱数据独立，不能反映数据的特点；</li>
<li>同时，TransE未考虑知识的时间约束。</li>
</ul>
<p>因此，诞生了一系列的Trans系列的方法。TransH, TransR, CTransR, TransD, TranSparse, TransM, ManiFoldE, TransF, TransA, KG2E, TransG。</p>
<h4 id="张量分解模型">4.2.2 张量分解模型</h4>
<p>这一方法的核心是将整个图表示为一个张量<span class="math inline">\(G\)</span>（tensor，就是多阶向量），0/1表示某个边是否存在，之后将所有的实体和关系表示为<span class="math inline">\(d\)</span>维的embedding，每个维度都代表某种能够对预测结果产生影响的latent factor，这样理由d个latent factor去尝试重建表示图的张量<span class="math inline">\(G\)</span>。</p>
<blockquote>
<p>A tensor is a multidimensional numeric field that generalises scalars (0-order tensors), vectors (1-order tensors) and matrices (2-order tensors) towards arbitrary dimension/order.</p>
</blockquote>
<p>下图是关于CP d-rank分解的实例，图中的<span class="math inline">\(x_i,y_i, z_i\)</span>表示的是在<span class="math inline">\(x,y,z\)</span>三个方面的第<span class="math inline">\(i\)</span>种latent factor。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200826105942543.png" style="zoom:50%;" /></p>
<p>这一类型的方法有LFM， RESCAL，DistMult，ComplEx，ANALOGY，HolE。</p>
<h4 id="神经网络模型">4.2.3 神经网络模型</h4>
<p>上面的这些方法都是linear或者billear的scoring function，之后就有人使用non-linear的神经网络方法学习embedding。</p>
<p>一般的神经网络方法包括SME、NTN、MLP。但它们的问题在于容易过拟合，如果想要效果较好就需要较大的embedding维度，但这毫无疑问是不可接受的（由于数量巨大的实例数量）。</p>
<p>之后就出现了很多其它网络模型，包括使用CNN、RNN、GNN等。</p>
<p>CNN在知识图谱上的应用源于ConvE，之后发展出一系列的方法，ConvR、ConvKB、HypER、InteractE等。</p>
<p>使用RNN实际上是受到了word embedding的启发。例如基于word2vec和random work找寻路径的RDF2Vec，融合GloVe和PageRank的KGloVe。</p>
<p>基于GNN是得益于最近图神经网络的突飞猛进，模型有R-GCN，VR-GCN，COMPGCN，KBGAT等。这个方向还有很多可以研究的内容。</p>
<p>对于GNN目前没有统一全面的认识，简单说明，主要有两类GNN，一类是Recursive graph neural networks，一类是Convolutional graph neural networks。</p>
<p>Recursive graph neural networks的思想起源于The Graph Neural Network Model（2009），核心是对于graph中的每一个node/edge都有一个feature vector和一个hidden state vector，state vector不断aggregate邻居节点的信息获得新的state vector，使用transition function和邻居节点的feature vector构造要传递的信息，之后使用output function输入新的state vector得到最终的预测结果。至于什么时候停止要看是否能够达到fixpoint。</p>
<p>Convolutional graph neural networks是模拟了CNN处理图像的思想，但是与图像的区别在于无法很好的定义neighbour。这个方向又可以分为基于spectral和基于spatial的方法。</p>
<p>两类GNN方法的区别：</p>
<blockquote>
<p>There are two main differences between RecGNNs and ConvGNNs.</p>
<ul>
<li><p>First, RecGNNs aggregate information from neighbours recursively up to a fixpoint, whereas ConvGNNs typically apply a fixed number of convolutional layers.</p></li>
<li><p>Second, RecGNNs typically use the same function/parameters in uniform steps, while different convolutional layers of a ConvGNN can apply different kernels/weights at each distinct step.</p></li>
</ul>
</blockquote>
<h4 id="融合多元信息的模型">4.2.5 融合多元信息的模型</h4>
<p>这里的多源是指除单纯的三元组之外的信息</p>
<ol type="1">
<li>实体类别：同一类别的实体在表示空间中应该距离较近
<ul>
<li>SSE、TKRL</li>
</ul></li>
<li>关系路径：三元组与三元组可以拼接为路径
<ul>
<li>pTransE</li>
</ul></li>
<li>文本描述：每个实体/关系都有自己名字
<ul>
<li>NTN：先用新闻语料库对词汇进行表示，然后用词汇表示初始化实体的表示</li>
</ul></li>
<li>逻辑规则：融合逻辑规则，学习知识表示
<ul>
<li>ILP、KALE</li>
</ul></li>
<li>实体属性：大部分KGE将实体属性也看做关系处理，但是有时并不合理。例如（Obama，gender，male）</li>
<li>时序信息：在三元组的基础上添加时间维度</li>
</ol>
<h3 id="symbolic-learning">4.4 Symbolic Learning</h3>
<p>之前谈到的演绎的知识，它的规则或者DL都是可以通过已有的知识图谱中归纳出来的。如果我们能够挖掘出这样的规则，那么就可以为我们预测未知的链接是否存在提供可解释的依据。只不过是这样归纳的规则不一定是正确的。</p>
<p>上面自动归纳规则的方法就是Symbolic Learning：</p>
<blockquote>
<p>An alternative (sometimes complementary) approach is to adopt symbolic learning in order to learn hypotheses in a symbolic (logical) language that “explain” a given set of positive and negative edges.</p>
</blockquote>
<p>主要分为两大类，Rule mining和Axiom mining。</p>
<p>Rule mining的主要目标：</p>
<blockquote>
<p>The goal of rule mining is to identify new rules that entail a high ratio of positive edges from other positive edges, but entail a low ratio of negative edges from positive edges.</p>
</blockquote>
<p>从Inductive Logic Programming (ILP)开始已经有很多对于规则挖掘的探讨，但是由于知识图谱的规模大以及不完备性，又有很多新的专用方法出现。</p>
<p>一个非常重要的方法是AMIE，它是利用启发式的方法不断构造新的规则，然后判断这些规则在已有的facts中是否成立，confidence是否够高。之后还有很多的改进方法比如AMIE+，Gad-Elrab，RuLES，CARL等。</p>
<p>另外一种流派是认为矩阵乘法可以表示规则推导，叫做differentiable rule mining，The core idea is that the joins in rule bodies can be represented as matrix multiplication。这一类的方法有NeuralLP，DRUM等。</p>
<p>Axiom mining是自动挖掘DL的方法。</p>
<h2 id="quality-assessment">5 QUALITY ASSESSMENT</h2>
<p>在知识图谱创建或者从不同的来源获得更新之后，需要对知识图谱的质量进行评估。</p>
<p>四个被广泛使用的评估维度</p>
<h3 id="accuracy">5.1 Accuracy</h3>
<p>准确度是指要求知识图谱中的实体和关系能够准确的反映现实世界中的事物。</p>
<blockquote>
<p>Accuracy refers to the extent to which entities and relations – encoded by nodes and edges in the graph – correctly represent real-life phenomena.</p>
</blockquote>
<ul>
<li>Syntactic accuracy：语法的准确性是指知识图谱中的数据是不是准确符合定义的语法。一种度量指标就是错误的实例的比例。</li>
<li>Semantic accuracy：语义准确性是指数据是否正确的对应了现实，比如由于不恰当的知识抽取导致出现了错误的实例。一种度量的方法是拿知识图谱和多个对应的数据来源自动进行对比。</li>
<li>Timeliness：时间线是指知识图谱能够及时得到更新的度量。可以用多久进行一次更新进行度量。</li>
</ul>
<h3 id="coverage">5.2 Coverage</h3>
<p>覆盖范围/覆盖程度主要是指与领域相关的信息丢失的程度。</p>
<blockquote>
<p>Coverage refers to avoiding the omission of domain-relevant elements, which otherwise may yield incomplete query results or entailments, biased models, etc</p>
</blockquote>
<ul>
<li>Completeness：完备性是指知识图谱包含所有信息的程度。包括预先定义的schema是否完备（schema completeness）、属性对应的值是否完备（property completeness）、现实当中所有的实体和关系是否完备（population completeness）、已有实体之间的联系是否完备（linkability completeness）。</li>
<li>Representativeness：代表性是关注当前的知识图谱的biases。比如人口方面的知识图谱偏向反映某个地区/人种的信息。一种度量方式是拿知识图谱与当前已知的统计分布进行对比。</li>
</ul>
<h3 id="coherency">5.3 Coherency</h3>
<p>一致性是指知识图谱中的实例在语义/约束是否一致。</p>
<blockquote>
<p>Coherency refers to how well the knowledge graph conforms to – or is coherent with – the formal semantics and constraints defined at the schema-level.</p>
</blockquote>
<ul>
<li>Consistency：一致性是指知识图谱内部信息是否互相矛盾。</li>
<li>Validity：有效性是指知识图谱是否与预先的约束冲突。</li>
</ul>
<h3 id="succinctness">5.4 Succinctness</h3>
<p>简洁性是指要求知识图谱只包含准确，足够的内容，避免冗余信息。</p>
<blockquote>
<p>Succinctness refers to the inclusion only of relevant content (avoiding “information overload”) that is represented in a concise and intelligible manner.</p>
</blockquote>
<ul>
<li>Conciseness：简洁性是指知识图谱的schema和已有的数据是否存在于领域无关的情况。</li>
<li>Representational-conciseness：代表的简洁性是要求知识图谱已有数据是紧密联系的，避免出现同一个概念不同的实体/关系。</li>
<li>Understandability：可理解性是指知识图谱的内容能够无歧义的被人类理解。</li>
</ul>
<h2 id="review-previous-work">Review previous work</h2>
<p>现在回顾之前的工作，用的方法是神经网络模型，主要利用GNN做encoder，CNN做decoder，最后输出semantic socres。预测任务是link prediction，设想的场景是knowledge graph completion，该场景属于对于已有知识图谱质量中完备性的提升（refinement），方法是补全已有的实体和关系之间的联系。核心是学习knowledge graph embedding，学习到的是inductive knowledge，没有涉及多元信息的融合。</p>
<p>可以改进的方向：</p>
<ol type="1">
<li>从GNN的角度入手，目前可以想到的是改进注意力机制</li>
<li>从知识图谱角度入手，比如考虑在聚合一阶邻居的时候区分出属性和一般的关系、还可以考虑加入多步路径</li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KG</category>
      </categories>
  </entry>
  <entry>
    <title>MR-GCN</title>
    <url>/kge/MR-GCN/</url>
    <content><![CDATA[<h1 id="mr-gcn-multi-relational-graph-convolutional-networks-based-on-generalized-tensor-product">MR-GCN: Multi-Relational Graph Convolutional Networks based on Generalized Tensor Product</h1>
<p>IJCAI 2020</p>
<p>2020-7</p>
<p>作者在定义了在multi-relational graph中的卷积操作，命名为MR-GCO（multirelational graph convolution operators），提出了一个可以用来做node classification的网络MR-GCN。</p>
<span id="more"></span>
<p><strong>motivation</strong>：现在的几个解决multi relation的GCN模型，倾向于在不同relation的graph中执行GCN卷积操作，然后混合（blending）结果。作者认为这种做法忽略了relation之间的correlation。</p>
<p>现有的处理multi-relational graph的方法主要有两种思路：</p>
<ol type="1">
<li>每个relation graph下进行GCN，然后融合，比如R-GCN，mGCN，Megan等，在这种情况下relation之间的correlation无法被显式的捕获。</li>
</ol>
<blockquote>
<p>The ﬁrst line conducts GCN on each single relation and then integrates the results with multi-view learning.</p>
</blockquote>
<ol start="2" type="1">
<li>另一种思路是把multi-relational graph转换为一个同质图homogeneous graph。比如Multi-GCN等。这一类方法存在的问题是可能存在信息的损失等。</li>
</ol>
<blockquote>
<p>Another line is aggregating the multi-relational graph into a homogeneous graph.</p>
</blockquote>
<p><strong>methods</strong>：作者在定义了在multi-relational graph中的卷积操作，命名为MR-GCO（multirelational graph convolution operators），提出了一个可以用来做node classification的网络MR-GCN。</p>
<p><strong>contribution</strong>：</p>
<ul>
<li>首个通过tensor eigen-decomposition，从GCNs spectral graph theory发展到multi-relational graphs下的convolution operator。</li>
<li>MR-GCN是通过定义generalized tensor product的tensor eigen-decomposition进行的，因此除了可以基于快速傅里叶变换进行外，还可以融合Haar, Discrete Cosine transform (DCT)等。</li>
</ul>
<p>MR-GCO是作者论文的核心，主要思想从推导过程来看和一般情况下的图卷积是一致的。</p>
<p>由于对泛化的张量积的核心思想不了解，因此无法确切的理解作者的操作。</p>
<p>MR-GCO的定义，对于图信号 <span class="math inline">\(x\in \mathbb{R}^{N\times R}\)</span>和过滤器<span class="math inline">\(g\in \mathbb{R}^{N\times R}\)</span>，作者定义为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210626164638896.png" style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(U\)</span>是对于多关系拉普拉斯矩阵进行张量特征分解后的结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210626164341117.png" style="zoom:50%;" /></p>
<p>其中的特殊运算 <span class="math inline">\(\diamondsuit_\Phi\)</span>就是泛化的张量积<span class="math inline">\(\Phi\)</span>-product，<span class="math inline">\(\Phi\)</span>是转化矩阵。</p>
<p>其中的拉普拉斯矩阵是多关系的三阶张量，每个relation有一个不同的拉普拉斯矩阵</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210626165323451.png" style="zoom:50%;" /></p>
<p>直接看作者结果</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210626164015015.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>NSCaching</title>
    <url>/kge/NSCaching/</url>
    <content><![CDATA[<h1 id="nscaching-simple-and-efﬁcient-negative-sampling-for-knowledge-graph-embedding">NSCaching: Simple and Efﬁcient Negative Sampling for Knowledge Graph Embedding</h1>
<p>ICDE 2019</p>
<p>提出了一种针对KGE的动态负采样方法<a href="https://github.com/yzhangee/NSCaching">NSCaching</a>，核心思想是得分高的负样本很重要但是数量少，因此，作者直接使用cache来保存得分高的负样本，同时随着训练动态更新cache，可以看做是基于GAN的负采样方法的distilled版本。</p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p><strong>motivation</strong>：在训练KGE的时候，负样本的质量很重要，也就是说那些越难与正样本区分的负样本可能越重要。<em>high-quality negative triplets should have large scores</em>，因为基于embedding的model实际上对于大多数负样本不敏感，给出的都是比较低的打分。如果使用random采样，采样得到的负样本，激活函数如果是sigmoid函数，那么如果负样本得分在&lt;&lt;0的区间内，那么梯度会很小，造成梯度消失的问题。</p>
<p>下面的图分析了负样本得分与正样本得分差距的情况。红线右侧这一部分是值得训练的负样本。越大的margin表示负样本与正样本越相等，越有训练的价值，随着训练的进行，这一部分的负样本越来越少。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210722174158272.png" alt="image-20210722174158272" style="zoom:50%;" /></p>
<p>目前有方法比如KBGAN等，尝试使用GAN解决上面的问题，但是GAN首先会引入额外的训练参数；同时GAN的训练存在instability和degeneracy的问题，并且它们可能有更高的variance，导致训练结果更不稳定。</p>
<p><strong>method</strong>：高质量的负样本数量并不多，分布上来看是一个很skew的曲线，因此可以使用cache来保存高质量的负样本，同时随着训练，不断更新这些负样本。</p>
<h2 id="method">Method</h2>
<p>方法很直观，为每个head和tail保存高质量负样本cache，负样本的质量用上一步训练的模型对它的预测结果进行衡量。从cache中随机选择head或者tail entity构造负样本。然后用于KGE model进行训练。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210722173128966.png" style="zoom:50%;" /></p>
<p>step 6和step 8是重点。</p>
<p><strong>Uniform sampling strategy from the cache</strong></p>
<p>由于负样本cache中的实体都能够用来构造高质量负样本，同时因为最大得分的负样本也可能是假阴性样本，因此不应该总是采样最大得分负样本，直接使用Uniform sampling来控制false negative triplets。</p>
<p><strong>Importance sampling strategy to update the cache</strong></p>
<p>对于head cache和tail cache都是使用一样的更新过程。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210722173851214.png" alt="image-20210722173851214" style="zoom:50%;" /></p>
<p>从所有实体中选择<span class="math inline">\(N_2\)</span>个实体作为更新候选项并入cache中，然后基于相对重要性采样<span class="math inline">\(N_1\)</span>个实体作为更新后的cache。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210722173831073.png" alt="image-20210722173831073" style="zoom:50%;" /></p>
<p>这一步没有总是保留最大得分的<span class="math inline">\(N_1\)</span>​个实体也是为了控制假阴性样本。因为假阴性负样本的存在，总是使用top N最大得分的负样本也不合适。</p>
<blockquote>
<p>NSCaching will learn from easy samples ﬁrst, but then gradually focus on hard ones, which is exactly the principle of self-paced learning</p>
</blockquote>
<p>在作者实验中，采用<span class="math inline">\(N_1=N_2=50\)</span>，负样本数量为1。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
      <tags>
        <tag>KGE</tag>
      </tags>
  </entry>
  <entry>
    <title>PATHCON</title>
    <url>/kge/PATHCON/</url>
    <content><![CDATA[<h1 id="relational-message-passing-for-knowledge-graph-completion">Relational Message Passing for Knowledge Graph Completion</h1>
<p>在这篇论文中，作者只考虑了KG中的relation embedding，没有学习entity embedding。更具体的说，学习两个方面的结构信息，relational context和relation paths。前者是头/尾实体的邻居relation，后者是头尾实体在KG中相连的relational path。提出了<a href="https://github.com/hwwang55/PathCon">PATHCON</a></p>
<p>作者预测的是relation prediction，<span class="math inline">\(&lt;h,?,t&gt;\)</span>，区别于常见的head/tail prediction，这样情况下relation prediction的候选项是所有的relation，会少很多候选项。这篇文章，作者还提出了一个新的数据集，DDB14，基于医药和疾病的一个知识图谱。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p><strong>motivation</strong>：作者认为实体的周围关系有很丰富的信息，可以使用GNN来学习这样的邻居结果。但是一般的KG上的GNN是迭代的将消息从实体传递到另外的实体。作者认为KG中的relation应该起到更大的作用。</p>
<p><strong>method</strong>：作者提出了一种relational message passing的方法，只考虑relation embedding，然后让messages在relation之间传播。同时，为了降低计算复杂度，作者提出了改进版alternate relational message passing，让relation先传递给entity，再传递给relation。</p>
<p>作者认为重点建模relation而不是entity有三方面的好处：</p>
<blockquote>
<ol type="1">
<li><p>it is inductive, since it can handle entities that do not appear in the training data during inference stage;</p></li>
<li><p>it is storage-efficient, since it does not calculate embeddings of entities; and</p></li>
<li><p>it is explainable, since it is able to provide explainability for predicted results by modeling the correlation strength among relation types.</p></li>
</ol>
</blockquote>
<p>这篇文章，作者还提出了一个新的数据集，DDB14。</p>
<h2 id="method">2 Method</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807105609410.png" alt="image-20210807105609410" style="zoom:50%;" /></p>
<p><strong>Alternate relational message passing</strong></p>
<p>为了降低以edge为底的聚合方法的计算复杂度（作者提供了计算复杂度的计算公式，没有细看），提出了交替的关系消息传递函数。让relation先传递给entity，再传递给relation。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807103941361.png" alt="image-20210807103941361" style="zoom:50%;" /></p>
<p>注意，这个公式里面的，<span class="math inline">\(e\)</span>和<span class="math inline">\(v\)</span>表示边relation和节点entity。<span class="math inline">\(N(v)\)</span>不是表示实体<span class="math inline">\(v\)</span>的邻居实体，而是实体<span class="math inline">\(v\)</span>的邻居关系。<span class="math inline">\(A_1,\ A_2\)</span>是两个构造函数。</p>
<p>接下来解释作者使用到的两个KG上的关系信息</p>
<h3 id="relational-context">Relational Context</h3>
<p>头尾实体的周围关系。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807104339704.png" alt="image-20210807104339704" style="zoom:50%;" /></p>
<h3 id="relational-paths">Relational Paths</h3>
<p>头尾实体在KG上可以相连的路径，注意，为了限制路径数量，该路径被限制为各个节点的实体在这个路径上是唯一的，这样避免出现循环圈这样的情况。</p>
<p>对于一个路径<span class="math inline">\(p\)</span>​​，作者只保留中间的各个relation，然后给这样的relation赋予一个独立的embedding <span class="math inline">\(s_p\)</span>​，而不是去用某种方式产生。</p>
<p>虽然这种做法看起来会导致参数量爆炸，实际上作者发现出现的relational path数量并不多，单独赋予embedding，是可以接受的。</p>
<h3 id="combining-relational-context-and-paths">Combining Relational Context and Paths</h3>
<p>对于要预测的三元组<span class="math inline">\(&lt;h,?,t&gt;\)</span>，首先产生一个relation context</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807105123264.png" alt="image-20210807105123264" style="zoom:50%;" /></p>
<p>之后，基于注意力聚合Relational Paths</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807105237434.png" alt="image-20210807105237434" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807105253024.png" alt="image-20210807105253024" style="zoom:50%;" /></p>
<p>最终的预测输出</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210807105324839.png" alt="image-20210807105324839" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>KG</tag>
      </tags>
  </entry>
  <entry>
    <title>ParamE</title>
    <url>/kge/ParamE/</url>
    <content><![CDATA[<h1 id="parame">ParamE</h1>
<p>这篇文章提出了新的KGE方法叫做ParamE，既能够建模关系的翻译属性，又能够利用非线性的联系。</p>
<p>最大的创新点在于<strong>将神经网络的参数看做是relation embedding</strong>，在实验中，为了验证，设计了三个方法，ParamE-MLP，ParanE-CNN，ParamE-Gate</p>
<p>实际是为所有的relation都设计了单独的神经网络。</p>
<span id="more"></span>
<p>最后得到的表示投影到tail entity embedding space中，类似于ConvE，与所有tail entity embedding相乘，经过sigmoid得到预测得分。</p>
<p>ParamE-MLP：三层，每一层都有W和b，维度是200，400，800，输入只有head entity embedding，激活函数relu；</p>
<p>ParamE-CNN：两层卷积层后变为vector，激活函数relu，第一层卷积核32个，第二层64个，都是3x3卷积核；</p>
<p>ParamE-Gate：使用了一个gate。</p>
<p>训练过程：每个epoch训练固定次数n，每次都按照比例抽取某一组关系，从中随机抽取batch size大小的triples。</p>
<p>在WN18RR和FB15k-237上实验，效果很好，在FB15k-237上的MRR达到了0.399，最好的模型是ParamE-Gate。</p>
<p>优点：将relation embedding作为network parameters，能够充分的捕获关系和实体之间的交互，也能够表示“翻译”这种属性。</p>
<p>缺点：如果模型很复杂，那肯定不能将所有网络的参数都作为relation embedding。可以尝试在哪些模型中哪一部分适合作为由relation embedding构建的参数，哪些不适合。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>R-GCN</title>
    <url>/kge/R-GCN/</url>
    <content><![CDATA[<h1 id="modeling-relational-data-with-graph-convolutional-networks">Modeling Relational Data with Graph Convolutional Networks</h1>
<p>2018</p>
<p>首个在KG上应用GNN的模型R-GCN</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>一个物品很多的信息隐藏在它的邻居内。R-GCN设计了一个encoder model，可以和其它的tensor factoraction model结合作为decoder。</p>
<p>R-GCN使用了DisMult作为decoder。</p>
<p>在FB15k-237，FB15k，WN18上面都进行了实验。</p>
<h2 id="neural-relational-modeling">2 Neural Relational Modeling</h2>
<h3 id="relational-graph-convolutional-networks">2.1 Relational Graph Convolutional Networks</h3>
<p>一般的GCN的形式可以定义为 <span class="math display">\[
h_i^{l+1}=\sigma(\sum_{m \in M_i}g_m(h_i^{l}, h_j^{l}))
\]</span> <span class="math inline">\(g_m\)</span>可以是neural network，也可以是简单的线性转换，<span class="math inline">\(g_m(h_i, h_j)=Wh_j\)</span></p>
<p>基于以上的原理，设计了如下的传播层： <span class="math display">\[
h_i^{l+1}=\sigma(\sum_{r\in R}\sum_{j\in N_i^r} \frac{1}{c_{i,r}} W_r^{l}h_j^{l} + W_o^l h_i^l)
\]</span> 公式中的<span class="math inline">\(c_{i,r}\)</span>可以为<span class="math inline">\(|N_i^r|\)</span>，某个关系r的邻居的数量。</p>
<p><em>以下公式非论文原本内容</em> <span class="math display">\[
h_i^{l+1}=\sigma(\sum_{r\in R}\sum_{j\in N_i^r} \frac{1}{\sqrt{c_{i}} \sqrt{c_{j}}} W_r^{l}h_j^{l})
\]</span></p>
<p><span class="math display">\[
h_i^{l+1}=\sigma(\sum_{r\in R}\sum_{j\in N_i^r} \frac{1}{\sqrt{c_{i}} \sqrt{c_{j}}} W_r^{l} [h_j^{l},e_r^{l}])
\]</span></p>
<h3 id="regularization">2.2 Regularization</h3>
<p>这样设计导致了不同层的不同关系都有不同的weight matrix，在large scale knowledge graph下会导致快速增加的参数数量，导致过拟合。</p>
<p>为此，R-GCN使用了两种正则方式，都是针对<span class="math inline">\(W_r^l\)</span>进行改进。</p>
<p>basis- and block-diagonal decomposition</p>
<p><strong>1、basis decomposition</strong>： <span class="math display">\[
W_r^l=\sum_b^B a_{r,b}^l V_b^l
\]</span> <span class="math display">\[
V_b^l \in R^{d^{(l+1)}\times (d^l)}
\]</span></p>
<p>这种情况下<span class="math inline">\(W_r^l\)</span>成为线性组合同一层的不同关系，能够共享<span class="math inline">\(V_b^l\)</span>，区别在于<span class="math inline">\(a_{r,b}^l\)</span>。</p>
<blockquote>
<p>The basis function decomposition can be seen as a form of eﬀective weight sharing between different relation types</p>
</blockquote>
<p>这种方式可以看做是有<span class="math inline">\(B\)</span>个矩阵<span class="math inline">\(V\)</span>，然后与邻居实体embedding相乘，得到<span class="math inline">\(B\)</span>个message embedding，然后对于不同的关系使用权重<span class="math inline">\(a_{1,b}^l,\dots,a_{B,b}^l\)</span>去聚合。</p>
<p><strong>2、block-diagonal decomposition</strong> <span class="math display">\[
W_r^l=\oplus_b^B Q_{b,r}^l
\]</span></p>
<p><span class="math display">\[
W_r = diag(Q_{1r}^{l},\cdots,Q_{Br}^{l})\ with\ Q_{br}^{l} \in \mathbb{R}^{(d^{l+1}/B)\times (d^{l}/B)}
\]</span></p>
<p>其中符号<span class="math inline">\(\oplus\)</span>是矩阵加法中的Direct Sum，不是普通的相加，而是下面的形式，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210421222339835.png" style="zoom:50%;" /></p>
<p>这里说明下block-diagonal matrix，根据维基百科的解释</p>
<blockquote>
<p>A <strong>block diagonal matrix</strong> is a block matrix that is a <a href="https://en.wikipedia.org/wiki/Square_matrix">square matrix</a> such that the main-diagonal blocks are square matrices and all off-diagonal blocks are zero matrices.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210421222219414.png" style="zoom:50%;" /></p>
<p>对于这种正则化方式的理解</p>
<blockquote>
<p>The block decomposition can be seen as a sparsity constraint on the weight matrices for each relation type.</p>
</blockquote>
<p>它与bias decomposition的区别是它没有设置共享参数的结构，而是直接使用更加系数的<span class="math inline">\(W_r\)</span>去拟合。</p>
<h2 id="entity-classiﬁcation">3 Entity Classiﬁcation</h2>
<p>对于实体分类，就是将entity 分类为K个class当中，那么在R-GNN的基础上，直接在最后一层的输出增加softmax就可以，训练时的loss为 <span class="math display">\[
L=-\sum_{i\in Y}\sum_{k=1}^{K}t_{ik}lnh_{ik}^L
\]</span> <span class="math inline">\(Y\)</span>是所有有label的entity集合。</p>
<h2 id="link-prediction">4 Link Prediction</h2>
<p>要进行Link Prediction，在R-GCN的基础上需要设计一个score function。</p>
<p>论文直接使用了DistMult作为decoder， <span class="math display">\[
f(s,r,o)=e_s^TRe_o
\]</span> 训练的loss为 <span class="math display">\[
L=-\frac{1}{(1+w)|\varepsilon|}\sum_{(s,r,o,y)\in \Gamma}{ylog(f(s,r,o)) + (1-y)log(1-f(s,r,o)) }
\]</span> 前面的系数为归一系数，<span class="math inline">\(w\)</span>为对于每一个postivite sample取<span class="math inline">\(w\)</span>个negative samples，<span class="math inline">\(|\varepsilon|\)</span>为所有实体的个数。</p>
<h2 id="empirical-evaluation">5 Empirical Evaluation</h2>
<h3 id="entity-classiﬁcation-experiments">5.1 Entity Classiﬁcation Experiments</h3>
<p>数据集</p>
<ul>
<li>AIFB</li>
<li>MUTAG,</li>
<li>BGS</li>
<li>AM</li>
</ul>
<p>超参设计</p>
<ul>
<li>2-layer model with 16 hidden units</li>
<li>basis function decomposition</li>
<li>Adam，learning rate of 0.01</li>
</ul>
<p>Baseline：</p>
<ul>
<li><p>RDF2Vec embeddings</p></li>
<li><p>WeisfeilerLehman kernels (WL)</p></li>
<li><p>hand-designed feature extractors (Feat)</p></li>
</ul>
<h2 id="link-prediction-experiments">5.2 Link Prediction Experiments</h2>
<table>
<thead>
<tr class="header">
<th>Dataset</th>
<th>WN18</th>
<th>FB15K</th>
<th>FB15k-237</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Entities</td>
<td>40,943</td>
<td>14,951</td>
<td>14,541</td>
</tr>
<tr class="even">
<td>Relations</td>
<td>18</td>
<td>1,345</td>
<td>237</td>
</tr>
<tr class="odd">
<td>Train edges</td>
<td>141,442</td>
<td>483,142</td>
<td>272,115</td>
</tr>
<tr class="even">
<td>Val. edges</td>
<td>5,000</td>
<td>50,000</td>
<td>17,535</td>
</tr>
<tr class="odd">
<td>Test edges</td>
<td>5,000</td>
<td>59,071</td>
<td>20,466</td>
</tr>
</tbody>
</table>
<p>FB15k-237是FB15K的reduced版本，去除了所有的inverse relation。</p>
<p>评估指标：</p>
<ul>
<li>MRR</li>
<li>HIT@</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>KG</tag>
      </tags>
  </entry>
  <entry>
    <title>RDGCN</title>
    <url>/kge/RDGCN/</url>
    <content><![CDATA[<h1 id="relation-aware-entity-alignment-for-heterogeneous-knowledge-graphs">Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs</h1>
<p>IJCAI 2019</p>
<p><a href="https://github.com/StephanieWyt/RDGCN"><strong>RDGCN</strong></a> (Relation-aware Dual-Graph Convolutional Network)，预测任务是KG的实体对齐，主要是为了捕获更多的在dual KG中的relation的信息。核心创新点是对于dual KG（即要对齐的两个KG），构造了Dual Relation Graph，捕获relation和relation之间的联系。之后在这个Dual Relation Graph上学习relation的表示，融入到original KG中进行entity的表示学习，最终用于entity之间的对齐。</p>
<span id="more"></span>
<h2 id="method">Method</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827161832004.png" alt="image-20210827161832004" style="zoom:50%;" /></p>
<h3 id="constructing-the-dual-relation-graph">Constructing the Dual Relation Graph</h3>
<p>有两个KG，<span class="math inline">\(G_1\)</span>和<span class="math inline">\(G_2\)</span>，然后这两个图看做是一个大的graph，<span class="math inline">\(G_e\)</span>。注意，两个KG没有相连。</p>
<p>构造relation graph，relation作为node，如果两个relation具有相同的头/尾实体，那么两个relation node构造一条边。</p>
<p>更进一步，为这个边赋值一个权重，表示两个关系相连的紧密程度。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827162305649.png" alt="image-20210827162305649" style="zoom:50%;" /></p>
<p><span class="math inline">\(H\)</span>和<span class="math inline">\(T\)</span>是所有的头/尾实体。</p>
<h3 id="dual-attention-layer">Dual Attention Layer</h3>
<p>这一层是用来捕获更复杂的关系信息，从而辅助下面的实体表示的学习。</p>
<p>在dual realtion graph中，一个关系node的表示为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827193821221.png" alt="image-20210827193821221" style="zoom:50%;" /></p>
<p>需要注意，这里没有给关系赋予一个独立的表示，而是直接使用头尾实体的平均表示。</p>
<p>之后，基于gat进行relation之间的聚合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827193932914.png" alt="image-20210827193932914" style="zoom:50%;" /></p>
<h3 id="primal-attention-layer">Primal Attention Layer</h3>
<p>利用上面学习到的relation的表示，在original graph中进行实体的表示学习。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827194018172.png" alt="image-20210827194018172" style="zoom:50%;" /></p>
<p>随后，使用残差</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827194112479.png" alt="image-20210827194112479" style="zoom:50%;" /></p>
<h3 id="incorporating-structural-information">Incorporating Structural Information</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827194151191.png" alt="image-20210827194151191" style="zoom:50%;" /></p>
<p>使用highway gnn更新，保留上一步的信息</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827194230407.png" alt="image-20210827194230407" style="zoom:50%;" /></p>
<p>最后，进行实体对齐</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210827194312252.png" alt="image-20210827194312252" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>KGE</tag>
      </tags>
  </entry>
  <entry>
    <title>RESCAL</title>
    <url>/kge/RESCAL/</url>
    <content><![CDATA[<h1 id="a-three-way-model-for-collective-learning-on-multi-relational-data">A Three-Way Model for Collective Learning on Multi-Relational Data</h1>
<p>2011</p>
<blockquote>
<p>we propose the relational learning approach RESCAL which is based on a tensor factorization that is related to DEDICOM but does not exhibit the same constraints.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>说明最近tensor decomposition方法逐渐被应用在relational learning，原因：</p>
<ul>
<li>从建模的角度讲，tensor decomposition更直接，各种relation可以直接表示为high-order tensor。同时，没有先验知识需要</li>
<li>从learning的角度讲，关系型的数据通常是高维并且稀疏的，适用于tensor decomposition。</li>
</ul>
<p>关系型数据的重要特征是相关性能够通过各种相连的node产生，但是目前的模型都无法很好的满足要求。</p>
<blockquote>
<p>we propose the relational learning approach RESCAL which is based on a tensor factorization that is related to DEDICOM but does not exhibit the same constraints.</p>
</blockquote>
<h2 id="modelling-and-notation">2 Modelling and Notation</h2>
<p>看一下对于relational data如何表示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200223224511662.png" style="zoom:50%;" /></p>
<p>整体的数据被表示为张量<span class="math inline">\(\cal{X}\)</span>，<span class="math inline">\(\cal{X}_{ijk}=1\)</span>，表示fact存在。</p>
<h2 id="methods-and-theoretical-aspects">4 Methods and Theoretical Aspects</h2>
<p>文中定义了collective learning，大概含义是通过利用相关node的信息perform task。</p>
<blockquote>
<p>We will refer to the mechanism of exploiting the information provided by related entities regardless of the particular learning task at hand as collective learning.</p>
</blockquote>
<h3 id="a-model-for-multi-relational-data">4.1 A Model for Multi-Relational Data</h3>
<p>核心在于： <span class="math display">\[
{\cal{X}_k} \approx AR_kA^T,\ k = 1,2,\dots,m,\\
A \in R^{n\times r}, R_k\in R^{r\times r}
\]</span> 对于该式子的理解是，<span class="math inline">\(R_k\)</span>表示关系<span class="math inline">\(r\)</span>的转换，<span class="math inline">\(R_kA^T\)</span>将<span class="math inline">\(A\)</span>转换到了<span class="math inline">\(R_k\)</span>表示的向量空间当中，通过与<span class="math inline">\(A\)</span>乘积，最终得到的对于<span class="math inline">\((h,r,t)\)</span>，通过点积表示fact。</p>
<p>通过最小化得到最终的embedding： <span class="math display">\[
min\ f(A,R_k)+g(A,R_k) \\
f(A,R_k)=\frac{1}{2}(\sum_k {\lVert {\cal{X}}-AR_kA^T \rVert}_F^2) \\
g(A,R_k)=\frac{1}{2}\lambda({\lVert A \rVert}^2_F + \sum_k{\lVert R_k \rVert}^2_F)
\]</span></p>
<h2 id="evaluation">5 Evaluation</h2>
<p>进行了四方面的比较，</p>
<ul>
<li>Collective Classiﬁcation</li>
<li>Collective Entity Resolution</li>
<li>Kinships, Nations and UMLS</li>
<li>Runtime Performance and Technical Considerations</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>RGHAT</title>
    <url>/kge/RGHAT/</url>
    <content><![CDATA[<h1 id="relational-graph-neural-network-with-hierarchical-attention-for-knowledge-graph-completion">Relational Graph Neural Network with Hierarchical Attention for Knowledge Graph Completion</h1>
<p>AAAI 2020</p>
<p>使用了两层注意力，相同关系下的实体的注意力+不同关系的注意力</p>
<span id="more"></span>
<p><strong>无开源代码</strong></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200906193934782.png" style="zoom:50%;" /></p>
<p>使用了两层的attention，</p>
<p>Relation-level attention <span class="math display">\[
\mathcal{a}_{h,r}=W_1[h||v_r] \\
\alpha_{h,r}=softmax_r(\alpha_{h,r})=\frac{exp(\sigma(p\cdot a_{h,r}))}{\sum_{r^\prime\in N_h } exp(\sigma(p\cdot a_{h,r^\prime}))}
\]</span> Entity-level attention <span class="math display">\[
b_{h,r,t}=W_2[a_{h,r}||t] \\
\beta_{r,t}=softmax_t(b_{h,r,t})
\]</span> 最后计算triple-level attention <span class="math display">\[
\mu_{h,r,t}=\alpha_{h,r}\cdot \beta_{r,t}
\]</span> 邻居信息的聚合 <span class="math display">\[
\hat{h} = \sum_{r\in \cal{N}_{h}} \sum_{t\in \cal{N}_{h,r}} \mu_{h,r,t} b_{h,r,t}
\]</span> 与自身信息的聚合 <span class="math display">\[
h^\prime = \frac{1}{2} ( \sigma(W_3(h+\hat{h})) + \sigma(W_3(h \odot \hat{h})))
\]</span> 以上就是encoder，decoder是ConvE。</p>
<p>在实践中，</p>
<blockquote>
<ul>
<li><p>In the training stage, we adopt a two-layer RGHAT</p></li>
<li>For the encoder, the embedding size of entities is set as 100 for both the input and output layer.</li>
<li><p>The number of heads for the multi-head attention mechanism is set as 8.</p></li>
<li>A dropout with the rate as 0.5 is applied to each input layer of the encoder and the normalized attention coefﬁcients following graph attention network.</li>
<li><p>L2 regularization with λ = 0.0005</p></li>
</ul>
</blockquote>
<p>实验效果看起来很漂亮，但是无法复现就无法确定代码是否有正误，特别是在KBGAT存在test data leakage的情况下。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200906194013652.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>Re-eval-KGC</title>
    <url>/kge/Re-eval-KGC/</url>
    <content><![CDATA[<h1 id="a-re-evaluation-of-knowledge-graph-completion-methods">A Re-evaluation of Knowledge Graph Completion Methods</h1>
<p>2019-11-10 ACL 2020</p>
<p>重新发现目前的KGC方法中存在的问题，提出了一个RANDOM的评估策略。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>最近出现的nn的model for Knowledge Graph Completion(KGC)，的效果存在问题：</p>
<blockquote>
<p>in ConvKB, there is a 21.8% improvement over ConvE on FB15k-237, but a degradation of 42.3% on WN18RR, which is surprising given the method is claimed to be better than ConvE.</p>
</blockquote>
<p>它们在一个数据集(FB15K-237)上取得很好的结果，但是在另外的数据集(WRR18)上的效果反而下降了。本论文就针对这个问题进行了调查。发现是由于它们的评估策略的问题。</p>
<h2 id="observations">3 Observations</h2>
<p>经过调查发现，在最后进行评估的时候，部分受到影响的模型如ConvKB，KBAT等，它们会对于很多的negative sample产生和valid triple一样的score。</p>
<blockquote>
<p>On average, ConvKB and CapsE have 125 and 278 entities with exactly same score as the valid triplet over the entire evaluation dataset of FB15k-237, whereas ConvE has around 0.002,</p>
</blockquote>
<p>在这样的情况下，如果一开始的valid triple是作为评估triple的开头的话，效果就会虚假的高。</p>
<h2 id="evaluation-method">4 Evaluation Method</h2>
<p>因此，论文就提出了一个评估的策略：<em>RANDOM</em></p>
<blockquote>
<p>RANDOM:</p>
<p>In this, the correct triplet is placed randomly in <span class="math inline">\(\cal{T^{&#39;}}\)</span> .</p>
</blockquote>
<p>其中， <span class="math display">\[
\cal{T^{&#39;}} = \{ (h, r, t^{&#39;})\ |\ t^{&#39;} \in \cal{E} \}
\]</span></p>
<blockquote>
<p>RANDOM is the best evaluation technique which is both rigorous and fair to the model.</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>RelGNN</title>
    <url>/kge/RelGNN/</url>
    <content><![CDATA[<h1 id="relation-aware-graph-attention-model-with-adaptive-self-adversarial-training">Relation-aware Graph Attention Model With Adaptive Self-adversarial Training</h1>
<p>AAAI 2021</p>
<p>作者提出了RelGNN方法处理带attribute的heterogeneous graph，核心部分包括一个采取了注意力机制的R-GCN方法以及能够降低负采样false negative sample的自对抗负采样方法adaptive self-adversarial (ASA) negative sampling。</p>
<p>个人认为最大的创新点是这种负采样的方法ASA。负采样的核心思路是如何寻找最难区分discriminative的样本。而ASA方法的核心思想是计算正样本和负样本得分score之间的绝对差距，采样使这种差距最小的负样本。作者认为如果一个构造的负样本计算的得分比正样本的得分还要大，那么这样的负样本更有可能是false negative，因此不能直接选择这样最难区分的负样本，而是考虑正样本的预测值。</p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p><strong>motivation</strong>：两个问题</p>
<ol type="1">
<li>作者认为目前处理heterogeneous graph的GNN在聚合邻居信息的时候没有考虑边的语义信息，知识在进行meta-path遍历或者消息构造函数时起到作用。</li>
<li>目前训练采用的负采样方法，无法考虑false negatives的问题。</li>
</ol>
<p><strong>method</strong>：提出RelGNN</p>
<ol type="1">
<li>在聚合消息时，使用注意力机制，同时考虑node state和edge state。</li>
<li>提出ASA采样方法，使用每一次训练好的模型为下一次训练寻找negative samples。思路是认为一个positive sample的confidence level应该和它衍生的negative sample的概率是匹配的。</li>
</ol>
<h2 id="method">Method</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702160109326.png" style="zoom:50%;" /></p>
<h3 id="attribute-embedding">attribute embedding</h3>
<p>在Attributed Heterogeneous Graph中，对于不同node type，有不同的attribute schema，有不同的attribute。使用不同的方法处理这些特征，然后拼接，投影至相同空间中，获得node <span class="math inline">\(v\)</span>的attribute embedding <span class="math inline">\(h_{v}^{(0)}\)</span>。</p>
<h3 id="message-passing">Message Passing</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702161233932.png" style="zoom:50%;" /></p>
<p>上面就是R-GCN。实际上，为了避免过度参数化，使用了R-GCN的<em>basis-decomposition</em>。</p>
<p>接下来，是使用了edge embedding的attention：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702161403878.png" style="zoom:50%;" /></p>
<p>采用多头机制，同时要注意这个attention是不包括self-loop传递过来的信息的。</p>
<p>最后，为了融合attribute embedding <span class="math inline">\(h_{v}^{(0)}\)</span>以及graph embedding <span class="math inline">\(h_{v}^{last}\)</span>，使用attention来融合</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702161953963.png" style="zoom:50%;" /></p>
<p>使用了<em>averaging</em>的multi-attention。</p>
<h3 id="asa-negative-sampling">ASA negative sampling</h3>
<p>以前的自对抗采样方法self-adversarial negative sampling，寻找最难预测的负样本。</p>
<blockquote>
<p>The core idea is to use the model itself to evaluate the hardness of negative samples,</p>
</blockquote>
<p>RelGNN预测三元组存在的概率，使用了DistMult来打分：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702163057832.png" style="zoom:50%;" /></p>
<p>之前的自对抗负采样方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702163147312.png" style="zoom:50%;" /></p>
<p>改进后的负采样方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702163241877.png" style="zoom:50%;" /></p>
<p>加入<span class="math inline">\(u\)</span>之后，实际上是减小了小于正样本得分的负样本和正样本之间的差距，扩大了大于正样本得分的负样本和正样本之间的差距，让模型倾向于选择小于正样本得分的负样本。随着模型训练，模型越来越“正确”，可以考虑减小<span class="math inline">\(u\)</span>的值，让模型去选择更难预测的负样本。</p>
<p><span class="math inline">\(u\)</span>如果太小，会让模型倾向选择更hard的负样本，增大false negative的概率。</p>
<p><span class="math inline">\(u\)</span>如果太大，会倾向于选择那些trivial samples，不够discriminate。</p>
<h2 id="experiment">Experiment</h2>
<p>主要的结果忽略，可以学习的是它对于attention的可视化，计算每个node的领奖attention的熵entropy，计算不同节点的注意力的熵，熵约低，表示这个节点的邻居注意力差异越小，约不混沌，值约集中，越关注某些特定的邻居。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210702163855948.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>KRL</tag>
      </tags>
  </entry>
  <entry>
    <title>SACN</title>
    <url>/kge/SACN/</url>
    <content><![CDATA[<h1 id="end-to-end-structure-aware-convolutional-networks-for-knowledge-base-completion">End-to-End Structure-Aware Convolutional Networks for Knowledge Base Completion</h1>
<p>AAAI 2019</p>
<p>W-GCN+Conv-TransE</p>
<p>W-GCN把不同的关系类型看做是不同的sub graph，不同的sub graph包括不同的weight。请注意这里的weight不同于一般的self-attention，W-GCN的weight是只与relation type有关的，而且不包括self-loop。</p>
<span id="more"></span>
<p><span class="math display">\[
h_{i+1}=\sigma{\sum_{j\in N_{i}}\alpha_t^l h_j^l W^l + h_i^lW^l}
\]</span> Conv-TransE是在ConvE的基础上，取消了feature reshaing。直接将head entity embedding和relation embedding stack成<span class="math inline">\(2\times d\)</span>的矩阵，之后使用<span class="math inline">\(2\times k\)</span>的卷积核进行卷积操作，这样仍然能够保持TransE中的transformation property。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200906104625946.png" style="zoom:50%;" /></p>
<p>需要注意的是，它构建了一个新的数据集，FB15k-237-Attr，从FB24k中导出属性，增加到FB15k-237数据集中。</p>
<blockquote>
<p>We extract the attribute triples of entities in FB15k-237 from FB24k. During the mapping, there are 7,589 nodes from the original 14,541 entities which have the node attributes. Finally, we extract 78,334 attribute triples from FB24k. These triples include 203 attributes and 247 relations. Based on these triples, we create the “FB15k-237-Attr” dataset, which includes 14,541 entity nodes, 203 attribute nodes, 484 relation types. All the 78,334 attribute triples are combined with the training set of FB15k-237.</p>
</blockquote>
<p>对于W-GCN如何处理attribute没有看懂。</p>
<p>实验结果</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200906104552852.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>T-GAP</title>
    <url>/kge/T-GAP/</url>
    <content><![CDATA[<h1 id="learning-to-walk-across-time-for-interpretable-temporal-knowledge-graph-completion">Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion</h1>
<p>T-GAP KDD 2021</p>
<p><a href="https://github.com/sharkmir1/T-GAP.">https://github.com/sharkmir1/T-GAP</a></p>
<blockquote>
<p>Static knowledge graphs (KGs), despite their wide usage in relational reasoning and downstream tasks, fall short of realistic modeling of knowledge and facts that are only temporarily valid. Compared to static knowledge graphs, temporal knowledge graphs (TKGs) inherently reflect the transient nature of real-world knowledge. Naturally, automatic TKG completion has drawn much research interests for a more realistic modeling of relational reasoning. However, <strong>most of the existing models for TKG completion extend static KG embeddings that do not fully exploit TKG structure, thus lacking in 1) accounting for temporally relevant events already residing in the local neighborhood of a query, and 2) path-based inference that facilitates multi-hop reasoning and better interpretability.</strong> In this paper, we propose T-GAP, a novel model for TKG completion that maximally utilizes both temporal information and graph structure in its encoder and decoder. T-GAP encodes query-specific substructure of TKG by focusing on the temporal displacement between each event and the query timestamp, and performs path-based inference by propagating attention through the graph. Our empirical experiments demonstrate that T-GAP not only achieves superior performance against state-of-the-art baselines, but also competently generalizes to queries with unseen timestamps. Through extensive qualitative analyses, we also show that T-GAP enjoys transparent interpretability, and follows human intuition in its reasoning process.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p>作者期望解决的问题：</p>
<p>目前对于TKG补全的方法大多是之前对于静态KG方法的拓展，而在静态KG上的邻居信息已经证明了是有效的，但是如何在TKG上利用邻居信息还没有充分探究。</p>
<p>作者的解决方案：</p>
<p>编码阶段：作者看重对于捕获的邻居边的timestamp和要查询的timestamp之间的时间位移进行探究</p>
<blockquote>
<p>we focus on encoding the temporal displacement between the timestamps of the input query and each edge being encoded.</p>
</blockquote>
<p>比如下面的例子，要查询COVID-19在12月20日感染的人，明显重要的信息是COVID-19在两天前感染了A，然后在一天前A和B相遇。重要的是相对时间关系和时间的跨度，而不是具体的时间点。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220719183241840.png" style="zoom:30%;" /></p>
<p>解码阶段：作者提出了基于注意力value的路径传播方法</p>
<h2 id="method">Method</h2>
<p>整体上使用了GNN作为编码器，attention flow作为解码器。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721214613250.png" style="zoom:50%;" /></p>
<p>在编码器部分，就是在原始的graph上（论文中是称作preliminary graph）进行GNN操作。核心是通过不同相对时间关系的参数+时间位移的embedding来改造基于transformer-attention的GNN。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721220641053.png" style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721220210975.png" style="zoom:40%;" /></p>
<p>其中的，<span class="math inline">\(h_i\)</span>表示头实体embedding，初始值为随机初始化；<span class="math inline">\(\rho_{ij}\)</span>表示的是关系向量；<span class="math inline">\(\tau_{|\triangle t_{ij}|}\)</span>表示相对时间位移大小的向量。随后基于多头注意力进行聚合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721221555351.png" style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721221627204.png" style="zoom:40%;" /></p>
<p>在编码器部分，是执行最多<span class="math inline">\(T\)</span>次的解码过程，首先是采样得到新的子图；其次是利用这样的子图进行和编码器相同过程但是不同参数的GNN操作；最后进行attention flow，便于下一步的采样子图。</p>
<p>子图采样是一个非参数化的过程，核心思想是采样当前采样得到的子图中，最大attention value的node，然后在这些比较重要的node出发，采样它们引出的比较重要的边，加入到子图中去。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721222218056.png" style="zoom:45%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721222236241.png" style="zoom:45%;" /></p>
<p>在采样得到的子图上，进行GNN操作，聚合邻居信息。主要过程和编码器部分一致。最后融合query相关的embedding：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721222552555.png" style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721222618124.png" style="zoom:40%;" /></p>
<p>最后，进行attention flow，核心思想是给定中心节点attention value <span class="math inline">\(1\)</span>，然后让这个value通过GNN聚合得到的信息，在graph上不断传播，自动计算各个路径的重要程度。公式里的第一个score用来计算已经在当前采样得到的子图中的node的重要程度，第二个score会更加偏好采样得到还没在当前采样子图图中的node。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721222945282.png" style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721223059254.png" style="zoom:40%;" /></p>
<p>总的采样过程实例如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220721223151983.png" style="zoom:40%;" /></p>
<p>通过上面的过程，T-GAP可以让注意力不断通过路径在graph上流动，最后得到attention value最大的node，就可以看做是要预测的目标。训练使用的loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220802181917428.png" style="zoom:40%;" /></p>
<h2 id="experiment">EXPERIMENT</h2>
<p>T-GAP的实验包括下述三方面：</p>
<ul>
<li>时序KG补全的性能</li>
<li>对于未见过的时间戳的泛化性</li>
<li>可解释性/与人类直观认识的关联</li>
</ul>
<p>实验的数据集包括：ICEWS14, ICEWS05-15和Wikidata11k。这三个数据集是较为通用的数据集，被之前的研究者建议使用（<em>Learning Sequence Encoders for Temporal Knowledge Graph Completion</em>）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220805173558600.png" style="zoom:40%;" /></p>
<p>ICEWS14包括2014年发生的社会政治事件；ICEWS05-15包括A.D. 25到2020发生的事件；</p>
<p>Wikidata11k是Wikidata的子集，在其中所有的fact加入了时空标识符<em>occurSince</em>和<em>occurUntil</em>。随着<em>Learning Sequence Encoders for Temporal Knowledge Graph Completion</em>的做法，作者把原来的时空标识符和关系合并起来，作为新的relation，比如(A, loves, B, since, 2020)变为(A, loves-since, B, 2020)。</p>
<h3 id="benchmark-performance">Benchmark Performance</h3>
<p>总体性能：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220805174207341.png" style="zoom:40%;" /></p>
<p>相对提升了10%，很明显的提升</p>
<p>消融实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220805174251297.png"  style="zoom:40%;" /></p>
<h3 id="temporal-generalization">Temporal Generalization</h3>
<p>沿着前人的做法（<em>Diachronic embedding for temporal knowledge graph completion</em>），把ICEWS14训练集中每个月的第5、15和25天发生的fact拿出来作为验证集和测试集，来验证对于queries with unseen timestamps的泛化性能。</p>
<p>结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220805174504528.png" alt="image-20220805174504528" style="zoom:40%;" /></p>
<h3 id="interpretability">Interpretability</h3>
<p>T-GAP的可解释性从两方面进行，（1）不同relation和时序位移的联系（2）attention flow推理过程的case study。</p>
<p>（1）Relation Type and Temporal Displacement</p>
<p>作者通过不同relation下，T-GAP学习到的attention的分布来分析relation和时序位移之间的联系。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220805174749639.png" alt="image-20220805174749639" style="zoom:50%;" /></p>
<p>（2）Reasoning Process</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220805174822723.png" alt="image-20220805174822723" style="zoom:40%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>TKG</category>
      </categories>
      <tags>
        <tag>TKG</tag>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>SEEK</title>
    <url>/kge/SEEK/</url>
    <content><![CDATA[<h1 id="seek-segmented-embedding-of-knowledge-graphs">SEEK: Segmented Embedding of Knowledge Graphs</h1>
<p>ACL 2020</p>
<p>虽然目前对于KGE的研究已经很多了，但是目前的方法都存在一个问题，简单的方法模型的表达能力不够；复杂的方法参数多，复杂性高，难以应用与实际的大规模的知识图谱。</p>
<p>本文就考虑如何在不增加复杂度的情况下增加模型的表达能力：</p>
<ul>
<li>增加特征之间的交互</li>
<li>保存关系的属性——对称性与不对称性</li>
<li>设计有效的得分函数</li>
</ul>
<p>核心方法是将实体和关系的embedding拆分为k个segment。</p>
<span id="more"></span>
<p>模型方法：</p>
<p>首先将实体和关系的embedding拆分为k个segment。</p>
<p>直接看最后的得分函数</p>
<p><span class="math display">\[
f_4(h,r,t)= \sum_{0\leq x,y&lt; k} s_{x,y} \cdot \left \langle r_x, h_y, t_{w_{x,y}} \right \rangle \\
\]</span></p>
<p><span class="math display">\[
w_{x,y} = \begin{cases}
y,  &amp; \mbox{if }x\mbox{ is even}, \\
(x+y)\%k, &amp; \mbox{if }x\mbox{ is odd}
\end{cases} 
\]</span></p>
<p><span class="math display">\[
s_{x,y} =
\begin{cases}
-1,  &amp; \mbox{if }x\mbox{ is odd and } x+y\geq k, \\
1, &amp; otherwise
\end{cases} \\
\]</span> 分析上面的方法，引入<span class="math inline">\(s_{x,y}\)</span>可以建模关系的对称和不对称性，将<span class="math inline">\(h\)</span>和<span class="math inline">\(t\)</span>互换的情况下，<span class="math inline">\(f_4(h,r,t)\)</span>不一样。</p>
<p>引入<span class="math inline">\(w_{x,y}\)</span>限制了<span class="math inline">\(t_{w_{x,y}}\)</span>，不再是所有分段的全体组合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20200929220716325.png" style="zoom:50%;" /></p>
<p>最终实验在FB15K，DB100K，YAGO37三个数据集下进行了实验。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
  </entry>
  <entry>
    <title>TACT</title>
    <url>/kge/TACT/</url>
    <content><![CDATA[<h1 id="topology-aware-correlations-between-relations-for-inductive-link-prediction-in-knowledge-graphs">Topology-Aware Correlations Between Relations for Inductive Link Prediction in Knowledge Graphs</h1>
<p>AAAI 2021</p>
<p><a href="https://github.com/MIRALab-USTC/KG-TACT">TACT</a>，作者主要考虑的是inductive link prediction，使用gnn，捕获relation之间的语义上的关联性，即semantic correlation。作者认为relation之间的关联性通过relation的拓扑结构得到体现，因此，作者将所有的relation之间相连的拓扑结构分为7种，在relation形成的graph中进行学习，提出了RCN。</p>
<span id="more"></span>
<blockquote>
<p>Inductive link prediction—where entities during training and inference stages can be different—has been shown to be promising for completing continuously evolving knowledge graphs. Existing models of inductive reasoning mainly focus on predicting missing links by learning logical rules. However, many existing approaches do not take into account semantic correlations between relations, which are commonly seen in real-world knowledge graphs. To address this challenge, we propose a novel inductive reasoning approach, namely TACT, which can effectively exploit Topology-Aware CorrelaTions between relations in an entity-independent manner. TACT is inspired by the observation that the semantic correlation between two relations is highly correlated to their topological structure in knowledge graphs. Speciﬁcally, we categorize all relation pairs into several topological patterns, and then propose a Relational Correlation Network (RCN) to learn the importance of the different patterns for inductive link prediction. Experiments demonstrate that TACT can effectively model semantic correlations between relations, and signiﬁcantly outperforms existing state-of-the-art methods on benchmark datasets for the inductive link prediction task.</p>
</blockquote>
<h2 id="introduction">1 Introduction</h2>
<p>作者考虑的是比较另类的link prediction，inductive link prediction。即在测试集中要预测的实体没有在训练集中出现。像是最常见的link prediction都是transductive link prediction，不能保证对新出现的实体也有比较好的预测效果。</p>
<p>为了进行inductive learning，就必须保证能够将训练集中训练好的信息能够迁移到测试集上。具体到link prediction上，就是说需要方法能够进行entity-independent的学习。因为relation应该是已有的，不是新出现的。</p>
<p>之前的inductive link prediction很多事基于rule的学习，因为学习到规则的话，这种规则是entity-independent的。</p>
<p>作者考虑在relation上做文章，主要考虑利用topology pattern捕获relation之间的semantic correlation。</p>
<h2 id="methods">2 Methods</h2>
<p>首先把KG上所有的relation的关联关系分为7种，作者在附录中证明了一共只有7种。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210510171104138.png" style="zoom:50%;" /></p>
<p>然后看一下整体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210510170648225.png" style="zoom:50%;" /></p>
<p>两个模块，RCN+R-GCN</p>
<p>RCN是核心创新点，构造了一个只由relation组成的graph，relation之间的edge有6种（NC的这种不存在）。</p>
<p>RCN学习了<span class="math inline">\(\mathbf{r}_t\)</span>，R-GCN学习<span class="math inline">\(\mathbf{e}_u\)</span>，<span class="math inline">\(\mathbf{e}_v\)</span>，以及graph embedding<span class="math inline">\(\mathbf{e}_G\)</span>。</p>
<p>主要看下RCN，两步：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210510171135345.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(N_t^P\in \mathbb{R}^{1\times |R|}\)</span>，取值为0/1，表示关系之间的相连性；<span class="math inline">\(\Lambda_t^P\in \mathbb{R}^{1\times |R|}\)</span>，是可学习的参数，表示relation之间的correlation coefﬁcients，并且保证 <span class="math inline">\(\sum_{i=1}^{|R|}\Lambda_t^P=1\)</span>。</p>
<p>然后得到relation <span class="math inline">\(t\)</span>最终表示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210510170730416.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>KGE</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>KGE</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention-survey-2021</title>
    <url>/ml/Attention-survey-2021/</url>
    <content><![CDATA[<h1 id="a-general-survey-on-attention-mechanisms-in-deep-learning">A General Survey on Attention Mechanisms in Deep Learning</h1>
<p>TKDE 2021</p>
<blockquote>
<p>Attention is an important mechanism that can be employed for a variety of deep learning models across many different domains and tasks. This survey provides an overview of the most important attention mechanisms proposed in the literature. The various attention mechanisms are explained by means of a framework consisting of a general attention model, uniform notation, and a comprehensive taxonomy of attention mechanisms. Furthermore, the various measures for evaluating attention models are reviewed, and methods to characterize the structure of attention models based on the proposed framework are discussed. Last, future work in the ﬁeld of attention models is considered.</p>
</blockquote>
<p>这篇文章调研了大量的注意力方法，集中在surprised learning领域。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>让模型模仿人的注意力（attention），只关注重要部分，忽略次要部分的思想，最早出现在CV领域，例如论文<em>Learning to combine foveal glimpses with a third-order Boltzmann machine NIPS 2010</em>和<em>Recurrent models of visual attention NIPS 2014</em>。但是我们普遍认为现在的注意力机制起源，是在NLP领域，<em>Neural machine translation by jointly learning to align and translate ICLR 2015</em>。</p>
<p>注意力受到研究人员的重视，有以下原因：</p>
<ul>
<li>效果好，取得SOTA的模型往往会采用注意力方法（特别是在Transformer方法被提出后）。使用注意力方法在各个领域都被证明有效。</li>
<li>注意力机制可以很容易的和原来的base model结合，一起通过BP优化。</li>
<li>某些情况下，注意力可以为深度学习带来更合理的解释</li>
</ul>
<p>这篇survey的贡献：</p>
<ul>
<li>使用统一的描述、统一的框架描述了大量不同领域的注意力机制</li>
<li>提出注意力的一种分类法</li>
<li>评估注意力模块的不同方法</li>
</ul>
<h2 id="general-attention-model">2 General Attention Model</h2>
<p>作者讨论的模型架构分为四部分，feature model、attention model、query model和output model。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516213153701.png" style="zoom:50%;" /></p>
<p>feature model是base model，也就是用来处理原始数据，进行信息提取，然后得到需要进行attention的特征向量。它可以是CNN、RNN、GNN等各种网络网络结构，假设经过feature model之后，得到了特征集合<span class="math inline">\(F\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516213545170.png" style="zoom:50%;" /></p>
<p>query model会产生查询向量，它根据此刻output model需要的context生成，用来评估各个特征向量哪个是可能更重要的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516214139491.png" style="zoom:50%;" /></p>
<p>query vector可能是直接定义的某个向量；也可能是RNN中之前的隐藏状态等。</p>
<p>attention model是关键，它的整个过程如图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516214418565.png" style="zoom:50%;" /></p>
<p>attention model接收到上面feature model和query model的输入后，根据特征向量会构建对应的<strong>value集合</strong>和<strong>key集合</strong>。这一步可能是类似于Transformer中的线性投影；也可能什么都不做，直接使用特征向量；可以是任意合理的映射函数。下面是采用Transformer中的线性投影：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516213902561.png" style="zoom:50%;" /></p>
<p>接下来经过三个步骤：</p>
<p><strong>1. score function</strong></p>
<p>利用query和key，计算attention value：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516214648154.png" style="zoom:50%;" /></p>
<p><span class="math inline">\(e_l\)</span>表示第<span class="math inline">\(i\)</span>个key vector对于query <span class="math inline">\(\mathbf{q}\)</span>有多重要。最终对应每个value vector都有一个attention value：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516214804659.png" alt="image-20220516214804659" style="zoom:50%;" /></p>
<p><strong>2. alignment function</strong></p>
<p>在很多情况下，得到的attention value可能会超出<span class="math inline">\([0,1]\)</span>，并且我们期望的注意力最后得到的输出是平均加权和。所以attention value会经过一个alignment function进行重新分布（redistributed）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516215219118.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516215321857.png" style="zoom:50%;" /></p>
<p>最常用的方法是softmax，当然还有其它的方法。</p>
<p><strong>3. weight average</strong></p>
<p>对value vector根据attention weight，加权求和：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220516215431614.png" style="zoom:50%;" /></p>
<p>output model是使用feature model提取出的特征向量经过attention之后得到的输出，表示后续的网络结构。</p>
<h2 id="attention-taxonomy">3 Attention Taxonomy</h2>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Survey</category>
      </categories>
      <tags>
        <tag>Attention</tag>
      </tags>
  </entry>
  <entry>
    <title>HyperNetworks</title>
    <url>/ml/HyperNetworks/</url>
    <content><![CDATA[<h1 id="hypernetworks">HYPERNETWORKS</h1>
<p>ICLR 2017</p>
<p>核心贡献是将Hypernetwork扩展到了convolutional networks和long recurrent networks，证明其在使用更少的参数情况下，在序列模型和卷积网络的多个预测任务下都达到了不错的训练结果。</p>
<span id="more"></span>
<h2 id="introduction">Introduction</h2>
<p>Hypernetwork是一个能够为另一个更大的网络产生weight的较小的网络。示例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725110111444.png" alt="image-20210725110111444" style="zoom:50%;" /></p>
<blockquote>
<p>In this work, we consider an approach of using a small network (called a “hypernetwork&quot;) to generate the weights for a larger network (called a main network).</p>
</blockquote>
<blockquote>
<p>hypernetwork takes a set of inputs that contain information about the structure of the weights and generates the weight for that layer</p>
</blockquote>
<p>HyperNEAT是一个使用hypernetwork的实例，输入时weight的virtual coordinates。</p>
<p>这篇文章的hypernetwork直接接收一个描述weight的embedding vector。同时设计了CNN和RNN的两种变体。</p>
<h2 id="method">Method</h2>
<h3 id="static-hypernetwork-a-weight-factorization-approach-for-deep-convolutional-networks">Static Hypernetwork : A Weight Factorization Approach For Deep Convolutional Networks</h3>
<p><span class="math inline">\(K^j\)</span>是第<span class="math inline">\(j\)</span>​层的卷积核，一共有<span class="math inline">\(D\)</span>层</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111008315.png" alt="image-20210725111008315" style="zoom:50%;" /></p>
<p>它由一个hypernetwork产生，每层接收一个描述weight的embedding <span class="math inline">\(z^j\)</span></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111037575.png" alt="image-20210725111037575" style="zoom:50%;" /></p>
<p>具体产生方法，一个静态的hypernetwork，简单看了下实验，<span class="math inline">\(z^j\)</span>是一个比较小的embedding，甚至只有4。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111153567.png" alt="image-20210725111153567" style="zoom:50%;" /></p>
<h3 id="dynamic-hypernetwork-a-daptive-weight-generation-for-recurrent-networks">Dynamic Hypernetwork : A Daptive Weight Generation For Recurrent Networks</h3>
<p>一个新的RNN，weight是生成的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111430981.png" alt="image-20210725111430981" style="zoom:50%;" /></p>
<p>这个hypernetwork同样是用另一个小的RNN产生。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111544605.png" alt="image-20210725111544605" style="zoom:50%;" /></p>
<p>示例图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111631387.png" alt="image-20210725111631387" style="zoom:50%;" /></p>
<p>实际上，作者使用了另一种简化的版本，每一层定义了一个weight scaling vector <span class="math inline">\(d\)</span>​​，不再是完成生成weight matrix，而是生成weight vector。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111733324.png" alt="image-20210725111733324" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210725111717560.png" alt="image-20210725111717560" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Fast-weights-RNN</title>
    <url>/ml/Fast-weights-RNN/</url>
    <content><![CDATA[<h1 id="using-fast-weights-to-attend-to-the-recent-past">Using Fast Weights to Attend to the Recent Past</h1>
<p>NIPS 2016</p>
<p>作者将fast weights引入到RNN中实现了更好的效果。本质上是在RNN的t时刻到t+1时刻中间，插入了一段新的RNN结构，每个step计算之前的隐藏状态和当前隐藏状态的关系权重，不断累加，最后达到比较好的效果。</p>
<span id="more"></span>
<p>这里需要先介绍下fast weights。</p>
<p>在1987年的时候，有一篇paper《Using Fast Weights to Deblur Old Memories》，提出了下面的说法：</p>
<blockquote>
<p>Despite the emerging biological evidence that changes in synaptic efficacy at a single synapse occur at many different time-scales (Kupferman, 1979; Hartzell, 1981), there have been relatively few attempts to investigate the computational advantages of giving each connection several different weights that change at different speeds.</p>
</blockquote>
<p>意思是说如果把一个weight的更新看做是神经元的一次神经活动，那么weight的更新也应该是有不同time scalse的。</p>
<p>那么如果模仿这个过程，除了一般的weight外，还可以尝试加入其它time scale的weight，也就是fast weight，fast weight用来模拟短时的记忆。</p>
<ul>
<li>Slow weight: The slow weights are like the weights normally used in connectionist networks-they change slowly and they hold all the long-term knowledge of the network.</li>
<li>Fast weight: The fast weights change more rapidly and they continually regress towards zero so that their magnitude is determined solely by their recent past.</li>
</ul>
<p>来看一下作者具体怎么样把fast weight引入到RNN中：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220401213438036.png" alt="image-20220401213438036" style="zoom:40%;" /></p>
<p>首先定义一个fast weight matrix：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220401213526767.png" alt="image-20220401213526767" style="zoom:50%;" /></p>
<p>然后在RNN的<span class="math inline">\(t\)</span> step到<span class="math inline">\(t+1\)</span> step中间，插入新的多个step：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220401213626396.png" alt="image-20220401213626396" style="zoom:50%;" /></p>
<p>从这里可以看出来，<span class="math inline">\(A\)</span>被用来快速更新状态。</p>
<p>由于实际中，sequence的time step数量是要比定义的hidden state vector的维度要小的，所以最后计算出来的A实际上远远不是一个满秩的矩阵。为了计算方便，作者假定对于不同sequence，<span class="math inline">\(A\)</span>的初始值是0，那么有：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220401213830869.png" alt="image-20220401213830869" style="zoom:50%;" /></p>
<p>通过简单计算之前时刻隐藏状态和最近隐藏状态的点积，作为权重（也是attention），然后加上以前的隐藏状态，计算很快速。</p>
<p>作者还使用了layer normalization来防止两个向量的点积可能出现的数值消失或者爆炸的问题。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Theory</category>
      </categories>
  </entry>
  <entry>
    <title>Independence Survey</title>
    <url>/ml/Independence-Survey/</url>
    <content><![CDATA[<h1 id="independence-modeling-method">Independence Modeling Method</h1>
<p>对目前接触的集中能够约束差异性/独立性的方法做个简单汇总。包括</p>
<ul>
<li>互信息Mutual information.</li>
<li>距离相关性Distance correlation.</li>
<li>Hilbert-Schmidt Independence Criterion (HSIC)</li>
</ul>
<span id="more"></span>
<p>Mutual information和Distance correlation.在推荐模型KGIN（Learning Intents behind Interactions with Knowledge Graph for Recommendation）中得到了使用，用于约束几个特定embedding之间的独立性。</p>
<p>Mutual information：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709151338821.png" style="zoom:50%;" /></p>
<p>其中的函数<span class="math inline">\(s()\)</span>是计算相似度的函数，在文章中使用了cosine similarity。</p>
<p>Distance correlation：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709151449098.png" style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(dCor()\)</span>是距离相关性distance correlation：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709151520931.png" style="zoom:50%;" /></p>
<p>Hilbert-Schmidt Independence Criterion (HSIC)方法在AM-GCN中应用，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210709151711018.png" style="zoom:50%;" /></p>
<p>对于上述的集中方法还没有深入理解，先做一下记录。</p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
  </entry>
  <entry>
    <title>Meta-learning-intro</title>
    <url>/ml/Meta-learning-intro/</url>
    <content><![CDATA[<h1 id="meta-learning-learning-to-learn-fast">Meta-Learning: Learning to Learn Fast</h1>
<p>这是一篇博客（<a href="https://lilianweng.github.io/posts/2018-11-30-meta-learning/">Meta-Learning: Learning to Learn Fast</a>）的笔记，另外参考了对应的<a href="https://wei-tianhao.github.io/blog/2019/09/17/meta-learning.html">中文博客</a>，简单了解什么是meta-learning。</p>
<p>元学习尝试解决深度学习经常需要大量实例数据才能收敛的问题。我们期望好的元学习模型拥有好的泛化能力和适应能力，能够根据少量的样本就学习到比较合适的信息。</p>
<p>元学习可以解决一类定义好的预测任务，这篇文章主要讨论的是监督学习下的元学习问题。例如让一个图片分类器在训练集中没有猫的情况下，在测试集中能够实现只看到几张猫的图片就能够学会识别猫。</p>
<span id="more"></span>
<h2 id="overview">Overview</h2>
<p>假设有很多的任务可以学习，我们期望元学习模型能够在整个的任务空间下都达到比较好的效果，即使是遇到了一个新的任务也能够表现不错。比如下面的任务：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330211915167.png" style="zoom:35%;" /></p>
<p>上面的任务是少次学习的一个示例图，它是元学习在监督学习问题的一个实例，一般说明K-shot N-class，是指一个数据集中class包括K个labeled examples。</p>
<p>为了模拟测试集中的推理过程，在训练的时候，会尝试采样一个support set和一个prediction set，support set用来计算一次loss，然后假梯度下降，使用这个假更新后的参数计算模型在prediction set上的loss，计算梯度，使用这时候的梯度才真正的更新原来的梯度。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330212645013.png" style="zoom:50%;" /></p>
<p>通过上面的操作，让梯度下降的方向不是当前loss的梯度，而是“往前看了一步”，让梯度朝着更能拟合新的prediction task的方向优化。</p>
<p>接下来介绍三类经典的meta-learning模型。</p>
<h2 id="metric-based">Metric-Based</h2>
<p>基于度量的方法，核心思想是计算新的样本和当前support set中的样本的相似程度，让后让已有的样本提供信息。</p>
<h3 id="siamese-neural-networks">Siamese Neural Networks</h3>
<p><a href="http://www.cs.toronto.edu/~rsalakhu/papers/oneshot1.pdf">Koch, Zemel &amp; Salakhutdinov</a>提出。对于one-shot任务，设计一个CNN网络导出图片特征，然后分辨两个图片对于的embedding的相似程度（使用L1-distance），如果属于同一类就输出1，否则输出0。在测试的时候，让测试样本和support set中所有的图片计算相似度，最相似的那一个图片对应的类就是测试样本的类别。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330213424764.png" alt="image-20220330213424764" style="zoom:30%;" /></p>
<h3 id="matching-networks">Matching Networks</h3>
<p><a href="http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf">Vinyals et al., 2016</a>提出。对于K-shot任务，使用下面的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330213849574.png" alt="image-20220330213849574" style="zoom:30%;" /></p>
<p>核心公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330213923274.png" alt="image-20220330213923274" style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330213937734.png" alt="image-20220330213937734" style="zoom:40%;" /></p>
<h3 id="relation-network">Relation Network</h3>
<p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers_backup/Sung_Learning_to_Compare_CVPR_2018_paper.pdf">Sung et al., 2018</a>提出。样本的相似度计算是使用一个CNN方法<span class="math inline">\(g_{\phi}\)</span>来实现的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330214037937.png" alt="image-20220330214037937" style="zoom:40%;" /></p>
<h3 id="prototypical-networks">Prototypical Networks</h3>
<p><a href="http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf">Snell, Swersky &amp; Zemel, 2017</a>提出。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330214215177.png" alt="image-20220330214215177" style="zoom:40%;" /></p>
<h2 id="model-based">Model-Based</h2>
<p>让模型本身拥有快速学习的能力。</p>
<h3 id="mann-for-meta-learning">MANN for Meta-Learning</h3>
<p><a href="http://proceedings.mlr.press/v48/santoro16.pdf">Santoro et al., 2016</a>提出。以<a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#neural-turing-machines">NTM模型</a>为基础让拥有外部存储单元的MANN（Memory-Augmented Neural Networks）模型（注意，仅仅是GRU和LSTM这些不属于MANN）适用于元学习。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330215049680.png" alt="image-20220330215049680" style="zoom:50%;" /></p>
<h3 id="metanet">MetaNet</h3>
<p><a href="https://arxiv.org/abs/1703.00837">Munkhdalai &amp; Yu, 2017</a>提出。这里的fast weights和slow weights需要进一步了解。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330215357448.png" alt="image-20220330215357448" style="zoom:40%;" /></p>
<h2 id="optimization-based">Optimization-Based</h2>
<p>不再依赖于具体的模型，而是直接从梯度下降的原理出发进行设计。</p>
<h3 id="lstm-meta-learner">LSTM Meta-Learner</h3>
<p>适用LSTM来显式建模梯度下降的过程。<a href="https://openreview.net/pdf?id=rJY0-Kcll">Ravi &amp; Larochelle (2017)</a>提出。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330215638810.png" alt="image-20220330215638810" style="zoom:40%;" /></p>
<p>把梯度下降，看做是一步LSTM中的状态更新：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330215906741.png" alt="image-20220330215906741" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330215923820.png" alt="image-20220330215923820" style="zoom:50%;" /></p>
<p>然后使用LSTM来显式的建模梯度下降步骤：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220330220104006.png" alt="image-20220330220104006" style="zoom:50%;" /></p>
<h3 id="maml">MAML</h3>
<p><strong>Model-Agnostic Meta-Learning</strong> 简称 <strong>MAML</strong> (<a href="https://arxiv.org/abs/1703.03400">Finn, et al. 2017</a>)，是一种通用的优化算法，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/maml-algo.png" alt="MAML Algorithm" style="zoom:40%;" /></p>
<p>使用不同task，分别计算梯度，然后再使用prediction set进行实际的参数更新。</p>
]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>meta-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>NN-extrapolate</title>
    <url>/ml/NN-extrapolate/</url>
    <content><![CDATA[<h1 id="how-neural-networks-extrapolate-from-feedforward-to-graph-neural-networks">HOW NEURAL NETWORKS EXTRAPOLATE: FROM FEEDFORWARD TO GRAPH NEURAL NETWORKS</h1>
<p>ICLR 2021</p>
<p>这篇文章主要从理论和实验角度研究了MLP和GNN的外推（extrapolate）性能。</p>
<span id="more"></span>
<blockquote>
<p><strong>We study how neural networks trained by gradient descent extrapolate, i.e., what they learn outside the support of the training distribution.</strong> Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) – structured networks with MLP modules – have shown some success in more complex tasks. Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufﬁciently “diverse”. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-speciﬁc non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel. Empirically, our theory holds across different training settings.</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>什么是模型的外推性能？</p>
<blockquote>
<p>We say a neural network extrapolates well if it learns a task outside the training distribution.</p>
</blockquote>
<p>作者的两点贡献：</p>
<ul>
<li>分析并证明了MLP外推的结果以及什么情况下MLP外推效果好</li>
<li>解释了为什么GNN能够在一些算法任务上（比如动态规划DP）外推效果好，并且提出了合适的改进方法</li>
</ul>
<p>一些相关的关键工作。</p>
<ul>
<li>有研究者证明了ReLU MLP最后学习到的是分段线性函数，例如《Complexity of linear regions in deep networks》</li>
<li>有研究者在更大的graph上测试GNN的外推性能，发现在找最短路径等任务上外推性能好，但是没有使用理论分析</li>
</ul>
<h2 id="how-feedforward-neural-networks-extrapolate">HOW FEEDFORWARD NEURAL NETWORKS EXTRAPOLATE</h2>
<p>外推效果的定义，通过定义外推loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411211241283.png" alt="image-20220411211241283" style="zoom:50%;" /></p>
<p>一个ReLU MLP是如何外推的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411211349989.png" alt="image-20220411211349989" style="zoom:50%;" /></p>
<p>ReLU MLP不会顺着灰色的期望进行外推，而是很快就外推成为一个线性function。看一看下面的定理（MLP是使用NTK来训练的）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411211822939.png" alt="image-20220411211822939" style="zoom:50%;" /></p>
<p>怎么样让ReLU MLP能够外推结果好？</p>
<ol type="1">
<li>让MLP拟合的目标函数是线性的</li>
<li>让训练集足够的diverse，这样训练好的模型能够学到足够多合适“方向”便于外推</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411211558986.png" alt="image-20220411211558986" style="zoom:50%;" /></p>
<p>其它激活函数MLP什么时候效果好？</p>
<ul>
<li>当目标函数的分布和激活函数大致相似的时候</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411211727352.png" alt="image-20220411211727352" style="zoom:50%;" /></p>
<p>图中MAPE是指平均绝对误差比例，越小越好（原论文没提）。</p>
<h2 id="how-graph-neural-networks-extrapolate">HOW GRAPH NEURAL NETWORKS EXTRAPOLATE</h2>
<p>GNN实际是在MLP拟合线性function的基础上，通过让模型本身就编码了task-specific的非线性，来获得好的外推性能。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411212409057.png" alt="image-20220411212409057" style="zoom:50%;" /></p>
<p>上面第一个图是使用GNN进行最短路径寻找的任务，如果使用sum的聚合方法，外推效果就差；如果是使用min的聚合方法，外推效果就比较好。这是因为此时的GNN实际上是在拟合BF最短路径算法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411212547418.png" alt="image-20220411212547418" style="zoom:50%;" /></p>
<p>GNN拟合BF算法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411212610549.png" alt="image-20220411212610549" style="zoom:50%;" /></p>
<p><span class="math inline">\(d[k][u]\)</span>是指第<span class="math inline">\(k\)</span>轮迭代，到节点<span class="math inline">\(u\)</span>的最短路径。</p>
<p>此时GNN只是使用MLP来拟合一个线性函数<span class="math inline">\(d[k-1][v]+w(v,u)\)</span>，因此外推效果较好。</p>
<p>同样的道理，可以使用max聚合方法，让GNN在计算graph的最大度任务上，外推效果好。</p>
<p>可以拓展来看，很多可以使用DP算法解决的问题，由于DP算法和GNN的聚合思想很像，或许可以从算法的角度改进GNN，让GNN外推效果好：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220411213021249.png" alt="image-20220411213021249" style="zoom:50%;" /></p>
<p>作者还提出了另外一种让GNN能够外推效果好的方法，就是提前获得某些合适的非线性的表示，然后让GNN只需要使用MLP拟合线性部分即可，最后结合非线性的表示就可以逼近理想的函数。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>TPE</title>
    <url>/ml/TPE/</url>
    <content><![CDATA[<h1 id="the-intuitions-behind-tree-structured-parzen-estimator">The intuitions behind Tree-structured Parzen estimator</h1>
<p>TPE：一种基于贝叶斯推断的超参数调优方法。</p>
<span id="more"></span>
<h2 id="reference">Reference</h2>
<p>[1] Frazier P I. A tutorial on bayesian optimization[J]. arXiv preprint arXiv:1807.02811, 2018.</p>
<p>[2] Bergstra J S, Bardenet R, Bengio Y, et al. Algorithms for hyper-parameter optimization[C]//Advances in neural information processing systems. 2011: 2546-2554.</p>
<p>[3] Xia Y, Liu C, Li Y Y, et al. A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring[J]. Expert Systems with Applications, 2017, 78: 225-241.</p>
<p>[4] <a href="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f">A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning</a></p>
<h2 id="bayesian-hyper-parameter-optimization">1. Bayesian hyper-parameter optimization</h2>
<p>贝叶斯超参数优化是一种为序列模式的模型提供的求全局优化的方法。</p>
<p>针对的问题：求解object function：</p>
<p><span class="math display">\[ min_{x\in A} f(x) \]</span></p>
<p>主要适用的情景：</p>
<ul>
<li>x的维度不是太大，一般会限制在<span class="math inline">\(d\lt20\)</span>，x可以理解为一个超参数序列</li>
<li><span class="math inline">\(f(x)\)</span>是一个计算起来很消耗时间的函数，例如损失函数</li>
<li>对<span class="math inline">\(f(x)\)</span>很难求导</li>
<li>......</li>
</ul>
<p>举例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110144728090.png" style="zoom:50%;" /></p>
<p>纵坐标是<span class="math inline">\(f(x)\)</span>，很明显如果是我们人工去选择下一组超参数的话，会在左下角score=20的这几个点中间去搜索，而不会还是进行一个全局的抽样。这实际就是一个贝叶斯优化过程。</p>
<p>但是对于Random search，grid search这些方法，并不会利用到历史的信息来进行选择。</p>
<h2 id="sequential-model-based-global-optimization-smbo">2. Sequential model-based global optimization (SMBO)</h2>
<h3 id="伪代码">2.1 伪代码</h3>
<p>序列化模型全局优化(SMBO)是把贝叶斯优化的一个形式化的定义。具体的伪代码如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110161036552.png" style="zoom:50%;" /></p>
<p>伪代码中出现的符号含义：</p>
<ul>
<li><span class="math inline">\(\lambda\)</span>：超参数</li>
<li><p><span class="math inline">\(L\)</span>：object function，通常是损失函数</p></li>
<li><p><span class="math inline">\(H\)</span>：记录了所有(超参数<span class="math inline">\(\lambda\)</span>, <span class="math inline">\(L\)</span>)的历史集合</p></li>
<li><p>$ S_{t} <span class="math inline">\(：一个从超参数\)</span>L $的映射概率模型</p></li>
</ul>
<p>循环一共进行T次：</p>
<ol type="1">
<li>每次先根据已有的历史试验集合找出一个更可能拥有更小objective function的超参数集合<span class="math inline">\(\lambda\)</span></li>
<li>之后计算实际的object function的值</li>
<li>加入历史集合</li>
<li>更新<span class="math inline">\(S\)</span></li>
</ol>
<h3 id="一些粗浅的理解">2.2 一些粗浅的理解</h3>
<ol type="1">
<li><p>不断的利用历史试验(trial)记录，构建出了一个下面的概率模型：</p>
<p><span class="math display">\[ P(objective\ function\ score\quad |\quad hyperparameters) \]</span></p></li>
<li><p>叫做贝叶斯的原因是出现了先验概率的思想</p></li>
<li><p>核心想法是<strong>在更有可能得到更好结果的超参数范围内选择新的超参数</strong></p></li>
</ol>
<h3 id="核心要素">2.4 核心要素</h3>
<h4 id="domain">2.4.1 Domain</h4>
<p>不同的超参数有自己的取值范围，以及先验分布，例如均匀分布，log均匀分布等</p>
<h4 id="objective-function">2.4.2 Objective Function</h4>
<p>Objective Function是我们想要优化的目标。接受超参数作为输入，输出的值可以是超参数实例化后拟合了训练集的经验风险函数，如均方误差。</p>
<p>我们不会直接拿这个作为优化目标，而是使用下面的替代函数Surrogate Function。</p>
<h4 id="surrogate-function">2.4.3 Surrogate Function</h4>
<p>替代函数，也叫做响应面(response surface)，是基于之前的历史记录的一种关于objective function的概率表示。</p>
<p>叫做响应面是因为它是在高维层次的objective function score的关于超参数的概率。如下图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110145710920.png" style="zoom:50%;" /></p>
<p>存在几种不同的替代函数，如：</p>
<ul>
<li>Gaussian Processes</li>
<li>Random Forest regression</li>
<li><strong>Tree-structured Parzen Estimator</strong></li>
</ul>
<h4 id="selection-function">2.4.4 Selection Function</h4>
<p>选择函数是如何根据前面的Surrogate Function，来选择新的超参数集合进行试验。</p>
<p>关于选择函数也有不同的表示，例如：</p>
<ul>
<li><strong>Expected Improvement (EI)</strong></li>
<li>Probability of Improvement</li>
</ul>
<h2 id="tree-structured-parzen-estimatortpe">3 Tree-structured Parzen estimator(TPE)</h2>
<h3 id="基础认识">3.1 基础认识</h3>
<ol type="1">
<li><p>Tree：超参数优化问题可以理解为在图结构的参数空间上不断寻找objective function最优解的问题。所谓tree，是提出TPE的作者将该优化问题限制在了树状结构上，例如：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110163042989.png" style="zoom:50%;" /></p>
<p>一些超参数只有在其它的超参数确定后才能够进行确认，例如网络的层数与每一层的节点数量，当然这不意味着这两个超参数是相关的。<strong>实际上在TPE中，要求所估计的超参数必须是相互独立的</strong>。</p></li>
<li><p>Parzen：<a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">Parzen–Rosenblatt window</a>是在核密度估计问题中，由 <a href="https://en.wikipedia.org/wiki/Emanuel_Parzen">Emanuel Parzen</a> 和 <a href="https://en.wikipedia.org/wiki/Murray_Rosenblatt">Murray Rosenblatt</a>提出的能够根据当前的观察值和先验分布类型，估计估计值的概率密度。一般的函数如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110163827025.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110163935502.png" style="zoom:50%;" /></p>
<p><strong>在TPE中，假设了核函数都是高斯核函数</strong></p></li>
</ol>
<h3 id="具体过程推演">3.2 具体过程推演</h3>
<h4 id="expected-improvement-ei">3.2.1 Expected Improvement (EI)</h4>
<p>对于选择一组新的超参数后的objective function的提升可以表示为：</p>
<p><span class="math display">\[ I(\lambda) = max(c^{*}-c(\lambda), 0) \tag{1}\]</span></p>
<p><span class="math inline">\(c^{*}\)</span>是当前记录的H中所有c的一个分割点，我们这里直接认为c表示的就是风险函数。</p>
<p>通过这样的转换，我们就把原来的objective function最优问题转换成了一个新的问题。</p>
<p>如果新的<span class="math inline">\(\lambda\)</span>对应的<span class="math inline">\(c(\lambda)\)</span>更小，则它是更好的超参数设置，但是这需要训练，然后求出风险函数，并不是我们想要的。</p>
<p>那么如果一个新的<span class="math inline">\(\lambda\)</span>对应的提升的期望是大于0的，那么可认为这个<span class="math inline">\(\lambda\)</span>是有较大可能使得风险减小的。故有：</p>
<p><span class="math display">\[ \begin{split}EI(\lambda) &amp;= \int\limits_{-\infty}^{c^{*}}(c^{*}-c)P_{S_{t-1}}(c|\lambda)dc \\ &amp;= \int\limits_{-\infty}^{c^{*}}(c^{*}-c)\frac{p(\lambda|c)p(c)}{p(\lambda)}dc \end{split} \tag{2} \]</span></p>
<p>式子中的<span class="math inline">\(p(\lambda|c)\)</span>定义为：</p>
<p><span class="math display">\[ p(\lambda|c) = \left\{ \begin{aligned} &amp;l(\lambda) \quad c \lt c^{*} \\ &amp;g(\lambda) \quad c \ge c^{*} \end{aligned} \right. \tag{3} \]</span></p>
<p><span class="math inline">\(c^{*}\)</span>是一个阈值，通常是在H所有的c中，满足<span class="math inline">\(p(c&lt;c^{*})=\gamma\)</span>，<span class="math inline">\(\gamma\)</span>默认可设置为0.15。这样所有的历史记录就分成了两部分，即风险较小的那部分和风险相对较大的那部分，<span class="math inline">\(l(\lambda)\)</span>是由所有的风险较小的那部分的超参数集合形成的分布，<span class="math inline">\(g(\lambda)\)</span>是由所有的风险较大的那部分的超参数集合形成的分布。如下图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110191535439.png" style="zoom: 33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191110191405221.png" style="zoom:33%;" /></p>
<p>直觉上我们从风险较小的分布中抽样新的超参数，应该是比较合理的，下面的数学推理也证明了这一点。</p>
<p>继续推导公式2：</p>
<p><span class="math display">\[\begin{split} p(\lambda) &amp;= \int_{R}p(\lambda|c)p(c)dc \\ &amp;= \int_{-\infty}^{c^{*}}p(\lambda|c)p(c)dc + \int_{c^{*}}^{+\infty}p(\lambda|c)p(c)dc \\ &amp;= \gamma l(\lambda)+(1-\gamma) g(\lambda) \end{split}\]</span></p>
<p><span class="math display">\[\begin{split} \int_{-\infty}^{c*} (c^{*}-c)p(\lambda|c)p(c)dc &amp;= l(\lambda)\int_{-\infty}^{c*}(c^{*}-c)p(\lambda|c)p(c)dc \\ &amp;=\gamma c^{*}l(\lambda) -l(\lambda) \int_{-\infty}^{c*} cp(c)dc \end{split}\]</span></p>
<p>最终得到：</p>
<p><span class="math display">\[\begin{split} EI(\lambda) &amp;= \frac{\gamma c^{*}l(\lambda) -l(\lambda) \int_{-\infty}^{c*} cp(c)dc}{\gamma l(\lambda)+(1-\gamma) g(\lambda)} \\ &amp; \propto \big( \gamma+\frac{g(\lambda)}{l(\lambda)}(1-\gamma) \big)^{-1} \end{split}\]</span></p>
<p>这说明在<span class="math inline">\(l(\lambda)\)</span>的分布下取样得到的参数更有可能让<span class="math inline">\(EI(\lambda)\)</span>有更大的值。</p>
<h4 id="估计超参数的分布">3.2.2 估计超参数的分布</h4>
<p>由 <span class="math inline">\(c^{*}\)</span>将历史记录分为了两部分，以 $ c c^{*} $ 的那部分超参数集合为例。</p>
<p>假设存在n个取值 $ (x_1,x_2, , x_n) $ ，那么概率密度的估计是</p>
<p><span class="math display">\[ \hat{p}(x) = \frac{1}{nh}\sum\limits_{i=1}^{n}K\big( \frac{x-x_i}{h} \big) \]</span></p>
<p>其中</p>
<p><span class="math display">\[ K\big( \frac{x-x_i}{h} \big) = \frac{1}{\sqrt{2\pi}} exp\big( -\frac{1}{2}(\frac{x-x_i}{h})^2 \big) \]</span></p>
<h4 id="求解的过程">3.2.3 求解的过程</h4>
<p>利用TPE，首先对于所有的超参数形成的那棵树进行设置，因为TPE要求所有的超参数要相互独立，即一种正交的概念，即效果不能相互影响，例如学习率，提升树方法的迭代次数，和树的最大深度就存在一个权衡，所以需要先固定一些不能一起用于优化的超参数，如固定学习率和迭代次数。</p>
<p>由树从根结点从上而下的利用Parzen estimator，对某一个节点，在 <span class="math inline">\(l(\lambda)\)</span>分布下采样，比如采样100次。</p>
<p>每一次的采样得到的超参数集合可以分别得到它们的概率，然后相乘得到联合概率，算出 $ l()$和 <span class="math inline">\(g(\lambda)\)</span>。选取其中 <span class="math inline">\(l(\lambda)/g(\lambda)\)</span> 的最大值，作为这一次迭代选取的超参数。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>ML</category>
      </categories>
  </entry>
  <entry>
    <title>BatchNorm</title>
    <url>/ml/batchnorm/</url>
    <content><![CDATA[<h1 id="batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</h1>
<p>ICML 2015</p>
<p>谷歌团队的经典论文，batchnorm操作。题目中的Internal Covariate Shift是论文中提出的一个名词，主要是指在网络结构中，由于各层模型参数不同，每一层接受的输入的分布都会改变。这种现象被称作<strong>internal covariate shift</strong>。这篇文章通过对把每层的激活值做归一化处理，提升模型训练速度与效果。</p>
<p>归一化处理会增大feature之间的相对差异，排除绝对差异，因此可能更好训练。另外，归一化操作能够让激活值处于激活函数类似sigmoid的梯度较大的区域，能够缓解梯度消失问题。</p>
<span id="more"></span>
<p>pytorch中的核心公式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210708161603064.png" style="zoom:50%;" /></p>
<p><span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\beta\)</span>是两个很重要的可学习的参数，它从理论上保证归一化后的值<span class="math inline">\(y\)</span>通过学习合适的<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\beta\)</span>可以还原原来的<span class="math inline">\(x\)</span>。比如：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210708161844290.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210708161902153.png" style="zoom:50%;" /></p>
<p>在mini-batch训练策略下的核心算法，对第<span class="math inline">\(i\)</span>维的激活值<span class="math inline">\(x\)</span>。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210708161527909.png" style="zoom:50%;" /></p>
<p>从<a href="https://blog.csdn.net/qq_25737169/article/details/79048516">博客</a>上找的python代码实现方便理解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Batchnorm_simple_for_train</span>(<span class="params">x, gamma, beta, bn_param</span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">param:x    : 输入数据，设shape(B,L)</span></span><br><span class="line"><span class="string">param:gama : 缩放因子  γ</span></span><br><span class="line"><span class="string">param:beta : 平移因子  β</span></span><br><span class="line"><span class="string">param:bn_param   : batchnorm所需要的一些参数</span></span><br><span class="line"><span class="string">	eps      : 接近0的数，防止分母出现0</span></span><br><span class="line"><span class="string">	momentum : 动量参数，一般为0.9， 0.99， 0.999</span></span><br><span class="line"><span class="string">	running_mean ：滑动平均的方式计算新的均值，训练时计算，为测试数据做准备</span></span><br><span class="line"><span class="string">	running_var  : 滑动平均的方式计算新的方差，训练时计算，为测试数据做准备</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">	running_mean = bn_param[<span class="string">&#x27;running_mean&#x27;</span>]  <span class="comment">#shape = [B]</span></span><br><span class="line">  running_var = bn_param[<span class="string">&#x27;running_var&#x27;</span>]    <span class="comment">#shape = [B]</span></span><br><span class="line">	results = <span class="number">0.</span> <span class="comment"># 建立一个新的变量</span></span><br><span class="line">    </span><br><span class="line">	x_mean=x.mean(axis=<span class="number">0</span>)  <span class="comment"># 计算x的均值</span></span><br><span class="line">  x_var=x.var(axis=<span class="number">0</span>)    <span class="comment"># 计算方差</span></span><br><span class="line">  x_normalized=(x-x_mean)/np.sqrt(x_var+eps)       <span class="comment"># 归一化</span></span><br><span class="line">  results = gamma * x_normalized + beta            <span class="comment"># 缩放平移</span></span><br><span class="line"></span><br><span class="line">  running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * x_mean</span><br><span class="line">  running_var = momentum * running_var + (<span class="number">1</span> - momentum) * x_var</span><br><span class="line"></span><br><span class="line">  <span class="comment">#记录新的值</span></span><br><span class="line">  bn_param[<span class="string">&#x27;running_mean&#x27;</span>] = running_mean</span><br><span class="line">  bn_param[<span class="string">&#x27;running_var&#x27;</span>] = running_var </span><br><span class="line">    </span><br><span class="line">	<span class="keyword">return</span> results , bn_param</span><br></pre></td></tr></table></figure>
<p>论文实际没有完整读一遍，只看了核心算法方便实验，以后找时间从头看一遍。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
  </entry>
  <entry>
    <title>entropy-softmax</title>
    <url>/ml/entropy-softmax/</url>
    <content><![CDATA[<h1 id="机器学习中的sigmoidsoftmax与entropy">机器学习中的Sigmoid、Softmax与entropy</h1>
<p>这篇文章期望总结与讨论机器学习中常见的sigmoid、softmax函数与entropy熵。</p>
<p>参考资料：</p>
<ol type="1">
<li><a href="https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)">熵，维基百科</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/55016125">sigmoid函数推导，知乎</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/105722023">一文详解Softmax函数，知乎</a></li>
<li><a href="https://zh.wikipedia.org/zh-tw/S%E5%9E%8B%E5%87%BD%E6%95%B0">S型函数，维基百科</a></li>
<li><a href="https://www.zhihu.com/question/274997106/answer/1055696026">信息熵越大，信息量到底是越大还是越小？，知乎</a></li>
<li><a href="https://www.zhihu.com/question/294679135/answer/885285177">softmax和cross-entropy是什么关系？</a></li>
</ol>
<p>总结：</p>
<ol type="1">
<li>sigmoid可以看做是神经网络输出<span class="math inline">\([p,0]\)</span>的softmax变形<span class="math inline">\([e^x/(e^x+1), 1/(e^x+e^0)]\)</span>，只不过由于对应标签1的概率<span class="math inline">\(p\)</span>是我们的期望值，另外一个0不做过多讨论。</li>
<li>softmax+交叉熵基本是绑定的，这是因为会使得loss的计算和求导都更简单。</li>
<li>我们经常使用交叉熵，是因为它作为KL散度的核心变化部分，能够衡量输出分布和真实分布之间的差异。</li>
<li>使用softmax而不是hardmax的目的是期望能够让模型从不同类的预测值上获得更多的梯度。</li>
</ol>
<span id="more"></span>
<h2 id="sigmoid函数">Sigmoid函数</h2>
<p>在机器学习领域，如果在了解完线性回归（linear regression）后，发现线性回归很难拟合非线性的分布；那么你很快能看到一个强大的分类器，逻辑斯蒂回归。</p>
<p>逻辑斯蒂回归，logistics regression，就是在线性回归的输出加上了一个特殊的非线性函数，sigmoid函数（在很多文章，也把sigmoid函数叫做S型函数，而把逻辑斯蒂回归中使用的非线性函数单独称作logistic function）：</p>
<p><span class="math display">\[
f(x)=\frac{1}{1+e^{-x}}=\frac{e^x}{e^x+1}
\]</span> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/v2-24758bffbd6a9a5d243ff226cb1e3306_1440w.jpg"  style="zoom:40%;" /></p>
<p>该函数是S型函数的一种，指其函数形状类似于S。S型函数在实数范围内可微，并且只有一个拐点（指函数凹凸发生变化的点）。S型函数还包括了很多其它的函数形式。</p>
<p>sigmoid函数取值在<span class="math inline">\([0,1]\)</span>，常被用来输出单类预测区间在<span class="math inline">\([0,1]\)</span>的任务。sigmoid函数的导数是以他自身为因变量的函数，<span class="math inline">\(f^\prime(x)=F(f(x))\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220923161828071.png"  style="zoom:50%;" /></p>
<h2 id="softmax函数">Softmax函数</h2>
<p>如果我们期望进行单标签多类预测，比如某篇文章/某张图片属于什么主题，最后输出的一个序列<span class="math inline">\([0,0,1,0,0,\dots]\)</span>。注意这种情况下，所有类的和是1，仍然是单标签预测。如果是多标签预测，那么会出现多个同时成立的<span class="math inline">\(1\)</span>。</p>
<p>在这种情景中，在模型不变的情况下，试想下我们还可以使用sigmoid函数来预测吗？</p>
<p>模型此时的输出<span class="math inline">\(\bf{x}\)</span>是一个实数向量<span class="math inline">\([0.23472,11.78,-99.99,0.0,\dots]\)</span>，我们可以对每个element分别应用sigmoid函数，那么它可以转化成期望的01预测序列。</p>
<p>但这样做有什么问题？</p>
<p>每个element是独立判别的，比如每个主题都会得到自己的<span class="math inline">\(0-1\)</span>估计，它们的和不能保证是<span class="math inline">\(1\)</span>。这种做法适用于多标签的情况，但不适用于单标签多分类。单标签多分类的概率和应该是1，并且从直觉角度看，不同类之间应该存在信息的互相影响。</p>
<p>为了解决上述问题，softmax是对于sigmoid函数的拓展： <span class="math display">\[
softmax(x_i)=\frac{e^{x_i}}{\sum_{j=1}e^{x_j}}
\]</span> 上述形式和sigmoid进行对比后可以发现，sigmoid函数的分母部分是两个元素和，除了<span class="math inline">\(e^x\)</span>之外多了<span class="math inline">\(1\)</span>。而softmax函数是所有预测元素/概率的<span class="math inline">\(e\)</span>指数和作为总的分母。</p>
<p>从值的角度来看，softmax通过平均，保证了输出值在<span class="math inline">\([0,1]\)</span>。</p>
<p><strong>为什么叫做soft的max？</strong></p>
<p>想一下，我们完全可以直接把最大的那个实数拿出来作为预测结果（这就叫做hard max）。我们为什么非要求和以后，再计算最大实数在和中的占比呢？</p>
<p>因为在很多情况下，我们并不想直接丢掉其它类的预测值，我们往往希望能够获得神经网络对所有类的预测概率。</p>
<p>从优化的角度讲，直接把最大的实数挑出来，那么就只会依据这个实数对应的类进行优化，比如它对应的类不是真实标签，那么优化器会强迫神经网络在接下来对这个类的预测值减小，但是不会同时强迫神经网络对其它标签（包括真实标签）的预测值增大/减小。如果它对应的类是真实标签的话，那么优化器会会强迫神经网络在接下来对这个类的预测值增大，但是不会同时强迫神经网络对其它标签的预测值更小。这种做法不是一种很理想的决策。</p>
<p>另外，softmax对于目标标签的概率输出考虑到了其它类（作为分母）。这样在优化的时候，其它类对应的神经元也能够得到对应的梯度。相反，直接hardmax把最大的挑出来，那就只有最大值对应的神经元可以得到优化了。</p>
<p>接下来讨论<strong>为什么引入指数底<span class="math inline">\(e\)</span></strong>？而不是直接求和？下面解答来自<a href="https://zhuanlan.zhihu.com/p/105722023">一文详解Softmax函数，知乎</a>。</p>
<p><span class="math inline">\(e^x\)</span>的斜率逐渐增加，随着<span class="math inline">\(x\)</span>越来越大，斜率也越来越大。这就导致了，引入<span class="math inline">\(e^x\)</span>会拉大不同预测概率之间的差距，这实际相当于增加了马太效应，即强者越强，一个输出值<span class="math inline">\(z_i\)</span>增加很小的幅度，也会被<span class="math inline">\(e^x\)</span>放大。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tf.__version__) <span class="comment"># 2.0.0</span></span><br><span class="line">a = tf.constant([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], dtype = tf.float32)</span><br><span class="line"></span><br><span class="line">b1 = a / tf.reduce_sum(a) <span class="comment"># 不使用指数</span></span><br><span class="line"><span class="built_in">print</span>(b1) <span class="comment"># tf.Tensor([0.2 0.3 0.5], shape=(3,), dtype=float32)</span></span><br><span class="line"></span><br><span class="line">b2 = tf.nn.softmax(a) <span class="comment"># 使用指数的Softmax</span></span><br><span class="line"><span class="built_in">print</span>(b2) <span class="comment"># tf.Tensor([0.04201007 0.11419519 0.8437947 ], shape=(3,), dtype=float32)</span></span><br></pre></td></tr></table></figure>
<p>同时，<span class="math inline">\((e^x)^\prime=e^x\)</span>，求导比较方便。</p>
<p>引入指数就没有缺点吗？</p>
<p>当然有，指数函数在<span class="math inline">\(x\)</span>比较大时，会输出过于大的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">scores = np.array([<span class="number">123</span>, <span class="number">456</span>, <span class="number">789</span>])</span><br><span class="line">softmax = np.exp(scores) / np.<span class="built_in">sum</span>(np.exp(scores))</span><br><span class="line"><span class="built_in">print</span>(softmax) <span class="comment"># [ 0.  0. nan]</span></span><br></pre></td></tr></table></figure>
<p>在深度学习框架TensorFlow中，因为softmax和交叉熵通常是一起的，因此设置了额外的loss函数同时实现了softmax和交叉熵的计算，避免出现上述情况。</p>
<p>接下来我们要讨论<strong>softmax函数的求导</strong>。</p>
<p><span class="math inline">\(p_i=softmax(x_i)\)</span>函数，分母包括了所有的<span class="math inline">\(x_j\)</span>，而分子只包括<span class="math inline">\(x_i\)</span>。所以我们要分类讨论。</p>
<p>当<span class="math inline">\(j==i\)</span>时，对<span class="math inline">\(x_j\)</span>也就是<span class="math inline">\(x_i\)</span>进行求导，此时分子要参与求导（下面的<span class="math inline">\(z\)</span>就是前面的<span class="math inline">\(x\)</span>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924151830047.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924151900166.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152207932.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152223554.png"   style="zoom:50%;" /></p>
<p>上述公式可以写成，<span class="math inline">\(p_i\times (1-p_j)\)</span>，由于<span class="math inline">\(i==j\)</span>，因此最终结果为<span class="math inline">\(p_i-p_i^2\)</span>。</p>
<p>当<span class="math inline">\(j\ne i\)</span>时，对<span class="math inline">\(x_j\)</span>进行求导，分子导数是<span class="math inline">\(0\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152709867.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152740503.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152803996.png"   style="zoom:50%;" /></p>
<p>最终结果为，<span class="math inline">\(-p_j\times p_i\)</span>。</p>
<p>即，<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152907614.png"   style="zoom:50%;" /></p>
<p>softmax的导数形式意外的简单，可以直接利用前馈过程中计算出的结果算出导数。</p>
<p>在使用了softmax之后，我们得到了预测序列<span class="math inline">\([0.11,0.43,0.006,\dots]\)</span>，那么怎么样计算loss呢？</p>
<p>我们首先可以给softmax输出结果加上一个<span class="math inline">\(log\)</span>，这样不改变它的单调性：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924153634383.png"   style="zoom:50%;" /></p>
<p>那么接下来假设<span class="math inline">\(i\)</span>的真实标签就是<span class="math inline">\(1\)</span>，如果我们让<span class="math inline">\(log(p_i)\)</span>不断增大不就可以了吗？当然，loss一般是越小越好，所以有：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154005224.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154019920.png"   style="zoom:50%;" /></p>
<p>记住上面的式子，在推导交叉熵的时候，两者会统一起来。</p>
<h2 id="entropy熵">Entropy熵</h2>
<p>信息论中的熵的概念，由1948年，<a href="https://zh.wikipedia.org/wiki/克劳德·艾尔伍德·香农">克劳德·艾尔伍德·香农</a>將<a href="https://zh.wikipedia.org/wiki/熱力學">熱力學</a>的熵引入，因此也叫做香农熵。熵是对不确定性的度量，不确定性越大，熵越大。</p>
<p>熵的数学定义为： <span class="math display">\[
H(X)=E[I(X)]=E[-ln(P(X))]=E[ln(\frac{1}{P(X)})]
\]</span> 即随机事件/变量，概率的平均期望。</p>
<p>对于有限样本：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924155220119.png"   style="zoom:50%;" /></p>
<p>在这里<span class="math inline">\(b\)</span>是对数所使用的底，通常是2,自然常数e，或是10。当<span class="math inline">\(b = 2\)</span>，熵的单位是bit；当<span class="math inline">\(b = e\)</span>，熵的单位是nat；而当<span class="math inline">\(b\)</span> = 10,熵的单位是Hart。</p>
<p>投一次硬币，出现的花纹（正反面）这个事件的不确定性是1 bit。</p>
<p>熵和信息量有什么区别？</p>
<p>不能简单的把熵就认为是信息量。事实上熵减才能衡量信息量的增加。我们往一个事件/随机变量当中注入新的信息，比如额外事件的发生，不确定性才会减小。</p>
<p>在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。这句话表达的是随机变量能够容纳/表达的信息量的大小和熵是有关的。</p>
<p>香农对于某个确定的事件发生后的信息量的定义，核心是发生概率越小，一旦发生后，信息量越大： <span class="math display">\[
h(x)=-log_2(p(x))
\]</span> 然后介绍下交叉熵，用来衡量两个独立变量的分布差异：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930164612247.png"   style="zoom:50%;" /></p>
<p>评估变量Q和变量P分布差异的大小，如果两者分布完全一致，KL散度值为0；KL散度值越大，分布差异越大；KL散度值越小，分布差异越小。</p>
<p>在机器学习中，如果我们把P看做是真实分布，Q是模型预测的分布，那么KL散度可以衡量机器学习模型的预测性能。在这种情况下，对KL散度进一步推导：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930165237326.png"  style="zoom:50%;" /></p>
<p>公式的前半部分是真实分布P的负熵，后半部分就是真实分布P做系数、log预测分布Q的交叉熵（同时包括了真实和预测分布，所以叫做交叉）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930173153047.png"   style="zoom:50%;" /></p>
<p>前半部分是个固定常量，只要后半部分越小，KL散度就越小。</p>
<p>在了解到什么是交叉熵之后，我们再回到使用softmax推导出的式子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154019920.png"   style="zoom:50%;" /></p>
<p>对于常常使用one-hot编码标签值的机器学习算法来说，只有正确类标签值是1，其它是0：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174029787.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174059045.png"   style="zoom:50%;" /></p>
<p>也就是两者完全等价。</p>
<p>然后使用交叉熵进行求导：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174650609.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174806703.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174914329.png"   style="zoom:50%;" /></p>
<p>最后的求导结果，只需要预测值和实际标签就能得到导数。</p>
<p>这就是当拿交叉熵和softmax一起做loss时候的优点，求导更加简单。</p>
<p>另外一点是，当计算出softmax之后，再计算交叉熵： <span class="math display">\[
S= \sum_j y_k\times log(S_j)
\]</span> 如果<span class="math inline">\(S_j\)</span>是softmax输出结果，那么，可以一步到位直接计算<code>logSoftmax</code>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930212116078.png"   style="zoom:50%;" /></p>
<p>在pytorch的<code>nn.CrossEntropyLoss()</code>函数实现中，就是直接输入神经网络计算得到的激活值<span class="math inline">\(a_j\)</span>（无需经过<code>Softmax</code>）即可，<code>nn.CrossEntropyLoss()</code>会按照<code>logSoftmax</code>来计算最终的loss</p>
]]></content>
      <categories>
        <category>ML</category>
        <category>Theory</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>prototypical-network</title>
    <url>/ml/prototypical-network/</url>
    <content><![CDATA[<h1 id="prototypical-networks-for-few-shot-learning">Prototypical Networks for Few-shot Learning</h1>
<p>作者为少次学习和零次学习提出了一种新的网络Prototypical network。核心思想是为不同的class定义不同的prototype的表示。这个prototype是有相同class下的所有实例求平均得到的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220310164356012.png" alt="image-20220310164356012" style="zoom:50%;" /></p>
<span id="more"></span>
<p>直接看核心公式，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220310164441739.png" alt="image-20220310164441739" style="zoom:50%;" /></p>
<p><span class="math inline">\(S_k\)</span>就是class <span class="math inline">\(k\)</span>下的所有实例。<span class="math inline">\(f_{\phi}\)</span>是某种编码函数，或者叫embedding function，可以为任意合适的方法来产生最后的向量。例如作者就使用了CNN，作为在图像数据集下，few-shot的编码函数。</p>
<p>因此，如果要求某个新的实例<span class="math inline">\(x\)</span>是否属于class <span class="math inline">\(k\)</span>，通过定义距离函数<span class="math inline">\(d(\cdot, \cdot)\)</span>，经过<span class="math inline">\(softmax\)</span>就可求出：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220310164703633.png" alt="image-20220310164703633" style="zoom:50%;" /></p>
<p>距离越大，当然成为class <span class="math inline">\(k\)</span>的概率就越小。</p>
<p>作者在训练的时候，使用了之前工作采用的采样batch的方法，叫做<em>episodes</em>，核心思想是模拟少次学习在test时候的情况，每次train的时候，也只采样几个class，几个shot。具体作者的做法如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220310170614007.png" alt="image-20220310170614007" style="zoom:40%;" /></p>
<p>作者额外的证明了一些其它的性质，比如如果距离函数是属于regular Bregman divergences（布雷格曼发散），推测一个点属于class的概率就是上面的softmax结果。简单查了一下，这个Bregman divergences的含义是说，它满足空间中距离所有点最小“距离”的点，就是所有点的平均值。这个条件是当且仅当的。</p>
<p>作者还证明了，如果使用欧式距离作为距离函数的话，求解属于哪个class的公式就等价于一个线性的模型：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220310170123470.png" alt="image-20220310170123470" style="zoom:50%;" /></p>
<p>上面公式中的第一项对于不同的class都是固定的，而对于后面两项：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220310170201612.png" alt="image-20220310170201612" style="zoom:50%;" /></p>
<p>求<span class="math inline">\(x\)</span>属于class <span class="math inline">\(k\)</span>的概率就等价于一个拥有参数<span class="math inline">\(w_k\)</span>和<span class="math inline">\(b_k\)</span>的线性模型。</p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>theory</tag>
      </tags>
  </entry>
  <entry>
    <title>FL-MSRE</title>
    <url>/mmml/FL-MSRE/</url>
    <content><![CDATA[<h1 id="fl-msre-a-few-shot-learning-based-approach-to-multimodal-social-relation-extraction">FL-MSRE: A Few-Shot Learning based Approach to Multimodal Social Relation Extraction</h1>
<p>AAAI 2021，<a href="https://github.com/%20sysulic/FL-MSRE">代码</a>。</p>
<blockquote>
<p>Social relation extraction (SRE for short), which aims to infer the social relation between two people in daily life, has been demonstrated to be of great value in reality. <strong>Existing methods for SRE consider extracting social relation only from unimodal information such as text or image, ignoring the high coupling of multimodal information</strong>. Moreover, previous studies overlook the serious unbalance distribution on social relations. To address these issues, this paper proposes FL-MSRE, a few-shot learning based approach to extracting social relations from both texts and face images. Considering the lack of multimodal social relation datasets, this paper also presents three multimodal datasets annotated from four classical masterpieces and corresponding TV series. Inspired by the success of BERT, we propose a strong BERT based baseline to extract social relation from text only. FL-MSRE is empirically shown to outperform the baseline signiﬁcantly. This demonstrates that using face images beneﬁts text-based SRE. Further experiments also show that using two faces from different images achieves similar performance as from the same image. This means that FL-MSRE is suitable for a wide range of SRE applications where the faces of two people can only be collected from different images.</p>
</blockquote>
<p>作者在这篇工作中，创建了包括文本和脸部图像的多模态social relation extraction数据集，Dream of the Red Chamber (DRC-TF), Outlaws of the Marsh (OM-TF) and the Four Classic (FC-TF)。红楼梦、水浒传和四大名著数据集，TF指text and face。</p>
<p>并且由于不同social relation的分布差异很大，作者考虑使用少次学习来解决，提出了方法FL-MSRE。</p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p><strong>motivation</strong>：之前的social relation extraction主要集中在对单模态信息的处理，忽略了多模态之间信息可能存在高耦合。比如在下图，仅仅通过文本是不能推断Obama和正在拥抱的人的实际关系的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221017223017579.png"  style="zoom:50%;" /></p>
<p><strong>method</strong>：为了能够同时从text和image中导出信息，由于目前没有合适的数据集，作者在Du et al.的从四大名著导出的基于文本数据集基础上进行拓展，通过从翻拍的电视剧中提取对应人物的图像，来预测人物实体之间的关系。同时，鉴于不同relation之间的分布差异巨大，作者考虑使用少次学习来进行关系抽取。</p>
<h2 id="multimodal-social-relation-datasets">2 Multimodal Social Relation Datasets</h2>
<p>构造过程：</p>
<ul>
<li>Du et al.等人从中国四大名著的文本中导出了至少包含两个人的句子；</li>
<li>作者在此基础上，通过人工标注判断两个人之间是否存在social relation；如果两个人有多种social relation，选择最specific的relation；</li>
<li>使用FFmepg删除字幕，删除重复的图片；</li>
<li>使用FaceNet选择出至少包括两个人的图片；每个人的脸部被bounding box框出来，并且标注了是哪个角色；</li>
</ul>
<p>最后，由于有的名著样本量太少，因此分为了三个数据集：Dream of the Red Chamber (DRC-TF), Outlaws of the Marsh (OM-TF) and the Four Classic (FC-TF)。</p>
<p>统计情况：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221017223855386.png" alt="image-20221017223855386" /><figcaption>image-20221017223855386</figcaption>
</figure>
<p>不同关系对应的句子数量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221017224420446.png" style="zoom:40%;" /></p>
<p>查看下具体的数据：</p>
<p>Text：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&quot;servant_girl&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;sbj&quot;</span>: <span class="string">&quot;雪雁&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;obj&quot;</span>: <span class="string">&quot;林黛玉&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;sentence&quot;</span>: <span class="string">&quot;每人一个奶娘并一个丫头照管，余者在外间上夜听唤．一面早有熙凤命人送了一顶藕合色花帐，并几件锦被缎褥之类．林黛玉只带了两个人来：一个是自幼奶娘王嬷嬷，一个是十岁的小丫头，亦是自幼随身的，名唤作雪雁．&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;mask_sentence&quot;</span>: <span class="string">&quot;每人一个奶娘并一个丫头照管，余者在外间上夜听唤．一面早有熙凤命人送了一顶藕合色花帐，并几件锦被缎褥之类．$尾$只带了两个人来：一个是自幼奶娘王嬷嬷，一个是十岁的小丫头，亦是自幼随身的，名唤作#头#．&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>Image：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&quot;林黛玉&quot;: &#123;</span><br><span class="line">        &quot;雪雁&quot;: [</span><br><span class="line">            &quot;hlm_EP01_2282.jpg&quot;,</span><br><span class="line">            &quot;hlm_EP01_2336.jpg&quot;,</span><br><span class="line">            &quot;hlm_EP01_2448.jpg&quot;,</span><br><span class="line">            &quot;hlm_EP40_1706.jpg&quot;,</span><br><span class="line">            &quot;hlm_EP43_1600.jpg&quot;,</span><br><span class="line">            <span class="string">&quot;hlm_EP43_1645.jpg&quot;</span></span><br><span class="line">        ],</span><br><span class="line">        &quot;春纤&quot;: [</span><br><span class="line">            <span class="string">&quot;hlm_EP16_0681.jpg&quot;</span></span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure>
<p><code>hlm_EP01_2282.jpg</code>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/hlm_EP01_2282.jpg" alt="hlm_EP01_2282" style="zoom: 33%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MRE</tag>
        <tag>MMKG</tag>
      </tags>
  </entry>
  <entry>
    <title>EEGA</title>
    <url>/mmml/EEGA/</url>
    <content><![CDATA[<h1 id="joint-multimodal-entity-relation-extraction-based-on-edge-enhanced-graph-alignment-network-and-word-pair-relation-tagging">Joint Multimodal Entity-Relation Extraction Based on Edge-enhanced Graph Alignment Network and Word-pair Relation Tagging</h1>
<p>EEGA，<a href="https://github.com/YuanLi95/EEGA-for-JMERE" class="uri">https://github.com/YuanLi95/EEGA-for-JMERE</a>，AAAI 2023，联合MNER和MRE。</p>
<p>首个提出将MNER和MRE联合训练的方法，作者将text和image表示为两个graph，然后除了进行visual object和textual entity的对齐，还进行了object-object relation和entity-entity relation的对齐。</p>
<blockquote>
<p>Multimodal named entity recognition (MNER) and multimodal relation extraction (MRE) are two fundamental subtasks in the multimodal knowledge graph construction task. However, the existing methods usually handle two tasks independently, which ignores the bidirectional interaction between them. This paper is the ﬁrst to propose jointly performing MNER and MRE as a joint multimodal entity-relation extraction task (JMERE). Besides, the current MNER and MRE models only consider aligning the visual objects with textual entities in visual and textual graphs but ignore the entity-entity relationships and object-object relationships. To address the above challenges, we propose an edge-enhanced graph alignment network and a word-pair relation tagging (EEGA) for JMERE task. Speciﬁcally, we ﬁrst design a word-pair relation tagging to exploit the bidirectional interaction between MNER and MRE and avoid the error propagation. Then, we propose an edge-enhanced graph alignment network to enhance the JMERE task by aligning nodes and edges in the cross-graph. Compared with previous methods, the proposed method can leverage the edge information to auxiliary alignment between objects and entities and ﬁnd the correlations between entity-entity relationships and object-object relationships. Experiments are conducted to show the effectiveness of our model.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>作者首次提出了多模态实体-关系联合抽取任务JMERE（joint multimodal entity-relation extraction），NER任务和RE任务进行交互能够相互辅助提升预测效果。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212144428938.png" alt="image-20221212144428938" /><figcaption>image-20221212144428938</figcaption>
</figure>
<p>作者提出，在进行多模态信息抽取的时候，除了会类似于之前的论文要考虑object-entity的对齐，还应该考虑object-object relation和entity-entity relation的对齐。比如在上面的例子中，如果我们能够识别出image中的多个人object，那么可以辅助预测Thompson，Curry和Green可能是人；另外如果还能够知道image中的man_0和trophy的关系是holding，如果可以把holding对应到要预测的实体Thompson和O’Brien Trophy之间的关系可能是awarded。</p>
<p>如果把文本和实体都对应到两个graph上，就是除了要考虑node和node的对齐，还要考虑edge到edge的对齐：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212144653728.png" alt="image-20221212144653728" /><figcaption>image-20221212144653728</figcaption>
</figure>
<p>另外，考虑到如果直接拼接MNER和MRE方法形成一个pipeline的话，可能会出现error propagation的情况，也就是MNER的错误输出会导致MRE的进一步错误预测（<em>Joint multi-modal aspect-sentiment analysis with auxiliary cross-modal relation detection. EMNLP 2021</em>），作者提出了一个word-pair relation tagging的方法实现同时实现NER和RE（目前不清楚是不是有很多联合抽取模型都是使用了相似的方法）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212145619808.png"  style="zoom:40%;" /></p>
<h2 id="method">2. Method</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212145718727.png" alt="image-20221212145718727" /><figcaption>image-20221212145718727</figcaption>
</figure>
<h3 id="graph-encoder">2.1 Graph Encoder</h3>
<h4 id="textual-graph">2.1.1 Textual Graph</h4>
<p>使用<a href="https://spacy.io/models">语法依赖解析工具</a>将text解析为语法依赖树，形成一个textual graph。每个node使用BERT学习到的embedding作为初始表征；每个edge也有自己的可训练embedding。</p>
<h4 id="visual-graph">2.1.2 Visual Graph</h4>
<p>使用Mask-RCNN作为视觉特征导出器，然后构造场景图scene graph（<em>Unbiased scene graph generation from biased training. CVPR 2020</em>），只保留top-k的objects。每个node使用Mask-RCNN导出的视觉embedding作为初始表征；每个edge也有自己的可训练embedding。</p>
<h4 id="attribute-transformer">2.1.3 Attribute Transformer</h4>
<p>作者进一步提出使用Transformer把edge information融合到token/object表征上，使用edge embedding作为key和value：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212151807388.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212151817488.png"   style="zoom:50%;" /></p>
<p>其中的<span class="math inline">\(A_T^i\in R^{1\times n}\)</span>表示的是第<span class="math inline">\(i\)</span>-th token的邻接矩阵，<span class="math inline">\(Z_T^i\in R^{n\times d_{zT}}\)</span>表示的是对应的edge embedding。之后再经过FFN和layer normalization。最后得到的token embedding matrix记为<span class="math inline">\(H_T\)</span>。</p>
<p>在视觉侧，也有相同结构，不同参数的attribute Transformer。最后得到的object embedding matrix记为<span class="math inline">\(H_I\)</span>。</p>
<h3 id="edge-enhanced-graph-alignment-module">2.2 Edge-enhanced Graph Alignment Module</h3>
<p>接下来，希望对两个graph的node和edge进行对齐。</p>
<h4 id="edge-enhanced-graph-optimal-transport">2.2.1 Edge-enhanced Graph Optimal Transport</h4>
<p>作者借鉴了在迁移学习中出现的optimal transport method进行对齐。使用了两种距离度量方法：</p>
<ul>
<li>Wasserstein Distance (WD) (Peyr´e, Cuturi et al. 2019) for node matching (the red lines)</li>
<li>Gromov-Wasserstein Distance (GWD) (Peyr´e, Cuturi, and Solomon 2016) for edge matching(the blue and green lines)</li>
</ul>
<p>WD：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212152751617.png"   style="zoom:50%;" /></p>
<p>其中<span class="math inline">\(T_{ij}\)</span>表示从<span class="math inline">\(i\rightarrow j\)</span>所需的代价，而<span class="math inline">\(c()\)</span>是cosine距离函数：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212152835533.png"   style="zoom:50%;" /></p>
<p>GWD：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212152806025.png"  style="zoom:50%;" /></p>
<p>其中，<span class="math inline">\(H_I^\prime,H_T^\prime\)</span>表示邻接节点集合。<span class="math inline">\(L()\)</span>函数用来度量两个graph的edge之间的距离： <span class="math display">\[
L(H_I^i,H_I^{i\prime},H_T^i,H_T^{i\prime})=||c(H_I^i,H_I^{i\prime})-c(H_T^i,H_T^{i\prime})||
\]</span> 之后，使用下面的loss函数优化对齐的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212154312654.png"  style="zoom:50%;" /></p>
<h4 id="image2text-attention">2.2.2 Image2text attention</h4>
<p>使用Transformer，将对齐后的视觉信息融合到文本表征中：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212154422600.png"   style="zoom:50%;" /></p>
<h3 id="multi-channel-layer">2.3 Multi-channel Layer</h3>
<p>作者还额外的使用了三种文本的特征来辅助word-pair <span class="math inline">\((w_i,w_j)\)</span>的关系预测：</p>
<ul>
<li><p>Part of Speech (Pos)：使用spaCy导出Pos特征，参考下图，把word-pair的词性向量相加作为Pos特征；</p></li>
<li><p>Syntactic Distance (Sd)：使用word-pair之间的相对语法距离，参考下图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212155021596.png" alt="image-20221212155021596" /><figcaption>image-20221212155021596</figcaption>
</figure></li>
<li><p>Word Co-occurrences matrix (Co)：使用PMI（Point-wise Mutual Information）衡量两个word在整个语料中的correlation；</p></li>
</ul>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212154606639.png" alt="image-20221212154606639" /><figcaption>image-20221212154606639</figcaption>
</figure>
<p>这三个矩阵被用来进一步学习文本的表征，对于每个矩阵，对于<span class="math inline">\(i-th\)</span> word使用W-GCN聚合来自其它文本的信息：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212155801935.png" alt="image-20221212155801935" /><figcaption>image-20221212155801935</figcaption>
</figure>
<p>三个矩阵的结果进行拼接：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212155839668.png"  style="zoom:50%;" /></p>
<p>然后获得<span class="math inline">\(w_i,w_j\)</span>的最终表征：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212155908737.png" alt="image-20221212155908737" /><figcaption>image-20221212155908737</figcaption>
</figure>
<p>预测：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212155948456.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212155957601.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212160020384.png"   style="zoom:50%;" /></p>
<h2 id="experiment">3 Experiment</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212160427390.png" alt="image-20221212160427390" /><figcaption>image-20221212160427390</figcaption>
</figure>
<p>这里的数据集JMERE，是作者联合了MNRE数据集和MNER（推测应该是Twitter-2015）取交集之后的结果：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221212160518901.png" alt="image-20221212160518901" /><figcaption>image-20221212160518901</figcaption>
</figure>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MNER</tag>
        <tag>MRE</tag>
        <tag>MMKG</tag>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>HVPNeT</title>
    <url>/mmml/HVPNeT/</url>
    <content><![CDATA[<h1 id="good-visual-guidance-makes-a-better-extractor-hierarchical-visual-prefix-for-multimodal-entity-and-relation-extraction">Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction</h1>
<p>Findings of NAACL 2022，<a href="https://github.com/zjunlp/HVPNeT">代码</a>。</p>
<p>作者认为目前的MNER和MRE方法无法很好的处理图像和文本内容不匹配的问题，因此提出了一种从图像中提取object-level的层级信息，用于补充文本信息的多模态信息抽取方法HVPNeT (Hierarchical Visual Prefix fusion NeTwork)。</p>
<blockquote>
<p>Multimodal named entity recognition and relation extraction (MNER and MRE) is a fundamental and crucial branch in information extraction. <strong>However, existing approaches for MNER and MRE usually suffer from error sensitivity when irrelevant object images incorporated in texts.</strong> To deal with these issues, we propose a novel Hierarchical Visual Prefix fusion NeTwork (HVPNeT) for visual-enhanced entity and relation extraction, aiming to achieve more effective and robust performance. Specifically, we regard visual representation as pluggable visual prefix to guide the textual representation for error insensitive forecasting decision. We further propose a dynamic gated aggregation strategy to achieve hierarchical multiscaled visual features as visual prefix for fusion. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our method, and achieve state-of-the-art performance 1 .</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p><strong>问题</strong>：作者认为一开始的MNER和MRE工作倾向于把整个图像的特征考虑到文本表征中；后来的工作倾向于把object-level的图像特征考虑到文本表征中；最近，RpBERT虽然能够判断整个图像和文本内容是否相关，但是不能做到判断visual object和文本是否相关。但考虑到实际情况，一个图像中可能包含了比较相关的object，也可能包含了不太相关的object。</p>
<p>因此有必要更好的学习视觉表征，同时降低模型对不相关的visual object的错误敏感性。</p>
<p><strong>方法</strong>：作者首先识别出图像中存在的多个visual object，然后利用CNN导出visual object的层级/金字塔型视觉特征；作者把这种层级的视觉特征看做是对于文本表征的视觉前缀visual prefix；visual prefix输入到BERT的每一层，用来提供文本表征所需的视觉信息。</p>
<h2 id="method">2 Method</h2>
<p>整体结构：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020143211904.png" alt="image-20221020143211904" /><figcaption>image-20221020143211904</figcaption>
</figure>
<h3 id="collection-of-pyramidal-visual-feature">2.1 Collection of Pyramidal Visual Feature</h3>
<p>作者首先利用visual grounding tool (A fast and accurate one-stage approach to visual grounding. ICCV 2019) 来标注出图像的前<span class="math inline">\(m\)</span>个视觉对象（在实现中<span class="math inline">\(m=3\)</span>）。</p>
<p>然后把整个图像<span class="math inline">\(I\)</span>和不同的视觉对象<span class="math inline">\(O=\{ o_1,o_2,\dots,o_m \}\)</span> resale为<span class="math inline">\(224\times244\)</span>的图像。</p>
<p>对于每个图像，作者利用Resnet-50的不同block，导出<span class="math inline">\(c\)</span>层的视觉特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020143823646.png"   style="zoom:50%;" /></p>
<p>然后把这些不同size的特征，利用1维卷积和池化操作重新映射为具有相同size合适大小：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020144000443.png"   style="zoom:50%;" /></p>
<h3 id="dynamic-gated-aggregation">2.2 Dynamic Gated Aggregation</h3>
<p>由于不同的Transformer层可能会需要不同的视觉特征，因此对于第<span class="math inline">\(l\)</span>层的Transformer，对于单个图像导出的层级视觉信息<span class="math inline">\(V_i\)</span>，作者首先通过一个全局平均池化操作把3维张量进行压缩，然后求和，最后计算attention weight：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020144533174.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020144648816.png"   style="zoom:50%;" /></p>
<p>随后，聚合不同层的视觉特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020145201860.png"   style="zoom:50%;" /></p>
<p>每个图像都进行了gated aggregation之后，把所有图像的聚合结果拼接到一起，作为最后要输入到第<span class="math inline">\(l\)</span>层Transformer的视觉特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020145335875.png"   style="zoom:50%;" /></p>
<h3 id="visual-prefix-guided-fusion">2.3 Visual Prefix-guided Fusion</h3>
<p>接下来的问题是，如何把视觉特征加入到文本表征中去。</p>
<p>首先是，基于BERT-base结构，对于输入文本序列</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020145541385.png"   style="zoom:50%;" /></p>
<p>先产生query、key和value：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020145612172.png"  style="zoom:50%;" /></p>
<p>然后根据视觉特征，产生key和value作为visual prefix：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020145704861.png"   style="zoom:50%;" /></p>
<p>最后，进行聚合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020145746443.png"   style="zoom:50%;" /></p>
<p>作者这种做法，是follow了Simvlm: Simple visual language model pretraining with weak supervision.的工作。</p>
<h3 id="classifier">2.4 Classifier</h3>
<p>对于MNER，采用常用的CRF层：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020150008708.png"   style="zoom:50%;" /></p>
<p>对于MRE，通过提前加入的<span class="math inline">\([CLS]\)</span> token进行分类：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020150148608.png"   style="zoom:50%;" /></p>
<h2 id="experimental-results">3 Experimental Results</h2>
<p>总体实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020150325131.png"   style="zoom:50%;" /></p>
<ul>
<li>HVPNeT-Flat：直接使用ResNet的最后输出结果，而不是使用层级的视觉特征（个人感觉从结果来看，不同层级的视觉特征对MRE的影响更大）</li>
<li>HVPNeT-1T3：由于ResNet有4个block，BERT有12层，所以作者尝试了把1个block对应到3个BERT层，而不是直接把所有的block都输入到每一个BERT层</li>
<li>HVPNeT-OnlyObj：只使用object-level的特征，不使用image-level的特征。（可以看到，即使不使用image-level的信息，差距也不是很大，说明主要起作用的还是object level的信息）</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MRE</tag>
        <tag>MMKG</tag>
      </tags>
  </entry>
  <entry>
    <title>IKRL</title>
    <url>/mmml/IKRL/</url>
    <content><![CDATA[<h1 id="image-embodied-knowledge-representation-learning">Image-embodied Knowledge Representation Learning</h1>
<p>清华大学2017年发表在IJCAI上的paper，IKRL，应该是第一个把图像信息注入到KGE中的方法。</p>
<p>基于TransE的思想，为不同的entity学习一个额外的image embedding，然后image embedding和原来的entity embedding通过<span class="math inline">\(h+r\approx t\)</span>评估三元组是否成立。</p>
<blockquote>
<p>Entity images could provide signiﬁcant visual information for knowledge representation learning. Most conventional methods learn knowledge representations merely from structured triples, ignoring rich visual information extracted from entity images. In this paper, we propose a novel Imageembodied Knowledge Representation Learning model (IKRL), where knowledge representations are learned with both triple facts and images. More speciﬁcally, we ﬁrst construct representations for all images of an entity with a neural image encoder. These image representations are then integrated into an aggregated image-based representation via an attention-based method. We evaluate our IKRL models on knowledge graph completion and triple classiﬁcation. Experimental results demonstrate that our models outperform all baselines on both tasks, which indicates the signiﬁcance of visual information for knowledge representations and the capability of our models in learning knowledge representations with images.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>作者首先举了一个例子来说明图片包含了能够辅助建模KGE：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907162730326.png"   style="zoom:40%;" /></p>
<p>关系<span class="math inline">\(has\ part\)</span>是一个spatial relation，它在图像体现的信息就比单纯在文本上要丰富，与action relation一样都比较适合可视化。但是要注意有很多的relation是很难可视化的，单纯在图像上也不太好进行推测，除非图像本身包含了明确的信息。比如关系<span class="math inline">\(spouse\)</span>，我们无法单纯从两个男女的照片上判断是不是配偶，但如果有两个人结婚的照片，我们就可以推测他们是配偶。</p>
<h2 id="method">2 Method</h2>
<p>作者的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163134837.png"   style="zoom:40%;" /></p>
<p>主要就是多了一个image embedding <span class="math inline">\(e_I\)</span>，在获得了image embedding后，进行translation-based的推测：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163251722.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163304108.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163411546.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163314931.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163326499.png"  style="zoom:50%;" /></p>
<p>如何获得image embedding？作者通过AlexNet（5卷积层+2全连接层）获得image representation，然后投影至entity space：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163549753.png"   style="zoom:40%;" /></p>
<p>然后结合注意力聚合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163736360.png"  style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907163750179.png"   style="zoom:40%;" /></p>
<h2 id="experiments">3 Experiments</h2>
<p>值得一提的是，作者构造了一个新的数据集WN9-IMG，可惜的是效果已经要做到顶了。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907164242990.png"   style="zoom:50%;" /></p>
<p>链路预测结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907164347235.png"   style="zoom:50%;" /></p>
<p>三元组分类结果（判断三元组是否成立），通过计算<span class="math inline">\(||h+r-t||\)</span>是否高于阈值<span class="math inline">\(\delta_r\)</span>，<span class="math inline">\(\delta_r\)</span>是一个可训练参数，通过评估在验证集下的效果进行更新：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907164431131.png"   style="zoom:50%;" /></p>
<h2 id="conclusion">Conclusion</h2>
<p>一个比较简单直接的基于TransE的MM KGE方法，把图像信息注入到实体表示中。有以下缺点：</p>
<ul>
<li>以image为单位进行attention过于粗糙，明显会带来大量的noise；并且从作者的实验来看，attention效果不够显著。</li>
<li>没有融合text information，算不上真正的多模态（不把单纯的三元组看做是一种模态的话）。</li>
<li>实际上学习到的image embedding也没有真正的融合到entity embedding中，仅仅独立存在着作为预测效果的一部分。entity embedding只是被用来评估那个image embedding更重要而已。</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MMKG</tag>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>MAF</title>
    <url>/mmml/MAF/</url>
    <content><![CDATA[<h1 id="maf-a-general-matching-and-alignment-framework-for-multimodal-named-entity-recognition">MAF: A General Matching and Alignment Framework for Multimodal Named Entity Recognition</h1>
<p>WSDM 2022，<a href="https://github.com/xubodhu/MAF">代码</a>，复旦大学。</p>
<p>作者通过判断post的text和image的匹配程度，计算进入文本表征中的图像信息，并且期望能够通过保持text和image不同模态表征的一致性。</p>
<blockquote>
<p>In this paper, we study multimodal named entity recognition in social media posts. Existing works mainly focus on using a crossmodal attention mechanism to combine text representation with image representation. However, they still suffer from two weaknesses: (1) the current methods are based on a strong assumption that each text and its accompanying image are matched, and the image can be used to help identify named entities in the text. However, this assumption is not always true in real scenarios, and the strong assumption may reduce the recognition effect of the MNER model; (2) the current methods fail to construct a consistent representation to bridge the semantic gap between two modalities, which prevents the model from establishing a good connection between the text and image. To address these issues, we propose a general matching and alignment framework (MAF) for multimodal named entity recognition in social media posts. Specifically, <strong>to solve the first issue, we propose a novel cross-modal matching (CM) module to calculate the similarity score between text and image, and use the score to determine the proportion of visual information that should be retained.</strong> <strong>To solve the second issue, we propose a novel cross-modal alignment (CA) module to make the representations of the two modalities more consistent.</strong>We conduct extensive experiments, ablation studies, and case studies to demonstrate the effectiveness and efficiency of our method.The source code of this paper can be found in https://github.com/xubodhu/MAF.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p><strong>问题</strong>：</p>
<ol type="1">
<li>很多目前的MNER方法建立在认为post的text和image是匹配的假设上，因此总是会同时使用text和image的信息进行NER。但是并不是所有的text和image都是匹配的。</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117204106769.png"   style="zoom:30%;" /></p>
<ol start="2" type="1">
<li>现有的方法忽略了学习text和image两个模态表征的一致性，因此两个模态的表征之间存在语义差异（semantic gap）</li>
</ol>
<p><strong>方案</strong>：</p>
<ol type="1">
<li>提出了一个跨模态匹配模块（cross-modal matching，CM）来计算text和image的相似度得分</li>
<li>提出了一个跨模态对齐模块（cross-modal alignment，CA）使得两个模态的表征更加一致</li>
</ol>
<h2 id="method">2. Method</h2>
<p>总体结构：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117204539318.png" alt="image-20221117204539318" /><figcaption>image-20221117204539318</figcaption>
</figure>
<p>两个模态的encoder：</p>
<ul>
<li>text encoder：pretrained BERT-base。输入是最大长度128的token序列，在开头加入[CLS] token，在空白处加入[PAD] token。输出是768维向量。总的Transformer block有12层。</li>
<li>image encoder：pretrained 152层ResNet。输入是224x224的resized image，输出是<span class="math inline">\(2048\times 7\times 7\)</span>的代表49个region的张量。每个region向量通过独立的投影矩阵，转化为768维向量。</li>
</ul>
<h3 id="cross-modal-alignment-module-ca">2.1 Cross-Modal Alignment Module (CA)</h3>
<p>使用[CLS]的embedding作为文本序列的总表示<span class="math inline">\(T_s\)</span>；使用<span class="math inline">\(7\times 7\)</span>的均值池化操作获得图像的总表示<span class="math inline">\(T_g\)</span>。</p>
<p>两个表示通过独立的MLP来投影到具有相同维度大小的空间中，获得<span class="math inline">\(T_c\)</span>和<span class="math inline">\(V_c\)</span>。</p>
<p>然后使用这两个表征来尝试让两个模态空间下的向量表示具有更多的一致性。</p>
<p>基于对比学习学习text和image的匹配距离，在一个batch中，把image或者text换为其它post对应的image或者text作为负样本，把原来的样例作为正样本。</p>
<p>首先，计算正样本的Image embedding和所有样本的Text embeddings的距离，对比损失为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117205634445.png"   style="zoom:50%;" /></p>
<p>其中，计算相似度的函数是余弦相似度。</p>
<p>然后，计算正样本的Text embedding和所有样本的Image embeddings的距离，对比损失为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117210112669.png"   style="zoom:50%;" /></p>
<p>两个loss加载一起，就是CA模块的text-image匹配loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117210157967.png"   style="zoom:50%;" /></p>
<h3 id="cross-modal-interaction-module">2.2 Cross-Modal Interaction Module</h3>
<p>基于co-attention，text作为query，image作为key和value，学习text-aware的图像表征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117210326579.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117210336910.png"  style="zoom:50%;" /></p>
<h3 id="cross-modal-matching-module-cm">2.3 Cross-Modal Matching Module (CM)</h3>
<p>作者设计了个CM模块，用来计算前一步学习到的text-aware的图像表征应该有多少被保留。</p>
<p>同样是基于text-image匹配任务，但是并不是基于对比学习，不使用对比学习，而是二分类问题，预测是否matching。</p>
<p>训练样本的构造也不同，不再是基于每个正样本都分别构造负样本，而是直接在一个batch中，选择2k个样本，前k个样本的image和后k个样本的image进行互换，构造出负样本；剩下的batch中的样本作为正样本。</p>
<p>预测是否匹配，直接把text和image图像展开，然后拼接输入到MLP</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117212038708.png" style="zoom:50%;" /></p>
<p>训练的loss就是BCE：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117212103443.png"   style="zoom:50%;" /></p>
<p>然后，根据这个分类器，可以判断在整个图像层次下，有多少信息应该保留：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117212309060.png"  style="zoom:50%;" /></p>
<h3 id="cross-modal-fusion-module">2.4 Cross-Modal Fusion Module</h3>
<p>一个基于gate的模块被作者用来决定，在token level上有多少图像信息应该保留：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117212538168.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117212546622.png"   style="zoom:50%;" /></p>
<p>其中，<span class="math inline">\(g\in \mathbb{R}^{d\times (n+2)}\)</span>是token level的权重。</p>
<p>最后，经过层层过滤的图像信息，与文本表征进行拼接，就得到了最后的表征<span class="math inline">\(H\)</span>。</p>
<p>整个模型训练的loss，<span class="math inline">\(\alpha=\beta=0.2\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117213043975.png"   style="zoom:50%;" /></p>
<h2 id="experiment">3. Experiment</h2>
<p>整体性能并不是非常突出：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117213142042.png" alt="image-20221117213142042" /><figcaption>image-20221117213142042</figcaption>
</figure>
<p>消融实验：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221117213159257.png" alt="image-20221117213159257" /><figcaption>image-20221117213159257</figcaption>
</figure>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MNER</tag>
        <tag>MMKG</tag>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>MEGA</title>
    <url>/mmml/MEGA/</url>
    <content><![CDATA[<h1 id="multimodal-relation-extraction-with-efficient-graph-alignment">Multimodal Relation Extraction with Efficient Graph Alignment</h1>
<p>ACM MM 21，<a href="https://github.com/thecharm/Mega">代码</a></p>
<p>作者提出了一种，通过识别图像的scene graph和textual graph，进行图对齐的多模态关系抽取方法MEGA。</p>
<blockquote>
<p>Relation extraction (RE) is a fundamental process in constructing knowledge graphs. However, previous methods on relation extraction suffer sharp performance decline in short and noisy social media texts due to a lack of contexts. Fortunately, the related visual contents (objects and their relations) in social media posts can supplement the missing semantics and help to extract relations precisely. We introduce the multimodal relation extraction (MRE), a task that identifies textual relations with visual clues. To tackle this problem, we present a large-scale dataset which contains 15000+ sentences with 23 pre-defined relation categories. Considering that the visual relations among objects are corresponding to textual relations, we develop a dual graph alignment method to capture this correlation for better performance. Experimental results demonstrate that visual contents help to identify relations more precisely against the text-only baselines. Besides, our alignment method can find the correlations between vision and language, resulting in better performance. Our dataset and code are available at https://github.com/thecharm/Mega.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p><strong>problem</strong>：之前的关系抽取主要有两种，sequence-based和dependency-based方法。但是这些方法主要集中在文本信息的抽取，如果应用到social media posts这样文本信息比较少，缺乏上下文信息的时候，效果会很差。</p>
<p><strong>motivation</strong>：作者发现，可以使用post中的image来补充缺失的上下文信息。作者认为，和多模态命名实体有所区别的是，MRE不仅要考虑捕获visual object和textual entity的联系，还要考虑visual object之间的visual relation和textual relation之间的联系。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019102038143.png"   style="zoom:40%;" /></p>
<p>比如在上面的实例中，visual relation <code>holding</code>可以用来辅助推测textual relation <code>awarded</code>。</p>
<h2 id="method">2 Method</h2>
<p>总体结构：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019152840889.png" alt="image-20221019152840889" /><figcaption>image-20221019152840889</figcaption>
</figure>
<h3 id="semantic-feature-representation">2.1 Semantic Feature Representation</h3>
<p>首先是通过BERT和scene graph generation来获得文本和视觉的表征。</p>
<h4 id="textual-semantic-representation">2.1.1 Textual Semantic Representation</h4>
<p>对于输入的文本序列<span class="math inline">\(s_1\)</span>，添加token为下面的形式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019153202538.png" alt="image-20221019153202538" style="zoom:50%;" /></p>
<p>为了让所有的序列有固定长度<span class="math inline">\(l\)</span>，对于长度不足<span class="math inline">\(l\)</span>的序列添加token <span class="math inline">\([PAD]\)</span>。</p>
<p>随后，作者还设置了另一个序列<span class="math inline">\(s_2\)</span>区分正常token和<span class="math inline">\([PAD]\)</span> token，<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019153452300.png"   style="zoom:50%;" />。</p>
<p>最后，fine-tune下pretrained好的BERT就得到了token的表征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019153612318.png"   style="zoom:50%;" /></p>
<h4 id="visual-semantic-representation">2.1.2 Visual Semantic Representation</h4>
<p>使用前人的工作<em>Unbiased Scene Graph Generation From Biased Training CVPR 2020</em>来获得scene graph以及对应的表征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019153833135.png"   style="zoom:50%;" /></p>
<p>由于可能识别出很多不相关的visual object，因此作者设置一个阈值，只有大于这个阈值的，并且是前<span class="math inline">\(m\)</span>个最大分类得分的object才会被使用。如果选择出来的数量小于<span class="math inline">\(m\)</span>，就添加0向量。</p>
<h3 id="structural-feature-representation">2.2 Structural Feature Representation</h3>
<p>使用ELMo (<em>Deep contextualized word representations. NAACL 2018</em>)将input text解析为语法依赖树Syntax Dependency Tree。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019154240627.png"  style="zoom:50%;" /></p>
<p>这样的语法依赖树就可以表示为一个文本图 <span class="math inline">\(G_1\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019154320428.png"   style="zoom:50%;" /></p>
<p>类似的，场景图也是一个graph <span class="math inline">\(G_2\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221019154414958.png"  style="zoom:50%;" /></p>
<h3 id="multimodal-feature-alignment">2.3 Multimodal Feature Alignment</h3>
<h4 id="graph-structure-alignment">2.3.1 Graph Structure Alignment</h4>
<p>图结构的对齐，主要是有两步，一是通过分解节点标识node identity相似矩阵来获取node embedding；二是通过计算node embedding之间的相似度来对齐实体。</p>
<p>在学习node embedding时，作者follow了<em>REGAL: Representation Learning-based Graph Alignment. CIKM 2018</em>的工作。下面的具体原理没懂。</p>
<p>首先是统计两个graph下每个node的度分布：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020185920116.png"   style="zoom:50%;" /></p>
<p>然后，利用这样的度分布可以评估两个node之间的节点相似度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020190013767.png"   style="zoom:50%;" /></p>
<p>然后，随机选择<span class="math inline">\(p\)</span>个node作为&quot;landmark&quot; node，计算它们和所有node之间的相似度，可以得到相似度矩阵<span class="math inline">\(C\in \mathbb{R}^{n\times p}\)</span>。从矩阵<span class="math inline">\(C\)</span>中，可以选出<span class="math inline">\(p\times p\)</span>的landmark-to-landmark矩阵<span class="math inline">\(W_p\)</span>。</p>
<p>。。。</p>
<p>最后 ，得到了node embedding：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020191126590.png"   style="zoom:50%;" /></p>
<p>使用node embedding计算node之间的相似度，对于每个node，选择和它相似度最大的node作为对齐的node：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020191221431.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020191236209.png"  style="zoom:50%;" /></p>
<p>最后的矩阵<span class="math inline">\(\alpha\)</span>的第<span class="math inline">\(i\)</span>行<span class="math inline">\(j\)</span>列表示第<span class="math inline">\(i\)</span>个word和第<span class="math inline">\(j\)</span>个object的结构的相似度。这本文当中，作者只保留了最相关的object（也就是每一行相似度最大的值保留下来），其它的都置为0。</p>
<h4 id="semantic-features-alignment">2.3.2 Semantic Features Alignment</h4>
<p>假设得到的文本表征是<span class="math inline">\(X\)</span>，视觉表征是<span class="math inline">\(Y\)</span>，通过自注意力来进行计算：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020191522282.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020191541700.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020191722037.png"   style="zoom:50%;" /></p>
<p>最后，同时使用structural和semantic对齐的结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020191915124.png"   style="zoom:50%;" /></p>
<h3 id="entities-representation-concatenation">2.4 Entities Representation Concatenation</h3>
<p>聚合所有object的视觉表征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020192128473.png"   style="zoom:50%;" /></p>
<p>获得实体的文本表征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020192148484.png"   style="zoom:50%;" /></p>
<p>输出关系预测结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020192207164.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020192222002.png"   style="zoom:50%;" /></p>
<h2 id="experimental-results">3 Experimental Results</h2>
<p>MRE实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020192344464.png"   style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MRE</tag>
        <tag>MMKG</tag>
      </tags>
  </entry>
  <entry>
    <title>MKGformer</title>
    <url>/mmml/MKGformer/</url>
    <content><![CDATA[<h1 id="hybrid-transformer-with-multi-level-fusion-for-multimodal-knowledge-graph-completion">Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion</h1>
<p>SIGIR 2022，<a href="https://github.com/zjunlp/MKGformer">代码</a>，Zhejiang University。</p>
<p>作者提出了一种基于Transformer的能够适用于不同多模态知识图谱预测任务的方法，MKGformer。对于不同的预测任务，作者通过定义输入数据和输出数据拥有相同的格式，从而到达不改变模型结构，还能够同时用于不同预测任务；其次，作者提出了一种在text和image模态之间，进行multi-level混合的Transformer结构。</p>
<p>作者在多模态KG补全、多模态关系抽取和多模态命名实体识别三个任务的有监督学习和低资源学习的场景上进行了实验。</p>
<blockquote>
<p>Multimodal Knowledge Graphs (MKGs), which organize visualtext factual knowledge, have recently been successfully applied to tasks such as information retrieval, question answering, and recommendation system. Since most MKGs are far from complete, extensive knowledge graph completion studies have been proposed focusing on the multimodal entity, relation extraction and link prediction. However, different tasks and modalities require changes to the model architecture, and not all images/objects are relevant to text input, which hinders the applicability to diverse real-world scenarios. In this paper, we propose a hybrid transformer with multi-level fusion to address those issues. Specifically, we leverage a hybrid transformer architecture with unified input-output for diverse multimodal knowledge graph completion tasks. Moreover, we propose multi-level fusion, which integrates visual and text representation via coarse-grained prefix-guided interaction and fine-grained correlation-aware fusion modules. We conduct extensive experiments to validate that our MKGformer can obtain SOTA performance on four datasets of multimodal link prediction, multimodal RE, and multimodal NER.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>作者认为目前的多模态KGC任务存在以下问题：</p>
<ol type="1">
<li>Architecture universality：不同的KGC任务，对于不同模态需要设计不同的编码器，从而限制了模型的通用性和易用性。</li>
<li>Modality contradiction：大多的multimodal KGC的方法很大程度上忽略了图像信息可能带来的噪音问题，因为在多模态KG中，一个实体可能会关联到多个不同的image，实际上只有部分的图像信息可能才是所需的。</li>
</ol>
<p>为了解决上述问题，作者提出了：</p>
<ol type="1">
<li>之前有研究者发现，预训练模型能够在Transformer的self-attention层和feed-forward层激活和输入数据相关的knowledge。因此，作者尝试基于Transformer架构，同时学习textual和visual的信息。</li>
<li>作者提出的MKGformer，有两个核心结构，prefix-guided interaction module (PGI)和correlation-aware fusion module (CAF)。前者用于pre-reduce不同模态的heterogeneity，后者用来进一步降低模型对于irrelevant image/text的错误敏感性。</li>
</ol>
<h2 id="approach">2 Approach</h2>
<p>总体结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902145750837.png"  style="zoom:40%;" /></p>
<h3 id="unified-multimodal-kgc-framework">2.1 Unified Multimodal KGC Framework</h3>
<p>对于文本，使用BERT进行编码（T-Encoder）；对于图像，使用ViT (<em>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</em>)进行编码（V-Encoder）。先分别独立进行几层的学习之后，在最后<span class="math inline">\(M\)</span>层，利用作者提出的M-Encoder进行模态混合。需要注意的是，这里的M-Encoder并不是额外的层，而是作者在BERT和ViT的架构基础上，直接进行了改进，让不同模态模型之间能够进行信息流通。</p>
<p>模型对于输入和输入数据格式的变形，首先是有三个预测任务：</p>
<ol type="1">
<li><p>Multimodal Link Prediction is the most popular task for multimodal KGC, which focuses on predicting the tail entity given the head entity and the query relation, denoted by <span class="math inline">\((𝑒_ℎ ,𝑟, ?)\)</span>. 预测未知fact。多模态带来的新条件是，每个实体可能拥有多个image <span class="math inline">\(I_h\)</span>。</p></li>
<li>Multimodal Relation Extraction aims at linking relation mentions from text to a canonical relation type in a knowledge graph. 给定一段描述文本<span class="math inline">\(T\)</span>，已知其中的头尾实体<span class="math inline">\((e_h,e_t)\)</span>，预测实体间的关系<span class="math inline">\(r\)</span>。多模态带来的新条件是，描述文本有对应的image <span class="math inline">\(I\)</span>。</li>
<li><p>Multimodal Named Entity Recognition is the task of extracting named entities from text sequences and corresponding images. 从一个token序列中<span class="math inline">\(T=\{w_1,\dots,w_n\}\)</span>，预测对应的标签序列<span class="math inline">\(y={y_1,\dots,y_n}\)</span>。多模态带来的条件是，描述文本有对应的image <span class="math inline">\(I\)</span>。</p></li>
</ol>
<p>对于输入数据和预测数据的变形：</p>
<ol type="1">
<li><p>对于多模态链路预测，作者首先设计了特别的一步操作，Image-text Incorporated Entity Modeling，具体而言，在保持整个模型参数不动的情况下，只训练学习新出现的entity embedding。这样是的文本信息和视觉信息都能够融合到entity embedding上。对于实体<span class="math inline">\(e_i\)</span>关联的图像，输入到V-Encoder；对于实体<span class="math inline">\(e_i\)</span>的文本描述<span class="math inline">\(d_{e_i}=(w_1,\dots,w_n)\)</span>，改造为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902153930132.png" style="zoom:50%;" /></p>
<p>然后预测<span class="math inline">\([mask]\)</span>是实体<span class="math inline">\(e_i\)</span>的概率。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902154509283.png"   style="zoom:50%;" /></p>
<p>随后，正式开始预测missing entity，将<span class="math inline">\((𝑒_ℎ ,𝑟, ?)\)</span>变形为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902154627839.png"   style="zoom:50%;" /></p></li>
<li><p>对于多模态命名实体识别，作者利用CRF函数（<em>Neural Architectures for Named Entity Recognition.</em>）进行预测（这个没看过..）</p></li>
<li><p>对于多模态关系抽取，作者在原来的文本描述上，加入<span class="math inline">\([CLS]\)</span> token，最后预测<span class="math inline">\([CLS]\)</span>是目标关系的概率：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902155007744.png"   style="zoom:50%;" /></p></li>
</ol>
<p>对于MNER和MRE任务，使用<em>A Fast and Accurate One-Stage Approach to Visual Grounding. ICCV 2019</em> 导出前<span class="math inline">\(m\)</span>个visual objects。</p>
<p>对于MMKGC任务，直接使用整个图像。</p>
<h3 id="hybrid-transformer-architecture">2.2 Hybrid Transformer Architecture</h3>
<p>首先是原始的Transformer结构，MHA表示多头注意力，FFN表示前馈网络。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902155227398.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902155249701.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902155307966.png"   style="zoom:50%;" /></p>
<p>V-Encoder，ViT：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902155348746.png"   style="zoom:50%;" /></p>
<p>T-Encoder，BERT：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902155427336.png"   style="zoom:50%;" /></p>
<p>M-Encoder，在V-Encoder和T-Encoder之间，先PGI，再CAF：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902155825058.png"   style="zoom:50%;" /></p>
<h3 id="insights-of-m-encoder">2.3 Insights of M-Encoder</h3>
<h4 id="pgi">2.3.1 PGI</h4>
<p>对于PGI（Prefix-guided Interaction Module），作者是受到了前面研究的影响（<em>Prefix-Tuning: Optimizing Continuous Prompts for Generation</em>和<em>Towards a Unified View of Parameter-Efficient Transfer Learning.</em>）。</p>
<p>作者在自注意力层，让visual Transformer侧考虑聚合textual信息，通过让visual query和textual key，textual value进行操作。实际上是询问当前的patch image和哪些token更接近，然后聚合token embedding。视觉侧的query，文本侧和视觉侧的key，文本侧和视觉侧的value：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902161732093.png"   style="zoom:50%;" /></p>
<p>很简单的操作，应该是直接拼接。作者进一步推算公式为：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902161833850.png"   style="zoom:50%;" /></p>
<p>这里我没有直接推算出来。但是从作者推算出的可以看出来，实质上它是降低了原来单纯的visual attention，增加了文本-图像的跨模态注意力。</p>
<h4 id="caf">2.3.2 CAF</h4>
<p>对于CAF（Correlation-aware Fusion Module），作者受到前面研究的影响，之前有人发现Transformer中的FFN层能够学习到task-specific textual pattern（<em>Transformer Feed-Forward Layers Are Key-Value Memories</em>）。因此作者通过计算token embedding和patch embedding之间的相似性矩阵来衡量视觉信息的重要性。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902163451512.png" alt="image-20220902163451512" style="zoom:50%;" /></p>
<p>然后聚合视觉信息，文本侧的query，视觉侧的key，视觉侧的value：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902163506163.png" alt="image-20220902163506163" style="zoom:50%;" /></p>
<p>上述过程实际和自注意力的过程是一样的。最后把聚合的视觉信息和原来的文本信息拼接到一起：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902163525975.png"   style="zoom:50%;" /></p>
<p>回顾下上述两个过程，作者都是没有直接创建新的layer进行信息融合，而是通过让信息在dual Transformer之间进行流通。因为作者提出图像的信息噪音很大，对自注意力层和全连接层的改造都是围绕这一点来的。先在注意力层让文本信息流通到视觉信息上，让V-Encoder侧能够考虑文本信息，而不是单纯在patch之间聚合信息。试想下，如果让视觉信息流通到文本信息上，那么就意味着视觉的噪音直接加入到了文本侧，不太合适。随后，在全连接层让已经考虑了文本信息的视觉信息，再流通回文本侧，进一步降低视觉噪音。</p>
<h2 id="experiments">3 Experiments</h2>
<h3 id="experimental-setup">3.1 Experimental Setup</h3>
<p>数据集：</p>
<ul>
<li>链路预测：WN18-IMG和FB15k-237-IMG，都是原来的数据集的实体分别关联到了10个image。</li>
<li>关系抽取：MNRE数据集，人工构造，来源Twitter。</li>
<li>命名实体识别：Twitter-2017，包括了2016-2017年间用户的多模态posts。</li>
</ul>
<p>训练设置：</p>
<p>在所有的情况下，M-Encoder保持3层，基于BERT_base和ViT-B/32。</p>
<h3 id="overall-performance">3.2 Overall Performance</h3>
<p>链路预测（作者提到了，原来的论文中对于FB15k-237-IMG的结果由于作者代码对于数据处理错误，因此出现了错误的性能提升，作者在arxiv上上传了更新后的结果）：</p>
<p>原论文结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902165320438.png"   style="zoom:40%;" /></p>
<p>更新后的结果，可以看出来结果变化挺大</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221118160223529.png" alt="image-20221118160223529" /><figcaption>image-20221118160223529</figcaption>
</figure>
<p>关系抽取和命名实体识别：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902165357479.png"   style="zoom:40%;" /></p>
<h3 id="low-resource-evaluation">3.3 Low-Resource Evaluation</h3>
<p>作者认为对文本和图像，使用类似的网络结构进行处理，降低了差异性，在低资源预测任务中这种作用更加突出。在数据量更少的情况下，需要想办法更好的处理数据模态之间的差异性，因此模型对于不同模态的差异性的处理能力可能需要更加突出。</p>
<p>在低资源的设置下，作者发现直接把视觉-语言预训练模型应用到KGC任务上，并没有表现出特别优越的性能。作者认为可能是原来的预训练数据和KGC任务相关性不是特别相关的原因。</p>
<p>低资源链路预测：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902165501174.png"  style="zoom:40%;" /></p>
<p>低资源关系抽取：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902165640257.png"   style="zoom:40%;" /></p>
<p>低资源命名实体识别：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902165544824.png"   style="zoom:40%;" /></p>
<h3 id="ablation-study">3.4 Ablation Study</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902165723859.png"   style="zoom:40%;" /></p>
<h3 id="case-analysis-for-image-text-relevance">3.5 Case Analysis for Image-text Relevance</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220902165850066.png"   style="zoom:50%;" /></p>
<p>从这个实际案例可以看出，图像确实和整个描述文本是相关的，但是图像不一定能够对应到所需要的实体。并且，一个图像中存在很多不需要的噪音。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>KG</tag>
        <tag>multimodal</tag>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>MM-Transformer-Survey</title>
    <url>/mmml/MM-Transformer-Survey/</url>
    <content><![CDATA[<h1 id="multimodal-learning-with-transformers-a-survey">Multimodal Learning with Transformers: A Survey</h1>
<p>2022-06 arxiv</p>
<p>牛津大学学者的一篇多模态Transformer综述，系统的描述了目前多模态Transformer可能注意的不同改进点。</p>
<blockquote>
<p>Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and big data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal big data era, (2) a theoretical review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>我们期待的理想的人工智能具有的能力至少是可以做到人类能够做到的一切，这里就包括了人类感知世界的方式：看、听、摸等。人类使用特定感知器sensor和外界建立特定的交流通道，这种特定交流通道中传递/表达的信息形式我们称作是模态modality，比如语言或视觉：</p>
<blockquote>
<p>In general, a modality is often associated with a specific sensor that creates a unique communication channel, such as vision and language.</p>
</blockquote>
<p>这篇survey主要是考虑使用Transformer解决多模态任务，Transformer适用于多模态的几点原因：</p>
<ul>
<li>更少的模态特定的假设，比如RNN的序列化输入；CNN的局部迁移不变性，使得Transformer天然的适用于处理更多模态数据</li>
<li>对于许多多模态数据来说，可以被轻易的转换成适合于Transformer的序列输入形式</li>
<li>Transformer的内部结构，比如self-attention，很适合被改造为跨模态交互/多模态融合的形式</li>
</ul>
<p>有一些其它的survey是从更加广泛的模型来讨论多模态学习：</p>
<ul>
<li>Multimodal machine learning: A survey and taxonomy. 2018</li>
<li>Multimodal intelligence: Representation learning, information fusion, and applications. 2020</li>
<li>Multimodal co-learning: Challenges, applications with datasets, recent advances and future directions. 2022</li>
</ul>
<h2 id="background">2. Background</h2>
<p>多模态学习（multimodal machine learning，MML）并不是一个新词，从20世纪80年代开始就有人研究视觉听觉语音识别（<em>Integration of acoustic and visual speech signals using neural networks. 1989</em>）。在深度学习时代，随着Transformer模型的出现，算力的急速增长，多模态数据集规模的不断增加共同促进多模态学习进步。</p>
<p><em>更多背景请参考论文内容</em></p>
<h2 id="multimodal-transformers">3. Multimodal Transformers</h2>
<h3 id="multimodal-input">3.1 Multimodal Input</h3>
<p>对于任意模态数据，要输入到Transformer通常是做两步：</p>
<ol type="1">
<li><p>tokenize the input</p></li>
<li><p>select an embedding space to represent the tokens</p></li>
</ol>
<p>对于单模态数据，我们有不同的方法实现tokenization和选择合适的token embedding。比如对于image，我们可以选择ROI作为tokens，然后CNN导出的feature作为token embedding；可以选择将image划分成不同的patch，每个patch经过linear projection之后作为token embedding；也可以选择将image上的不同object作为tokens，使用GNN学习场景图的特征作为token embedding（<em>Multimodal sentiment detection based on multi-channel graph neural networks. 2021</em>）。</p>
<p>下面的表格是总结的一些多模态tokens处理的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230223150507977.png" /></p>
<p>通常还会加入一些special tokens，用来服务一些特定的目的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230223150851043.png" /></p>
<p>在实践中，人们常常会在embedding层选择融合不同的信息，属于early-fusion的一种。最常见的方式就是在每个位置的token上直接加上不同的信息。比如在原始的Transformer中，token embedding会加上position embedding；VL-BERT选择“linguistic token embedding <span class="math inline">\(\oplus\)</span> full image visual feature embedding”；InterBERT选择在ROI的embedding加入位置信息，“ROI embedding <span class="math inline">\(\oplus\)</span> location embedding”。</p>
<h3 id="self-attention-variants-in-multimodal-context">3.2 Self-Attention Variants in Multimodal Context</h3>
<p>接下来讨论用于多模态的self-attention变体。</p>
<p>下面是作者总结的变体：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230301104906563.png" /></p>
<p><strong>Early summation</strong></p>
<p>在embedding layer对于两个模态的token embedding直接进行element-wise summing：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230223172136061.png" /></p>
<p>其中的<span class="math inline">\(Z_{(A)}\)</span>和<span class="math inline">\(Z_{(B)}\)</span>表示是来自两个模态的token embedding matrix；<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(\beta\)</span>是两个人工定义的权重；<span class="math inline">\(TF\)</span>表示Transformer layer/block。</p>
<p>这样做的好处是不会增加计算量。</p>
<p>坏处是<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(\beta\)</span>需要人工选择，并且直接相加两个模态的embedding，显得过于粗暴了。</p>
<p><strong>Early Concatenation</strong></p>
<p>不是相加，而是直接拼接两个模态的token序列，组成新的序列输入到Transformer：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230223172712248.png" /></p>
<p>这种做法使得一个模态的token embedding可以直接以其它模态的token embedding作为context进行学习。这种做法也叫做“all-attention”。</p>
<p>坏处是更大的输入序列长度，当然会增加计算复杂度。</p>
<p><strong>Hierarchical Attention (multi-stream to one-stream)</strong></p>
<p>每个模态各自有Transformer，然后拼接到一起输入到一个统一的Transformer：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230223173045776.png" /></p>
<p>这种做法是late fusion的一种；也可以看做是一种特殊的early concatenation（在输入到真正的多模态Transformer之前，先使用单模态Transformer对token embedding进行了编码）。</p>
<p><strong>Hierarchical Attention (one-stream to multi-stream)</strong></p>
<p>和前面的相反，首先使用一个统一的Transformer处理多模态数据，然后每个模态再有自己独立的Transformer：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230223173438330.png" /></p>
<p>这种做法的一个例子是InterBERT。</p>
<p><strong>Cross-Attention</strong></p>
<p>很常见也非常自然的想法，每个模态都有Transformer，但是内部Transformer的query是来自于其它模块：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230223174400978.png" /></p>
<p>这种做法叫做cross attention或者co-attention，是VilBERT方法首次提出（<em>Vilbert: Pretraining taskagnostic visiolinguistic representations for vision-and-language tasks. 2019</em>）。这种做法能够将其它模型的信息引入到当前模态，也没有增加Transformer的输入token序列长度，但是它丢失了全局上下文，也就是不能够像前面的all-attention一样，同时考虑所有模态的token embedding。</p>
<p><strong>Cross-Attention to Concatenation</strong></p>
<p>另外一个变种就是在co-attention之后，使用拼接或者另外的Transformer来继续处理。这样同样可以捕获多个模态的global context。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230227144954372.png" /></p>
<h2 id="transformers-for-multimodal-pretraining">4 Transformers for Multimodal Pretraining</h2>
<h3 id="task-agnostic-multimodal-pretraining">4.1 Task-Agnostic Multimodal Pretraining</h3>
<p>对于任务无关的预训练Transformer模型，存在以下的几个现状/趋势：</p>
<ul>
<li>Vision-language pretraining (VLP)是有最多研究的方向，包括了image+language，video+language。</li>
<li>VLP模型有两种组合方式：two-stage方式，（如LXMERT，VilBERT，VL-BERT等）使用了object detector（如Faster R-CNN）。end-end方式（如Pixel-BERT，SOHO，KD-VLP等）没有使用额外的object detector。</li>
<li>大多数都是以自监督self-supervised的方式进行训练，但是这种训练方法非常依赖于大量提前对齐的多模态数据作为跨模态监督。比如最常用的image-text pairs，instructional videos（比如教做饭的视频，其中的图像和文本更可能是对齐的）。这种数据实际上也不是很好获得，更多现实情况下可能是weakly-aligned或者unaligned的多模态数据。当然目前也出现了一些弱对齐/无对齐的多模态数据进行预训练的工作（<em>Product1m: Towards weakly supervised instance-level product retrieval via cross-modal pretraining ICCV 21</em>，<em>Simvlm: Simple visual language model pretraining with weak supervision 21</em>，<em>Zero-shot text-to-image generation 21</em>）</li>
</ul>
<p>另外一个很重要的点是如何设计pretext task。pretext task起源于CV领域，可以翻译为前置任务/代理任务/预训练任务；它一般是比较泛化的，能够潜在的对一系列下游任务有帮助的辅助任务。通常是某种自监督学习任务，比如masked language modelling (MLM)、masked object classiﬁcation (MOC)、image rotation等等。</p>
<p>单纯的从任务角度讲，这些pretext task可以分为是单模态预测任务和多模态预测任务。但要注意的是，单模态预测任务实际上很可能涉及到利用多模态信息，这和具体模型训练时的信息编码策略有关。</p>
<p>从motivation的角度讲，pretext task可以分为masking、describing、matching和ordering，如：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230301162531606.png" /></p>
<p>尽管目前多模态预训练Transformer方法已经取得了很大的进展，比如VLP模型可以在一系列下游的multimodal discriminative tasks达到很好的效果，但是对于生成任务generative tasks不能直接应用。如文献（<em>Xgpt: Cross-modal generative pretraining for image captioning 21</em>）中指出，VideoBERT和CBT都需要额外训练一个解码器才能够完成video captioning任务。</p>
<p>另外，如何设计合适的pretext task也是个重点。多任务学习和对抗学习都被研究用来提升预训练效果（<em>12-in1: Multi-task vision and language representation learning CVPR 20</em>，<em>Product1m: Towards weakly supervised instance-level product retrieval via cross-modal pretraining. ICCV 21</em>），然而多个pretext任务如何平衡？如何设计pretext，越复杂的就越好吗？</p>
<h3 id="task-speciﬁc-multimodal-pretraining">4.2 Task-Speciﬁc Multimodal Pretraining</h3>
<p>也有很多的研究工作是针对特定领域/任务的预训练，这是因为上述的通用预训练模型有些情况下（如预训练语料领域不重叠/结构不能够充分捕获领域特征/预训练任务设计不合适等）很难直接应用到特定领域。此类特定领域/问题/任务包括：</p>
<ul>
<li>vision and language navigation：需要做sequential decision</li>
<li>generative task：一般的VLP模型无法无缝的适用于生成任务</li>
<li>programming：需要考虑代码结构</li>
<li>health</li>
<li>fashion domain</li>
</ul>
<h3 id="transformers-for-speciﬁc-multimodal-tasks">4.3 Transformers for Speciﬁc Multimodal Tasks</h3>
<p>Multimodal Transformer结构当然也可以直接用于特定的多模态任务，具体不展开。</p>
<h2 id="challenges-and-designs">5 Challenges and Designs</h2>
<h3 id="fusion">5.1 Fusion</h3>
<p>按照阶段，fusion可以分为early fusion（input level）、middle fusion(intermediate representation)、late fusion（prediction）。</p>
<p>一个值得注意的方法是bottleneck fusion（<em>Attention Bottlenecks for Multimodal Fusion</em>）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230301201634535.png" /></p>
<h3 id="alignment">5.2 Alignment</h3>
<p>真实的数据常常是多个模态数据同时发生，因此天然存在对齐的模态数据。多模态数据的对齐是最常用的想法就是把多模态数据映射到通用空间下，然后通过对比学习等方法进行优化。除了比较粗粒度的image-text match的问题，还有更加细粒度的对齐任务，比如需要图像上region-level的对齐。</p>
<p>很多下游任务都需要对齐能力，比如visual grounding、text-to-speech等。当使用多任务学习进行训练时，可以看做是一种隐式的task-level的对齐。</p>
<h3 id="transferability">5.3 Transferability</h3>
<p>可迁移性是multimodal Transformer的另一个挑战，包括以下几个方面：</p>
<ul>
<li>训练数据与实际/测试数据之间的差距，比如如何把在well-aligned cross-modal pairs训练好的模型迁移到weakly-aligned cross-modal pairs。CLIP是一个很好的工作，它通过prompt template来弥补训练和测试之间的差异。</li>
<li>过拟合是另一个妨碍迁移性的问题。由于Transformer的建模能力比较强，很容易在训练数据上过拟合。</li>
<li>不同任务之间的差异也是需要克服的困难。比如判别任务和生成任务之间的差异，BERT-like的模型不能直接应用在生成任务上。再比如有时候多模态模型需要处理某些模态数据缺失的问题，这种情况下知识蒸馏是一个可能的解决方案。可以用多个单模态Transformer作为teacher，一个多模态Transformer作为student（<em>Towards a uniﬁed foundation model: Jointly pre-training transformers on unpaired images and text 21</em>）。</li>
<li>跨语言的差异。</li>
</ul>
<h3 id="efficiency">5.4 Efficiency</h3>
<p>multimodal Transformer的效率问题主要体现在两个互相影响的方面：</p>
<ol type="1">
<li>需要大量训练样本</li>
<li>随着输入序列长度的增加，训练时间和显存按照平方级增长</li>
</ol>
<p>解决的核心方法是减少训练样本或者减少模型参数，目前有以下几种思路来提高效率：</p>
<ul>
<li>Knowledge distillation. 通过知识蒸馏，从大的Transformer模型获得小的Transformer模型。</li>
<li>Simplifying and compressing model. 移除一些模型的模块，比如在VLP模型中移除object detector；权重共享，multimodal Transformer中的部分模型参数可以共享。</li>
<li>Asymmetrical network structures. 不同的模态给定不同大小的模型部分。</li>
<li>Improving utilization of training samples. 充分挖掘训练样本的潜在信息。</li>
<li>Compressing and pruning model. 选择multimodal Transformer的最优子结构。</li>
<li>Optimizing the complexity of self-attention. 直接优化Transformer的self-attention，比如稀疏注意力。</li>
<li>Optimizing the complexity of self-attention based multimodal interaction/fusion. 优化多模态交互带来的计算成本，比如bottleneck fusion方法。</li>
<li>Optimizing other strategies. 其它策略，比如有研究者（<em>Multiview transformers for video recognition 22</em>）提出可以逐步的融合多模态tokens，而不是直接融合所有多模态token。</li>
</ul>
<h3 id="universalness">5.5 Universalness</h3>
<p>通用性是当前很多模型主要考虑的问题之一，出现了以下几种体现通用性的思路：</p>
<ul>
<li>Unifying the pipelines for both uni-modal and multimodal inputs/tasks. 单模态场景和多模态场景通用，比如上面提到的使用知识蒸馏来增加迁移性。</li>
<li>Unifying the pipelines for both multimodal understanding and generation. 判别任务和生成任务通用。</li>
<li>Unifying and converting the tasks themselves. 模型不变，通过改动任务设置让模型在多个任务上通用，比如CLIP。</li>
</ul>
<h3 id="interpretability">5.4 Interpretability</h3>
<p>可解释性。研究者尝试设计一些探测任务来评估预训练过程中模型到底学习到了什么（<em>Behind the scene: Revealing the secrets of pre-trained vision-and-language models ECCV 20</em>，<em>Probing image language transformers for verb understanding 21</em>）。</p>
<h2 id="discussion-and-outlook">6 Discussion and outlook</h2>
<p>作者提出了几个开放问题：</p>
<ul>
<li>设计更加通用的多模态架构，不仅仅是在多模态任务上，也要在各个单模态任务上取得最好的效果。常常发现尽管使用了更多的多模态数据，多模态模型在单模态任务上的表现不如单模态模型。为了解决这个问题，可能探究和理解multimodal Transformer背后的原理和机制是比不断尝试新的网络架构更有价值的问题。</li>
<li>发现跨模态数据之间的隐式对齐。</li>
<li>multimodal Transformer的高效学习问题还没有被充分探究，尽管efficient Transformer的各种变体已经出现了很多研究工作。</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Multimodal</category>
      </categories>
      <tags>
        <tag>Multimodal</tag>
        <tag>Survey</tag>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>MMKG-survey-fudan</title>
    <url>/mmml/MMKG-survey-fudan/</url>
    <content><![CDATA[<h1 id="multi-modal-knowledge-graph-construction-and-application-a-survey">Multi-Modal Knowledge Graph Construction and Application: A Survey</h1>
<p>复旦大学计算机系在2022年出的关于MMKG的综述，主要针对图片和语言组成的MMKG，从construction和application两个方面进行描述。</p>
<blockquote>
<p>Recent years have witnessed the resurgence of knowledge engineering which is featured by the fast growth of knowledge graphs. However, most of existing knowledge graphs are represented with pure symbols, which hurts the machine’s capability to understand the real world. The multi-modalization of knowledge graphs is an inevitable key step towards the realization of human-level machine intelligence. The results of this endeavor are Multi-modal Knowledge Graphs (MMKGs). In this survey on MMKGs constructed by texts and images, we ﬁrst give deﬁnitions of MMKGs, followed with the preliminaries on multi-modal tasks and techniques. We then systematically review the challenges, progresses and opportunities on the construction and application of MMKGs respectively, with detailed analyses of the strength and weakness of different solutions. We finalize this survey with open research problems relevant to MMKGs.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>首先我们已经拥有了很多不同领域的知识图谱：</p>
<ul>
<li>常识知识图谱common sense knowledge：Cyc, ConceptNet</li>
<li>语言知识图谱lexical knowledge：WordNet, BabelNet</li>
<li>百科式知识图谱encyclopedia knowledge：Freebase, DBpedia, YAGO , WikiData, CN-Dbpedia</li>
<li>分类学知识图谱taxonomic knowledge：Probase</li>
<li>地理知识图谱geographic knowledge：GeoNames</li>
</ul>
<p>但是大多数这些KG仅仅是用纯符号pure symbols表示的，这实际上很大程度限制了机器描述和理解现实世界的能力。单纯的符号表达的信息不够充分。比如dog这个词，我们知道现实的狗拥有远比dog这个单词表达含义丰富的信息。因此我们需要把symbolic链接到non-symbolic experiences。</p>
<blockquote>
<p>it is necessary to ground symbols to corresponding images, sound and video data and map symbols to their corresponding referents with meanings in the physical world, enabling machines to generate similar “experiences” like a real human [12].</p>
</blockquote>
<p>从另外的方面讲，很多的应用比如关系抽取、视觉问答等任务都需要知识图谱拥有更多模态信息去进行推理。</p>
<h2 id="definitions-and-preliminaries">2 Definitions and Preliminaries</h2>
<p>在这个survey中，作者把KG的属性attribute和关系relation做了区分，虽然都是三元组形式。作者使用谓词predicate同时描述属性和关系。</p>
<p>作者把现存的主要的MMKG分为了两类：A-MMKG和N-MMKG（没搞懂为什么简称N）</p>
<ol type="1">
<li><p>A-MMKG：<em>multimodal data (images in this survey) as particular attribute values of entities or concepts.</em> 指image仅仅是作为实体的一个属性存在，image之间不存在更多的语义联系。举例如下图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905170655742.png"  style="zoom:40%;" /></p></li>
<li><p>N-MMKG：<em>multi-modal data as entities in KGs.</em> image作为新的实体，因此image之间存在互相的语义联系。举例如下：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905171029083.png"   style="zoom:40%;" /></p></li>
</ol>
<p>对于N-MMKG来说，不同image之间可以存在关系：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905180159624.png"   style="zoom:40%;" /></p>
<p>除此之外，在N-MMKG当中对于image还常常会保存它的一些简要的image descriptors，比如Gray Histogram Descriptor (GHD)、Histogram of Oriented Gradients Descriptor (HOG)、Color Layout Descriptor (CLD)等。下面是A-MMKG和N-MMKG中对于image是如何表示的示例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905180421754.png"   style="zoom:40%;" /></p>
<p>目前在各个multimodal tasks领域内都已经有很大的进展，但是引入MMKG可以进一步带来更多的好处：</p>
<ul>
<li>MMKG provides sufficient background knowledge to enrich the representation of entities and concepts, especially for the long-tail ones. (<em>Knowledge aware semantic concept expansion for image-text matching. IJCAI 2019</em>)</li>
<li>MMKG enables the understanding of unseen objects in images. (<em>Describing natural images containing novel objects with knowledge guided assitance. arXiv 2017</em>)</li>
<li>MMKG enables multi-modal reasoning. (<em>Okvqa: A visual question answering benchmark requiring external knowledge. IEEE Conference on Computer Vision and Pattern Recognition 2019</em>)</li>
<li>MMKG usually provides multi-modal data as additional features to bridge the information gaps in some NLP tasks. (<em>Adaptive co-attention network for named entity recognition in tweets. AAAI 2018</em>)</li>
</ul>
<p>下面的图是目前几个主流的MMKG：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905185128319.png"   style="zoom:40%;" /></p>
<h2 id="construction">3 Construction</h2>
<p>构造MMKG的关键是能够把原始KG中的symbolic knowledge关联到对应的image。有两种不同方向的方法，一个是从image出发，把image关联到symbols上；一个是从symbols出发，关联到相应的image。</p>
<h3 id="from-images-to-symbols-labeling-images">3.1 From Images to Symbols: Labeling Images</h3>
<p>在CV界已经出现了很多的image labeling方法，正好使用与把images和KG中的symbols关联起来。下面是几个有名的image-based的visual knowledge extraction系统：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905193241031.png"   style="zoom:40%;" /></p>
<p>From Images to Symbols，把图片和符号对应起来，隐含的假设是我已经拥有了一大堆相关图片，并不需要额外去寻找。这个或许适用于某个特定的项目里，我拥有了项目相关的很多图片，这些图片的领域性非常强，在外界很难找得到，也不需要继续寻找了。那么接下来我要做的就是把图片对应到文字上。</p>
<p>根据导出的knowledge的不同，可以分为visual entity/concept extraction、visual relation extraction和visual event extraction。下面先介绍视觉实体导出。</p>
<h4 id="visual-entityconcept-extraction">3.1.1 Visual Entity/Concept Extraction</h4>
<blockquote>
<p>Visual entity (or concept) extraction aims to detect and locate target visual objects in images, and then label these objects with entity (or concept) symbols in KG.</p>
</blockquote>
<p>先识别image上的不同object，然后再关联到KG的实体上。</p>
<p><strong>Challenges.</strong> 这一task面临的最大挑战是有合适的标注数据集。一般的CV数据集对于KG来说粒度太粗，entity表现在image上可能是更小的区域/单元。</p>
<p>这一方向的方法主要可分为两类：object recognition方法和visual grounding方法。前者是通过识别image上的object；后者是通过把caption中的phrase对应到image上最相关的区域。</p>
<p><strong>Object Recognition Methods</strong></p>
<p>基于object recognition的方法首先通过提前训练好多个不同的目标探测器，让这些目标探测器到图像上分别探测不同的objects；之后由于可能对于同一实体，会产生多个不同的探测出来的objects（比如由于位置、姿势等不同很多探测出来的objects实际上指的是同一个entity）。因此通常又会使用聚类的办法找出最具代表性的object作为visual entity。</p>
<p>基于object recognition的方法是有监督的方法，它需要大量具有bounding box的image数据，提前训练好的多个探测器以及提前定义好的可以获取的实体/概念。因此，它实际上很难应付具有大量实体的KG，比如拥有数十亿实体的KG。（试想一下对于每个实体都需要训练一个探测器并且准备好数据集）</p>
<p><strong>Visual Grounding Methods</strong></p>
<p>接下来，更加实际的采取visual grounding的方法，我们需要一种方法能够同时识别出大量的、不同的objects。首先，从Web（比如新闻网站）上可以较为容易的获得大量的image-caption pairs，接下来我们要做的就是把caption中的phrase在image上的对应region找出来。这就是一个弱监督学习问题。</p>
<p>在实现的时候，我们通常会直接找找出在图像中和word对应的pixels：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905195939709.png"   style="zoom:40%;" /></p>
<p>当前有基于注意力的方法（<em>Gaia: A ﬁne-grained multimedia knowledge extraction system. ACL 2020</em>）和基于重要性的方法（<em>Cross-media structured common space for multimedia event extraction. ArXiv 2020</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905200212691.png"   style="zoom:40%;" /></p>
<p>尽管visual grounding方法不再需要人工画bounding boxes，但是由于可能存在错误匹配的情况，所以仍然需要辅助人工验证。比如visual grounding出来的visual entities可能在语义层次上是不一致的，例如troops可能会匹配到一个有几个人穿着军队服装的images上；Ukraine (country)可能会匹配到一个乌克兰国旗的图片上。尽管它们都是有关联的，但是并不等价，我们不能直接进行把图片和实体关联到一起。</p>
<p><strong>Opportunities.</strong> 另外，作者提出基于预训练的language model已经表现出了很强的visual object segmentation能力,利用这样的模型或许可以很大程度地减轻标注visual objects的工作量，从而辅助构造MMKG。下面是ViLT的实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905200911530.png"   style="zoom:40%;" /></p>
<h4 id="visual-relation-extraction">3.1.2 Visual Relation Extraction</h4>
<p>视觉关系抽取的定义：</p>
<blockquote>
<p>Visual relation extraction aims at identifying semantic relations among detected visual entities (or concepts) in images, and then labeling them with the relations in KGs. (<em>Neil: Extracting visual knowledge from web data. ICCV 2016</em>)</p>
</blockquote>
<p><strong>Challenges.</strong> 在CV界对于探测到的objects的关系探测已经有了很多的研究。但是原来CV中对一个图片上的objects关系的推测都是很简单的，语义层级较弱，不能用在KG里。比如CV方法预测的是<em>(person, standing on, beach)</em>，构建MMKG需要更general的semantic relations。</p>
<p>现有的方法主流是两种：rule-based relation extraction和statistic-based relation extraction。除此之外，也有一些研究关注long-tail relation和fine-grained relation。</p>
<p><strong>Rule-based Relation Extraction</strong></p>
<p>基于规则的关系导出方法需要人工定义好标准。比如通过识别出来的objects的label和它们的bounding box之前的相对位置，可以推测它们之间的可能的relation。比如在NEIL方法中探测出来的关系类型（<em>Neil: Extracting visual knowledge from web data. ICCV 2016</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220906103359640.png"   style="zoom:33%;" /></p>
<p>比如一个探测到的wheel对象的bounding box总是包含在car对象的bounding box里，结合wheel属于entity，car属于concept，依据定义好的rules，我们推测wheel和car的relation是<span class="math inline">\(kind\ of\)</span>。</p>
<p>这种做法准确度比较高，但是需要大量人工，不适应大规模MMKG。</p>
<p><strong>Statistic-based General Relation Extraction</strong></p>
<p>基于统计的关系导出方法就是通过编码特征，然后通过分类模型预测relation。比起基于规则的关系导出，这种做法更”自动“，也更”黑“。</p>
<p>一些研究发现，预测关系是非常依赖于头尾实体的类型的；但是实体并不依赖于关系的类型（<em>Neural motifs: Scene graph parsing with global context. CVPR 2018</em>）。那么就有研究尝试把language model的先验知识加到objects的label中，从而提高关系预测性能（<em>Visual relationship detection with language priors. ECCV 2016.</em>, <em>Visual translation embedding network for visual relation detection. CVPR 2017</em>）。</p>
<p>另外，也有研究工作尝试建模探测到的objects之间的graph structure信息（<em>Scene graph generation by iterative message passing. CVPR 2017</em>，<em>Graph r-cnn for scene graph generation. ECCV 2018</em>）。</p>
<p><strong>Long-tail and Fine-grained Relation Extraction</strong></p>
<p><strong>Long-tail relations</strong>：关系导出中，由于不同relation对应的sample数量是非常悬殊的，因此可能导致模型倾向于预测有更多sample数量的relation。为了解决这一问题，[Learning to compose dynamic tree structures for visual contexts. CVPR 2019]提出了一个新的评估指标，先计算出每个relation的指标，然后再平均，这样long-tail relation能预测效果就能够在指标上得到体现。还有基于对比学习（<em>Large-scale visual relationship understanding. AAAI 2019</em>）、少次学习（<em>One-shot learning for long-tail visual relation detection。 AAAI 2020</em>）和迁移学习的方法（<em>Memory-based network for scene graph with unbalanced relations. ACM-MM 2020</em>）。</p>
<p><strong>Fine-grained Relation</strong>：fine-grained relation是long-tail relations的一种。研究者认为很多的预测long-tail relation的方法实际上不能更进一步分辨fine-grained relation。比如关系<span class="math inline">\(on\)</span>可以被长尾分布方法预测出来，但是关系<span class="math inline">\(on/sit,\ on/walk,\ on/lay\)</span>就没法区分出来了（<em>Unbiased scene graph generation from biased training. CVPR 2020</em>）。</p>
<p><strong>Opportunities.</strong> 作者提出了这一方向存在的两个挑战。（1）Visual Knowledge Relation Judgement. 第一个问题是识别出来的visual triples不能够直接作为visual knowledge使用，特别是很多的visual triples仅仅是对于images场景的描述。（2）Relation Detection based on Reasoning. 第二个问题是对于关系的预测缺乏推理过程，我们需要能够自动总结这样的推理链。</p>
<h4 id="visual-event-extraction">3.1.3 Visual Event Extraction</h4>
<p>在一般的，基于文本的事件图谱构建过程中，对于事件（event）的探测，核心有两步，一是通过发现关键的触发词（trigger）判断事件的类型；二是判断在这个时间中的关键元素（argument）并判断它们的角色（argument role），比如时间/地点/任务。</p>
<div class="note info"><p>事件图谱和事理图谱有所区别，经过调研，事理图谱是哈工大社会计算与信息检索研究中心提出的，可参考<a href="https://www.jiqizhixin.com/articles/2018-12-29-23">[事理图谱，下一代知识图谱]</a>进一步进行了解。事件图谱更多是事理图谱的一个初级阶段，不包含本体。</p>
</div>
<p><strong>Challenges.</strong> 作者认为这一领域的挑战包括：（1）通常事件的抽取需要提前定义好不同事件类型的schema，不适用大规模事件抽取，如何能够从visual patterns中自动挖掘出事件schema？（2）如何从image/videos中抽取出visual事件元素？</p>
<p>当前visual event extraction工作集中在两方面：visual event schema mining和visual event arguments extraction。</p>
<p><strong>Visual Event Schema Mining</strong></p>
<p>在CV领域有个很相似的任务叫做场景识别（situation recognition task），这个任务会识别一个图片表示的主要事件以及相应的元素，存在几个标注好的数据集，如SituNet（<em>Situation recognition: Visual semantic role labeling for image understanding. CVPR 2016</em>）和SWiG（<em>Grounded situation recognition. ECCV 2020</em>）。</p>
<p>同样的，如果要导出大量的事件，不能够期望人工标注。借助于大量的image-caption pairs，可以辅助进行事件抽取（<em>Improving event extraction via multimodal integration. ACM-MM 2017</em>）。</p>
<p><strong>Visual Event Arguments Extraction</strong></p>
<p>事件元素的抽取就是对相关事件的images，识别不同argument role对应的visual objects。这里需要注意的是，我们需要确保visual arguments之间的关系和text arguments之间的关系是一致的。因此还需要对齐。（<em>Cross-media structured common space for multimedia event extraction. arXiv 2020</em>）</p>
<p>作者提到，实际上对于visual事件的抽取，更加合理且前景广阔的场景是从video中抽取。一个video可能包含了多个不同的事件，单一帧上的事件元素会关联到不同时间帧上的事件元素，因此是一个更加复杂的task。</p>
<p>visual event extraction还是一个在初期阶段的领域。</p>
<h3 id="from-symbols-to-images-symbol-grounding">3.2 From Symbols to Images: Symbol Grounding</h3>
<p>Symbol grounding符号定位指的是把传统KG中的元素定位到multimodal data。</p>
<blockquote>
<p>Symbol grounding refers to the process of finding proper multi-modal data items such as images to denote a symbol knowledge exists in a traditional KG.</p>
</blockquote>
<p>和image到symbol不同，这里我需要自己找对应的图片，因此是symbol到image。</p>
<p>symbol grounding方法是目前主流的MMKG构造方法，大多数见到的MMKG都是使用这种方式构建的。</p>
<h4 id="entity-grounding">3.2.1 Entity Grounding</h4>
<blockquote>
<p>Entity grounding aims to ground entities in KGs to their corresponding multi-modal data such as images, videos and audios. (<em>The symbol grounding problem. 1990</em>)</p>
</blockquote>
<p><strong>Challenges.</strong> 两个关键问题：（1）如何找到足够数量且高质量的图片？（2）如何选择最符合实体的图片？</p>
<p>两种主要的方法：（1） from online encyclopedia (such as Wikipedia)；（2）from the Internet through Web search engines.</p>
<p><strong>From Online Encyclopedia</strong></p>
<p>网上的百科，通常是一篇article描述一个entity。把article里的图片都拿过来，就变成了entity的对应图片了。并且这样的图片通常和实体相关性很高，难度也比较低。下面以维基百科为例说明这种方法可能存在的问题。</p>
<p>但是基于维基百科搭建MMKG存在3个问题：1. 每个实体对应的图像太少，比如在维基百科中，一个实体的平均图片仅有1.16；2. 维基百科中出现的图片和期望的实体仅仅是相关（relevant），而不是确切的指向该实体（exactly refered to），比如北京动物园文章里的图片包括了动物、建筑等，但都不是直接指向北京动物园；3. 使用维基百科搭建的MMKG的覆盖率有限，比如80%的维基百科文章没有图片，只有超过8.6%的文章有超过2张图片，并且维基百科涉及的实体数量也不一定覆盖所有的实体。</p>
<p><strong>From Search Engines</strong></p>
<p>为了提高MMKG的覆盖率，另一种简单有效的方法是直接用搜索引擎寻找相应的图片，然后以排在前面的照片作为候选。这种做法无疑很大程度提高了覆盖率，但是它的图片相关性不一定足够高，图片的噪音可能也比较大，还可能出现很多个非常相似的图片。</p>
<p>比如我们希望寻找实体Bank相关的图片，如果直接用Bank去搜，可能会找到River Bank相关的照片，但是我们实际是希望找到Commercial Bank。很多的方法研究如何清洗候选的图片，比如通过拓展查询语句（<em>Imagenet: A large-scale hierarchical image database. CVPR 2009</em>）。另一方面，我们期望search到的图片，除了能够符合目标实体外，还能够能够充分反应实体不同方面的（diversity），具有较好的多样性（<em>Richpedia: a large-scale, comprehensive multi-modal knowledge graph. Big Data Research 2020</em>）。</p>
<p>事实上，上面的两种方法通常会一起使用之后作为搭建MMKG的主要手段（<em>Richpedia: a large-scale, comprehensive multi-modal knowledge graph. Big Data Research 2020</em>）。</p>
<p><strong>Opportunities.</strong> 作者提出两个在entity grounding方向的挑战：（1）实体会对应到不同的图片，哪些图片是最具有代表性的？（2）作者提出一个很有趣也很难的新task，叫做<strong>multiple grounding</strong>。作者认为事实上每个实体在实际中有不同的方面，不同的图片应该对应到这些不同的方面中去。这个想法实际上是把hasImage这个关系，进一步细分到不同的fine-grained relations上。比如下面的例子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220906165126632.png"  style="zoom:33%;" /></p>
<p>想法很好，但是从哪里找这么多质量高的图片呢？</p>
<h4 id="concept-grounding">3.2.2 Concept Grounding</h4>
<blockquote>
<p>Concept grounding aims to find representative, discriminative and diverse images for visual concepts.</p>
</blockquote>
<p><strong>Challenges.</strong> 虽然concept grounding和entity grounding有很多的相似之处，但是面临新的挑战。我们可以把概念分为可以可视化的concept和不可可视化concept两种。对于visualizable concepts存在的问题是，它可能对应了很多不同的图片，怎么样选择期望的图片，比如Princess这个概念，它可以联系到迪士尼公主、古代公主等等，怎么样选择合理的图片？对于non-visualizable concepts来说，我们较难直接定位到符合的图片，比如irreligionist无宗教信仰者就很难直接可视化。</p>
<p>这一方向的主要工作包括：</p>
<p><strong>Visualization Concept Judgment</strong></p>
<blockquote>
<p>The task aims to automatically judge visualizable concepts and is a new task to be solved.</p>
</blockquote>
<p>判断概念是否能够被可视化的新task。[Towards fairer datasets: Filtering and balancing the distribution of the people subtree in the imagenet hierarchy.] 研究发现只有12.8%的Person相关概念可以被较好的可视化。比如Rock star容易可视化，Job candidate就不太容易可视化。</p>
<p>为了自动判断一个概念是否能够被可视化，[80 million tiny images: A large data set for nonparametric object and scene of singapore. ] 就移除了所有的抽象概念，仅仅保留非抽象概念。但也不是所有的抽象词都无法可视化，比如Anger这个概念是可以定位到人发火的图片的。另外的方法是使用谷歌搜索引擎，如果搜索出来的图片结果比web结果多，那这个概念就可能是可以可视化的（<em>Graph-based clustering and ranking for diversified image search.</em>）。</p>
<p><strong>Representative Image Selection</strong></p>
<p>这个任务主要是选择合适的图片。</p>
<blockquote>
<p>The task essentially aims to re-rank the images according to their representativeness.</p>
</blockquote>
<p>首先我们希望选择的图片足够有代表性，主流方法采用聚类算法，然后认为一个image在它所位于的cluster中越靠近中心，这个image在这个cluster中就越具有代表性（<em>Representative image selection from image dataset.</em>）。</p>
<p>还有的方法把image的caption和tag也加入到判断过程中来（<em>A joint optimization model for image summarization based on image content and tags. AAAI 2014</em>）。</p>
<p><strong>Image Diversiﬁcation</strong></p>
<p>我们还希望选择的图片有足够的多样性，</p>
<blockquote>
<p>The task requires the images which concepts are grounded to should balance diverse and relevant.</p>
</blockquote>
<p>尽可能从不同类的image clusters中选择，而不是反复从一个cluster中选择图片（<em>Towards a relevant and diverse search of social images. IEEE Trans. MM 2010</em>）。</p>
<p>这一方向的方法大多只是关注text-image检索，但是搜集到的图片中可能同样蕴含着偏见bias，比如对gender、age、race的偏见。</p>
<p><strong>Opportunities.</strong> concept grounding还是属于新生的领域，还有很多问题需要解决。</p>
<ul>
<li><p>Abstract Concept Grounding：抽象概念很难可视化，但是很多概念还是可以关联/定位到某些场景的。比如提到<span class="math inline">\(Love\)</span>这个概念，事实上它可能关联到baby/cute/newborn, dog/pet, heart/red/valentine, beach/sea/couple, sky/cloud/sunset, flower/rose等单词（<em>Computing iconic summaries of general visual concepts. 2008</em>）。</p></li>
<li><p>Gerunds Concept Grounding：动名词的可视化很大程度依赖于对人的姿态的判断（<em>Zero-shot learning via visual abstraction. ECCV 2014</em>）。</p></li>
<li><p>Non-visualizable Concept Grounding via Entity Grounding：一个概念可能很难可视化，但是可以通过它的对应实体，来寻找符合的图片。比如拿爱因斯坦实体的照片作为物理学家概念的图片：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220906183203563.png"   style="zoom:40%;" /></p>
<p>但是这种方法很难决定什么是typical的图片，比如为什么我们会使用爱因斯坦而不是其他物理学家的图片。</p></li>
</ul>
<h4 id="relation-grounding">3.2.3 Relation Grounding</h4>
<p>关系定位主要指寻找能够表达特定relation的image。</p>
<blockquote>
<p>Relation grounding is to find images from an image data corpus or the Internet that could represent a particular relation.</p>
</blockquote>
<p>输入可以是具有这个relation的多个triples，输出就是预期的图片。</p>
<p><strong>Challenges.</strong> 当使用三元组进行查询的时候，找到的图片常常会过于和头尾实体相关，而不是和关系本身相关。</p>
<p>目前主要的研究都是针对spatial relation或者action relation。那这样看来，在KG更常见的更多的语义relation很难找到符合的图片。</p>
<p><strong>Text-Image Matching</strong></p>
<p>把text和image都表示为同一表达空间下的向量，然后计算相似性。[Visual relations augmented cross-modal retrieval. 2020]方法使用GNN来学习visual relation。也有方法使用预训练方法[<em>Unimo: Towards uniﬁed-modal understanding and generation via cross-modal contrastive learning. arXiv 2020</em>]。</p>
<p><strong>Graph Matching</strong></p>
<p>接下来有的研究方法尝试能够更加显式地进行relation和objects的匹配。比如[<em>Cross-modal scene graph matching for relationship-aware image-text retrieval. 2020</em>]方法就是通过描述的语法结构和图片上对象的依赖关系结构进行graph match（<em>Crossmodal scene graph matching for relationship-aware image-text retrieval. IEEE/CVF 2020</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220906193254305.png"   style="zoom:40%;" /></p>
<p><strong>Opportunities.</strong> 作者提出能否把除了空间关系和行为关系以外的关系也进行可视化？个人认为很难，因为首先人工都很难标注。</p>
<h2 id="application">4 Application</h2>
<h3 id="in-mmkg-applications">4.1 In-MMKG Applications</h3>
<p>知识图谱本身就有knowledge，我们当然可以直接基于符号进行推理。但是难用，也不好与主流的DL方法结合。</p>
<p>在编码MMKG的图像信息时，通常还是直接使用visual encoder的编码器的hidden state，很少利用其它visual features比如Gray Histogram Descriptor (GHD)，Histogram of Oriented Gradients Descriptor (HOG)，Color Layout Descriptor (CLD)等。</p>
<p>下面是MMKG的一些主要应用和benchmark datasets：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220906211153963.png"   style="zoom:40%;" /></p>
<h4 id="link-prediction">4.1.1 Link Prediction</h4>
<p>预测头尾实体或者预测关系。</p>
<p>来想一个关键问题，Visual信息对预测实体有帮助吗？ 比如设想某个relation对应的尾实体通常具备某种共通的视觉特征，头实体也具备某种共通的视觉特征，这种视觉特征可以辅助预测，并且无法被单纯的文本描述。比如spouse两边表现出来的应该都是人形，而不是动物。</p>
<p>再比如，Person的图像可以提供信息，用来判断age等profession（<em>Embedding multimodal relational data for knowledge base completion</em>）。</p>
<h4 id="triple-classiﬁcation">4.1.2 Triple Classiﬁcation</h4>
<p>直接判断一个给定的三元组是不是成立的，可以看做是KG补全的一种形式。具体的工作参见论文。</p>
<h4 id="entity-classiﬁcation">4.1.3 Entity Classiﬁcation</h4>
<p>判断实体属于哪一类？同样可以看做是一种特殊的链路预测，预测关系<span class="math inline">\(IsA\)</span>，候选项是MMKG中的concepts。</p>
<h4 id="entity-alignment">4.1.4 Entity Alignment</h4>
<p>MMKG实体对齐。具体相关工作看论文。这里提一个有意思的想法，[<em>Mmkg: Multi-modal knowledge graphs. ESWC 2019</em>]把MMKG对齐也看做了是一个链路预测任务<span class="math inline">\(&lt;h?,sameAs,t&gt;\)</span>或者<span class="math inline">\(&lt;h,sameAs,t?&gt;\)</span>只不过是这里的头尾实体不在同一个MMKG中。</p>
<h3 id="out-of-mmkg-applications">4.2 Out-of-MMKG Applications</h3>
<p>在MMKG以外的应用当然有很多，包括：</p>
<ul>
<li>Multi-modal Entity Recognition and Linking：给定一段文本和相应的图片，识别出描绘的实体（<em>Adaptive co-attention network for named entity recognition in tweets. AAAI 2018</em>）</li>
<li>Visual Question Answering：针对图片提问。由于需要对于detected objects实现复杂的推理过程，因此引入MMKG进行辅助推理（<em>Okvqa: A visual question answering benchmark requiring external knowledge. CVPR 2019</em>）。</li>
<li>Image-Text Matching：是一个非常关键的基础的task，判断image-text pair的相似程度。引入MMKG来获得更多的信息，对image和text有更多的理解，从而提升预测效果（<em>Knowledge aware semantic concept expansion for image-text matching. IJCAI 2019</em>）。</li>
<li>Multi-modal Generation Tasks
<ul>
<li>Image Tagging：引入增强对图像的理解（<em>Enhancing the quality of image tagging using a visio-textual knowledge base. IEEE Trans. MM 2019</em>）</li>
<li>Image Captioning：引入MMKG生成更加准确和合理的caption（<em>Relational reasoning using prior knowledge for visual captioning. arXiv 2019</em>）</li>
<li>Visual Storytelling：给定连续的图片序列，然后讲故事。引入MMKG来更好的寻找不同图片中的对象的关系，并且能够获得额外的训练集意外的知识（<em>“Knowledge-enriched visual storytelling. AAAI 2020</em>）</li>
</ul></li>
<li>Multi-modal Recommender System：买东西的时候我们当然会很关注视觉信息，并且视觉信息很难用文本充分描述出来，引入MMKG提升推荐性能（<em>Multi-modal knowledgeaware reinforcement learning network for explainable recommendation. Knowledge-Based Systems 2021</em>）</li>
</ul>
<h2 id="open-problems">5 Open Problems</h2>
<h3 id="complex-symbolic-knowledge-grounding">5.1 Complex Symbolic Knowledge Grounding</h3>
<p>在前面介绍了entity、concept和relation的grounding方法。一方面这些方向都有自身的挑战，比如abstract concept找不到；relation也不好找。</p>
<p>另一方面，如果我们拓展下思维，大多数的MMKG仅仅是实体找到了对应图片，但并不是KG中所有的knowledge都找到了图片。比如一个path或者subgraph也找不到符合的图片，而这样的信息往往在某些任务中是可用的。比如对于实体Trump，他的妻子的照片，儿子的照片和女儿的照片都可以结合到一起成为一个subgraph，这样的subgraph可以对应到一个他们全家福的照片上。</p>
<p>作者把这样的task叫做<em>multiple relational grounding</em>，这无疑是一个很难的任务。</p>
<h3 id="quality-control">5.2 Quality Control</h3>
<p>MMKG本身也存在质量问题，比如errors、missing facts和outdated facts。举例，对于long-tail的entity来说，它就可能会对应到不相符的照片上，因为可能在Web上就没有符合的图片。</p>
<p>MMKG除了一般KG可能存在的问题外，还由于引入图像带来了新的问题：</p>
<ol type="1">
<li><p>一个实体的图片可能会和另外的很相关的实体图片混合在一起。比如下图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220907103645534.png"   style="zoom:50%;" /></p>
<p>鳄鱼鸟的照片就经常出现鳄鱼，如果鳄鱼本身也是一个实体的话，这样就可能出现了信息的混合。</p></li>
<li><p>越是出名的照片越有可能出现。比如上图中刘慈欣的《漫步地球》在搜索引擎上找到的照片总是另一本书《黑暗森林》的照片。</p></li>
<li><p>一些抽闲的概念很可能对应到错误的照片上。比如上图中的发怒arrogance实体对应到了错误的图片。</p></li>
</ol>
<p>为了解决上述问题，可能需要对视觉信息进行更多分析，结合背景信息综合判断。</p>
<h3 id="efficiency">5.3 Efficiency</h3>
<p>在构建MMKG时，因为要处理多模态的数据，往往需要大量的时间。比如NEIL（<em>Neil: Extracting visual knowledge from web data. ICCV 2013</em>）就花了350K的CPU hours处理了2273个objects的400K图像实例，这当然没法处理可能拥有上亿乃至数十亿实体的大规模KG。</p>
<p>另一个是对于在线实时的MMKG应用算法，大多数的算法无法适应实时场景。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
        <tag>survey</tag>
      </tags>
  </entry>
  <entry>
    <title>MNRE-dataset</title>
    <url>/mmml/MNRE-dataset/</url>
    <content><![CDATA[<h2 id="mnre-a-challenge-multimodal-dataset-for-neural-relation-extraction-with-visual-evidence-in-social-media-posts">MNRE: A Challenge Multimodal Dataset for Neural Relation Extraction with Visual Evidence in Social Media Posts</h2>
<p>MNRE，ICME 2021。作者创建了首个用于multimodal relation extraction的数据集MNRE，<a href="https://github.com/thecharm/MNRE">地址</a>。</p>
<p>数据来源于Twitter posts，关注点是文本中的上下文信息不够充分时，通过post中的image，来补充上下文信息。</p>
<blockquote>
<p>Extracting relations in social media posts is challenging when sentences lack of contexts. However, images related to these sentences can supplement such missing contexts and help to identify relations precisely. To this end, we present a multimodal neural relation extraction dataset (MNRE), consisting of 10000+ sentences on 31 relations derived from Twitter and annotated by crowdworkers. The subject and object entities are recognized by a pretrained NER tool and then ﬁltered by crowdworkers. All the relations are identiﬁed manually. One sentence is tagged with one related image. We develop a multimodal relation extraction baseline model and the experimental results show that introducing multimodal information improves relation extraction performance in social media texts. Still, our detailed analysis points out the difﬁculties of aligning relations in texts and images, which can be addressed for future research. All details and resources about the dataset and baselines are released on https://github.com/thecharm/MNRE.</p>
</blockquote>
<span id="more"></span>
<h3 id="introduction">1. Introduction</h3>
<p>relation extraction（RE）是预测一个句子中两个命名实体之间的关系relation。</p>
<p><strong>challenges</strong>:之前大多数的RE模型关注的是文本信息很充分的场景下的关系抽取，比如newswire domain。但是，一旦文本很短，并且缺少必要的上下文信息的时候，RE模型效果会出现严重的下降。即便是使用了pretrained modal来进行关系抽取，效果也很糟糕。</p>
<p><strong>solution</strong>: 作者认为，对于在推特post这样很可能文本中缺乏足够充分的上下文信息的场景，可以使用image的visual information来补充上下文信息。</p>
<p>比如在下面的图中，如果只有文本，那么可能会判断出来JFK和Obama和Harvard的关系是residence；但是如果能够识别图像中的信息，比如校园、学位帽等，可以判断出来JFK和Obama和Harvard的关系应该是graduated_at。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221012204338075.png"   style="zoom:40%;" /></p>
<p>但是目前并没有这样满足文本+图像的数据集存在，因此作者就希望能够解决这一点，主要贡献如下：</p>
<ul>
<li>创建了在社交媒体posts上的数据集Multimodal dataset for Neural Relation Extraction（MNRE）</li>
<li>在MNRE数据集基础上，构建了几个不同的baseline方法</li>
</ul>
<h3 id="mnre-dataset">2. MNRE Dataset</h3>
<h4 id="dataset-collection">2.1 Dataset Collection</h4>
<p>数据来源有三个：</p>
<ul>
<li>Twitter 2015：有8357个候选实例（指一个完整的post和对应image、named entities和relations）</li>
<li>Twitter 2017：有4819个候选实例</li>
<li>Crawled Twitter data：爬取了Twitter 2019年1月到2月的post和对应图片，不限制具体的领域；如果一个post有多张图片，就随机选择一张。最终获取了20000候选实例</li>
</ul>
<h4 id="twitter-name-tagging">2.2 Twitter Name Tagging</h4>
<p>使用预训练的<a href="https://allennlp.org/elmo">NER tagging tool</a>在爬取的Twitter data上标注实体和对应的实体类型entity type。</p>
<p>大多数的RE数据集没有对应的实体类型标注；但是作者认为实体类型是很重要的。</p>
<h4 id="human-annotation">2.3 Human Annotation</h4>
<p>众包。让4个受到过良好教育的标注者过滤掉错误标注的句子，并且标注实体之间的关系；</p>
<p>每个标注者需要判断是否能够从text和image中判断出对应的relation；同时，需要给选择的relation打confidence score；</p>
<p>最后，汇总4个标注者的标注结果，根据候选relation的总的confidence score来作为标注的relation。</p>
<h4 id="dataset-statistics">2.4 Dataset Statistics</h4>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221012210628691.png"   style="zoom:50%;" /></p>
<p>最终包含了10k的实例，31种关系；平均句子的长度是11.62，远远小于之前文本上下文信息丰富的RE数据集中的句子平均长度。 作者在后续更新了数据集，得到了MNRE-2：</p>
<blockquote>
<p>2021.6.22 We provide MNRE-2, a refined version which merges several ambigious categories with much more support samples. The original version has been moved to <a href="https://github.com/thecharm/MNRE/blob/main/Version-1">Version-1</a></p>
</blockquote>
<p>MNRE-2的统计： <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/20221017115553.png" /></p>
<p>下图是不同关系类型的统计：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221017145814092.png"   style="zoom:50%;" /></p>
<p>经过检查发现，实际的训练集还包括了关系<code>None</code>。上面的统计图没有展现出None关系的分布。</p>
<p>作者的MNRE-2数据集从32变为了23种关系，发现大部分的关系还是和人相关的。MNRE-2训练集有12247、验证集1624和测试集1614实例。</p>
<p>查看下具体的数据集内容，在一个训练实例中，包括</p>
<ul>
<li><p><code>token</code>: <code>['The', 'latest', 'Arkham', 'Horror', 'LCG', 'deluxe', 'expansion', 'the', 'Circle', 'Undone', 'has', 'been', 'released', ':']</code></p></li>
<li><p><code>h</code>: <code>&#123;'name': 'Circle Undone', 'pos': [8, 10]&#125;</code></p></li>
<li><p><code>t</code>: <code>&#123;'name': 'Arkham Horror LCG', 'pos': [2, 5]&#125;</code>，这个<code>Arkham Horror LCG</code>应该是一种卡牌游戏</p></li>
<li><p><code>img_id</code>: <code>'twitter_19_31_16_6.jpg'</code>，所有的图片下载完后是1.2GB，下图是对应的图片</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/twitter_19_31_16_6.jpg"   style="zoom:40%;" /></p></li>
<li><p><code>relation</code>: <code>/misc/misc/part_of</code></p></li>
</ul>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221012210820441.png" alt="image-20221012210820441" /><figcaption>image-20221012210820441</figcaption>
</figure>
<p>上图是数据集中的实例。可以看到，需要同时结合视觉和文本信息，才能够做出准确的关系预测。</p>
<h3 id="experimental-results">3. Experimental Results</h3>
<p>作者试验了几个已有的方法，Glove+CNN、BertNRE、Bert+CNN、PCNN。并且尝试了几种加入视觉信息的方法，包括拼接image label的embedding、拼接通过一个pretrained object detector导出的视觉特征embedding和利用visual-text的bi-linear注意力层。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221012211312936.png"   style="zoom:50%;" /></p>
<p>几个需要引入视觉信息，才能实现正确预测relation的实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221012211533605.png"  style="zoom:50%;" /></p>
<h3 id="thoughts">Thoughts</h3>
<ol type="1">
<li><p>感觉每个post对应一个image，然后单纯的从图像中抽取视觉信息来辅助关系抽取，所能够获得信息和覆盖范围还是比较受限。可能更理想的还是要有多张图片，从多张关联图片中进行信息抽取；或者说要从单个图片出发，进行信息拓展（图片搜索，寻找更多的相似/关联图片？图片进行场景识别后，转化为text，然后再从文本信息出发进行搜索？）</p></li>
<li><p>另外的一个问题是，如果随机检查图像信息和对应的文本，发现有不少的实例还是可能不需要图像信息就能够预测关系的，比如：</p>
<ul>
<li><p><code>token</code>: <code>['(', 'UPDATE', 'CHARA', ')', 'Baejoohyunews', ':', '[', 'PHOTO', ']', '190130', '#', &quot;REDVELVET'REDMARE&quot;, ':', 'Japan', 'Arena', 'Tour', 'in', 'Yokohama', &quot;'&quot;, 'Day2', 'RVsmtown']</code></p></li>
<li><code>h</code>: <code>&#123;'name': 'Japan Arena Tour', 'pos': [13, 16]&#125;</code></li>
<li><code>t</code>: <code>&#123;'name': 'Yokohama', 'pos': [17, 18]&#125;</code></li>
<li><code>img_id</code>: <code>twitter_19_31_9_14.jpg</code></li>
<li><p><code>relation</code>: <code>/misc/loc/held_on</code></p></li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/twitter_19_31_9_14.jpg"  style="zoom:50%;" /></p>
<p>实际上通过文本中的单词<code>in</code>就能够判断出来关系可能是<code>held_on</code></p></li>
</ol>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MRE</category>
      </categories>
      <tags>
        <tag>MRE</tag>
        <tag>MMKG</tag>
      </tags>
  </entry>
  <entry>
    <title>MoRe</title>
    <url>/mmml/MoRe/</url>
    <content><![CDATA[<h1 id="named-entity-and-relation-extraction-with-multi-modal-retrieval">Named Entity and Relation Extraction with Multi-Modal Retrieval</h1>
<p>作者通过text和image检索在Wikipedia上相关的text信息来辅助多模态信息抽取。</p>
<p>上海科技与阿里达摩，EMNLP 2022，<a href="http://github.com/modelscope/adaseq/examples/MoRe">代码</a>。</p>
<blockquote>
<p>Multi-modal named entity recognition (NER) and relation extraction (RE) aim to leverage relevant image information to improve the performance of NER and RE. Most existing efforts largely focused on directly extracting potentially useful information from images (such as pixel-level features, identified objects, and associated captions). However, such extraction processes may not be knowledge aware, resulting in information that may not be highly relevant. <strong>In this paper, we propose a novel Multi-modal Retrieval based framework (MoRe). MoRe contains a text retrieval module and an imagebased retrieval module, which retrieve related knowledge of the input text and image in the knowledge corpus respectively. </strong>Next, the retrieval results are sent to the textual and visual models respectively for predictions. Finally, a Mixture of Experts (MoE) module combines the predictions from the two models to make the final decision. Our experiments show that both our textual model and visual model can achieve state-of-the-art performance on four multi-modal NER datasets and one multimodal RE dataset. With MoE, the model performance can be further improved and our analysis demonstrates the benefits of integrating both textual and visual cues for such tasks.</p>
</blockquote>
<span id="more"></span>
<h2 id="method">Method</h2>
<p>作者的方法图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901151432582.png"   style="zoom:50%;" /></p>
<p>作者从English Wikipedia dump中分别以text和image作为关键进行检索：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901151548710.png"   style="zoom:40%;" /></p>
<p>具体来说：</p>
<ul>
<li>Textual Retrieval System：待抽取text作为query，使用ElasticSearch，基于BM25算法检索Wikipedia中语义相似的句子（key），然后把包含句子的paragraph返回（value）作为检索结果。</li>
<li>Image-base Retrieval System：使用ViTB/32 in CLIP将待抽取image和Wikipedia article中的images都编码为vector，然后基于k-NN算法，使用Faiss进行高效搜索。把检索到的article的introduction section返回未做检索结果。</li>
</ul>
<p>分别检索到top-K（实验中<span class="math inline">\(K=10\)</span>）的结果之后，检索到的结果与原有的待抽取text拼接，分别经过独立的task model输出对于实体或者关系的预测结果。NER任务使用CRF decoder，RE任务使用简单的线性softmax。task model在实验中是XLM-RoBERTa large。</p>
<p>对于两个prediction distributions，作者使用MoE进行混合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152335088.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152320697.png"   style="zoom:50%;" /></p>
<p>这里的MoE是计算两个prediction distributions的对应权重，然后进行混合。对于NER任务，由于CRF将NER看做是序列标注预测，对应可能的序列集合范围很大。因此作者使用了自己之前在CLNER工作中的方法，将序列标注预测转变为认为不同位置的NER label是互相独立的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152615131.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152631421.png"   style="zoom:50%;" /></p>
<p>这样最后预测就是让每一个位置上的token的NER label概率最大，而不是让所有token的NER label组合序列的概率最大。</p>
<h2 id="experiment">Experiment</h2>
<p>主要实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230901152831756.png"   style="zoom:40%;" /></p>
<p>可以看到，如果仅仅是只使用text或image检索，大概带来了1%的提升。通过使用MoE将效果提升到了2%。但是总的效果来看还比不上目前直接使用multimodal representation进行prediction的方法，特别是在MNRE数据集上。</p>
<p>作者MNER任务除了使用最常用的Twitter2015和Twitter2017数据集外，还将WikiDiverse这个multimodal entity linking数据集中对于实体的标注导出来进行预测，这样除了可以对social media domain进行评估外，还可以对News domain进行评估。</p>
<blockquote>
<p>The WikiDiverse dataset is a very recent multi-modal entity linking dataset constructed by Wang et al. (2022d) based on Wikinews. The dataset has annotations of entity spans and entity labels. We convert the multi-modal entity linking dataset into a multi-modal NER dataset to further show the effectiveness of MoRe on the news domain.</p>
</blockquote>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MIE</category>
      </categories>
      <tags>
        <tag>MNER</tag>
        <tag>MRE</tag>
        <tag>Multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>PromptMNER</title>
    <url>/mmml/PromptMNER/</url>
    <content><![CDATA[<h1 id="promptmner-prompt-based-entity-related-visual-clue-extraction-and-integration-for-multimodal-named-entity-recognition">PromptMNER: Prompt-Based Entity-Related Visual Clue Extraction and Integration for Multimodal Named Entity Recognition</h1>
<p>复旦大学计算机科学学院，上海数据科学重点实验室，DASFAA 2022</p>
<p>作者提出了一种利用prompt来更好的导出实体相关的视觉特征的方法。</p>
<blockquote>
<p>Multimodal named entity recognition (MNER) is an emerging task that incorporates visual and textual inputs to detect named entities and predicts their corresponding entity types. However, existing MNER methods often fail to capture certain entity-related but textloosely-related visual clues from the image, which may introduce taskirrelevant noises or even errors. To address this problem, we propose to utilize entity-related prompts for extracting proper visual clues with a pre-trained vision-language model. To better integrate diﬀerent modalities and address the popular semantic gap problem, we further propose a modality-aware attention mechanism for better cross-modal fusion. Experimental results on two benchmarks show that our MNER approach outperforms the state-of-the-art MNER approaches with a large margin.</p>
</blockquote>
<span id="more"></span>
<p>作者主要是提出了在图像中，对于MNER任务来说，更加重要的是entity-related的视觉特征，而单纯的text-related的视觉特征是和entity以外的文本关联，可能包括了更多的噪音。</p>
<p>为了解决这一问题，作者设计了entity-related prompts，通过利用pretrained vision-language model来判断不同prompt和图像之间的匹配程度，进而选择合适的prompt来作为entity-related的视觉特征。</p>
<h2 id="method">Method</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512153907747.png" alt="image-20230512153907747" /><figcaption>image-20230512153907747</figcaption>
</figure>
<p>作者定义的prompt形式是<span class="math inline">\(P_i = \mbox{an image of }[w_i]\)</span>，<span class="math inline">\(w_i\)</span>可以是discrete的word/phrase，也可以是continuous的embedding。</p>
<p>discrete的<span class="math inline">\(w_i\)</span>来源如下：</p>
<ul>
<li>NER的所有实体标签，如person, location, organization</li>
<li>从<a href="http://relatedwords.org">Related Words</a>中和实体标签相关的词，如person的关联词有people, someone, individual, worker, child</li>
<li>专家定义的实体标签，如person的人工定义的词有player, pants, hat, suit, group of people, team</li>
</ul>
<p>因为想要找到所有合适的word描述图像内容是不实际的，因此作者也是用了continuous prompts作为补充，也就是定义没有现实意义的embedding直接作为<span class="math inline">\(w_i\)</span>。作者发现定义100个continuous prompt达到了最好的效果。</p>
<p>为了确定哪个prompt是最好的描述了图像信息，作者使用CLIP对图像和prompt分别进行编码，然后计算匹配度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512155631323.png"   style="zoom:50%;" /></p>
<p><span class="math inline">\(&lt;s_i,v&gt;\)</span>是表示余弦相似度。<span class="math inline">\(s_i\)</span>是<span class="math inline">\(i\)</span>-th prompt的embedding，<span class="math inline">\(v\)</span>是图像信息。计算出来的匹配程度与prompt embedding相乘作为找到的视觉特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512155919285.png"   style="zoom:50%;" /></p>
<p>聚合的时候使用了跨模态注意力，这里看图即可，不再赘述。</p>
<p>最后使用基于span的NER分类器：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512160449263.png"   style="zoom:50%;" /></p>
<p><span class="math inline">\(i,j\)</span>表示的token <span class="math inline">\(i\)</span>到token <span class="math inline">\(j\)</span>的序列，把序列的头尾token embedding拿出来进行分类，<span class="math inline">\(\{\mbox{person, location, organization, misc, not entity}\}\)</span>。</p>
<h2 id="experiment">Experiment</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230512160707006.png" alt="image-20230512160707006" /><figcaption>image-20230512160707006</figcaption>
</figure>
<p>效果上来看还是可以的。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MNER</tag>
        <tag>MMKG</tag>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>TRC_Dataset</title>
    <url>/mmml/TRC-Dataset/</url>
    <content><![CDATA[<h1 id="categorizing-and-inferring-the-relationship-between-the-text-and-image-of-twitter-posts">Categorizing and Inferring the Relationship between the Text and Image of Twitter Posts</h1>
<p>ACL 2019，<a href="https://github.com/danielpreotiuc/text-image-relationship">代码</a>，彭博社</p>
<blockquote>
<p>Text in social media posts is frequently accompanied by images in order to provide content, supply context, or to express feelings. This paper studies how the meaning of the entire tweet is composed through the relationship between its textual content and its image. <strong>We build and release a data set of image tweets annotated with four classes which express whether the text or the image provides additional information to the other modality.</strong> We show that by combining the text and image information, we can build a machine learning approach that accurately distinguishes between the relationship types. Further, we derive insights into how these relationships are materialized through text and image content analysis and how they are impacted by user demographic traits. These methods can be used in several downstream applications including pre-training image tagging models, collecting distantly supervised data for image captioning, and can be directly used in end-user applications to optimize screen estate.</p>
</blockquote>
<p>作者对tweet的文本和图像之间的关系进行了定性与定量的分析，提出了文本和图像之间存在两个维度的关系：</p>
<ol type="1">
<li>文本内容是否在图像中表示（Text is represented / Text is not represented），关注文本和图像之间是否存在信息的重叠overlap</li>
<li>图像内容是否增加了tweet的语义（Image adds / Image does not add），关注图像的语义在整个tweet语义的作用，关注图像能否提供文本之外的信息</li>
</ol>
<p>作者创建了基于Twitter数据的文本-图像分类数据集TRC（Text-image relation classiﬁcation）</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221116234200056.png" alt="image-20221116234200056" /><figcaption>image-20221116234200056</figcaption>
</figure>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p><strong>问题</strong>：图像在tweet中是一个很重要的角色，很大一部分的tweet都会带有图像，并且根据2016年的一个调查（What 1 Million Tweets Taught Us About How People Tweet Successfully. 2016）发现拥有图片的tweet的参与度是没有图像的tweet的两倍。但是没有研究讨论post的文本内容是如何和图像信息相关的。</p>
<p><strong>方案</strong>：作者从两个维度描述tweet上文本和图像信息的关系：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221116202933322.png" alt="image-20221116202933322" /><figcaption>image-20221116202933322</figcaption>
</figure>
<ul>
<li>对于a和b，图像增加了文本内容。a的图像通过提供更多的解释信息，b的图像通过提供更加明确的上下文情景理解文本内容</li>
<li>对于c和d，图像没有增加文本内容。c的图像仅仅是文本的重复表示，d的图像是一个网络meme，甚至与文本内容无关。</li>
<li>对于a和c，文本和图像的信息有重叠。</li>
<li>对于b和d，文本和图像的信息没有重叠。</li>
</ul>
<h2 id="categorizing-text-image-relationships">2. Categorizing Text-Image Relationships</h2>
<p>判断文本内容和图像内容是否有重叠的几个依据（Text task）：</p>
<ol type="1">
<li>文本内容在图像中进行了表示，有信息重叠（Text is represented）：部分或者全部的文本在图像中进行了表示</li>
<li>文本内容在图像中没有进行表示（Text is not represented）：
<ul>
<li>没有文本单词在图像中有对应</li>
<li>文本是对于图像内容的评论</li>
<li>文本是对于图像内容的feeling</li>
<li>文本仅仅是指向了图像内容</li>
<li>文本与图像无关</li>
</ul></li>
</ol>
<p>判断图像是否能够拓展文本语义（Image task）：</p>
<ol type="1">
<li>图像能够拓展文本语义
<ul>
<li>图像中包括了其它额外的文本</li>
<li>图像描绘了增加文本内容的其它信息</li>
<li>图像描绘了文本中引用的实体</li>
</ul></li>
<li>图像没有拓展文本语义：图像没有描绘任何文本内容之外的信息</li>
</ol>
<h2 id="data-set">3. Data Set</h2>
<p>数据采样来源是从一个已知用户个人信息的列表中（Beyond Binary Labels: Political Ideology Prediction of Twitter Users. ACL 2017），随机选择他们发布的tweet：</p>
<ul>
<li>只采样2016年的tweet，避免随着时间用户发布tweet可能的改变</li>
<li>过滤掉所有的非英语tweet</li>
<li>只选择美国的用户，避免文化差异</li>
</ul>
<p>最终获得了2263个用户发布的4471个tweet。</p>
<p>在CrowdFlower上通过众包进行标注，最终的统计结果如下，来自RpBERT论文：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221116213926778.png" alt="image-20221116213926778" /><figcaption>image-20221116213926778</figcaption>
</figure>
<h2 id="predicting-text-image-relationship">5. Predicting Text-Image Relationship</h2>
<p>使用80%训练，20%测试，作者使用了一系列的方法进行判断：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221116214107361.png" alt="image-20221116214107361" /><figcaption>image-20221116214107361</figcaption>
</figure>
<p>结果发现同时使用文本和图像的方法，更能够准确的判断出来text-image的关系。</p>
<h2 id="analysis">6. Analysis</h2>
<p>作者使用用户的人口特征、tweet metadata（如账号的follow人数、tweet是否是reply等）以及文本，进行了综合的分析（使用Pearson correlation）。</p>
<p>结果发现用户的特征中，年龄和text-image的关系比较大，而其他的特征关系较弱。年龄大的喜欢发送和文本内容有重叠的tweet，年龄较小的用户喜欢发送和文本内容无关的tweet（比如一个表情包meme）。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221116214514737.png" alt="image-20221116214514737" /><figcaption>image-20221116214514737</figcaption>
</figure>
<p>作者发现tweet metadata和text-image关系没有显著关联。</p>
<p>对文本进行分析，发现某些特定文本词和text-image关系有关联：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221116214915524.png" alt="image-20221116214915524" /><figcaption>image-20221116214915524</figcaption>
</figure>
]]></content>
      <categories>
        <category>Paper</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>modality-discriminator</title>
    <url>/mmml/modality-discriminator/</url>
    <content><![CDATA[<h1 id="different-data-different-modalities-reinforced-data-splitting-for-effective-multimodal-information-extraction-from-social-media-posts">Different Data, Different Modalities! Reinforced Data Splitting for Effective Multimodal Information Extraction from Social Media Posts</h1>
<p>COLING 2022，<a href="https://github.com/xubodhu/RDS">代码</a>。</p>
<p>作者认为，不是所有的social media post都需要多模态信息，可能有的post更适合单模态模型，如果加入多模态信息反而可能造成错误的后果。因此，作者基于强化学习，提出了一种可以把social post分为单模态集合和多模态集合的方法。</p>
<blockquote>
<p>Recently, multimodal information extraction from social media posts has gained increasing attention in the natural language processing community. <strong>Despite their success, current approaches overestimate the significance of images. In this paper, we argue that different social media posts should consider different modalities for multimodal information extraction. </strong>Multimodal models cannot always outperform unimodal models. Some posts are more suitable for the multimodal model, while others are more suitable for the unimodal model. Therefore, we propose a general data splitting strategy to divide the social media posts into two sets so that these two sets can achieve better performance under the information extraction models of the corresponding modalities. Specifically, for an information extraction task, we first propose a data discriminator that divides social media posts into a multimodal and a unimodal set. Then we feed these sets into the corresponding models. Finally, we combine the results of these two models to obtain the final extraction results. Due to the lack of explicit knowledge, we use reinforcement learning to train the data discriminator. Experiments on two different multimodal information extraction tasks demonstrate the effectiveness of our method. The source code of this paper can be found in https://github.com/xubodhu/RDS.</p>
</blockquote>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p><strong>问题</strong> ：不是所有的social post都适合于多模态信息抽取方法。比如下图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020164307709.png" alt="image-20221020164307709" /><figcaption>image-20221020164307709</figcaption>
</figure>
<p>对于(a)和(c)来说，加入图像信息能够辅助信息抽取，比如我们可以知道[Kolo MISC]是一条狗，而不是一个人；从图像中两个人拉着手，可以判断出Meghan Markle和Prince Harry是夫妻而不是同事。</p>
<p>但是对于(b)和(d)来说，加入图像信息反而可能导致错误判断。在(b)里可能因为看到图像中有个人像，然后判断[Nasa ORG]是个人；在(d)里因为看到很多人类似的服装，错误判断出Angel和Jesennia Rodriguez是同事而不是夫妻。</p>
<p><strong>方法</strong>：作者期望能够设计一种把不同social post分类为适用于单模态和适用于多模态的方法。由于不存在这样的数据集，因此作者提出了一种基于强化学习的data discriminator。</p>
<h2 id="method">2 Method</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020165100186.png" alt="image-20221020165100186" /><figcaption>image-20221020165100186</figcaption>
</figure>
<p>首先，作者会把训练集随机分为<span class="math inline">\(D_{model}\)</span> (80%)和<span class="math inline">\(D_{split}\)</span> (20%)。</p>
<p><span class="math inline">\(D_{model}\)</span>用来训练单模态和多模态模型，这两种模型可以是任意的方法，训练完毕之后，就freeze所有参数。</p>
<p><span class="math inline">\(D_{split}\)</span>是用来训练Data discriminator，Data discriminator会判断某个输入样本是否适用于多模态方法，根据Data discriminator的判断结果，检测单模态和多模态模型在判断的单模态集合和多模态集合上的表现效果。如果在划分的多模态集合中，多模态模型效果比单模态模型效果越好；在划分的单模态集合中，单模态模型效果比多模态模型效果越好，就证明这个Data discriminator的判断效果越准确。</p>
<h3 id="data-discriminator">2.1 Data Discriminator</h3>
<p>作者基于<a href="https://huggingface.co/openai/clip-vit-base-patch32"><span class="math inline">\(CLIP_{32}\)</span></a>进行实现，对CLIPTextModel和CLIPVisionModel的输出进行投影、element-wise相乘，最后经过MLP得到预测结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170009371.png"   style="zoom:50%;" /></p>
<p><span class="math inline">\(p\)</span>越大，表示越适合于使用多模态方法进行信息抽取</p>
<p>在划分单模态集合和多模态集合的时候，在训练阶段，依据伯努利采样；在测试阶段，<span class="math inline">\(p\)</span>大于<span class="math inline">\(0.5\)</span>的被放入多模态集合，<span class="math inline">\(p\)</span>小于<span class="math inline">\(0.5\)</span>的被放入单模态集合。</p>
<h3 id="reward-function">2.2 Reward Function</h3>
<p>如何判断划分结果的好坏？核心思想是让单模态模型在单模态集合上表现效果更好；让多模态模型在多模态集合上表现效果更好。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170334868.png"   style="zoom:50%;" /></p>
<p><span class="math inline">\(k\)</span>代表适合于使用多模态数据的数据； <span class="math inline">\(l\)</span>代表适合用于单模态数据的数据</p>
<p>计算reward：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170433346.png"   style="zoom:50%;" /></p>
<p>在得到了reward之后，data discriminator如何更新参数？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170523043.png"   style="zoom:50%;" /></p>
<h3 id="training-algorithm">2.3 Training Algorithm</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170546235.png"   style="zoom:40%;" /></p>
<h2 id="experiment">3 Experiment</h2>
<p>对于MRE，作者使用MTB作为单模态模型，MEGA作为多模态模型，最终MRE结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170616500.png"   style="zoom:50%;" /></p>
<p>对于MNER，作者使用BERT-CRF作为单模态模型，UMT-BERT-CRF和MAF作为多模态模型，最终MNER结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170659801.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020170718093.png"   style="zoom:50%;" /></p>
<p>案例研究，作者挑选了两个在Twitter-2017中，两个拥有最低分类得分的post：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020172105930.png"   style="zoom:50%;" /></p>
<p>可以看到，在这两个实例中，text本身就有足够的信息，不需要引入图像的信息。</p>
<p>两个拥有最高分类得分的post：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020172202700.png"   style="zoom:50%;" /></p>
<p>对于(c)如果没有图像，很容易把Harry Potter和the Philosopher’s Stone分开，然后把Harry Potter判断为是一个人名；对于(d)如果没有图像，很容易把R.Shemiste认为是人名，但实际上它是品牌名。</p>
<p>两个得分在中间的post：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221020172402192.png"   style="zoom:50%;" /></p>
<p>可以看到，图像信息既没有带来更丰富的信息；也没有带来噪音。这两张图片里重复了一遍文本内容，实际上这一类的图像还挺常见的，使用单模态模型和多模态模型对这一类post的判断效果可能都差不多。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>MMKG</category>
      </categories>
      <tags>
        <tag>MRE</tag>
        <tag>MMKG</tag>
      </tags>
  </entry>
  <entry>
    <title>KGAT</title>
    <url>/recommendation/KGAT/</url>
    <content><![CDATA[<h1 id="kgat-knowledge-graph-attention-network-for-recommendation">KGAT: Knowledge Graph Attention Network for Recommendation</h1>
<p>在结合了知识图谱之后，就形成了一个关系更加丰富的graph neural network，使用GNN的方法来进行最后的预测。这篇论文就是在结合了知识图谱的基础上使用作者之前(2019)发表的neural graph collaborative filtering(ngcf)算法。理解了ngcf这篇论文就很好理解。</p>
<span id="more"></span>
<h2 id="现在结合知识图谱的推荐存在的问题">1. 现在结合知识图谱的推荐存在的问题</h2>
<h3 id="知识图谱出现解决的问题">1.1 知识图谱出现解决的问题</h3>
<p>推荐算法中的协同过滤考虑的根据某个用户的历史数据，寻找可能兴趣相投的群体，来推荐物品。比如在下图中，要给用户推荐物品，那么但从交互的物品来看，都与有交互，那么就可以认为是兴趣相投的用户，根据他们的历史数据来给推荐物品。但如果表示某部电影，的导演也是这部电影的演员，与之间是存在属性上的联系的，这种联系是单纯协同过滤无法解决的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191214102753089-8557739.png" style="zoom:50%;" /></p>
<p>为了解决这个问题，加入知识图谱(knowledge graph)，形成了下面的结构。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191229105855957-8557739.png" style="zoom:50%;" /></p>
<p>在这样的图中，与就关联起来了。同样给推荐物品，就能够找到更多的相似用户来进行推荐。</p>
<p>考虑之前的用户和物品交互矩阵，矩阵当中只存在一种关系，就是用户和物品的交互，并且物品和物品之间是没有直接交互的，如果结合了知识图谱，物品和物品之间就出现了直接的关系，增加了新的实体，矩阵中的关系也就由一个变为了多个。</p>
<p>在这样的条件下，就可以继续利用GNN来进行propagation。</p>
<h3 id="使用gnn的思路">1.2 使用GNN的思路</h3>
<p>在结合了知识图谱之后，就形成了一个关系更加丰富的graph neural network，使用GNN的方法来进行最后的预测。这篇论文就是在结合了知识图谱的基础上使用作者之前(2019)发表的neural graph collaborative filtering(ngcf)算法。理解了ngcf这篇论文就很好理解。</p>
<h2 id="模型结构">2 模型结构</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191214103645598-8557739.png" style="zoom:50%;" /></p>
<p>主要包括三层：</p>
<ol type="1">
<li>Embedding layer</li>
<li>Attentive embedding propaggation layer</li>
<li>Prediction layer</li>
</ol>
<h3 id="embedding-layer">2.1 Embedding layer</h3>
<p>对于用户-物品可以表示为， <span class="math display">\[
G_1 = \{(u, y_{ui}, i)|u\in U, i\in I, y_{ui}=1\}
\]</span> 知识图谱使用下面的三元组来表示， <span class="math display">\[
G_2 = \{(h, r, t)|h,t\in \epsilon , r\in R\}
\]</span> 这样整个结构也就都成为了一个三元组， <span class="math display">\[
G = \{(h, r, t)|h,t\in \epsilon^{&#39;} , r\in R^{&#39;}\}
\]</span> 在新的结构当中，由于每一个物品都对应到了知识图谱中的实体。所以现在的矩阵变为了<span class="math inline">\(N用户\times\ M^{&#39;}实体\)</span>。</p>
<p>在embeding layer这一层，存在一个loss，知识图谱embeding表示的loss。论文里使用了TransR，来获得知识图谱的embeding。</p>
<p>TransR的原理是实体使用d维embeding，关系表示使用k为embeding，一个连接<span class="math inline">\(&lt;h, r, t&gt;\)</span>在数学上的含义可以是h投影到关系r的k维空间上，加上r的k维表示，得到t的k维投影： <span class="math display">\[
W_re_h+e_r\approx W_re_t,\\ e_h, e_t\in R^d, e_r\in R^k, W_r\in R^{k\times d}
\]</span> <span class="math inline">\(W_r\)</span>是关系r的转换矩阵。这个等式两边越接近越好，这样可以定义一个相似性得分的函数： <span class="math display">\[
g(h,r,t)={\lVert W_re_h+e_r-W_re_t \rVert}^2_2
\]</span> 在整个的矩阵上，对于有关系的<span class="math inline">\(&lt;h, t&gt;\)</span>score越小越好，对于没有关系的<span class="math inline">\(&lt;h, t^{&#39;}&gt;\)</span>score越大越好。</p>
<p>因此可以得到一个损失函数： <span class="math display">\[
L_{KG}=\sum_{(h,r,t,t^{&#39;})}{-ln\sigma (g(h,r,t^{&#39;})-g(h,r,t)) }
\]</span> 在论文的代码实现当中，对于每一个head，取了1个positive，1个negative来计算loss。</p>
<h3 id="attentive-embeding-propagation-layers">2.2 Attentive Embeding Propagation Layers</h3>
<p>实质是在ngcf上加上了attention机制。</p>
<p>对于一个实体<span class="math inline">\(h\)</span>，对于和 <span class="math inline">\(h\)</span> 有关系 <span class="math inline">\(r\)</span> 的集合 <span class="math inline">\(N_h=\{ (h,r,t)|(h,r,t)\in G \}\)</span> 使用propagation： <span class="math display">\[
e_{N_h}=\sum_{(h,r,t)\in N_h} \pi (h,r,t)e_t
\]</span> Attention: <span class="math display">\[
\pi (h,r,t)=(W_re_t)^Ttanh(W_re_h+e_r) \\
\pi (h,r,t)=\frac{exp(\pi (h,r,t))}{\sum_{(h,r^{&#39;},t^{&#39;})\in N_h} \pi (h,r,t)e_t}
\]</span> 理解：</p>
<p><span class="math inline">\(W_re_t\)</span>是实体<span class="math inline">\(e_t\)</span>在关系<span class="math inline">\(r\)</span>空间内的投影，<span class="math inline">\(W_re_h+e_r\)</span>是<span class="math inline">\(e_h\)</span>投影到关系<span class="math inline">\(r\)</span>的k维空间上，加上r的k维表示。如果这两个embeding点积越大，表示这两个向量越相似，对应的权重应该更大。</p>
<p>之后的propagation和aggregation具体方式参考ngcf。</p>
<h3 id="训练方式">2.3 训练方式</h3>
<p>具体的，在训练之前，因为加入知识图谱相当于增加了新的物品，增加了大量的待训练参数，为了加快训练过程，首先利用BPR-MF的方式预训练好用户、物品的embeding，之后再进行kgat的训练。</p>
<p>在训练的时候，在一个epoch里，</p>
<ol type="1">
<li>分batch(1024)训练完embeding propagation，更新所有实体的embeding</li>
<li>分batch‘(2048)训练TransR，更新关系的转换矩阵<br />
</li>
<li>更新attentive embeding</li>
</ol>
<h2 id="experiments">3 Experiments</h2>
<p>研究问题：</p>
<ol type="1">
<li>KGAT和其它模型的比较</li>
<li>KGAT不同模型设置对结果的影响</li>
<li>KGAT对于用户偏好解释性的影响</li>
</ol>
<p>可以发现，这三个问题与NGCF中探究的问题一致。</p>
<p>数据集：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191214110411611-8557739.png" alt="image-20191229105855957" style="zoom:50%;" /></p>
<p>可以发现，如果加入知识图谱，物品的数量就会极大的增加，这也是为什么建议预训练好用户和物品的embeding。</p>
<p>评估指标： <span class="math display">\[
recall@K,\ ndcg@K,\ K=20
\]</span> 超参数设置：</p>
<ul>
<li>embeding size：64</li>
<li>batch size：1024</li>
<li>early stopping</li>
<li>KGAT layer size：[64, 32, 16]</li>
</ul>
<p>比较结果：</p>
<p>效果比较：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191229110432499-8557739.png" alt="image-20191229110432499" style="zoom:50%;" /></p>
<p>不同模型结构设置的影响：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191229111040431-8557739.png" alt="image-20191229110623067" style="zoom:50%;" /></p>
<p>对于用户偏好的解释：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191229110623067-8557739.png" alt="image-20191229111040431" style="zoom:50%;" /></p>
<p>从这张图上可以看出来通过加入知识图谱，获得了更多的额外信息。</p>
<h2 id="总结">4 总结</h2>
<p>加入知识图谱导致了更加丰富的物品信息</p>
<p>缺点：</p>
<p>在知识图谱中，存在一些常见的属性，例如图4中的English，这些属性有很多物品都具备，但是在attention的计算中，attention的计算仅在当前用户的交互实体下进行，没有考虑全局的情况。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>RS</category>
      </categories>
  </entry>
  <entry>
    <title>KGIN</title>
    <url>/recommendation/KGIN/</url>
    <content><![CDATA[<h1 id="learning-intents-behind-interactions-with-knowledge-graph-for-recommendation">Learning Intents behind Interactions with Knowledge Graph for Recommendation</h1>
<p>KGIN，WWW 2021</p>
<p>结合知识图谱，结合图神经网络。在user-item中加入了intent，在KGIN中的intent表现为知识图谱中关系relation的基于自注意力的组合，同时加入差异性约束，使得不同intent的差异增大。Intent的想法很有趣，直观上看本质上还是多头的，类似于集成学习ensemble learning的思想。</p>
<span id="more"></span>
<blockquote>
<p>Knowledge graph (KG) plays an increasingly important role in recommender systems. A recent technical trend is to develop end- to-end models founded on graph neural networks(GNNs). However, existing GNN-based models are coarse-grained in relational modeling, failing to (1) identify user-item relation at a fine-grained level of intents, and (2) exploit relation dependencies to preserve the semantics of long-range connectivity.</p>
<p>In this study, we explore intents behind a user-item interaction by using auxiliary item knowledge, and propose a new model, Knowledge Graph-based Intent Network (KGIN). Technically, we model each intent as an attentive combination of KG , relations, Negative Items : Positive Items encouraging the independence of different intents for better model capability and interpretability. Furthermore, we devise a new information aggregation scheme for GNN, which recursively integrates the relation sequences of long-range connectivity (i.e., relational paths). This scheme allows us to distill useful information about user intents and encode them into the representations of users and items. Experimental results on three benchmark datasets show that, KGIN achieves significant improvements over the state-of-the-art methods like KGAT [41], KGNN-LS [38], and CKAN [47]. Further analyses show that KGIN offers interpretable explanations for predictions by identifying influential intents and relational paths. The implementations are available at <a href="https://github.com/huangtinglin/Knowledge_Graph_based_Intent_Network" class="uri">https://github.com/huangtinglin/Knowledge_Graph_based_Intent_Network</a>.</p>
</blockquote>
<p>直接看方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428152321247.png" style="zoom:50%;" /></p>
<p>整个模型的训练分成两个部分，一个是user-item上对于user embedding的训练，一个是在KG上对于entity/item的训练。</p>
<h2 id="在user-item-graph上的训练">在user-item graph上的训练。</h2>
<p>首先引入intent，定义一个集合<span class="math inline">\(\mathcal{P}\)</span>对于所有的用户是共享的，然后针对user-item pair <span class="math inline">\((u,i)\)</span>，插入intent，变为<span class="math inline">\(\{ (u,p,i)\ p \in \mathcal{P} \}\)</span>。</p>
<p><strong>Representation Learning of Intents</strong>：</p>
<p>每一个intent <span class="math inline">\(p\)</span>对应一个表示embedding，同时为了让intent能够与KG中的relation联系起来，考虑不同relation的组合作用，将intent表示为基于注意力的relation的组合：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428153437851.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428153453247.png" style="zoom:50%;" /></p>
<p>KGIN为每个relation针对不同的intent <span class="math inline">\(p\)</span>定义了一个weight，<span class="math inline">\(w_{rp}\)</span>。不是简单的直接weighted sum而是经过了一层softmax。</p>
<p>另外，为了保证intent embedding之间存在差异性，对于不同的intent <span class="math inline">\(e_p\)</span>，使用了两种方法作为惩罚项加入loss function中。</p>
<ol type="1">
<li>Mutual information</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428153029551.png" style="zoom:50%;" /></p>
<ol start="2" type="1">
<li>Distance correlation</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428152948599.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428153949318.png" style="zoom:50%;" /></p>
<p>以上的思想是精髓，需要之后细看，并且类似的思想在<a href="#">Post not found: AM-GCN</a>中也有出现。</p>
<p>在得到了intent <span class="math inline">\(p\)</span>之后，聚合item，得到user的表示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428153959942.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428153813909.png" style="zoom:50%;" /></p>
<p>注意力的聚合，计算每个intent与目标用户embedding的相似程度。</p>
<h2 id="在kg上的训练">在KG上的训练</h2>
<p>不使用注意力，也没有intent，甚至也没有<span class="math inline">\(W\)</span>，直接聚合</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428152740113.png" style="zoom:50%;" /></p>
<p>需要注意：<span class="math inline">\(e_r\)</span>在intent embedding计算中出现，并且看公式的话，它不会随着layer的增加而改变。</p>
<h2 id="model-prediction">Model Prediction</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428154032654.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428153420725.png" style="zoom:50%;" /></p>
<h2 id="model-optimization">Model Optimization</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428154045082.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210428152227995.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>RS</category>
      </categories>
  </entry>
  <entry>
    <title>MKR</title>
    <url>/recommendation/MKR/</url>
    <content><![CDATA[<h1 id="multi-task-feature-learning-for-knowledge-graph-enhanced-recommendation">Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation</h1>
<p>WWW 2019</p>
<p>MKR将KG和RS看做两个不同的学习任务，提出了<em>cross&amp;compress</em> unit。能够显式的捕获item和entities之间的高阶交互，并且自动在两个学习任务中控制cross knowledge。</p>
<span id="more"></span>
<blockquote>
<p>Collaborative filtering often suffers from sparsity and cold start problems in real recommendation scenarios, therefore, researchers and engineers usually use side information to address the issues and improve the performance of recommender systems. In this paper, we consider knowledge graphs as the source of side information. We propose MKR, a Multi-task feature learning approach for Knowledge graph enhanced Recommendation. MKR is a deep end-to-end framework that utilizes knowledge graph embedding task to assist recommendation task. The two tasks are associated by cross&amp;compress units, which automatically share latent features and learn high-order interactions between items in recommender systems and entities in the knowledge graph. We prove that cross&amp;compress units have sufficient capability of polynomial approximation, and show that MKR is a generalized framework over several representative methods of recommender systems and multi-task learning. Through extensive experiments on real-world datasets, we demonstrate that MKR achieves substantial gains in movie, book, music, and news recommendation, over state-of-the-art baselines. MKR is also shown to be able to maintain a <strong>decent</strong> performance even if user-item interactions are sparse.</p>
</blockquote>
<p><strong>motivation</strong>：对于以前的很多基于KG的推荐方法，在处理KG的时候存在很多问题。比如PER和FMG，将KG作为一个异质信息网络，需要基于metapath进行推荐；对于RippleNet，没有办法很好的捕获KG中relation的重要性；对于CKE，利用了TransR进行训练，但是TransR更适合in-graph的任务而不是更适用于RS的任务。</p>
<p><strong>Method</strong>：为了解决上面的问题，MKR，将基于KG的推荐问题看做多任务学习问题。multi-task learning (MTL)。在KG上的学习和在推荐上的学习任务不是完全独立的。在文献Learning Multiple Tasks with Multilinear Relationship Networks中提到了，一个item和它对应的entities，在RS和KG上可能具有相近的结构，并且可能在任务无关的特征空间中共享相似的特征。</p>
<blockquote>
<p>Therefore, an item and its corresponding entity are likely to have a similar proximity structure in RS and KG, and share similar features in low-level and non-task-specific latent feature spaces.</p>
</blockquote>
<p>MKR提出了<em>cross&amp;compress</em> unit。能够显式的捕获item和entities之间的高阶交互，并且自动在两个学习任务中控制cross knowledge。</p>
<p>来看一下模型结构。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210502182518838.png" style="zoom:50%;" /></p>
<p>总体而言，两个学习任务，两个学习任务之间的item和entities经过<em>cross&amp;compress</em> unit进行学习，用户user和KG中的relation都是经过MLP进行学习。两个学习任务意味着两个loss。</p>
<p>在训练时，迭代一次，多次训练推荐任务，最后训练一次KG链路预测任务。</p>
<p>那么核心创新点就是<em>cross&amp;compress</em> unit，看一下式子。</p>
<p>Cross部分：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210502182833566.png" style="zoom:50%;" /></p>
<p>对于item和entities进行tensor dot，不同维度之间相乘，捕获pairwise的interaction。</p>
<p>Compress部分：</p>
<p>将feature interaction matrix，投影到item和entities的不同feature space中：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210502183100668.png" style="zoom:50%;" /></p>
<p><strong>需要注意的点</strong>：需要看到，它在投影时，即压缩时，在horizontal和vertical两个方向上同时进行投影。也就是说对于<span class="math inline">\(C_L\)</span>和<span class="math inline">\(C_l^T\)</span>同时投影。对于horizontal方向的压缩，不同行之间的区别在于<span class="math inline">\(\mathbf{v}_l\)</span>，即item的信息；对于vertical方向的压缩，不同列之间的区别在于<span class="math inline">\(\mathbf{e}_l\)</span>，即entities提供的信息。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>RS</category>
      </categories>
  </entry>
  <entry>
    <title>NGCF</title>
    <url>/recommendation/NGCF/</url>
    <content><![CDATA[<h1 id="neural-graph-collaborative-filtering">Neural Graph Collaborative Filtering</h1>
<blockquote>
<p><a href="https://arxiv.org/abs/1905.08108">Wang X, He X, Wang M, et al. Neural Graph Collaborative Filtering[J]. arXiv preprint arXiv:1905.08108, 2019.</a></p>
</blockquote>
<p>论文的主要贡献是提出了一种embeding propagation的方式，能够利用high order范围内的实体，训练得到用户和物品的embeding。结合知识图谱做推荐。</p>
<span id="more"></span>
<h2 id="介绍">1 介绍</h2>
<p>协同过滤(CF)有两个关键的点:</p>
<p>一个是如何表示用户和物品(embeding)，embeding的表示在各种方法里都不相同，可以直接使用用户/物品ID表示embeding，也可以利用各种特征，经过神经网络MLP，获得embeding表示。 另一个是如何表示两者的交互(interaction)，在MF中，直接使用用户与物品vector的点积表示交互（即一个鼠标点击广告的动作，或者购买该物品的历史）。</p>
<p>但是多数模型都没有通过利用user-item的交互来训练得到embeding，只使用了用户属性等基本描述性的特征。</p>
<p>如果要利用交互来获得embeding，存在的问题在于若使用user-item矩阵的形式表示交互，这样矩阵规模就非常的大，常常达到几百万量级，而且非常稀疏。</p>
<p>为了解决这个问题，论文中将交互转换为graph的形式，集中注意力在有过交互的物品上，例子如下图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191203225032817.png" style="zoom:50%;" /></p>
<p>图中的用户u1是推荐的目标用户。右边的图看成是以<span class="math inline">\(u_1\)</span>为根结点形成的一个树，这样对于<span class="math inline">\(u_1\)</span>的预测，就由原来的<span class="math inline">\(i_1, i_2, i_3\)</span>(first order)拓展到<span class="math inline">\(i_4, i_5\)</span>(third order)这样的high order范围。</p>
<p>论文的主要贡献是提出了一种embeding propagation的方式，能够利用high order范围内的实体，训练得到用户和物品的embeding。</p>
<h2 id="model结构">2 Model结构</h2>
<p>NGCF一共包括三层，</p>
<ol type="1">
<li>Embeding layer：表示user-item的look-up table</li>
</ol>
<p><span class="math display">\[
E=[\underbrace{e_{u_1}, e_{u_2}, \dots}_{N\ users},\underbrace{e_{i_1}, e_{i_1}}_{M\ items} ]^T
\]</span></p>
<ol start="2" type="1">
<li>Embedding Propagation Layers: 利用embeding进行多层的propagation</li>
<li>Prediction layer：预测<span class="math inline">\(&lt;u, i&gt;\)</span>的概率</li>
</ol>
<p>整个网络的结构如图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191215094628886.png" style="zoom:50%;" /></p>
<h3 id="embedding-layer">2.1 Embedding layer</h3>
<p>这一层与主流的推荐模型的embeding layer一样，对于N个用户u，M个物品i，使用d维的向量来表示，形成下面的矩阵(<span class="math inline">\((N+M)\times d\)</span>)： <span class="math display">\[
E = [e_{u_1}, \dots, e_{u_N},e_{i_1}, \dots, e_{u_M},]^T, e_u, e_i\ \in R^d
\]</span> 在实现中首次训练使用xavier initializer初始化。</p>
<h3 id="embedding-propagation-layers">2.2 Embedding Propagation Layers</h3>
<h4 id="first-order-propagation">2.2.1 First-order Propagation</h4>
<h5 id="message-construction">2.2.1.1 Message Construction</h5>
<p>对于一个用户u，我们首先可以直接使用那些与用户有直接交互的物品计算用户的embeding，表示为 <span class="math display">\[
m_{u\leftarrow i} = f(e_i, e_u, p_{ui})
\]</span> <span class="math inline">\(m_{u\leftarrow i}\)</span>称为物品i对于用户u的message embeding，<span class="math inline">\(f\)</span>称为message encoding function，<span class="math inline">\(p_{ui}\)</span>是系数，控制<span class="math inline">\(&lt;u, i&gt;\)</span>这条path的权重。</p>
<p>具体的，<span class="math inline">\(m_{u\leftarrow i}\)</span>表现为： <span class="math display">\[
m_{u\leftarrow i} = \frac{1}{\sqrt{|N_{u}||N_{i}|}} \big( W_1 e_i + W_2 (e_i\odot e_u)\big),\ \ W_1, W_2 \in R^{d^{&#39;}\times d}
\]</span> <span class="math inline">\(\odot\)</span>表示element wise乘法，<span class="math inline">\(N_{u},\ N_{i}\)</span>分别表示与用户u和物品i直接有交互的物品或者用户数量。</p>
<p><span class="math inline">\(\frac{1}{\sqrt{|N_{u}||N_{i}|}}\)</span>就是 <span class="math inline">\(p_{ui}\)</span>， 被称作graph Laplacian norm，它表示物品传递给用户的message的weight，可以这样理解，如果某个物品的<span class="math inline">\(N_i\)</span>越小，表示这个物品越”独特“，越能够体现用户的个性偏好， <span class="math inline">\(p_{ui}\)</span>增大；用户的<span class="math inline">\(N_u\)</span>越小表示该用户的兴趣越”集中“，那么他的历史数据中的每个物品的 <span class="math inline">\(p_{ui}\)</span>都应该增大，表示每个物品都能够较大的反映该用户偏好。</p>
<h5 id="message-aggregation">2.2.1.2 Message Aggregation</h5>
<p>对于一个用户u的多个物品i，得到了多个传递过来的message embeding，需要使用一种聚合起来形成最终的用户embeding的方式， <span class="math display">\[
e_u^{(1)} = LeakRelu\big( m_{u\leftarrow u} + \sum_{i \in N_u} m_{u\leftarrow i} \big),\\
m_{u\leftarrow u}=W_1 e_u
\]</span> <span class="math inline">\(e_u^{(1)}\)</span>是用户u经过第一次embeding propagation之后的embeding，可以看到最终聚合的方式是直接对所有的message embeding相加，最后联合原来的表示<span class="math inline">\(e_u\)</span>，经过一个leak-relu就得到了最后的表示。</p>
<p>上面过程以单个用户u为例，介绍了一次embeding propagation的过程。这个过程对于物品i也是一样的。</p>
<p>单个用户进行一次propagation，与用户u直接相连的所有物品的”信息“传递到了用户u上。但这个过程是同时在所有的用户u和物品i都进行的。一次propagation，让每个用户和物品都得到了从与它们直接相连的实体的信息。如果在进行一次propagation，用户和物品目前包含了自己下层直连的信息，就又会传递给上级。也就实现了获取high order连接信息的目的。</p>
<h4 id="high-order-propagation">2.2.2 High-order Propagation</h4>
<p>在first order propagation的基础上，得到多次propagation的表示， <span class="math display">\[
\begin{cases}
e_u^{(l)} = LeakRelu\big( m_{u\leftarrow u}^{l} + \sum_{i \in N_u} m_{u\leftarrow i}^{l} \big),\\
m_{u\leftarrow u}^{l}=W_1^{l} e_u^{(l-1)},\\
m_{u\leftarrow i}^{l} = \frac{1}{\sqrt{|N_{u}||N_{i}|}} \big( W_1^{l} e_i^{(l-1)} + W_2^{l} (e_i^{(l-1)} \odot e_u^{(l-1)})^{(l-1)} \big)
\end{cases}
\]</span></p>
<h4 id="propagation-rule-in-matrix-form">2.2.3 Propagation Rule in Matrix Form</h4>
<p>之前的例子作用于所有的用户和物品，就得到了矩阵形式的表达， <span class="math display">\[
E^{(l)} = LeakRelu \big( (L+I)E^{(l-1)} W_1^{l} + LE^{(l-1)} \odot E^{(l-1)} W_2^{l}\big)
\]</span> 其中<span class="math inline">\(L \in R^{(N+M)\times(N+M)}\)</span>，<span class="math inline">\(L_{ui}=\frac{1}{\sqrt{|N_{u}||N_{i}|}}\)</span>。</p>
<h3 id="model-prediction">2.3 Model Prediction</h3>
<p>经过l次propagation，一个用户u，得到<span class="math inline">\(\{e_u^{1}, \dots ,e_u^{l}\}\)</span>，在本论文里，直接将l个d维的embeding concat到一起。 <span class="math display">\[
e^*_u =e_u^{0}|| \dots ||e_u^{l},\qquad e^*_i =e_i^{0}|| \dots ||e_i^{l}
\]</span> 那么最后对于用户u，物品i的得分通过求内积得到， <span class="math display">\[
\hat{y}_{NGCF}(u,i) = (e^*_u)^T e^*_i
\]</span></p>
<h3 id="optimization">2.4 Optimization</h3>
<p>损失函数为BPR(Bayesian Personalized Ranking) loss， <span class="math display">\[
Loss = \sum_{(u, i, j)\in O}-ln\sigma(\hat{y}_{ui}-\hat{y}_{uj}) + \lambda {\lVert \theta \rVert}_2^2 \\
O = \{ (u, i, j)|(u, i)\in R^+,\ (u, j)\in R^- \}
\]</span> 使用Adam，early stoping。</p>
<p>为了防止过拟合，类似dropout方法，使用了两种dropout：</p>
<ol type="1">
<li>Message dropout：以一定的概率<span class="math inline">\(p_1^{l}\)</span>，在进行第l次embeding propagation时，丢弃一些用户或物品message embeding 。message dropou作用于<span class="math inline">\(E^{(l)}\)</span>。</li>
<li>Node dropout：以一定的概率<span class="math inline">\(p_2^{l}\)</span>，在进行第l次embeding propagation之前，丢弃上次产生的一些用户或物品的embeding 。实际是都使用了0.1概率。node dropout作用于<span class="math inline">\(L\)</span>.</li>
</ol>
<h2 id="eexperiments">3 Eexperiments</h2>
<p>在3个数据集上讨论了3个问题：</p>
<ol type="1">
<li>本文提出的NGCF和其它CF模型的比较</li>
<li>NGCF不同超参数的影响</li>
<li>能够利用high order connectivity信息，对于用户和物品的表示的影响</li>
</ol>
<h3 id="dataset">3.1 Dataset</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191214230017160.png" style="zoom:50%;" /></p>
<p>使用10-core形式，每个用户至少有10个历史交互数据。</p>
<p>80%的interaction为训练集，20%为测试集。</p>
<h3 id="experimental-settings">3.2 Experimental Settings</h3>
<p>评估指标针对每个用户推荐K个物品，然后计算 <span class="math inline">\(recall@K,\ ndcg@K\)</span>，默认情况下K设置为了20。</p>
<p>一些实验的超参数如下：</p>
<ul>
<li>batch size：1024</li>
<li>embeding size：64</li>
<li>ndcf layer：3，[64, 64, 64]</li>
<li>dropout: 0.1</li>
<li>message out: 0.1</li>
</ul>
<h3 id="rq1-comparison">3.3 RQ1: comparison</h3>
<h4 id="overall-comparison">3.3.1 Overall Comparison</h4>
<p>对比了几个不同的CF算法如下</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191203155628521.png" style="zoom:50%;" /></p>
<h4 id="comparison-w.r.t.-interaction-sparsity-levels.">3.3.2 Comparison w.r.t. Interaction Sparsity Levels.</h4>
<p>一个用户的推荐效果和这个用户的历史数据数量有很大的关系，如果交互的数量越少，越难推荐合适的物品，针对不同交互量用户分组进行了下图的研究。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191215095752801.png" style="zoom:50%;" /></p>
<p>图上能够看到在不同的分组下，NGCF都有最好的ndcg@20结果。</p>
<h3 id="rq1-study-of-ngcf">3.4 RQ1: Study of NGCF</h3>
<h4 id="effect-of-layer-numbers">3.4.1 Effect of Layer Numbers</h4>
<p>针对NGCF不同层数产生的效果的研究，NGCF-4虽然在两个数据集上得到了较好的结果，但是提升并不大，而且参数数量增多，训练成本增加，也容易过拟合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191215100237965.png" style="zoom:50%;" /></p>
<h4 id="effect-of-embedding-propagation-layer-and-layeraggregation-mechanism">3.4.2 Effect of Embedding Propagation Layer and LayerAggregation Mechanism</h4>
<p>对于embeding propagation的方式，进行了研究，</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191215095100798.png" style="zoom:50%;" /></p>
<h4 id="effect-of-dropout">3.4.3 Effect of Dropout</h4>
<p>研究在不同数据集下，node和message dropout不同数值对于结果的影响</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191215100632501.png" style="zoom:50%;" /></p>
<p>结果显示多数情况下，相同概率的node dropout方式好于message dropout，而且node dropout方式得到的最好效果要优于message dropout。</p>
<p>一个可能的原因是node dropout会直接丢弃原来的node，这些node不会产生任何的效果，具有更强的鲁棒性。</p>
<h3 id="rq3-effect-of-high-order-connectivity">3.5 RQ3: Effect of High-order Connectivity</h3>
<p>为了研究利用high-order connectivity是否有效果，在Gowalla测试数据集中，截取6个用户和它们的物品在NGCF-1和NGCF-3下的embeding，利用t-SNE进行探究。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20191215102635413.png" style="zoom:50%;" /></p>
<p>从图上可以看出来，在3-order下，一个用户和它的物品更加倾向形成一聚类，即通过它的物品，能够更好的反映用户的实际情况。这表示利用high-order起到了作用，能够更好的捕获协同信息。</p>
<h2 id="conclusion">4 Conclusion</h2>
<p>论文的主要成果</p>
<ul>
<li>一种新的embeding propagation方式</li>
<li>在三个数据集上进行的不同的研究</li>
</ul>
<p>下一步方向</p>
<ul>
<li>现在每层的neighbor的权重都是一样的，可以考虑加入attention(在作者的下一篇论文KGAT中实现了)</li>
<li>结合知识图谱（KGAT）</li>
<li>结合social network，cross-feature等</li>
</ul>
<p>不足</p>
<ul>
<li>单纯的使用了用户的历史交互信息，用户和物品的其它特征并没有利用，能否结合FM, NFM，得到更加丰富的embeding？</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>RS</category>
      </categories>
  </entry>
  <entry>
    <title>ONN</title>
    <url>/recommendation/ONN/</url>
    <content><![CDATA[<h2 id="背景">1 背景</h2>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0893608019302850?via%3Dihub">ONN(Operation-aware Neural Networks for user response)</a>是2018年腾讯广告算法比赛最优的推荐算法。主要任务是预测用户点击推荐广告的概率(click-through rate, CTR)或者进行其它期望的行为(conversion rate, CVR)。在基本的通用的Base model上，<strong>将PNN与FFM结合起来</strong>，实现了在embedding层的每一个feature对于不同operation（内积或者外积）有不同的表示，之后进入MLP，得到更好的预测结果</p>
<span id="more"></span>
<h2 id="创新点">2 创新点</h2>
<h3 id="针对的问题">2.1 针对的问题</h3>
<p>目前的大多数的模型对于一个feature上的embedding vector进行不同的operation都是使用相同的表示。但是<strong>对于不同的操作，一个feature的最好表示不总是相同的</strong>(<a href="https://dl.acm.org/citation.cfm?doid=2959100.2959134">Juan et al., 2016</a>; <a href="https://dl.acm.org/citation.cfm?doid=1718487.1718498">Rendle &amp; Schmidt-Thieme, 2010</a>)</p>
<h3 id="解决思路">2.2 解决思路</h3>
<p>在基本的通用的Base model上，<strong>将PNN与FFM结合起来</strong>，实现了在embedding层的每一个feature对于不同operation（内积或者外积）有不同的表示，之后进入MLP，得到更好的预测结果</p>
<h2 id="相关的模型">3. 相关的模型</h2>
<h3 id="ffm">3.1 FFM</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/884D03E3-A229-4894-AF6A-177AAE3FE851.jpg" style="zoom:50%;" /></p>
<center>
The architecture of the FFM model.
</center>
<h3 id="base-model">3.2 Base Model</h3>
<p>深度学习引入推荐系统之后，深度学习的优势在于可以获取到特征的高维信息，一般的过程可以概括成以下三步：</p>
<ol type="1">
<li>一个embedding layer，负责将离散的feature映射到更低维的表示形式。
<ul>
<li>对于一个样本的特征表示为<span class="math inline">\(f=[x_0, x_1, \ldots x_m]\)</span></li>
<li>embedding矩阵表示为<span class="math inline">\(M = [V^0, V^1, \ldots V^m]\)</span></li>
<li>两者作积得到的这一步的输出概括为： <span class="math display">\[ e = [V^0x_0, V^1x_1, \ldots V^mx_m] \]</span><br />
其中的<span class="math inline">\(V^i\)</span>是中对应<span class="math inline">\(i\)</span>th feature的那一列，<span class="math inline">\(x_i\)</span>是<span class="math inline">\(i\)</span>th feature的one hot表示。</li>
</ul></li>
<li>对于上一步得到的结果进行operation，这一步可以表示为<span class="math inline">\(f = [o_1(e), o_2(e), \ldots o_l(e)]\)</span>，<span class="math inline">\(o_i\)</span>是表示<span class="math inline">\(i\)</span>th operation，这个operation可以是两个向量内积或者外积，在多数的结构中，这个操作只是一个copy操作，暨不进行任何的操作。这种在embedding向量上进行的操作可以看成是一种初期的特种工程。</li>
<li>第二步得到的结果输入MLP(multi-layer perceptron)，最终输出<span class="math inline">\(\hat{y} = \sigma(\Phi(f))\)</span>，<span class="math inline">\(\sigma\)</span>是sigmoid函数，<span class="math inline">\(\Phi\)</span>是MLP的非线性转换</li>
</ol>
<h3 id="pnn">3.3 PNN</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/8B9A5379-797C-4D1B-AF09-4C4F7D6DFE55.jpg" style="zoom:50%;" /></p>
<center>
The architecture of the PNN model.
</center>
<h2 id="onn结构">4 ONN结构</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/389A9CB8-2500-4FBE-8FC8-5571A91C8D22.jpg" style="zoom:50%;" /></p>
<center>
The architecture of the ONN model.
</center>
<p>可以看到最大的特点在于对于<span class="math inline">\(i\)</span>th feature的one-hot表示转换为embedding后拥有多个表示，在进行不同的operation时，采取了不同的表示形式。</p>
<h3 id="operation-aware-embedding">4.1 Operation-aware embedding</h3>
<p>下面说一下对于<span class="math inline">\(i\)</span>th feature的具体转换过程。 <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/31572F4F-DF1E-4FEE-A231-B17B92F090C3.jpg" style="zoom:50%;" /></p>
<center>
The structures of the normal embedding layer and the operation-aware embedding layer.
</center>
<p>在上图的左边部分中，<span class="math inline">\(e_i\)</span>是feature的转换后的embedding，<span class="math inline">\(V^i\)</span>代表对应<span class="math inline">\(i\)</span>th feature的embedding matrix，这样得到的<span class="math inline">\(e_i\)</span>就只会有一种表示。<br />
而在ONN改进后的右边部分中，设置了<span class="math inline">\([V^{i,l}, V^{i,l}, \ldots V^{i,l}]\)</span>，其中的<span class="math inline">\(V^{i,l}\)</span>表示对于<span class="math inline">\(i\)</span>th feature的<span class="math inline">\(l\)</span>项操作。这里要注意的是同一种操作比如求内积，<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span> 求内积与 <span class="math inline">\(i\)</span>和<span class="math inline">\(p\)</span> 求内积是不一样的操作。 最终的到的<span class="math inline">\(e_i\)</span>就是一个矩阵，<span class="math inline">\([e^1_i, e^2_i, \dots, e^l_i]=[V^{i,l}x_i, V^{i,l}x_i, \ldots V^{i,l}x_i]\)</span>，在进行<span class="math inline">\(k\)</span>项操作时，取出<span class="math inline">\(e^k_i\)</span>表示进行操作。 为了表示在<span class="math inline">\(i\)</span>th feature上进行操作<span class="math inline">\(o\)</span>时要使用的<span class="math inline">\(k\)</span>表示定义为：<span class="math inline">\(\Gamma(o, i)=k\)</span><br />
在实现当中，实际求内积只在用户特征和推荐广告的特征之间进行，</p>
<h3 id="incipient-feature-extraction-layer">4.2 Incipient feature extraction layer</h3>
<p>在上一个的基础上，来看一下对于一个样例 <span class="math inline">\(f\)</span>的最终输出形式是什么。 <span class="math display">\[ f = [e_f, i_f] \]</span> 其中第一项<span class="math inline">\(e_f\)</span>是<span class="math inline">\(f\)</span>的所有特征的embedding vector，表示为: <span class="math display">\[ e_f=[e_1^{\Gamma(o(c, 1), 1)}, e_2^{\Gamma(o(c, 2), 2)}, \dots, e_m^{\Gamma(o(c, m), m)}] \]</span><br />
公式中的<span class="math inline">\(o(c, i)\)</span>是指对<span class="math inline">\(i\)</span>th feature进行copy操作 第二项<span class="math inline">\(i_f\)</span>是表示feature interactions，具体的说是两个feature embedding vector的内积。只求两个向量间的内积是再多的就过于复杂，求内积是在之前的实验中证明了内积效果比外积要好<a href="https://ieeexplore.ieee.org/document/7837964">(Qu et al., 2016）</a>。公式为： <span class="math display">\[ i_f=[p_{1, 2}, p_{1, 3}, \dots, p_{m-1, m}] \]</span> <span class="math inline">\(p_{i, j}\)</span>是指在<span class="math inline">\(i\)</span>th feature和<span class="math inline">\(j\)</span>th feature之间求内积，<span class="math inline">\(p_{i, j}=\big \langle e_i^{\Gamma(o(p, i, j), i)}, e_j^{\Gamma(o(p, i, j), j)} \big \rangle\)</span></p>
<h3 id="mlp">4.3 MLP</h3>
<p>两个hidden layer，最后一个sigmoid输出 两个hidden layer的输出表示为： <span class="math display">\[ l_1=BN(relu(W_1\hat{f}+b_1)) \]</span> loss函数是交叉熵</p>
<h2 id="与其它模型pnn-ffm的关系">5 与其它模型(PNN, FFM)的关系</h2>
<ul>
<li>回顾一下PNN模型的结构，和ONN的主要区别在于embedding layer，ONN实现了operation aware，即一个feature有了多种embedding vector，这样对于不同操作可以选择不同的feature表示。这样在训练时就得到了更好的特征表示。</li>
<li>和FFM模型最大的区别在于ONN加入了MLP，加入了深层网络后，深度网络能够更好的挖掘特征深层次的依赖，能够学习到复杂的特征依赖关系</li>
</ul>
<h2 id="实验">6 实验</h2>
<h3 id="数据集">6.1 数据集</h3>
<ol type="1">
<li>Criteo: 包含45million条用户点击广告的记录，使用了最后5million作为测试集(8:1)，数据集中包括13个连续特征和26个分类特征。通过<span class="math inline">\(discrete(x)=\lfloor 2 \times log(x) \rfloor\)</span>将连续量离散化</li>
<li>腾讯广告数据集: 包含了14天内app推荐广告的记录，用户信息，广告信息以及安装的app的记录。论文使用了39个分类特征，去掉了最后2天噪声过大的数据，使用前11天数据作为训练，第12天的数据作为数据。最终22million训练集，2million测试集(11:1)</li>
</ol>
<h3 id="对比的方面">6.2 对比的方面</h3>
<p>分别从AUC，cross entropy，pearson‘s R以及root mean squared error在线下，线上以及采用不同的operation来进行试验</p>
<h4 id="offline-training-performance-comparison">6.2.1 Offline-training performance comparison</h4>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/AF76B24C-D512-4773-9889-07101C1075D9.png" style="zoom:50%;" /></p>
<p>从上面这两张表格可以看出来的有：</p>
<ul>
<li>PNN这些加入了深度网络的模型效果要优于FM, FFM，说明了深层的模型效果是要优于浅层的网络</li>
<li>FFM优于FM，ONN优于PNN，说明采用了operation aware embedding是优于一般的embedding层的</li>
<li>PNN，DeepFM，ONN优于了DNN，说明了进行求积的操作是有效的。</li>
</ul>
<h4 id="online-training-performance-comparison">6.2.2 Online-training performance comparison</h4>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/75087804-9474-4E93-AA7E-755B4C585275.png" style="zoom:50%;" /></p>
<p>在线上的测试中，每一个测试样例只能够被训练一次，对于FM, PNN这些只有一种表示形式的模型来说，一次epoch就学到比较好的表示是比较难的。ONN依旧取得了最好的效果。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/81E8040F-874A-4D9C-89D8-A7D87F654C5B.jpg" style="zoom:50%;" /></p>
<center>
Model convergence curves on the Criteo dataset.
</center>
<p>从上面的收敛趋势可以看到FFM，ONN这样使用了aware的模型，logloss收敛速度是由于其它模型的。</p>
<h4 id="analysis-of-different-operations">6.2.3 Analysis of different operations</h4>
<p>默认情况下ONN是使用内积作为operation，论文中就inner-product, outer-product, sub-network, inner+outer-product四种operation进行了比较。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/2E4E4961-55CF-49DE-9AD3-B67660A93A59.png" style="zoom:50%;" /></p>
<p>可以看到inner+outer-product获得了最好的结果，但是优势并不明显，考虑到时间和空间复杂性，它并不是一个很好的选择。所以依旧是使用了inner product。 但需要注意的是，sub-network取得的效果也是非常有竞争性的。而且它在Criteo数据集上的AUC指标上取得了很好的效果，这个可以考虑为下一步的研究方向。</p>
<h2 id="总结">7 总结</h2>
<ul>
<li>线上测试的结果表明ONN比较适合于线上的环境。</li>
<li>operation aware这种想法可以考虑应用在其它地方</li>
</ul>
]]></content>
      <categories>
        <category>Paper</category>
        <category>RS</category>
      </categories>
  </entry>
  <entry>
    <title>ENTDA</title>
    <url>/nlp/ENTDA/</url>
    <content><![CDATA[<h1 id="entity-to-text-based-data-augmentation-for-various-named-entity-recognition-tasks">Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks</h1>
<p>ENTDA，ACL 2023 Findings，清华与阿里达摩</p>
<blockquote>
<p>Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). <strong>Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks.</strong> In this work, we propose a novel Entity-toText based data augmentation technique named ENTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data and low resource settings) show that ENTDA could bring more performance improvements compared to the baseline augmentation techniques.</p>
</blockquote>
<p>基于entity list生成对应的新data</p>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>数据增强data augment的定义：</p>
<blockquote>
<p>Data augmentation techniques (Shorten and Khoshgoftaar, 2019) expand the training set by generating synthetic data to improve the generalization and scalability of deep neural networks, and are widely used in NLP (Feng et al., 2021; Li et al., 2022a).</p>
</blockquote>
<p>数据增强就是通过人造数据扩充训练集，从而导致能够提升模型的泛化性和可缩放性</p>
<p>在NER任务上的数据增强方法存在的问题：</p>
<ul>
<li>Rule Based Techniques：可能会破坏新句子的连贯性，甚至引入语法错误。However, it still inevitably introduces incoherent replacement and results in syntax-incorrect texts.</li>
<li>Generative Techniques：之前的方法使用entity tagging的思路实现NER任务，没有保留原始entity，因此难以增强nested与discontinuous NER任务。</li>
</ul>
<h2 id="method">2. Method</h2>
<p>作者提出的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191701967.png"   style="zoom:50%;" /></p>
<p>作者的生成data思路是根据entity list，让language model来直接生成相应的句子。作者期望能够生成各种不同类型NER的任务的数据。</p>
<p>作者的输入是entity list，<span class="math inline">\(E = [e_1, e_2, \dots, e_m, \dots, e_l]\)</span>，其中<span class="math inline">\(e_m= [s_{m1}, d_{m1}, ..., s_{mj}, d_{mj}, t_m]\)</span>，<span class="math inline">\(s\)</span>和<span class="math inline">\(d\)</span>表示entity某个span的开始位置和结束位置。最后的<span class="math inline">\(t\)</span>表示实体类型。</p>
<p>首先是Entity List Augmentation，采用下面4中方法修改entity list：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191837370.png"  style="zoom:30%;" /></p>
<p>然后，让language model基于entity list生成对应的句子。为了提升生成句子的多样性diversity，作者提出了一种diversity beam search decoding策略：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191955856.png"  style="zoom:30%;" /></p>
<p>传统的beam search decoding策略：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911192059860.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911192121040.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911192323174.png"   style="zoom:50%;" /></p>
<p>保留beam width <span class="math inline">\(B\)</span>个候选项。</p>
<p>作者惩罚rank排在后面的候选项，让model更加选择倾向于由不同的previous tokens生成的候选项，这样就增大了产生前面由不一样的token产生的新token概率：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911192440850.png"   style="zoom:50%;" /></p>
<p>然后，作者检查生成的句子，排除掉所有没有包含准确的entity list的sentence。最后，作者将数据转变为下面的样子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911192635925.png"   style="zoom:30%;" /></p>
<h2 id="experiments">3. Experiments</h2>
<p>一些具体的实现细节：</p>
<ul>
<li>we fine-tune the T5-Base (Raffel et al., 2020) with the initial parameters on the Entity-to-Text data of the training set. 在原来的dataset上，微调T5，让T5初步学会根据entity list来生成sentence</li>
<li><span class="math inline">\(\gamma = 10\)</span>，<span class="math inline">\(B = 3\)</span></li>
<li>ENTDA and all baselines augment the training set by 3x for a fair comparison. 也就是说如果训练集有100个samples，生成新300个samples，把这300个新的samples加入到原来的training set中</li>
</ul>
<h3 id="full-data-results">3.1 Full Data Results</h3>
<p>在3种NER任务下，使用全部的训练数据进行实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193010932.png"   style="zoom:50%;" /></p>
<p>此时，作者的方法效果有提升；但是提升幅度不是很大</p>
<h3 id="low-resource-ner">3.2 Low Resource NER</h3>
<p>低资源NER，we randomly choose 10% training data from CoNLL2003/ACE2005/CADEC</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193116491.png"  style="zoom:30%;" /></p>
<p>低资源的情况下，效果提升明显，有<span class="math inline">\(2\)</span>%的提升幅度。</p>
<p>在真实的低资源NER数据集CrossNER的表现：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193212164.png"   style="zoom:30%;" /></p>
<p>同样提升比较明显。</p>
<h3 id="various-augmentation-multiples">3.3 Various Augmentation Multiples</h3>
<p>如果不断增大新数据的倍数multiples：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193348335.png"   style="zoom:30%;" /></p>
<p>（上面这两个figure为什么没有MELM方法的比较呢？）</p>
<h3 id="semantic-coherence-and-diversity-analysis">3.4 Semantic Coherence and Diversity Analysis</h3>
<p>作者使用GPT-2来计算生成句子的perplexity，作为评估语义连贯性的指标：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193532109.png"   style="zoom:30%;" /></p>
<p>作者使用Type-Token Ratio (TTR) (Tweedie and Baayen, 1998)作为自动计算的指标评估多样性；同时雇佣了5个人类标注者，对生成的200个句子的多样性进行打分（<span class="math inline">\(1\)</span>~<span class="math inline">\(5\)</span>），作为人工指标：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193946471.png"   style="zoom:30%;" /></p>
<h3 id="case-study">3.5 Case Study</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911194043792.png"  style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>NER</category>
      </categories>
      <tags>
        <tag>Data Augment</tag>
        <tag>NER</tag>
      </tags>
  </entry>
  <entry>
    <title>FewGen-icml2023</title>
    <url>/nlp/FewGen-icml2023/</url>
    <content><![CDATA[<h1 id="fewgen-icml2023">FewGen-ICML2023</h1>
<blockquote>
<p>Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. <strong>To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective.</strong> A classification PLM can then be fine-tuned on both the few-shot and the synthetic samples with regularization for better generalization and stability. Our approach FewGen achieves an overall better result across seven classification tasks of the GLUE benchmark than existing few-shot learning methods, improving no-augmentation methods by 5+ average points, and outperforming augmentation methods by 3+ average points.</p>
</blockquote>
<p>Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning. University of Illinois Urbana-Champaign. ICML 2023. <a href="https://github.com/yumeng5/FewGen">Code</a>.</p>
<p>一篇微调语言模型来生成训练数据的工作。主要关注如何学习label-discriminative (/dɪsˈkrɪmɪnətɪv/) samples。</p>
<span id="more"></span>
<h2 id="background">1. Background</h2>
<h3 id="few-shot-learning-with-plms">1.1 Few-Shot Learning with PLMs</h3>
<p>受限于大量有标注数据获取的成本，少次学习一直以来都是深度学习领域关注的核心问题。</p>
<blockquote>
<p>Few-shot learning has gained much attention recently due to its minimal resource assumption.</p>
</blockquote>
<p>经过预训练阶段的PLM的出现一定程度上缓解了few-shot学习问题。当然，解决少次学习有很多其它思路，比如meta-learning。这里主要讨论的是使用PLM来解决少次学习问题的研究思路。</p>
<p><em>standard fine-tuning</em>: 我们可以直接加载PLM预训练好的参数，利用预训练过程中被参数化编码的knowledge来更好的执行各类下游任务。但是通常要实现这一目标，我们可能会引入新的额外参数，比如对于分类问题，需要加上新的classification head。为了适应下游任务引入的新参数，一方面对于每个新的任务都需要学习额外的新参数，限制了模型的泛化能力。另一方面，这造成PLM在预训练时的预测模式和微调时的预测模式之间存在差异。</p>
<p>因此，<em>prompt-based approaches</em>方法出现了。它们通过将下游任务转化为natural language prompt这种统一format的形式，把下游任务的预测目标转化为预训练时的objective比如predicting next token，这样就实现了填补预训练阶段和下游任务阶段之间的gap，能够更好的利用/激发PLM在预训练阶段获得的language modeling ability。</p>
<p>沿着这个prompt-based approaches来进行downstream tasks思路有很多探究工作，比如：</p>
<ul>
<li>利用task prompt/将训练数据作为in-context demonstrations来finetune PLM（自然语言的、discrete/hard prompt）</li>
<li>之后有工作尝试通过gradient-based searching (Shin et al., 2020)或parameterizing prompts as continuous learnable embeddings (Lester et al., 2021; Zhang et al., 2022; Zhong et al., 2021)实现自动获取prompt（数值的、continuous/soft prompt）</li>
</ul>
<p>在PLM参数比较小的情况下，微调PLM是主要的利用PLM的方法。但是随着PLM参数量的不断增加，PLM的能力基本上不断增强，也就是<em>large language model</em>。一方面是微调PLM的成本越来越大、隐私、商业PLM不开源等问题；另一方面是即便不微调，很多任务也可以直接通过巧妙的调用PLM来解决（ICL、CoT等）。目前大多涉及到用大规模参数PLM解决各种下游任务是工作是不微调PLM的。</p>
<p>这篇工作不讨论这种几十B、上百B参数量的PLM，还是基于在PLM处在一个相对可以接受的参数量的情况下。上面提到的prompt-based approaches方法训练出来的model，和有大量labeled data训练出来的model的性能比起来仍然有很大差距。</p>
<h3 id="data-augmentation">1.2 Data Augmentation</h3>
<p>因此，有另外一种思路是不直接fine-tuning PLM on few-shot samples，而是尝试让PLM构造更多的训练数据。这就是<em>data augmentation</em>。</p>
<blockquote>
<p>Data augmentation methods aim to create similar samples to the existing ones so that the enlarged training set can benefit model generalization.</p>
</blockquote>
<p>data augmentation方法在各个领域都有很多的研究。比如在CV领域，通过旋转、翻折、裁剪等简单的方法可以创建更多的image samples。这里主要关注在NLP领域的数据增强。基本的发展思路有：</p>
<ul>
<li>基于规则的方法：利用人工设计的规则如同义词替换、随机插入token等获得新的text samples [<em>EDA: Easy data augmentation techniques for boosting performance on text classification tasks. 2019</em>]。但是这种方法一方面会降低原来text的fluency；一方面可能会破坏text原本的semantic。</li>
<li>基于PLM生成式的方法：将PLM在下游任务的少量labeled samples上进行训练，以学习label-conditioned generation probability。</li>
</ul>
<p>这篇工作沿着基于PLM生成式的方法来进行数据增强。</p>
<h3 id="controlled-text-generation">1.3 Controlled Text Generation</h3>
<blockquote>
<p>The goal of controlled text generation is to generate textual contents of desired semantics, styles or attributes.</p>
</blockquote>
<p>可控文本生成是对于PLM输出的控制。要达到这一点有不同的方法：</p>
<ul>
<li>During pretraining: control codes (Keskar et al., 2019) can be used as explicit guidance for training the model to generate domain/attributespecific texts; fine-tuning PLMs with attribute-specific data can also grant high-level control (e.g., certain topics or sentiments (Ziegler et al., 2019)), fine-grained control (e.g., specific words or phrases (Chan et al., 2021)) or both (Khalifa et al., 2021);</li>
<li>at inference time: control over desired attributes can also be enforced without updating the PLM parameters (Dathathri et al., 2020; Krause et al., 2021; Kumar et al., 2021; Liu et al., 2021a; Pascual et al., 2021; Yang &amp; Klein, 2021).</li>
</ul>
<p>利用PLM，让PLM能够根据不同label生成期望的data，也是一种可控text生成。</p>
<h2 id="introduction">2. Introduction</h2>
<p><strong>Issue</strong>: 之前的微调PLM进行数据生成的方法，没有显式地建模不同label之间的区别，可能导致在生成相似label对应的训练数据时，生成数据的质量难以保证。</p>
<p><strong>Soluation</strong>: 作者认为在生成的时候，应该考虑token对于label的独特性。</p>
<h2 id="method">3. Method</h2>
<p>作者提出的方法的总体结构图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031211555513.png"  style="zoom:50%;" /></p>
<h3 id="preliminaries">3.1 Preliminaries</h3>
<p>假定存在<span class="math inline">\(L\)</span>个label，每个类型有<span class="math inline">\(K\)</span>个训练数据，<span class="math inline">\(K\)</span>是一个很小的值，如<span class="math inline">\(K=16\)</span>。组成了训练集<span class="math inline">\(D_{train} = \{(\mathbf{x}, y)_i\}\)</span>。其中，<span class="math inline">\(\mathbf{x} = [x_1,x_2,\dots,x_n]\)</span>表示长度为<span class="math inline">\(n\)</span>个tokens的text。类似的，还有<span class="math inline">\(D_{dev}\)</span>和<span class="math inline">\(D_{test}\)</span>。</p>
<p>我们要在训练集上训练一个data generator，<span class="math inline">\(G_{\mathbf{\theta}}\)</span>，来构造新的数据，所有新的生成数据构成了新的数据集合<span class="math inline">\(D_{gen}=\{ (\tilde{\mathbf{x}},\tilde{y})_i \}\)</span>。</p>
<p>我们用<span class="math inline">\(C_\phi\)</span>表示训练出来执行downstream task的分类器模型。</p>
<p>之前常见的训练数据生成器的方法是利用autoregressive PLM <span class="math inline">\(G_{\mathbf{\theta}}\)</span>在<span class="math inline">\(D_{train}\)</span>上按照maximum likelihood generation loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231030233718879.png"  style="zoom:40%;" /></p>
<p>其中，<span class="math inline">\(\mathbf{h}_j\)</span>表示是对于第<span class="math inline">\(j\)</span>个位置PLM编码输出的embedding，<span class="math inline">\(\mathbf{e}_{j}\)</span>表示正确的原来token <span class="math inline">\(j\)</span>的token embedding，一共有<span class="math inline">\(V\)</span>个候选token。期望正确token的输出概率<span class="math inline">\(p_\theta\)</span>最大。训练结束后，就可以利用<span class="math inline">\(G_\theta\)</span>按照学习到的概率不断采样新的tokens，获得新的生成数据。</p>
<p>但是如果直接在一个很小的训练集上，更新所有的PLM参数<span class="math inline">\(\mathbf{\theta}\)</span>是不必要的。作者这里是利用prefix-tuning的方法，固定model整体的参数，只更新prefix vectors <span class="math inline">\(\mathbf{\theta}_p\)</span>，即最后学习到的data generator是<span class="math inline">\(G_{\mathbf{\theta}_p}\)</span>。</p>
<h3 id="label-discriminative-text-generator-tuning">3.2 Label-Discriminative Text Generator Tuning</h3>
<p>对于带有label的任务来说，能够让生成的数据和label匹配是必要的。不同的label对应的数据可能有自己特有的pattern。而要学习conditional text generation probability <span class="math inline">\(p(\mathbf{x}|y_l)\)</span>。最直接的方法是针对不同的label <span class="math inline">\(l\)</span>有自己的参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>，直接优化generative likelihood：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031100418153.png"  style="zoom:50%;" /></p>
<p>上面的方法没有考虑到label discriminativeness (/dɪˈskrɪmənətɪv/) <span class="math inline">\(p(y_l|\mathbf{x})\)</span>也就是期望被downstream能够学习到的到的真实/理想分布。最理想的情况下，是期望生成的新数据：</p>
<ul>
<li><span class="math inline">\(y_l\)</span>是正确的</li>
<li>理论上，一个有足够能力的task model，可以根据<span class="math inline">\(\mathbf{x}\)</span>非常confidence/明确的输出<span class="math inline">\(y_l\)</span></li>
</ul>
<p>如果生成的数据从理论上/让人类去判断，根据<span class="math inline">\(\mathbf{x}\)</span>既可以被分类为<span class="math inline">\(y_1\)</span>，又可以被分类为<span class="math inline">\(y_2\)</span>，很明显这个不是我们期望的理想数据。</p>
<p>对于很多challenging NLP tasks，是存在不同label之间有很相似的distributions的，不同label之间的差别很微妙。比如对于一个movie review：<code>a movie where the ending feels like a cop-out</code>，根据最后的<code>cop-out</code>可以判断这个是一个negative review（认为这个电影的结尾是个逃避式的结尾，比如作者选择了一种非常简单没法让人满意的方式结束了剧情，对于很多情节没有交代清楚）；但如果仅仅是调整下最后的表达，换为<code>revelation</code>，就变为了一个positive review（认为电影的结尾有新意，出乎人的意料）。</p>
<p>为了评估label-discriminativeness，作者定义了一个新的loss，也就是某个text token <span class="math inline">\(j\)</span>，在使用label <span class="math inline">\(l\)</span>时的对应参数 <span class="math inline">\(\mathbf{\theta}_p\)</span>的情况下出现的概率和使用其它labels的对应参数时生成的概率的比值：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031104013187.png"  style="zoom:50%;" /></p>
<p>作者观察到，如果仅仅是优化前面的生成式的loss <span class="math inline">\(\mathcal{L}_{gen}\)</span>，label-discriminative loss <span class="math inline">\(\mathcal{L}_{disc}\)</span>甚至是在增加的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031104530173.png"  style="zoom:50%;" /></p>
<p>对于这个现象的解释是，在优化生成式loss的过程中，每个token对于最后的loss有相同的loss weight <span class="math inline">\(1\)</span>。而大多数的token是label-indiscriminate，那么优化<span class="math inline">\(\mathcal{L}_{gen}\)</span>只需要让大多数的token，在无论输入参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>的情况下，都进行输出。就能够让<span class="math inline">\(\mathcal{L}_{gen}\)</span>在全局上越来越小。例如输入<code>a movie</code>，接下来的<code>that</code>在输入任意<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>的情况下，出现概率都差不多。让更多的token出现概率不会随着输入参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>变化，可能是让<span class="math inline">\(\mathcal{L}_{gen}\)</span>不断减小的较优解。</p>
<p>那么如何让PLM学会针对不同的label，生成的data有区别呢？</p>
<p>最直接的做法是同时优化label-discriminative loss <span class="math inline">\(\mathcal{L}_{disc}\)</span>。但这么做可能不会带来理想的结果，可能会让PLM倾向于对每个位置上的tokens都针对不同label用独特的描述。但是想到<code>the</code>这些词实际上是不需要随着label变化的。</p>
<p>也就是说我们需要让PLM能够学会将不同的token区分出来，关注到其中是label-discriminative的tokens。我们可以给每个token赋予不同的loss weight <span class="math inline">\(w_j\)</span>，如果一个位置上的token是label-discriminative的，那么就增大它的loss weight <span class="math inline">\(w_j\)</span>。这样实现让PLM在优化生成loss的时候，要更多的关注根据当前输入的label参数<span class="math inline">\(\mathbf{\theta}_{p_l}\)</span>和输出的label-discriminative的对应。比如输入的label是negative，输出的关键token是<code>cop-out</code>这样的词；输入的label是positive，输出的关键token是<code>revelation</code>这样的词。再比如如果出现<code>bad</code>/<code>good</code>这样的word，很明显也应该关注。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031112600909.png"  style="zoom:50%;" /></p>
<p><span class="math inline">\(w_j\)</span>是随着不同的text变化的，要想提前人工设定好是不实际的。那么就需要某种方法来自动学习<span class="math inline">\(w_j\)</span>。</p>
<p>首先，如果让<span class="math inline">\(w_j\)</span>看做是一个可学习的参数，赋值给输入的<span class="math inline">\(\mathbf{x}\)</span>上的不同tokens，然后通过优化上面的<span class="math inline">\(\mathcal{L}_{w-gen}\)</span>学习不同的token loss weight。但这意味着我们需要给每个训练数据的每一个token都学习一个参数<span class="math inline">\(w_j\)</span>。虽然这种做法可以实现，但很明显这种做法很笨拙，并且仅仅在样本量非常小的情况下可以应用。</p>
<p>作者的做法是借鉴了meta-learning的思想，将这个优化问题看做是bi-level optimization问题。</p>
<p>对于generator要优化的参数，还是通过optimize生成loss来获得：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031145421032.png"  style="zoom:50%;" /></p>
<p>这里每个token的loss weight是通过<span class="math inline">\(w_j(\mathbf{\omega})\)</span>函数计算得到的，它是一个带有softmax的feedforward network，输入是每个token计算得到的discriminative loss <span class="math inline">\(\mathcal{L}_{disc}^j\)</span>: <span class="math display">\[
g_{\mathbf{\omega}} (\mathcal{L}_{disc}^j) = FFN(\mathcal{L}_{disc}^j) \\
w_j(\mathbf{\omega}) = \frac{exp(g_{\mathbf{\omega}} (\mathcal{L}_{disc}^j))}{\sum_{j^\prime = 1}^n exp(g_{\mathbf{\omega}} (\mathcal{L}_{disc}^{j^\prime}))}
\]</span> 这样输入的一个text不同位置的所有token的loss weight和是<span class="math inline">\(1\)</span>。</p>
<p>对于要优化的weighting parameters <span class="math inline">\(\omega\)</span>是通过优化outer objective <span class="math inline">\(\mathcal{L}_{disc}\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031150702010.png"  style="zoom:50%;" /></p>
<p>具体的优化过程是两者迭代的进行优化：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031150843652.png"  style="zoom:40%;" /></p>
<p>步骤：</p>
<ul>
<li>采样一个batch集合<span class="math inline">\(\mathcal{B}\)</span></li>
<li>根据上一个优化步骤得到的<span class="math inline">\(\omega\)</span>计算不同token的weight，然后优化生成loss，生成一个暂时的更新后的生成器参数<span class="math inline">\(\mathbf{\hat{\theta}}_p^{(t)}\)</span>；</li>
<li>根据<span class="math inline">\(\mathbf{\hat{\theta}}_p^{(t)}\)</span>，计算不同位置的<span class="math inline">\(\mathcal{L}_{disc}^j\)</span>，优化weighting network parameters <span class="math inline">\(\omega\)</span>，获得<span class="math inline">\(\omega^{(t+1)}\)</span>；</li>
<li>用新的<span class="math inline">\(\omega^{(t+1)}\)</span>计算不同token的weight，优化生成loss，获得新的生成器参数<span class="math inline">\(\mathbf_p^{(t+1)}\)</span>；</li>
</ul>
<p>我们可以计算一下，在优化两个loss的情况下，对应的新的参数更新：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031152339639.png"  style="zoom:50%;" /></p>
<p>上面的优化过程中，<span class="math inline">\(w_j\)</span>越大，对于最后参数更新的影响也越大，新的参数<span class="math inline">\(\theta_p\)</span>更会朝着能够使得<span class="math inline">\(w_j\)</span>比较大的token的生成loss减小的梯度方向进行优化。</p>
<p>对于<span class="math inline">\(\omega\)</span>的更新：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031152759758.png"  style="zoom:50%;" /></p>
<p>后面这一项继续展开：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031152848181.png"  style="zoom:40%;" /></p>
<p>也就是说：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031153515784.png"  style="zoom:50%;" /></p>
<p><span class="math display">\[
\mathbf{\omega}^{t+1} = \mathbf{\omega}^{t} + \alpha \beta \sum_{j=1}^n d_j  \frac{\partial{w_j(\mathbf{\omega})}}{\partial{\mathbf{\omega}}}
\]</span></p>
<p><span class="math inline">\(d_j\)</span>代表着优化第<span class="math inline">\(j\)</span>个token的生成loss和优化discriminative loss对于参数<span class="math inline">\(\theta_p\)</span>梯度的相似程度。越大越相似，也就是说这个位置上的token，优化它的discriminative loss和generative loss都能够一致的减小。举例，对于前面提到的<code>good</code>/<code>bad</code>这些token，重点针对它们优化generative loss，能够使discriminative loss也减小。可以看出，<span class="math inline">\(\omega^{t+1}\)</span>最后优化方向会更多朝着<span class="math inline">\(d_j\)</span>比较大token，增大其<span class="math inline">\(w_j\)</span>的方向进行优化。</p>
<p>接下来是怎么样训练分类器<span class="math inline">\(C_\phi\)</span>，最大的问题是生成的data里无法避免的会存在错误标注的数据，也就是存在label noise。为了实现这一点，作者使用了一个简单的noise-robust training procedure。首先，先是在<span class="math inline">\(\mathcal{D}_{train}\)</span>上进行训练。然后在生成的数据集<span class="math inline">\(\mathcal{D}_{gen}\)</span>上进行训练。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031205511785.png"  style="zoom:50%;" /></p>
<p>这里的<span class="math inline">\(q_l = \mathbb{1} (l=\tilde{y}) (1-\epsilon ) + \epsilon/L\)</span>，如果<span class="math inline">\(l=\tilde{y}\)</span>，那么<span class="math inline">\(q_l =1- \epsilon + \epsilon/L = 1-\epsilon (L-1) / L\)</span>。如果<span class="math inline">\(l\neq\tilde{y}\)</span>，那么<span class="math inline">\(q_l = \epsilon / L\)</span>。label smooth之后，所有的标签和相加仍然是1。</p>
<p>第一项是交叉熵，第二项是针对temporal ensembling的正则项。其中是<span class="math inline">\(\bar{z}\)</span>是ensembled predictions，<span class="math inline">\(\hat{z}\)</span>是accumulated model prediction，<span class="math inline">\(p_\phi\)</span>是current model prediction：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031210559801.png" alt="image-20231031210559801" style="zoom:50%;" /></p>
<p>第二项的意思是期望降低当前的预测结果current model prediction <span class="math inline">\(p_\phi\)</span>和历史累积预测结果<span class="math inline">\(\bar{z}\)</span>之间的差异。也就是稳定更新参数后的task模型的预测结果与没有更新参数前的预测结果的变化。并且在这个过程中，只有计算出来的累积预测分布大于阈值<span class="math inline">\(\delta=0.8\)</span>的才会被考虑加入到训练过程中。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031211445616.png"  style="zoom:40%;" /></p>
<h2 id="experiments">4. Experiments</h2>
<h3 id="experimental-setup">4.1 Experimental Setup</h3>
<p>作者在GLUE这个benchmark上进行了实验。</p>
<p>使用CTRL（1.6B）作为data generator，使用RoBERTa-Large（356M）作为downstream task model。</p>
<h3 id="results">4.2 Results</h3>
<p>主要实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031213554404.png"  style="zoom:50%;" /></p>
<p>消融实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031214540871.png" style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031214711151.png"  style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20231031214920876.png"  style="zoom:40%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>Data Augmentation</category>
      </categories>
      <tags>
        <tag>Data Augmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>Demonstration-based-NER</title>
    <url>/nlp/Demonstration-based-NER/</url>
    <content><![CDATA[<h1 id="good-examples-make-a-faster-learner-simple-demonstration-based-learning-for-low-resource-ner">Good Examples Make A Faster Learner Simple Demonstration-based Learning for Low-resource NER</h1>
<p>南加州大学，ACL 2022，<a href="https://github.com/INK-USC/fewNER">代码</a>。</p>
<blockquote>
<p>Recent advances in prompt-based learning have shown strong results on few-shot text classiﬁcation by using cloze-style templates. Similar attempts have been made on named entity recognition (NER) which manually design templates to predict entity types for every text span in a sentence. However, such methods may suffer from error propagation induced by entity span detection, high cost due to enumeration of all possible text spans, and omission of inter-dependencies among token labels in a sentence. Here we present a simple demonstration-based learning method for NER, which lets the input be prefaced by task demonstrations for in-context learning. We perform a systematic study on demonstration strategy regarding what to include (entity examples, with or without surrounding context), how to select the examples, and what templates to use. Results on in-domain learning and domain adaptation show that the model’s performance in low-resource settings can be largely improved with a suitable demonstration strategy (e.g., 4-17% improvement on 25 train instances). We also find that good demonstration can save many labeled examples and consistency in demonstration contributes to better performance.</p>
</blockquote>
<p>作者试了几种为NER任务设计的demonstrations检索和对应的模板构造方法，只不过是在bert-base上进行的实验。</p>
<span id="more"></span>
<p>作者的方法图：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613221916295.png" alt="image-20230613221916295" /><figcaption>image-20230613221916295</figcaption>
</figure>
<p>作者提了2种检索NER demonstrations的方法：</p>
<ul>
<li>Entity-oriented：就是以实体为核心进行检索，包括简单的3种方式：
<ul>
<li>random：每一类entity type中，从训练集所有的对应实体进行检索（动态的）</li>
<li>popular：每一类entity type中，选择出现次数最多top-k的对应实体（静态的）</li>
<li>search：每一类entity type中，选择出现次数最多top-k的对应实体，grid search可能的实体组合，然后在验证集上找到效果最好哦的那种组合（静态的）</li>
</ul></li>
<li>Instance-oriented：以查询的当前句子为核心，进行检索，计算和其它训练集中句子的相似度，包括2种相似度计算方法：
<ul>
<li>SBERT：计算两个句子编码后CLS token embedding的余弦相似度（动态的）</li>
<li>BERTScore：两个句子不同token之间的相似度的和（动态的）</li>
</ul></li>
</ul>
<p>在找到了训练集中的demonstration之后，怎么样构造模板，作者提了3种方式：</p>
<ul>
<li>no-context：没有训练样例里面的句子，只保留实体，“entity is type.&quot;</li>
<li>context：保留对应的句子，再加上“entity is type.&quot;的描述</li>
<li>lexical：把原来句子中的entity替换为对应的entity type。这样获取能够直接捕获到不同label之间的对应关系</li>
</ul>
<p>demonstration模板示例：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613222921680.png" alt="image-20230613222921680" /><figcaption>image-20230613222921680</figcaption>
</figure>
<p>实验部分是基于bert-base-cased去做的。把找到的demonstrations拼接到要查询的query text前面，用bert编码以后的embedding过一个CRF，就得到了NER序列标注。</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613223525296.png" alt="image-20230613223525296" /><figcaption>image-20230613223525296</figcaption>
</figure>
<p>效果最好的，就是在验证集上进行评估，选择保留context。只不过作者这里只利用到了相似度计算，没有像现有的上下文学习方法利用kNN去做检索。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>IE</category>
      </categories>
      <tags>
        <tag>IE</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM-CRF</title>
    <url>/nlp/LSTM-CRF/</url>
    <content><![CDATA[<h1 id="neural-architectures-for-named-entity-recognition">Neural Architectures for Named Entity Recognition</h1>
<p>NAACL 2016，CMU</p>
<p>作者针对NER问题，提出了基于bi-LSTM和CRF（条件随机场）的模型以及transition-based的方法s-LSTM（该模型为详细阅读）。</p>
<blockquote>
<p>State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-speciﬁc knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures—one based on bidirectional LSTMs and conditional random ﬁelds, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.</p>
</blockquote>
<span id="more"></span>
<p>作者使用双向LSTM学习sentence的context信息。</p>
<p>输入层拼接了pretrained好的word embedding以及character-level的embedding。</p>
<p>输出层采用CRF，主要原因是合理NER的标注序列是满足某些内部约束的。也就是说不同token的tag之间不是完全独立的，某个token的tag的标注会对其它token的tag标注产生影响。</p>
<p>整体模型架构：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130203736133.png" alt="image-20221130203736133" /><figcaption>image-20221130203736133</figcaption>
</figure>
<p>输入层word embedding的产生：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130203815945.png"   style="zoom:40%;" /></p>
<p>图中的<span class="math inline">\(e_{Mars}\)</span>是来自于前人基于skip-n-gram，从语料无监督学习到的word embedding。用于捕获distributional evidence（比如常常是表示实体的单词倾向于出现在什么位置？）。</p>
<p><span class="math inline">\(l_{Mars}\)</span>和<span class="math inline">\(r_{Mars}\)</span>是使用一个新的character bi-LSTM建模得到的character-level的word embedding。用于捕获语言可能具备的orthographic evidence，拼写层次的特征（比如常常成为一个name的单词通常长什么样子？）。</p>
<p>两个embedding拼接，再经过dropout，得到了最后输入到LSTM-CRF模型的final word embedding。</p>
<p>输出预测序列标签的时候，最简单的方法是使用LSTM输出的hidden state为每个token单独进行预测。但是在NER任务中，实际上在不同token输出的标签之间，存在内部的依赖，比如I-PER这个tag不可能紧跟着出现在B-LOC后面。因此，作者考虑使用Conditional Random Field对不同token的预测标签进行联合建模，而不是单独建模。</p>
<p>对于输入序列：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130205734969.png"   style="zoom:50%;" /></p>
<p>计划输出序列：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130205807567.png"   style="zoom:50%;" /></p>
<p>首先，会输出一个矩阵<span class="math inline">\(P\in R^{n\times k}\)</span>，<span class="math inline">\(n\)</span>表示<span class="math inline">\(n\)</span>个token，<span class="math inline">\(k\)</span>表示一共有<span class="math inline">\(k\)</span>个不同的tag。<span class="math inline">\(P_{ij}\)</span>就表示第<span class="math inline">\(i\)</span>个token成为第<span class="math inline">\(k\)</span>个tag的概率。</p>
<p>为了建模不同token的tag之间的依赖，还定义了一个转移矩阵transition matrix <span class="math inline">\(A\in R^{k+2\times k+2}\)</span>。<span class="math inline">\(k+1\)</span>是因为新增了表示句子start和end的tag。<span class="math inline">\(A_{ij}\)</span>表示从tag <span class="math inline">\(i\)</span>转移到tag <span class="math inline">\(j\)</span>的score。</p>
<p>因此，可以定义下面的输出NER序列score：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130210358207.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130210450926.png"   style="zoom:40%;" /></p>
<p>最大化概率目标：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130210650954.png"  style="zoom:30%;" /></p>
<p>最后，选择最大score的<span class="math inline">\(y\)</span>就是预测的NER序列。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221130210504762.png"   style="zoom:50%;" /></p>
<p>NER的输出标签，常用的IOB格式（Inside, Outside, Beginning），Beginning表示当前token是某个entity的开始，Inside表示当前token是某个entity的中间，Outside表示当前token不属于任何token。在这篇论文中，作者采用了IOB格式的拓展IOBES，除了I，O，B外还包括了singleton entities（S）和the end of named entities（E）。作者在实验中没有发现IOB和IOBES有太大差距。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>NER</category>
      </categories>
      <tags>
        <tag>KG</tag>
        <tag>NER</tag>
      </tags>
  </entry>
  <entry>
    <title>MetaNER</title>
    <url>/nlp/MetaNER/</url>
    <content><![CDATA[<h1 id="learning-in-context-learning-for-named-entity-recognition">Learning In-context Learning for Named Entity Recognition</h1>
<p>ACL 2023，中科院，<a href="https://%20github.com/chen700564/metaner-icl">代码</a>。</p>
<blockquote>
<p>Named entity recognition in real-world applications suffers from the diversity of entity types, the emergence of new entity types, and the lack of high-quality annotations. To address the above problems, this paper proposes an in-context learning-based NER approach, which can effectively inject in-context NER ability into PLMs and recognize entities of novel types on-the-fly using only a few demonstrative instances. Specifically, we model PLMs as a meta-function λ instruction, demonstrations, text .M 1 , and a new entity extractor can be implicitly constructed by applying new instruction and demonstrations to PLMs, i.e., (λ.M)(instruction, demonstrations) → F where F will be a new entity extractor, i.e., F: text → entities. To inject the above in-context NER ability into PLMs, we propose a meta-function pre-training algorithm, which pre-trains PLMs by comparing the (instruction, demonstration)-initialized extractor with a surrogate golden extractor. Experimental results on 4 few-shot NER datasets show that our method can effectively inject in-context NER ability into PLMs and significantly outperforms the PLMs+fine-tuning counterparts.</p>
</blockquote>
<p>作者提出了一种让小参数量的预训练语言模型学会针对NER任务的in-context learning的方法。</p>
<span id="more"></span>
<h2 id="introduction">1. Introduction</h2>
<p>少次NER任务的出现就是为了解决实体类型多样、新实体类型和高质量标注缺乏的问题。现有的少次NER方法包括fine-tuning-based和metric-based methods。</p>
<ul>
<li>The main drawbacks of fine-tuning-based methods are that re-training is often expensive (especially for large-scale models) and new entity types cannot be addressed on-the-fly.</li>
<li>Metric-based methods are limited to the matching architectures and are sensitive to domain shift since they do not fully explore the information of target domain.</li>
</ul>
<p>因此作者提出了让PLM模型学会ICL，根据新出现的样例学会抽取新的实体类型。（这一问题事实上LLM已经学会了，不需要额外的训练。这篇论文的重点在于如何让小的模型学会针对特定任务的上下文学习能力）。</p>
<h2 id="method">2. Method</h2>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613000405586.png" alt="image-20230613000405586" /><figcaption>image-20230613000405586</figcaption>
</figure>
<p>作者针对NER任务构造的ICL模板：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612233331196.png"   style="zoom:50%;" /></p>
<p>为了让PLM能够根据demonstrations学会抽取新的实体类型，作者提出了Meta-Function Pre-training for In-Context NER。</p>
<p>重点在于如何让PLM能够学会从demonstrations学习特征，然后能够抽取新的实体类型是重点。如果我们已知了理想的实体抽取函数，那我们只需要最小化PLM的上下文学习的输出和理想的实体抽取函数之间的差距即可。但是这样的理想函数并不存在。</p>
<p>因此，作者使用一个在demonstrations上进行参数更新的抽取模型作为替代（a surrogate extractor）。具体来说，在给定instruction <span class="math inline">\(I\)</span>, demonstration <span class="math inline">\(D\)</span>和text <span class="math inline">\(T\)</span>的情况下。先让PLM进行编码，获取到 <span class="math inline">\(I\)</span>, <span class="math inline">\(T\)</span>的特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612234144717.png"   style="zoom:50%;" /></p>
<p>instruction <span class="math inline">\(I\)</span>里包括了新的实体类型信息，text <span class="math inline">\(T\)</span>包含了待抽取的文本信息。作者拿这两种feature去和一个经过了demonstrations训练后的模型，编码的特征靠拢：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235325601.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235253164.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235433252.png"   style="zoom:40%;" /></p>
<p>注意一下，这里的<span class="math inline">\(Encoder^\prime\)</span>是拷贝了原来的encoder之后，进行梯度更新之后的编码器，不会影响原来的encoder。</p>
<p>仅仅是学习如何进行上下文学习是不够的，更重要的是我们要学会识别实体。因此作者还有一个loss是针对实体识别进行优化的。不过作者是用语言模型的loss来构造实体抽取的loss：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230612235631628.png"  style="zoom:40%;" /></p>
<p>作者除了一般的信息抽取任务的形式，还提出了一种Pseudo Extraction Language Modeling Task。因为有实体标注的数据和没有实体标注数据之间的比例差距很大。因此作者想办法从一般的句子中也能够仿照NER任务构造出未标注来。比如：</p>
<p>instruction=&quot;Target types:<type2>;<type14>&quot;</p>
<p>demonstrations=&quot;Text: [MASK1] is cool and I really [MASK2] it [MASK3]. Entities: [MASK1] is <type2>. [MASK2] is <type14>&quot;（原来的句子I think this movie is cool and I really like it very much）</p>
<p>text=“Text: I do not like it.”</p>
<p>要预测的输出output是”like is <type14>“</p>
<p>将语言mask建模和span-based NER任务进行了统一。</p>
<h2 id="experiments">3. Experiments</h2>
<p>预训练的数据是通过对齐Wikipedia和Wikidata进行构造的。</p>
<p>测试结果（没有在对应NER数据集上进行训练）：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613000330165.png" alt="image-20230613000330165" /><figcaption>image-20230613000330165</figcaption>
</figure>
<p>效果还是比不过直接在NER数据集上进行训练，好处是可以处理新出现的实体类型，更有实际意义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230613002007764.png"   style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>IE</category>
        <category>ICL</category>
      </categories>
      <tags>
        <tag>IE</tag>
        <tag>ICL</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer</title>
    <url>/nlp/Transformer/</url>
    <content><![CDATA[<h1 id="attention-is-all-you-need">Attention Is All You Need</h1>
<p>NIPS 2017</p>
<p>本文提出了一个新的简单的网络结构，Transformer，只依赖于注意力机制。</p>
<p><a href="http://jalammar.github.io/illustrated-transformer/">可参考的博客</a></p>
<span id="more"></span>
<h2 id="introduction">1 Introduction</h2>
<p>RNN等模型已经取得了很大的成功，但是计算循环网络的代价通常会与输入输出序列的符号位置紧密相关。序列的符号位置决定了循环网络中输入的步数，导致很难并行化，就在时间和计算资源（内存）上限制了模型的训练。</p>
<p>注意力机制在sequence modeling 和 transduction models任务上已经取得了很大的成就，但是很少有模型会将注意力机制与RNN联系在一起。</p>
<p>本文就提出了一个新的方法Transformer，避免了循环，相反的是基于注意力机制完全依赖于输入和输出的整体。</p>
<blockquote>
<p>Transformer is the ﬁrst transduction model relying entirely on self-attention to compute representations of its input and output without using sequencealigned RNNs or convolution.</p>
</blockquote>
<h2 id="model-architecture">2 Model Architecture</h2>
<p>整个Transformer的结构是encoder和decoder的结构，如下图所示。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201011202918546.png" style="zoom:50%;" /></p>
<p>整体堆叠6层encoder，然后经过6层的decoder。6层encoder的最终输入会输入到每一层的decoder中。</p>
<p>每一层encoder包括两个sublayer，一个接受input的输入，然后经过<span class="math inline">\(h\)</span>个多头注意力，残差加上原来的输入，之后norm（这叫做post-normalization，指layernorm放在残差之后，实际上后来很多工作使用的是pre-normalization，也就是先norm，再经过attention或FFN，最后残差，可参考ViT的结构），第二层经过一个前馈网络，还是残差加上原来的输入，经过norm。encoder的初始输入是全部的原始输入。</p>
<p>每一层的decoder包括三个sublayer，有两个与encoder一样，但是多了一层会接受encoder的输出作为keys和values。decoder的初始输入是<span class="math inline">\(t-1\)</span>时刻的预测结果以及encoder的输出。</p>
<p>下面详细解析：</p>
<h3 id="multi-head-attention">2.1 Multi-head attention</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20201011204804340.png" style="zoom:50%;" /></p>
<p>首先计算单个attention，使用query，keys和values来计算。使用query和其它所有embedding的keys计算出权值，然后不同的权值与values相乘求和。querys和keys的维度是<span class="math inline">\(d_k\)</span>，values的维度是<span class="math inline">\(d_v\)</span>。 <span class="math display">\[
Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V
\]</span> 需要注意的是其中多了一个常量<span class="math inline">\(\sqrt{d_k}\)</span>，这是因为作者在实验中发现加入除数常量的效果很好，原因可能是因为softmax的输入在值较大的时候梯度会变小，因此加入了一个除数常量减小值。</p>
<blockquote>
<p>4 To illustrate why the dot products get large, assume that the components of q and k are independent random variables with mean 0 and variance 1. Then their dot product, <span class="math inline">\(q\cdot k=\sum^{d_k}_{i=1}q_ik_i\)</span> , has mean 0 and variance<span class="math inline">\(d_k\)</span> .</p>
</blockquote>
<p>除以<span class="math inline">\(\sqrt{d_k}\)</span>是为了防止在d_k特别大的时候，也就是hidden embedding维度比较大的时候，计算出来的注意力weight呈现出只有一个值非常靠近<span class="math inline">\(1\)</span>，其它值靠近<span class="math inline">\(0\)</span>的情况，这会导致bp的时候的梯度就很小，几乎是0。</p>
<p>除以<span class="math inline">\(\sqrt{d_k}\)</span>能够把输入softmax的absolute attention weight的值都scale的小一点； 减低指数函数<span class="math inline">\(e(\cdot)\)</span>带来的放大效应/马太效应。详细的数学解释可以参考<a href="https://towardsdatascience.com/transformer-networks-a-mathematical-explanation-why-scaling-the-dot-products-leads-to-more-stable-414f87391500">Transformer Networks: A mathematical explanation why scaling the dot products leads to more stable gradients</a></p>
<p>计算完成单个attention之后，再计算多头注意力，拼接起来之后再乘以一个权值矩阵： <span class="math display">\[
MultiHead(Q,K,V)=Concat(head_1,\dots,head_h)W^O
\]</span> 在实践中，使用了8个头，每个维度64，一共维度512。每一个头都可以看做是好比CNN中的不同的卷积通道，每个head独立训练，有自己的参数，期望每个head能够学习到不同的pattern。高层和底层、同一层的不同head有可能学习到不同的知识（这一点有相关文章探讨，发现不同注意力层会捕获不同层次的信息，但是每一层的不同head可能只有几个会学习到不同的pattern，比如不同的attention分布）。</p>
<p>decoder的结构与encoder类似，但是它多了一层encoder和decoder。</p>
<h3 id="self-attention">2.2 self-attention</h3>
<p>第一步：对于输入的每一个vector创建3个新的vector， a Query vector, a Key vector, and a Value vector。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/self-attention_softmax.png" style="zoom:50%;" /></p>
<p>第二步：计算单个的score，比如说计算第一个词Thinking，需要计算整个序列当中所有的vector对于Thinking的vector的重要程度，使用Thinking的query vector和其它所有的key vector做dot product。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/transformer_self_attention_score.png" style="zoom:50%;" /></p>
<p>第三步与第四步：实际是归一化socre，相当于产生relative score。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/self-attention-output.png" style="zoom:50%;" /></p>
<p>第五步：各个word vector与relative score相乘，求和。这样编码后的某个位置的新的embedding是由前一步所有输入的embedding共同决定的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/self-attention-matrix-calculation.png" style="zoom:50%;" /></p>
<p>第六步：矩阵形式的实际计算情况</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/transformer_decoder_output_softmax.png" style="zoom:50%;" /></p>
<h3 id="encoder-and-decoder">2.3 Encoder and Decoder</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/transformer_self_attention_vectors.png" style="zoom:50%;" /></p>
<h3 id="the-final-linear-and-softmax-layer">2.4 The Final Linear and Softmax Layer</h3>
<p>decoder的输出，经过一个全连接层，然后得到logits vector，其中每一维度对应一个word；再经过softmax，取出score最大的word。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/Screen-Shot-2020-10-13-at-8-46-23-PM.png" style="zoom:50%;" /></p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>when-how-paraphrase-NER</title>
    <url>/nlp/when-how-paraphrase-NER/</url>
    <content><![CDATA[<h1 id="when-and-how-to-paraphrase-for-named-entity-recognition">When and how to paraphrase for named entity recognition?</h1>
<p>ACL 2023</p>
<blockquote>
<p>While paraphrasing is a promising approach for data augmentation in classification tasks, its effect on named entity recognition (NER) is not investigated systematically due to the difficulty of <strong>span-level label preservation</strong>. In this paper, <strong>we utilize simple strategies to annotate entity spans in generations and compare established and novel methods of paraphrasing in NLP such as back translation, specialized encoder-decoder models such as Pegasus, and GPT-3 variants for their effectiveness in improving downstream performance for NER</strong> across different levels of gold annotations and paraphrasing strength on 5 datasets. We thoroughly explore the influence of paraphrasers, dynamics between paraphrasing strength and gold dataset size on the NER performance with visualizations and statistical testing. We find that the choice of the paraphraser greatly impacts NER performance, with one of the <strong>larger GPT-3 variants exceedingly capable of generating high quality paraphrases, yielding statistically significant improvements in NER performance with increasing paraphrasing strength,</strong> while other paraphrasers show more mixed results. Additionally, inline auto annotations generated by larger GPT-3 are strictly better than heuristic based annotations. We also find diminishing benefits of paraphrasing as gold annotations increase for most datasets. Furthermore, while most paraphrasers promote entity memorization in NER, the proposed GPT-3 configuration performs most favorably among the compared paraphrasers when tested on unseen entities, with memorization reducing further with paraphrasing strength. Finally, we explore mention replacement using GPT-3, which provides additional benefits over base paraphrasing for specific datasets.</p>
</blockquote>
<p>系统的分析了不同设置，不同的模型，用改写sentence的方式来做NER任务的data augmentation。</p>
<span id="more"></span>
<h2 id="datasets-and-paraphrasers">Datasets and Paraphrasers</h2>
<p>作者选择了5个不同领域的NER数据集。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221.png"   style="zoom:40%;" /></p>
<p>作者先对比两个已有的Paraphrasers工具：</p>
<ul>
<li>基于Back-translation（BT）：For our experiments we use pre-trained English-German and German-English models (∼738M parameters) available from Huggingface model hub via Tiedemann and Thottingal (2020) and the model architecture used is BART (Lewis et al., 2019).</li>
<li>基于PEGASUS：We use an off-the-shelf version of PEGASUS fine-tuned for paraphrasing released on Huggingface model hub. 3</li>
</ul>
<p>然后，作者利用两个GPT-3模型：<code>text-ada-001</code> (∼350M parameters), and <code>text-davinci-002</code> (∼175B parameters)。使用的temperature为0.8。</p>
<p>采用了两种prompt，一种是没有指定保留entity label的；一种是指定改写后的句子要保留entity mention和label的：</p>
<p>Prompt A：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214706736.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214723114.png"   style="zoom:40%;" /></p>
<p>Prompt B：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214754741.png"   style="zoom:40%;" /></p>
<p>对于改写后的句子，需要经过处理。首先是使用原来的entity mention进行case insensitive exact match标注entity span label。然后要过滤掉一些明显错误的句子：</p>
<ul>
<li>remove paraphrases for gold sentences shorter than 15 characters</li>
<li>remove paraphrases that are a duplicate of the gold sentence or of another paraphrase</li>
<li>remove paraphrases that generation contains an entity not present in entity space of the dataset</li>
</ul>
<p>对于不同改写方法的能力，除了可以用训练实验性能来评估外，作者还从两个方面进行评估：</p>
<ul>
<li>entity preservation：有多少原来句子中的entity mention会准确的出现在改写后的句子里？自动计算entity recall</li>
<li>paraphrase quality：人工给改写后的句子质量打分，既要多样性，又要preserving the meaning faithfully 保持原来句子的语义</li>
</ul>
<p>评估结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916215718419.png"   style="zoom:50%;" /></p>
<p>综合来看，基于GPT-3的改写能力是最好的。</p>
<h2 id="experiments">Experiments</h2>
<h3 id="using-gold-paraphrasing-data-for-training-ner">Using gold &amp; paraphrasing data for training NER</h3>
<h4 id="experimental-setup">Experimental setup</h4>
<p>同时使用原有的gold data和改写后的data进行训练。下面是一些基础的实验设置：</p>
<ul>
<li>the corresponding dataset is used to fine-tune a distilbert-base-cased base (66M parameters) model (Sanh et al., 2019)</li>
<li>作者详细对比了两种不同的data占比：
<ul>
<li>gold ratio (G-ratio) what percentage of gold data is used in a particular configuration 是指gold samples占全部training set的比例，<span class="math inline">\(G=0.01\)</span>表示使用<span class="math inline">\(1\)</span>%的原有所有训练样本作为gold data。</li>
<li>paraphrase ratio (P-ratio) what is the ratio of number of paraphrases compared to number of gold samples 是指gold samples的倍数，<span class="math inline">\(P=0.25\)</span>表示改写的数据是gold data的<span class="math inline">\(1/4\)</span>，<span class="math inline">\(P=0.0\)</span>代表不经过改写。</li>
</ul></li>
</ul>
<p>然后，为了调查训练好的NER模型的性能的变化受哪些因素影响。作者使用一些简单的统计特征，基于线性回归分析这些特征是否会导致NER F1指标的变化：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916220444026.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916220458842.png"   style="zoom:50%;" /></p>
<h4 id="results">Results</h4>
<p>先来看不同改写方法的效果。下面图中：</p>
<ul>
<li>一个方格表示一种改写方法</li>
<li>方格里的数值score的计算：如果某个方法在1个数据集上通过改写数据增强方法获得了效果提升，那么<span class="math inline">\(score+1\)</span>。如果效果下降，<span class="math inline">\(score-1\)</span>。一共有5个实验dataset，所以最低是<span class="math inline">\(-5\)</span>，最高是<span class="math inline">\(+5\)</span>。</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916220723109.png"   style="zoom:50%;" /></p>
<p>观察：</p>
<ul>
<li>GPT-3 DaV-B consistently outperforms, or matches other paraphrasers and is a safe default choice for paraphrasing across domains. GPT-3总是有效果的，可以考虑总是使用GPT-3来改写句子</li>
<li>数据增强在low-resource的情况下比较有效；当NER gold data逐渐增加的情况下，数据增强的效果逐渐减小</li>
</ul>
<p>线性回归分析的结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916220923007.png"   style="zoom:25%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916220940162.png"   style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li>Table 4中<span class="math inline">\(P\)</span>表示gold rate，而<span class="math inline">\(P\)</span>的影响系数<span class="math inline">\(\hat{\beta}=0.0148&gt;0\)</span>，<span class="math inline">\(P\)</span>和生成数据的比值<span class="math inline">\(G\)</span>的交互变量<span class="math inline">\(P:G\)</span>的影响系数<span class="math inline">\(\hat{\beta}=-0.0032&lt;0\)</span>。这说明更多的改写后生成的data能够有效的提升模型效果。但是当有更多gold data的时候，这种提升的趋势有一定程度的减弱；</li>
<li>有更少样例的entity class更容易从基于改写的数据增强策略中收益；</li>
<li>越长的entity mention有可能越难被预测，改写数据增强带来的提升越小；</li>
<li>大小写这种surface level的feature，对最终效果的变化没有特别大的影响；</li>
</ul>
<h3 id="using-only-paraphrases-for-training-ner">Using only paraphrases for training NER</h3>
<p>完全使用生成的数据来训练一个NER模型来评估生成数据的质量。</p>
<p>使用原来的测试集进行测试，测试结果发现还是GPT-3效果最好：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916221617132.png"   style="zoom:30%;" /></p>
<h4 id="entity-memorization">Entity Memorization</h4>
<p>作者关注数据增强可能带来的一个问题Entity Memorization。即目前基于改写的数据增强方法，没有改变entity mention，生成的data中出现了entity的重复。因此作者想检查模型是不是直接记住了entity和它对应的label，而不是学会从feature推测label。</p>
<p>如果是记忆，那么model意味着模型走了捷径shortcut learning [<em>Shortcut learning in deep neural networks. Nature 2020</em>]，那么此时model应该无法准确处理没有见过的entity。</p>
<p>因此，作者又进行了在test set中，不同entity type里，没有在训练集里出现过的entity作为新的测试集unseen entity (UE) test sets。</p>
<p>作者认为，如果entity memorization现象加重了，那么在UE测试集里，model的指标F1会出现下降：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223039664.png"   style="zoom:50%;" /></p>
<p>和前面类似，作者同样基于线性回归分析对这一现象出现的原因进行了调研。</p>
<h4 id="results-1">Results</h4>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223212876.png"  style="zoom:30%;" /></p>
<p>观察：</p>
<ul>
<li><p>GPT-3 Davichi相对来说能够缓解模型Entity Memorization问题</p></li>
<li>对于有很多样例的entity class，改写可能加重了对相应entity的记忆</li>
<li><p>带有数字的entity似乎更加容易被model记住</p></li>
</ul>
<p>为了缓解entity memorization问题，作者提出了一种解决方法Mention replacement（MR）。那就是不要重复entity mention，用GPT生成新的entity mention，然后去替换生成句子中的entity mention：</p>
<blockquote>
<p>In particular, for every entity mention in the gold set, we prompt GPT-3 DaVinci model to generate entity mentions that are similar to the gold entity mention, while also providing a phrase level definition of the entity type being replaced.</p>
</blockquote>
<p>使用到的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223735026.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223753805.png"   style="zoom:50%;" /></p>
<p>进行了entity mention后的效果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223834430.png"  style="zoom:30%;" /></p>
<p>不是所有数据集上，直接替换entity mention都是有效果的。</p>
]]></content>
      <categories>
        <category>Paper</category>
        <category>NER</category>
        <category>Data Augment</category>
      </categories>
      <tags>
        <tag>Data Augment</tag>
        <tag>LLM</tag>
        <tag>NER</tag>
      </tags>
  </entry>
  <entry>
    <title>camera-tutorial1</title>
    <url>/z-personal-taste/camera-tutorial1/</url>
    <content><![CDATA[<h1 id="相机与摄像入门笔记">相机与摄像入门笔记</h1>
<p><a href="https://www.bilibili.com/video/BV1pv411H78e/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&amp;vd_source=2862656caae0c18be380254a92306b47">教程来源，B站，从零开始手把手教你学摄影，20节课带你从小白到大师</a></p>
<span id="more"></span>
<h2 id="认识你的相机">1. 认识你的相机</h2>
<p>相机分类方式：</p>
<ul>
<li>可更换镜头相机</li>
<li>不可更换镜头相机</li>
</ul>
<p>作为个人业余用户，可更换镜头相机是最常用的。接下来重点讲解。</p>
<p>可更换镜头相机市面上主流有两类，单反和微单，两者的主要区别是光学结构的不同，这也导致了两种相机在体型上的差距，单反通常会更大一点。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023164758493.png"   style="zoom:50%;" /></p>
<ul>
<li>单反：包括了一个反光镜和五棱镜。单反如果进入实时取景模式，会抬起反光镜，那么此时它和微单是一样的。</li>
<li>微单：光线可以直接照射到传感器。</li>
</ul>
<p>尽管结构更简单，但是微单并不是比单反效果要差。实际上，微单才是未来相机的趋势。</p>
<p>第二种分类方式是根据传感器的大小。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023165146594.png" /></p>
<p>传感器的大小就是我们常说的底，或者是CMOS，它决定了我们画幅的大小。</p>
<p>大画幅作为普通人很少接触。</p>
<p>中画幅作为新手也很少接触。</p>
<p>全画幅和残画幅是新手接触比较多的。</p>
<p>相机画幅的大小可以很简单的看出来。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023193621965.png"   style="zoom:50%;" /></p>
<p>佳能、尼康和索尼的相机产品线命名：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023193816811.png" /></p>
<p>通常的讲，数字的位数越少，产品越高端。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023194131080.png" /></p>
<p>同样是数字位数越少，产品越高端。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023194304991.png" /></p>
<p>镜头的分类，大致可以分为原厂和副厂。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023194459349.png" /></p>
<p>另外常见的分类方式是根据镜头的焦距，焦距控制了相机视野的范围。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023194610826.png" /></p>
<p>焦距越小，视角越大，单个主体占比也就越小。</p>
<p>还有几个其它的分类方式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023194733150.png" /></p>
<p>光圈越大，有一个数值<code>f</code>就会越小，恒定的光圈镜头会好于浮动光圈镜头。光圈越小，镜头越贵。</p>
<p>对于变焦镜头有两种，一种是外变焦，一种是内变焦。外变焦镜头在转动变焦环的时候，镜头长度会变化；内变焦镜头，镜头长度不会发生改变。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195010363.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195218979.png" /></p>
<p>常见的变焦镜头黑话：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195325647.png" /></p>
<p>还有定焦镜头：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195452687.png" /></p>
<p>作为新手，还是建议使用变焦镜头。同时，视频作者建议，可以选择中焦焦段的镜头。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195705718.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195746989.png" /></p>
<p>选购建议：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195853378.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20221023195959749.png" /></p>
]]></content>
      <categories>
        <category>interest</category>
        <category>camera</category>
      </categories>
      <tags>
        <tag>camera</tag>
      </tags>
  </entry>
  <entry>
    <title>1-Interoduction-word-vectors</title>
    <url>/tutorial/cs224n-2019/1-Interoduction-word-vectors/</url>
    <content><![CDATA[<h1 id="introduction-and-word-vectors">1 Introduction and Word Vectors</h1>
<p><a href="https://www.youtube.com/watch?v=8rXD5-xhemo&amp;list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&amp;index=2">video</a></p>
<span id="more"></span>
<h2 id="human-language-and-word-meaning">Human language and word meaning</h2>
<p>human language的特征：</p>
<ul>
<li>不确定性。我们尝试使用语言来描述世界，表达自己的想法，但是自己表述的语言能否被其它的人接受实际是不确定的，可能是一种概率的问题。</li>
<li>”human language is a pathetically slow network“，说话这种方式能够表达的能力是很有限的，因此在人类的交流中，实际语言是实现了一种对于信息的压缩，能够理解语言的背后是我们的大脑中已经拥有了很多先验知识。</li>
</ul>
<p>Represent the meaning of word</p>
<p>Definition: <strong>meaning</strong></p>
<ul>
<li>the idea that is represented by a word</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/word2vec-prob.png" /></p>
<p>在早期的NLP中，人们将不同的词word表示为独立的符号（discrete symbol），这叫做localist representation，例如one-hot编码。</p>
<p>这样表示的问题：</p>
<ul>
<li>word的数量很大，甚至可以构造出无限多的word，导致one-hot编码的dim越来越大</li>
<li>对于one hot编码来说，不同的编码之间是独立的，和正交的，无法保留word原本的含义，也无法衡量两个word之间的相似程度</li>
</ul>
<p>如何获取一个word的meaning？</p>
<p>一个著名的观点是：</p>
<blockquote>
<p>”You shall know a word by the company it keeps“</p>
<p>——J. R. Firth 1957: 11</p>
<p>A word’s meaning is given by the words that frequently appear close-by.</p>
</blockquote>
<p>针对one hot的问题，我们尝试为每个word建立更dense vector，即使word的distributed representation，word vector。</p>
<h2 id="word2vec">Word2vec</h2>
<p>借助于前面的观点，word2vec出现了。</p>
<blockquote>
<p>Word2vec (Mikolov et al. 2013) is a framework for learning word vectors</p>
</blockquote>
<p>核心思想：</p>
<ul>
<li>一个大的语料库</li>
<li>每个word都使用固定长度的vector表示</li>
<li>选中center word，计算它周围的outside word/context word出现的概率，并且不断更新参数让这个概率最大</li>
</ul>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/idea-word2vec.png" /></p>
<p>核心问题在于如何计算<span class="math inline">\(P(w_{t+j}|w_t)\)</span>？</p>
<p>在word2vec中，对于每个word建立两个vector：</p>
<ul>
<li><span class="math inline">\(v_w\)</span> when word <span class="math inline">\(w\)</span> is a center word</li>
<li><span class="math inline">\(u_w\)</span> when word <span class="math inline">\(w\)</span> is a context word</li>
</ul>
<p>核心公式： <span class="math display">\[
P(o|c)=\frac{\text{exp}(u_o^T v_c)}{\sum_{w\in V} \text{exp}(u_w^T v_c)}
\]</span> 解释</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/meaning-of-words.png" /></p>
<p>使用点积来衡量相似度，当我们得知了context的时候，中心词的meaning应该也能知悉，即context与center word的meaning此时应该接近。对于在语料中经常出现的word，赋予它们比较大的概率。</p>
<p>上面的公示实际是softmax</p>
<ul>
<li>soft：指对于所有的预测目标都有一个估计概率，哪怕它可能很小</li>
<li>max：指softmax的输出是概率最大的值</li>
</ul>
]]></content>
      <categories>
        <category>Class</category>
        <category>CS224N</category>
      </categories>
  </entry>
  <entry>
    <title>Basic-Info</title>
    <url>/tutorial/cs224n-2019/resourse/</url>
    <content><![CDATA[<h1 id="cs224n-natural-language-processing-with-deep-learning">CS224n: Natural Language Processing with Deep Learning</h1>
<p><a href="https://web.stanford.edu/class/cs224n/index.html">Offical website</a></p>
<p><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z">Youtube video</a></p>
]]></content>
      <categories>
        <category>Class</category>
        <category>CS224N</category>
      </categories>
  </entry>
  <entry>
    <title>14-transformers</title>
    <url>/tutorial/cs224n-2019/14-transformers/</url>
    <content><![CDATA[<h1 id="transformers-and-self-attention">Transformers and Self-Attention</h1>
<p>序列化的模型类似于RNN，存在几个问题：</p>
<ul>
<li>Sequential computation的计算限制了并行计算</li>
<li>没有对于short和long dependencies的显式建模</li>
<li>我们希望能够建模层级</li>
</ul>
<span id="more"></span>
<p>对于迁移不变性的解释。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210329210505679.png" /></p>
<h2 id="section"></h2>
]]></content>
      <categories>
        <category>Class</category>
        <category>CS224N</category>
      </categories>
  </entry>
  <entry>
    <title>02-prop-of-graph-and-rand-model</title>
    <url>/tutorial/cs224w/02-prop-of-graph-and-rand-model/</url>
    <content><![CDATA[<h1 id="properities-of-networks-random-graph-model">Properities of networks, Random Graph Model</h1>
<p>在下面所提到的图默认是无向图。介绍了graph的四种属性</p>
<span id="more"></span>
<h2 id="network-properties">Network Properties</h2>
<p>4 key network properties</p>
<ol type="1">
<li>Degree distribution <span class="math inline">\(P(k)\)</span></li>
</ol>
<p>具有不同度的节点数量在所有graph node中的比例</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210309220725684.png" /></p>
<ol start="2" type="1">
<li>Paths in a graph</li>
</ol>
<p>在图中的路径path是指节点的序列。在有向图中的path需要遵循edge的direction。</p>
<p>有了path就可以衡量距离distance，两个节点的distance是最短路径shortest path。</p>
<p>定义了distance之后，可以定义graph的直径diameter。graph的diameter是所有节点对的distance中最长的值。</p>
<ol start="3" type="1">
<li>Clustering coefficient</li>
</ol>
<p>聚类系数clustering coefficient衡量了节点的邻居之间的连接性。clustering coefficient针对的是graph中的每一个node。具体算法是计算邻居之间的边/理想中最多的领居间边的数量。 <span class="math display">\[
C_i= \frac{2e_i}{k_i(k_i-1)}
\]</span> 其中，<span class="math inline">\(e_i\)</span>是邻居间的边的数量，<span class="math inline">\(k_i\)</span>是节点<span class="math inline">\(i\)</span>的度。<span class="math inline">\(k_i(k_i-1)\)</span>计算了所有邻居节点之间都存在一个边的上限情况。聚类系数在0-1区间。</p>
<ol start="4" type="1">
<li>Connectivity</li>
</ol>
<p>定义为最大连通单元中节点的数量。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210309222007993.png" /></p>
<h2 id="random-graph-model">Random Graph Model</h2>
<p>我们可以设定一些条件，产生人造的随机graph，来促进我们对于现实graph的理解。</p>
<p>可以有两种random graph</p>
<ol type="1">
<li><span class="math inline">\(G_{np}\)</span>：n个node，node之间产生edge的概率是<span class="math inline">\(p\)</span>。</li>
<li><span class="math inline">\(G_{nm}\)</span>：n个节点，随机产生<span class="math inline">\(m\)</span>个边。</li>
</ol>
<p>研究这两种random graph的properties。</p>
<p>对于<span class="math inline">\(G_{np}\)</span>：</p>
<h3 id="degree-distribution">Degree Distribution</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210322215556478.png" /></p>
<h3 id="clustering-coefficient">Clustering Coefficient</h3>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210322214919097.png" /></p>
<h3 id="path-length">Path Length</h3>
<p>首先定义Expansion，核心思想是随机选一个node集合，有多少的边会离开这个集合。</p>
<p>式子定义：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210323170924449.png" /></p>
<p>式子下面的分母表示对于一个划分来说，如果划分的S越大，节点越多，如果离开集合S的edge数量不变，那么expansion应该小；如果划分的集合S的node数量不变，那么离开S的edge数量越多，expansion越大。随机的划分S，能得到V-S，对于S和V-S都可以计算出一个expansion，离开这两个集合的edge数量一样，但是如果拿较大的集合来算的话，计算出来的expansion就会偏小。因此，总是以数量较少的集合作为考虑的点。</p>
<p>随机的划分集合，能得到很多的expansion，为了衡量整个graph的expansion，考虑expansion的下限，即最小的那个expansion。在这种情况下，如果graph的expansion比其它graph的expansion更大，可以理解为这个graph的expansion更大，locality更弱。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210323163010845.png" /></p>
<p>一个random graph的path length是<span class="math inline">\(O(log\ n)\)</span>。diameter是:</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210323163900359.png" /></p>
<p>也就是说对于random graph来说，随着node数量增加，diameter并不会增加很多。</p>
<h3 id="lagest-connected-components">Lagest Connected Components</h3>
<p>在random graph中，随着平均degree增加，node链接到giant component的概率增加。</p>
<h2 id="the-smallest-world-model">The Smallest-World Model</h2>
<p>仔细观察下network的properties会发现，聚类系数与graph的直径似乎是两个有点冲突的属性。如果聚类系数比较高，说明一个graph的locality强，那么node与较远的node之间就比较难有直接的链接，这会造成graph的路径很大。</p>
<p>一个graph的diameter衡量了graph的“shortcut”，如果diameter比较小，意味着对于一个node，可以在较小的step内链接到其它node。但是直径变小的话，一个graph的locality似乎会被破坏，一个node的很多邻居之间不相连，而是有更多的edge链接到其它的node上。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210323105306472.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210323105329615.png" /></p>
<p>那么，是否有办法让graph同时具有high clustering和small diameter？</p>
<p>解决方案是the smallest-world model。1998。</p>
<p>核心是对于一个已经具有high clustering的graph，引入randomness，新增/删减edge来创建更多的“shortcut”。</p>
<p>示例图：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210323110103346.png" /></p>
]]></content>
      <categories>
        <category>Class</category>
        <category>CS224W</category>
      </categories>
  </entry>
  <entry>
    <title>01-intro-graph</title>
    <url>/tutorial/cs224w/01-intro-graph/</url>
    <content><![CDATA[<h1 id="introduction-of-graphs">Introduction of graphs</h1>
<h2 id="introduction">Introduction</h2>
<p>为什么network/graph很重要？</p>
<blockquote>
<p>Networks are a general language for describing complex systems of interacting entities</p>
</blockquote>
<p>当我们谈论network的时候，经常讨论两种图：</p>
<ol type="1">
<li>Natural graph：对于现实事物的直接描述，例如社交网络、大脑神经元的链接网络等</li>
<li>Information graph：经过处理之后，带有信息的图，例如链接知识的图等</li>
</ol>
<span id="more"></span>
<p>实际上在某些情况下上面两种network的分界线是很模糊的。</p>
<p>很多事物都拥有图的结构，利用这些图的结构能够帮助我们更好的预测。</p>
<p>Why networks?</p>
<ul>
<li>Universal language for describing complex data</li>
<li>Shared vocabulary between fields</li>
<li>Data availability &amp; computational challenges</li>
</ul>
<p>Ways to analyze networks:</p>
<ul>
<li>Predict the type/color of a given node
<ul>
<li>Node classification</li>
</ul></li>
<li>Predict whether two nodes are linked
<ul>
<li>Link prediction</li>
</ul></li>
<li>Identify densely linked clusters of nodes
<ul>
<li>Community detection</li>
</ul></li>
<li>Measure similarity of two nodes/networks
<ul>
<li>Network similarity</li>
</ul></li>
</ul>
<h2 id="structure-of-graphs">Structure of Graphs</h2>
<p>graph的component：</p>
<ul>
<li>Objects: nodes, edges <span class="math inline">\(N\)</span></li>
<li>Interactions: links, edges <span class="math inline">\(E\)</span></li>
<li>System: network, graph <span class="math inline">\(G(N, E)\)</span></li>
</ul>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210309193044665.png" alt="image-20210309193044665" /><figcaption>image-20210309193044665</figcaption>
</figure>
<blockquote>
<p>We will try to make this distinction whenever it is appropriate, but in</p>
<p>most cases we will use the two terms interchangeably</p>
</blockquote>
<p>graph的基本概念：</p>
<ul>
<li>无向图</li>
<li>有向图</li>
</ul>
<p>node degree：对于无向图来说就是一个节点连接的边，因此一个无向图的平均度就是<span class="math inline">\(2E/N\)</span>。对于有向图来说度分为入度和出度，一个节点的in-degree就是有多少条箭头指向该节点；out-degree就是多少条边末端链接到该节点上。</p>
<p>几种特殊的graph：</p>
<ul>
<li>complete graph：对于无向图，一个complete graph指所有节点之间都存在边：<span class="math inline">\(E=E_{max}=\frac{N(N-1)}{2}\)</span></li>
<li>Bipartite graph：a graph whose nodes can be divided into two disjoint sets <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> such that every link connects a node in <span class="math inline">\(U\)</span> to one in <span class="math inline">\(V\)</span>; that is, <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are independent sets</li>
<li>Weighted graph：在邻接矩阵中的非0值不再只是1，而是其它衡量重要程度的实值，比如道路图</li>
<li>Self-edge graph：边的起始点都是同一个节点，比如蛋白质图protein graph</li>
<li>Multigraph：在节点和节点当中存在多条边，比如Communication graph、Collaboration graph</li>
</ul>
<p>在数学上表示一个图可以使用adjacent matrix表示。</p>
<ul>
<li>对于无向图，行和列求和相等，并且是对应节点的degree</li>
<li>对于有向图，行求和是out-degree，列求和是in-degree</li>
</ul>
<p>对于这种表示方式，需要在脑海里保持的一种直觉观点是，邻接矩阵是非常稀疏的。矩阵的稠密度计算：<span class="math inline">\(E/N^2\)</span>。</p>
<p>还可以使用edge list和adjacent list表示：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210309203007866.png" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210309203034763.png" /></p>
<p>graph的连通性connectivity：</p>
<ol type="1">
<li>对于无向图，如果说一个graph是Connected graph，这意味着任意两个节点都可以通过某个路径连接起来</li>
<li>对于有向图，分为强连接性图和弱连接性图</li>
</ol>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20210309204211861.png" /></p>
<p>在研究图的连通性当中，可能存在关键的边或者节点，如果把这些关键点或边删除整个图就不再连通。</p>
<ul>
<li>Bridge edge: If we erase the edge, the graph becomes disconnected</li>
<li>Articulation node: If we erase the node, the graph becomes disconnected</li>
</ul>
]]></content>
      <categories>
        <category>Class</category>
        <category>CS224W</category>
      </categories>
  </entry>
  <entry>
    <title>2021-02-tradition-ml</title>
    <url>/tutorial/cs224w/2021-02-tradition-ml/</url>
    <content><![CDATA[<h1 id="traditional-mehods-for-machine-learning-in-graphs">Traditional Mehods for Machine Learning in Graphs</h1>
]]></content>
      <categories>
        <category>Class</category>
        <category>CS224W</category>
      </categories>
  </entry>
  <entry>
    <title>Basic-Info</title>
    <url>/tutorial/cs224w/resourse/</url>
    <content><![CDATA[<h1 id="machine-learning-with-graphs">Machine Learning with Graphs</h1>
<p><a href="http://snap.stanford.edu/class/cs224w-2019/">offical 2019</a></p>
<p><a href="http://web.stanford.edu/class/cs224w/">offical 2020</a></p>
<p><a href="http://networksciencebook.com/chapter/1#vulnerability">online book: network science</a></p>
]]></content>
      <categories>
        <category>Class</category>
        <category>CS224W</category>
      </categories>
  </entry>
  <entry>
    <title>1-intro</title>
    <url>/tutorial/multimodal-cmu-2022/1-intro/</url>
    <content><![CDATA[<p><a href="https://cmu-multicomp-lab.github.io/mmml-tutorial/schedule/">CMU MML Tutorial Louis-Philippe Morency</a></p>
<h1 id="mmml-tutorial-introduction">MMML Tutorial: Introduction</h1>
<h2 id="多模态介绍">多模态介绍</h2>
<p>什么是multimodal？</p>
<p>在数学上，我们描述多模态是在概率上有不同的分布趋势。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903093913110.png"   style="zoom:20%;" /></p>
<p>但是现在，我们大多提到多模态，更多是在指multiple modalities。更准确的说是sensory modalities。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903094246738.png"   style="zoom:20%;" /></p>
<span id="more"></span>
<p>不同的模态意味着拥有不同的特征或者说信号。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903094422429.png"   style="zoom:20%;" /></p>
<p>那么接下来，什么是模态Modality？</p>
<p>一种较通用的定义是，多模态是指</p>
<blockquote>
<p>Modality refers to the way in which something expressed or perceived.</p>
</blockquote>
<p>也就是指信息被表达或者感知的方式。</p>
<p>下面是对于模态理解的一种角度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903094937416.png"   style="zoom:30%;" /></p>
<p>从这个角度出发，我研究的KG，本身就已经是经过人类处理之后的模态，已经较为抽象，脱离了一开始的原始形式。</p>
<p>什么是多模态Multimodal？</p>
<p>词典上的定义：</p>
<blockquote>
<p>Multimodal: with multiple modalities.</p>
</blockquote>
<p>研究人员的定义：</p>
<blockquote>
<p>Multimodal is the science of heterogeneous and interconnected data.</p>
</blockquote>
<p>核心解决两个问题：不同模态的差异性和不同模态如何联系到一起。</p>
<p>不同模态表示的信息，通常是异质的heterogeneous。并且，如果是更抽象的模态，表示的信息会更加趋同。（这么一想，或许这是为什么我们会尝试利用神经网络，在高层进行模态信息的融合，而不是在低层）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903095640357.png"   style="zoom:30%;" /></p>
<p>两个在不同角度拍摄的照相机，它们的结果当然是相近的（但肯定因为角度不同有所区别）；两个来自不同语言的文本，差异性就会比较大；而语言和视觉之间的差异就更大了。</p>
<p>不同模态信息可能存在差异的几个维度实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903100256385.png"   style="zoom:30%;" /></p>
<p>比如结构上的差异、表达空间的差异（例如speech通常是连续的）、信息表现的特征、特征的粒度、数据的噪音、模态是否和任务相关等等方面。</p>
<p>模态的元素之间通常是如何关联到一起的，对于关联到一起的元素，我们如何让它们之间进行交互？这个通常是多模态学习需要解决的关键核心问题。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903100802997.png" alt="image-20220903100802997" style="zoom:30%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903100826507.png"   style="zoom:30%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903100851250.png"   style="zoom:30%;" /></p>
<p>不同模态交互，可能存在的情况举例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903102403297.png"   style="zoom:30%;" /></p>
<p>从统计角度看，两个不同模态元素经常同时出现；某个模态经常依赖于另外模态的元素（时间/空间）；从语义角度看，两个模态元素都是在描述统一事物；或者两个模态元素之间存在语义联系。</p>
<p>接下来，对于关联的多模态元素，出现不同特征/信号的时候，可能出现什么样的结果？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903102645836.png"   style="zoom:33%;" /></p>
<p>举例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903102727947.png"   style="zoom:40%;" /></p>
<p>比如在上面的图中，不同模态出现了不同的信号，有不同的响应。不同模态响应同时作用下，可能出现响应的增强/互补、响应不变、响应倾向于某个模态、或者是出现新的响应形式。</p>
<p>对于不同模态元素的交互，通常可以从以下几个维度考虑：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903102212604.png"   style="zoom:30%;" /></p>
<h2 id="多模态研究历史">多模态研究历史</h2>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903104827261.png"   style="zoom:30%;" /></p>
<p>一开始的时候，研究人员从社会学的角度，研究不同模态之间的联系，比如David McNeill研究了手势和语言之间的联系，认为语言是speech的必要组成部分。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903104958575.png"  style="zoom:30%;" /></p>
<p>随后，出现了基于计算的研究</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903105058872.png"   style="zoom:30%;" /></p>
<p>由于在nlp方向，人们能够把token表示为向量，例如word2vec；在cv方向，人们同样能够适应cnn把image的object表示为向量。人们通过这种方法，让文本和图像之间表现出了更多的homogeneous。</p>
<p>在过去的五年中，利用深度学习，出现了大量的不同模态之间的研究方向</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903105144702.png"   style="zoom:30%;" /></p>
<h2 id="多模态机器学习">多模态机器学习</h2>
<p>什么是多模态机器学习？</p>
<blockquote>
<p>Multimodal Machine Learning (MML) is the study of computer algorithms that learn and improve through the use and experience of data from multiple modalities</p>
</blockquote>
<p>什么是多模态人工智能？</p>
<blockquote>
<p>Multimodal Artificial Intelligence (MAI) studies computer agents able to demonstrate intelligence capabilities such as understanding, reasoning and planning, through multimodal experiences, and data</p>
</blockquote>
<p>Tutorial作者认为multimodal AI是multimodal ML的超集。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903110850771.png"   style="zoom:50%;" /></p>
<p>在multimodal问题中，需要面临解决的6个核心challenge。</p>
<ol type="1">
<li>Representation</li>
</ol>
<blockquote>
<p>Learning representations that reflect cross-modal interactions between individual elements, across different modalities.</p>
</blockquote>
<p>如何表示不同模态的信息，如何表示不同模态中的单个element？这个问题几乎是multimodal learning中最基本也最核心的问题。可能存在以下几种情况：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903141449798.png"   style="zoom:30%;" /></p>
<p>fusion表示原始的模态信息，之后被融合到一个representation space中；coordination指不同模态始终有独立的表示空间；fission表示先融合，之后分裂到不同的空间中；</p>
<ol start="2" type="1">
<li>Alignment</li>
</ol>
<blockquote>
<p>Identifying and modeling cross-modal connections between all elements of multiple modalities, building from the data structure.</p>
</blockquote>
<p>对于不同模态中的所有element，如何发现它们之间存在的联系，并且利用这样的关联？</p>
<p>模态内部很可能存在内部的结构，不同模态元素之间也可能存在显式的连接，同时，利用representation，也可能找到潜在的关联。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903142254056.png"   style="zoom:33%;" /></p>
<ol start="3" type="1">
<li>Reasoning</li>
</ol>
<blockquote>
<p>Combining knowledge, usually through multiple inferential steps, exploiting multimodal alignment and problem structure.</p>
</blockquote>
<p>如何结合knowledge，进行推理？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903142655068.png"  style="zoom:33%;" /></p>
<p>几个sub-challenge：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903142737264.png"   style="zoom:33%;" /></p>
<p>如何从结构上融合knowledge？如何定义或者使用中间概念？如何设计推理模式？如何利用外部knowledge（例如commonsense knowledge）进行推理？</p>
<ol start="4" type="1">
<li>Generation</li>
</ol>
<blockquote>
<p>Learning a generative process to produce raw modalities that reflects cross-modal interactions, structure and coherence.</p>
</blockquote>
<p>generation可能存在几个不同的challenge：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903143031642.png"   style="zoom:33%;" /></p>
<p>summarization期望进行信息缩减；translation期望信息不丢失；creation可能是最难的，它期望获得信息的拓展，能够应用到新的模态中。</p>
<ol start="5" type="1">
<li>Transference</li>
</ol>
<blockquote>
<p>Transfer knowledge between modalities, usually to help the target modality which may be noisy or with limited resources.</p>
</blockquote>
<p>对于目标modality，如何利用来自其它模态的信息？来自其它模态的信息可能是有限的，也可能是noisy的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903143519103.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903143611127.png"  style="zoom:33%;" /></p>
<p>transfer指不同的模型学习不同模态，如何把不同模态的信息迁移到目标模态；co-learning是指使用同一个模型同时处理不同模态；</p>
<ol start="6" type="1">
<li>Quantification</li>
</ol>
<blockquote>
<p>Empirical and theoretical study to better understand heterogeneity, cross-modal interactions and the multimodal learning process.</p>
</blockquote>
<p>对多模态学习进行理论上的分析。如何理解heterogeneity？如何理解interaction？以及如何理解multimodal learning的过程？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903143838239.png"  style="zoom:33%;" /></p>
<p>以上的六个core challenge实际是关联在一起的。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903144057552.png"   style="zoom:33%;" /></p>
<p>首先，我们需要考虑如何表示不同模态的信息，是分别在独立的空间中进行学习，还是在联合空间下进行学习；其次，我们需要考虑如何发现多模态元素的关联；在前两步基础上，我们才可以进行目标推理，如何设计合理的结构，处理heterogeneity和interaction，对预测目标采用合理的步骤进行推理；同样的，我们可以进行模态生成，完成模态转换、summarization等任务；我们还可以进行模态的迁移，让其它模态辅助、增强目标模态的预测，它和模态生成的区别是，模态生成的输入不包括要预测的模态；最后，我们需要理论上对multimodal learning的支撑。</p>
]]></content>
      <categories>
        <category>tutorial</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>2-representation</title>
    <url>/tutorial/multimodal-cmu-2022/2-representation/</url>
    <content><![CDATA[<h1 id="mmml-tutorial-challenge-1-representation">MMML Tutorial Challenge 1: Representation</h1>
<p>Challenge 1 Representation：</p>
<blockquote>
<p>Learning representations that reflect cross-modal interactions between individual elements, across different modalities.</p>
</blockquote>
<p>Representation challenge有三个sub-challenge，Fusion、Coordination和Fission。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904163842455.png"   style="zoom:33%;" /></p>
<span id="more"></span>
<h2 id="sub-challenge-1-representation-fusion">Sub-Challenge 1: Representation Fusion</h2>
<p>fusion的定义：</p>
<blockquote>
<p>Learn a joint representation that models cross-modal interactions between individual elements of different modalities.</p>
</blockquote>
<p>学习模态之间的联合表示。有两种fusion：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903195752329.png"   style="zoom:33%;" /></p>
<p>basic fusion指融合两个已经同质较多的modality；complex fusion是指融合异质性强的modality。basic fusion是很重要的，因为对于complex fusion在网络学习过程中，随着抽象层次的增加，不同模态之间的同质性是在增加的，最后进行融合的时候，可以看做是一个basic fusion。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903200130379.png"   style="zoom:33%;" /></p>
<h3 id="basic-fusion">Basic fusion</h3>
<p>首先，对于两个模态，我们可以简单的把它们的表示拼接到一起，叫做additive fusion：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903200954360.png"   style="zoom:33%;" /></p>
<p>additive fusion可以应用到更复杂的情况：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903201046736.png"   style="zoom:33%;" /></p>
<p>additive fusion可以看做是一种集成的方法，或者叫做late fusion。</p>
<p>如果认为这样加性的混合不能够满足模态交互的要求，那么可以采用乘法的交互，multiplicative fusion。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903202429932.png"   style="zoom:33%;" /></p>
<p>bilinear fusion：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903202509100.png"   style="zoom:33%;" /></p>
<p>tensor fusion，从张量角度融合表示。（<em>Zadeh et al., Tensor Fusion Network for Multimodal Sentiment Analysis, EMNLP 2017</em>）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903202649615.png"   style="zoom:33%;" /></p>
<p>tensor fusion的结果tensor，会随着modality的数量增加而指数式增加。因此出现了降低计算成本的low-rank fusion（<em>Liu et al., Efficient Low-rank Multimodal Fusion with Modality-Specific Factors, ACL 2018</em>）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903202928027.png"   style="zoom:33%;" /></p>
<p>如果进一步拓展加法fusion和乘法fusion，我们可以获得high-order polynomial fusion（<em>Hou et al., Deep Multimodal Multilinear Fusion with High-order Polynomial Pooling, Neurips 2019</em>）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903203411430.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903203449368.png" alt="image-20220903203449368" style="zoom:33%;" /></p>
<p>gated fusion，对于不同模态，设计融合信息的gate（<em>Gated Multimodal Units for information fusion,</em>）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903204826371.png"   style="zoom:33%;" /></p>
<p>gate的设计可以是线性的，非线性的或者是核函数，都是在衡量模态间的相似程度。</p>
<p>Nonlinear Fusion就是利用神经网络进行融合，比如通过一个MLP。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903205016445.png"   style="zoom:33%;" /></p>
<p>对于这种方法，可以看做是一种early fusion，因为仅仅是拼接了两个向量后，然后进行融合，只不过融合的方法变成了神经网络。对于nonlinear fusion，必须注意的是，它真的学习到了nonlinear interaction吗？</p>
<p>之后有人提出了EMAP方法衡量fusion方法对nonlinear interaction的建模能力。核心思想是，通过EMAP，将nonlinear fusion投影到additive fusion上，如果得到的additive fusion的预测能力和nonlinear fusion的预测能力相近，那么就说明fusion没有很好的建模非线性的信息。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903210522579.png"   style="zoom:33%;" /></p>
<p>作者发现，部分的fusion方法表现出来的结果，并没有很好的建模非线性的交互信息。</p>
<h3 id="complex-fusion">Complex fusion</h3>
<p>仍然是非常有挑战的方法，如何直接处理异质性很强的模型？下面是一个实例，通过进行channel exchange直接进行模态fusion（<em>Deep multimodal fusion by channel exchanging</em>）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903211104205.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-2-representation-coordination">Sub-Challenge 2: Representation Coordination</h2>
<p>模态信息的协作coordination，定义是：</p>
<blockquote>
<p>Learn multimodally-contextualized representations that are coordinated through their cross-modal interactions.</p>
</blockquote>
<p>和fusion不同的是，它不会把所有模态信息融合到一个表示空间中，而是用某种方式保持模态信息的一致。存在两种coordination：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903212757995.png"   style="zoom:33%;" /></p>
<p>一般的，这种coordination function以loss function的形式实现：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903212934237.png"   style="zoom:33%;" /></p>
<p>下面是几种coordination function示例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903213014577.png"  style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903213034255.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903213100212.png"   style="zoom:33%;" /></p>
<p>CCA是指让不同模态的latent representation保持较强的相关性，下面是一个实例（DCCAE，<em>Wang et al., On deep multi-view representation learning, PMLR 2015</em>）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903213244674.png"  style="zoom:33%;" /></p>
<p>还有的方法，假设模型能够学习到完整的intact的表示，不同模态的表示只是intect representation在不同view下的表现（<em>Xu et al., Multi-View Intact Space Learning, TPAMI 2015</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903213414235.png"   style="zoom:33%;" /></p>
<p>再比如下面的方法，通过学习intact representation，然后设计在单个模态的degradation network（<em>Zhang et al., AE2-Nets: Autoencoder in Autoencoder Networks, CVPR 2019</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903213541449.png"   style="zoom:33%;" /></p>
<p>还有gated coordination：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903213631959.png"   style="zoom:33%;" /></p>
<p>另外一个popular的方法是对比学习Contrastive learning。它不需要像前面的方法一样，人工设计某种相似度函数，强迫latent representation互相靠近，而是定义关联的不同模态element pair，通过定义loss，让关联的不同模态的element pair互相靠近，不相关的pair互相远离，这样最后学习到的latent representation自然会表现出关联的相近，不关联的远离。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903214055573.png"   style="zoom:33%;" /></p>
<p>举例，比如CLIP（<em>Radford et al., Learning Transferable Visual Models From Natural Language Supervision, arxiv 2021</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903214142642.png" alt="image-20220903214142642" style="zoom:33%;" /></p>
<p>再比如（<em>Kiros et al., Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models, NIPS 2014</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903214223340.png" alt="image-20220903214223340" style="zoom:33%;" /></p>
<h2 id="sub-challenge-3-representation-fission">Sub-Challenge 3: Representation Fission</h2>
<p>fission定义：</p>
<blockquote>
<p>learning a new set of representations that reflects multimodal internal structure such as data factorization or clustering.</p>
</blockquote>
<p>同样有两种类似的fission：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903222515087.png"   style="zoom:33%;" /></p>
<p>Modality-Level Fission，期望能够学习只包含在modality A中的信息，学习至包含在modality B中的信息，学习同时包括A和B的信息：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903222639929.png"   style="zoom:33%;" /></p>
<p>如何学习这三种不同的表示？</p>
<p>有一种方法是从loss的角度，让不同的表示有不同的倾向（<em>Tsai et al., Learning Factoriazed Multimodal Representations, ICLR 2019</em>）。我们使用<span class="math inline">\(L_1\)</span>让不同的表示尽可能有所区别，避免信息重叠；使用<span class="math inline">\(L_2\)</span>还原原来的模态信息；使用<span class="math inline">\(L_3\)</span>进行预测任务。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903222802216.png"   style="zoom:33%;" /></p>
<p>对于上面这种做法的理解，可以从信息论的角度看（<em>Tsai et al., Self-Supervised Learning from a Multi-View Perspective, ICLR 2021</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903222949898.png"  style="zoom:33%;" /></p>
<p>让mutual information尽可能的大，让条件熵尽可能的小。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220903223031841.png"   style="zoom:33%;" /></p>
]]></content>
      <categories>
        <category>tutorial</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>4-reasoning</title>
    <url>/tutorial/multimodal-cmu-2022/4-reasoning/</url>
    <content><![CDATA[<h1 id="mmml-tutorial-challenge-3-reasoning">MMML Tutorial Challenge 3: Reasoning</h1>
<p>Reasoning的定义：</p>
<blockquote>
<p>Combining knowledge, usually through multiple inferential steps, exploiting multimodal alignment and problem structure.</p>
</blockquote>
<p>reasoning的基础是前面的representation和alignment，然后我们才可以考虑如何combine合适的不同模态的信息来得到理想的预测在值。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904153027700.png"   style="zoom:33%;" /></p>
<span id="more"></span>
<p>可以看到，reasoning和representation fusion在原理上是有相似之处的，但是reasoning比fusion更加的复杂，它可能需要multi-step实现对各种不同complex structure建模；fusion更多是指single-step的融合。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904154623849.png"  style="zoom:33%;" /></p>
<h2 id="sub-challenge-1-structure-modeling">Sub-Challenge 1: Structure Modeling</h2>
<p>定义，如何建模出现在不同模态间的复杂结构</p>
<blockquote>
<p>Defining or learning the relationships over which composition occurs.</p>
</blockquote>
<p>可能存在以下不同的结构：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904162348932.png"   style="zoom:33%;" /></p>
<p>接下来看一下如何实现对Temporal Structure的建模How can we capture cross-modal interactions across time? 一种方法是通过memory network来实现：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904155159816.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904155220741.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904155244531.png"   style="zoom:33%;" /></p>
<p>接下来是建模hierarchical structure，比如在visual grounding中，期望利用language的语法结构，然后能够利用这样的语法结构进行推理：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904160207597.png"   style="zoom:33%;" /></p>
<p>interactive structure，它同样是一种时间上的结构，但是和一般的temporal structure不一样的是，interactive structure中前一步的action，会影响未来的action。而在一般的temporal structure中不一定这样，temporal structure中的元素可能仅仅存在时间先后的联系，不一定存在直接的明确的影响。</p>
<p>建模interactive structure更多的依赖于reinforcement learning，这是一个很大的方向，完全可以作为一个新的tutorial，这里不进行详细的了解。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904161348542.png"   style="zoom:33%;" /></p>
<p>最后是structure discovery，我们不在自己定义complex network进行reasoning，而是通过网络结构搜索，让机器自动学习合适的reasoning structure。下面是一个实例（<em>Xu et al., MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records. AAAI 2021</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904161940163.png"  style="zoom:33%;" /></p>
<p>这样做的好处是无需人工的设计网络架构，我们做的只是定义好各种building blocks，让机器自己去找合适的结构就可以。缺点是需要大量的计算，机器需要不断的尝试不同的架构，进行训练，然后评估。</p>
<h2 id="sub-challenge-2-intermediate-concepts">Sub-Challenge 2: Intermediate Concepts</h2>
<p>中间概念intermediate concepts的定义：</p>
<blockquote>
<p>The parameterization of individual multimodal concepts in the reasoning process.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904163524657.png"   style="zoom:33%;" /></p>
<p>引入中间概念来辅助推理，可能是的reasoning process更加可信赖，更加interpolate。</p>
<p>下面是一个借助neuro-symbolic的实例（<em>Andreas et al., Neural Module Networks. CVPR 2016]</em>），它人工设计了概念作为中间状态：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904163420441.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-3-inference-paradigm">Sub-Challenge 3: Inference Paradigm</h2>
<p>inference paradigm challenge定义：</p>
<blockquote>
<p>How increasingly abstract concepts are inferred from individual multimodal evidences.</p>
</blockquote>
<p>粗暴一点的说，就是如何能够考虑逻辑？</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904165120144.png"   style="zoom:33%;" /></p>
<p>几种可能存在的inference模式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904165245476.png"   style="zoom:33%;" /></p>
<p>首先是对于logical inference，以VQA举例，很多的模型实际上无法捕获逻辑联系，比如在下面的实例中（<em>Gokhale et al., VQA-LOL: Visual Question Answering Under the Lens of Logic. ECCV 2020</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904165446797.png"   style="zoom:33%;" /></p>
<p>研究者提出的一种解决方案是，建模了可微分的逻辑操作符：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904165542182.png"   style="zoom:33%;" /></p>
<p>接下来是casual inference。当我们尝试简单的改变预测目标时，现在的很多模型会出现预测错误的情况，并且它们很可能捕获了错误的潜在correlation（<em>Agarwal et al., Towards Causal VQA: Revealing &amp; Reducing Spurious Correlations by Invariant &amp; Covariant Semantic Editing. CVPR 2020</em>）。比如在下面的例子中，雨伞和灯笼的颜色是无关的，但是模型错误的捕获了这种联系：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904170002737.png"   style="zoom:33%;" /></p>
<p>在另外的例子中，斑马和斑马的数量是相关的，但是模型没有能够捕获相关性：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904170109873.png"   style="zoom:33%;" /></p>
<p>那如何能够让模型更加robust？研究人员提出的一种方案是同时处理这种不相关的object和相关的object：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904170243235.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-4-knowledge">Sub-Challenge 4: Knowledge</h2>
<p>接下来是如何利用knowledge辅助多模态融合？</p>
<blockquote>
<p>The derivation of knowledge in the study of inference, structure, and reasoning.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904171350617.png"   style="zoom:33%;" /></p>
<p>接下来是几个knowledge的实例。首先是multimodal knowledge graph辅助VQA（<em>Marino et al., OK-VQA: A visual question answering benchmark requiring external knowledge. CVPR 2019</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904171725486.png"   style="zoom:33%;" /></p>
<p>为了能够利用knowledge辅助QA，研究人员提出的方法（<em>Gui et al., KAT: A Knowledge Augmented Transformer for Vision-and-Language. NAACL 2022</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904171811521.png"   style="zoom:33%;" /></p>
<p>另一个利用multimodal knowledge graph的例子（<em>Zhu et al., Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries. arXiv 2015</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904171908431.png"   style="zoom:33%;" /></p>
<p>实际上，还存在着大量可以研究的点：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904172117577.png"   style="zoom:33%;" /></p>
]]></content>
      <categories>
        <category>tutorial</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>5-generation</title>
    <url>/tutorial/multimodal-cmu-2022/5-generation/</url>
    <content><![CDATA[<h1 id="mmml-tutorial-challenge-4-generation">MMML Tutorial Challenge 4: Generation</h1>
<p>generation的定义是生成raw modality，也就是说应该和input modalities是不同的modality：</p>
<blockquote>
<p>Learning a generative process to produce raw modalities that reflects cross-modal interactions, structure, and coherence.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904212852739.png"   style="zoom:33%;" /></p>
<span id="more"></span>
<p>generation的两个维度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904213140854.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-1-translation">Sub-challenge 1: Translation</h2>
<p>translation定义：</p>
<blockquote>
<p>Translating from one modality to another and keeping information content while being consistent with cross-modal interactions.</p>
</blockquote>
<p>比如DALLE（<em>Ramesh et al., Zero-Shot Text-to-Image Generation. ICML 2021</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904214318958.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904215448827.png"   style="zoom:33%;" /></p>
<p>从content和generation的角度来看，因为我们做的translation，因此我们不需要存在信息损失，所以利用coordination来保持两个模态的信息能够互相协作。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904215635706.png"   style="zoom:33%;" /></p>
<p>比如DALL E 2（<em>Ramesh et al., Hierarchical Text-Conditional Image Generation with CLIP Latents. arXiv 2022</em>）和DALL-E核心原理是一致的：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904214502388.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-2-summarization">Sub-challenge 2: Summarization</h2>
<p>summarization的定义是缩减信息量并且找出重要的信息：</p>
<blockquote>
<p>Summarizing multimodal data to reduce information content while highlighting the most salient parts of the input.</p>
</blockquote>
<p>比如下面的例子，通过video和language生成summary（<em>Palaskar et al., Multimodal Abstractive Summarization for How2 Videos. ACL 2019</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904214917678.png"   style="zoom:33%;" /></p>
<p>summarization的content就需要是进行模态的fusion，并且生成的时候需要进行信息的缩减：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904215846397.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-3-creation">Sub-challenge 3: Creation</h2>
<p>creation需要创造新的modalities，是一个非常具有挑战性的方向：</p>
<blockquote>
<p>Simultaneously generating multiple modalities to increase information content while maintaining coherence within and across modalities.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904220312768.png"   style="zoom:33%;" /></p>
<p>实际上现在没有特别符合creation方向的方法，一个非常初步的方法是（<em>Tsai et al., Learning Factorized Multimodal Representations. ICLR 2019</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904220731108.png"   style="zoom:33%;" /></p>
<p>还存在很多的可以研究的点：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904221023855.png"  style="zoom:33%;" /></p>
]]></content>
      <categories>
        <category>tutorial</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>6-transference</title>
    <url>/tutorial/multimodal-cmu-2022/6-transference/</url>
    <content><![CDATA[<h1 id="mmml-tutorial-challenge-5-transference">MMML Tutorial Challenge 5: Transference</h1>
<p>Transference是指对于一个资源可能受限的主modality，使用另外的modality进行辅助。定义：</p>
<blockquote>
<p>Transfer knowledge between modalities, usually to help the primary modality which may be noisy or with limited resources</p>
</blockquote>
<p>存在两个可能的关键挑战：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904185728838.png"   style="zoom:33%;" /></p>
<span id="more"></span>
<h2 id="sub-challenge-1-transfer-via-foundation-mondels">Sub-Challenge 1: Transfer via Foundation Mondels</h2>
<p>challenge定义，通过利用pretrained model来迁移knowledge：</p>
<blockquote>
<p>Adapting large-scale pretrained models on downstream tasks involving the primary modality.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904190645782.png"   style="zoom:33%;" /></p>
<p>下面是一个利用language model辅助visual task的实例（<em>Tsimpoukelli et al., Multimodal Few-Shot Learning with Frozen Language Models. NeurIPS 2021</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904191330947.png"   style="zoom:33%;" /></p>
<p>在这个过程中，提前训练好的language model的参数是不变的。</p>
<p>还有一个方法是representation tuning，例如下面的例子，通过self-attention衡量audio information和vision information对language representation的重要程度，然后shift language representation（<em>Ziegler et al., Encoder-Agnostic Adaptation for Conditional Language Generation. arXiv 2019</em>, <em>Rahman et al., Integrating Multimodal Information in Large Pretrained Transformers. ACL 2020</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904191936187.png"   style="zoom:33%;" /></p>
<p>还有研究者使用multitask learning进行模态信息的迁移（<em>Liang et al., HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning. arXiv 2022</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904192254951.png"   style="zoom:33%;" /></p>
<p>还有类似的Gato（<em>A Generalist Agent</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904193047811.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-2-co-learning">Sub-Challenge 2: Co-learning</h2>
<p>通过共享representation space来transfer information，定义：</p>
<blockquote>
<p>Transferring information from secondary to primary modality by sharing representation spaces between both modalities.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904193409904.png"   style="zoom:33%;" /></p>
<p>对于如何引入modality B，有两种方式：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904193707229.png" style="zoom:33%;" /></p>
<p>可以在input layer融合modality B，也可以在prediction layer引入modality B。</p>
<h3 id="co-learning-via-fusion">Co-learning via fusion</h3>
<p>一个通过fusion进行co-learning的实例如下图（<em>Socher et al., Zero-Shot Learning Through Cross-Modal Transfer. NeurIPS 2013</em>）。它通过把image embedding靠近相应的word embedding，比如horse image embedding应该接近horse word embedding。在实现的时候，采用了challenge 1 representation中的coordination方式，让两个在不同空间的表示互相协作靠近。这样做好友一个好处就是它可以用于zero-shot，比如对于从来没有见过的class cat。因为我们已经学习到了cat的word embedding，通过model处理后，cat的image embedding应该会靠近cat word embedding。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904194611816.png"   style="zoom:33%;" /></p>
<p>另一个实例是学习joint model（<em>Foundations of Multimodal Co-learning.</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904195020522.png"   style="zoom:33%;" /></p>
<h3 id="co-learning-via-translation">Co-learning via translation</h3>
<p>接下来是通过在预测层融合其它modality的information。下面是一个在language和text之间进行信息迁移的实例（<em>Pham et al., Found in Translation: Learning Robust Joint Representations via Cyclic Translations Between Modalities. AAAI 2019</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904195755479.png"   style="zoom:33%;" /></p>
<p>但是这样的做法并不能确保两个模态的信息都被完全使用了，因为这仅仅是language到visual的translation：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904195908638.png"   style="zoom:33%;" /></p>
<p>作者的做法是让image再翻译回language：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904200006443.png"   style="zoom:33%;" /></p>
<p>之后，同样有研究者通过language来生成对应的image（<em>Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision. EMNLP 2020</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904200225098.png"   style="zoom:33%;" /></p>
<p>还存在更多可以探究的challenge：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904200535323.png"   style="zoom:33%;" /></p>
]]></content>
      <categories>
        <category>tutorial</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>3-alignment</title>
    <url>/tutorial/multimodal-cmu-2022/3-alignment/</url>
    <content><![CDATA[<h1 id="mmml-tutorial-challenge-2-alignment">MMML Tutorial Challenge 2: Alignment</h1>
<p>Alignment定义：</p>
<blockquote>
<p>Identifying and modeling cross-modal connections between all elements of multiple modalities, building from the data structure.</p>
</blockquote>
<p>存在三种可能的connection：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904100856424.png"   style="zoom:33%;" /></p>
<p>equivalence表示两个不同模态的element之间是完全相等的，correspondences表示两个element信息互相补充比如图像和对图像内容的描述，dependencies表示两个element之间存在关系。</p>
<span id="more"></span>
<p>dependency示例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904101631417.png"   style="zoom:33%;" /></p>
<p>比如说存在时间上的前后关系；或者是比较特殊的co-dependencies，指不同的元素总是同时出现。</p>
<h2 id="sub-challenge-1-explicit-alignment">Sub-Challenge 1: Explicit Alignment</h2>
<p>定义：</p>
<blockquote>
<p>Identifying explicit connections between elements of multiple modalities.</p>
</blockquote>
<p>比如把图像中的object和对应的文本描述关联起来：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904102128899.png"   style="zoom:33%;" /></p>
<p>speech的对齐：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904103040629.png"   style="zoom:33%;" /></p>
<p>在图像和文本的对齐中，对于模态element的定义是明确的。但是对于某些模态的定义就不够确切。比如如果我们希望对齐两个video。</p>
<p>比如存在有研究如何对齐两个video的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904104449428.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-2-implicit-alignment">Sub-Challenge 2: Implicit Alignment</h2>
<p>定义：</p>
<blockquote>
<p>Implicitly model connections between elements for better representation learning.</p>
</blockquote>
<p>比如期望实现下面的三个模态对齐：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904105557586.png"   style="zoom:33%;" /></p>
<p>我们无法直接提前选择好explicit connection，但是我们可以利用神经网络实现implicit connection。比如一个简单，但是efficient的方式是把所有的模态拼接到一起后，使用Transformer，通过self-attention，潜在地把不同模态的element融合到一起：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904105844754.png"   style="zoom:33%;" /></p>
<p>Transformer会把所有可能相关的element关联到一起。VisualBERT是一个关联image-language的实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904110121686.png"   style="zoom:33%;" /></p>
<p>上面的方法会直接把不同模态信息进行融合，最近出现了更多的pair-wise alignment：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904110811425.png"   style="zoom:33%;" /></p>
<p>仍然保持各自在不同的表示空间，但是对于modality A会尝试对齐来自modality 的信息，对于modality B尝试对齐来自modality A的信息。如果出现了三个以上的模态，同样可以进行跨模态的对齐。实现的主要思路是，比如我现在有个word embedding，使用这个word embedding作为query embedding，计算来自video slice的image embedding的相似度，然后基于attention聚合image embedding，这样就到达了衡量image对于language的重要程度。下面是一个cross-modal pairwise Transformer的实例：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904111052584.png"   style="zoom:33%;" /></p>
<p>使用到了这种cross-modal Transformer的实例，比如ViLBERT（<em>ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904111448833.png"   style="zoom:33%;" /></p>
<p>再比如LXMERT：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904111539420.png"   style="zoom:33%;" /></p>
<p>另外一个最近的研究兴趣是使用GNN实现alignment，不同模态的element可以互相关联到一起，通过不断的迭代GNN，对于每一个node都能够不断的看到更大的视野。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904151545587.png"   style="zoom:33%;" /></p>
<p>下面的方法是实例MTAG（<em>Modal-Temporal Attention Graph for Unaligned Human Multimodal Language Sequences, NAACL 2021</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220904151624388.png" style="zoom:33%;" /></p>
]]></content>
      <categories>
        <category>tutorial</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
  <entry>
    <title>7-quantification</title>
    <url>/tutorial/multimodal-cmu-2022/7-quantification/</url>
    <content><![CDATA[<h1 id="mmml-tutorial-challenge-6-quantification">MMML Tutorial Challenge 6: Quantification</h1>
<p>定义：</p>
<blockquote>
<p>Empirical and theoretical study to better understand heterogeneity, cross-modal interactions, and the multimodal learning process.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905090715105.png"   style="zoom:33%;" /></p>
<span id="more"></span>
<h2 id="sub-challenge-1-heterogeneity">Sub-Challenge 1: Heterogeneity</h2>
<p>定义：</p>
<blockquote>
<p>Quantifying the dimensions of heterogeneity in multimodal datasets and how they subsequently influence modeling and learning.</p>
</blockquote>
<p>对于modality异质性的探究有以下几个维度：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905091224546.png"   style="zoom:33%;" /></p>
<p>有研究者对modality biases进行了探究，例如在下面的VQA task中，因为训练集中80%的banana都是黄色的，因此在使用一个绿色的banana image进行测试的，VQA model也错误的回答成了黄色：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905091853994.png"   style="zoom:33%;" /></p>
<p>为了解决这个问题，研究人员提出了两种方法。第一种是直接从数据集的角度进行平衡；第二种是从训练过程进行平衡，让VQA model不仅仅依赖于单一的modality，而是也能够充分利用visual modality的信息：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905092226054.png"   style="zoom:33%;" /></p>
<p>在单模态中也存在social biases。比如下面的例子，模型会简单的根据桌子上有一个电脑而错误的认为在桌子前的是男性；也会因为图片中一个人手里拿的是网球拍，就认为这个人是男性（<em>Hendricks et al., Women also Snowboard: Overcoming Bias in Captioning Models. ECCV 2018</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905093014039.png"   style="zoom:33%;" /></p>
<p>另外的研究发现，跨模态反而可能进一步增加social biases：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905093143869.png"   style="zoom:33%;" /></p>
<p>引入visual information之后反而进一步增加了对性别的刻板印象（stereotype），比如总是认为男性带公文包；女性带钱包。</p>
<p>有研究针对heterogeneity中存在的噪音、多模态模型对于缺失模态的鲁棒性、多模态模型性能和鲁棒性的关系进行了探究：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905094316311.png"   style="zoom:33%;" /></p>
<p>为了提升模型的鲁邦性，有几种方法被提出：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905094407401.png"   style="zoom:33%;" /></p>
<p>比如在训练时就人为遮盖掉不同的modality input；使用modality translation来推测缺失的modality等。</p>
<h2 id="sub-challenge-2-cross-modal-interactions">Sub-Challenge 2: Cross-modal Interactions</h2>
<p>cross-modal interaction尝试解释不同模态element之间的联系：</p>
<blockquote>
<p>Quantifying the presence and type of cross-modal connections and interactions in multimodal datasets and trained models.</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905095703291.png"  style="zoom:33%;" /></p>
<p>下面的工作通过representation fission确定了overall cross-modal interaction的存在：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905095943110.png"  style="zoom:33%;" /></p>
<p>接下来，研究人员对individual cross-modal interaction进行了探究（<em>Liang et al., MultiViz: An Analysis Benchmark for Visualizing and Understanding Multimodal Models. arXiv 2022</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905100409439.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905100504291.png"   style="zoom:33%;" /></p>
<p>进一步，M2Lens对cross-modal interaction进行了分类（<em>Wang et al., M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis. IEEE Trans Visualization and Computer Graphics 2021</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905100802906.png"   style="zoom:33%;" /></p>
<p>作者还提供了一个可视化的网站：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905100907943.png"   style="zoom:33%;" /></p>
<p>最近的，研究者实现了multimodal Transformer的可视化（<em>Aflalo et al., VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers. CVPR 2022</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905101015744.png"  style="zoom:33%;" /></p>
<p>另外有研究者尝试对interoperation model进行评估，因为虽然这些model本身是用来解释multimodal model的，但是这些方法解释的是否正确，能不能让人真的理解，还需要进一步评估。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905103921503.png"   style="zoom:33%;" /></p>
<p>evaluating interoperation model是一个非常challenging的方向，一个最新的方法是引入人工来评估（<em>Liang et al., MultiViz: A Framework for Visualizing and Understanding Multimodal Models. arXiv 2022</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905103954645.png"   style="zoom:33%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905104017522.png"   style="zoom:33%;" /></p>
<p>这一方向还有很多的挑战：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905104111125.png"   style="zoom:33%;" /></p>
<h2 id="sub-challenge-3-multimodal-learning-process">Sub-Challenge 3: Multimodal Learning Process</h2>
<p>接下来是对multimodal learning process的探究：</p>
<blockquote>
<p>Characterizing the learning and optimization challenges involved when learning from heterogeneous data.</p>
</blockquote>
<p>例如在下面的一个例子，引入新的modality总能够带来更好的性能吗？（<em>Wang et al., What Makes Training Multi-modal Classification Networks Hard? CVPR 2020</em>）</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905104804142.png"   style="zoom:33%;" /></p>
<p>答案是没有，在上面的实例中，更多的modalities并没有带来更好的性能，相反它意味着更大的计算复杂度，实际上是一个更糟糕的结果。</p>
<p>一种可能的解释是，不同模态的过拟合-泛化的合适点不是一致的（<em>Wang et al., What Makes Training Multi-modal Classification Networks Hard? CVPR 2020</em>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905105121346.png"   style="zoom:33%;" /></p>
<p>解决这一问题的作者提出的方法是，首先通过记录training checkpoints来得到不同modality的overfitting-to-generalization ratio（OGR）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905105343046.png"   style="zoom:33%;" /></p>
<p>然后尝试在不同模态的OGR之间进行平衡：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905105516210.png"   style="zoom:33%;" /></p>
<p>除了上述三个challenge外，还存在许多的challenges：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220905105751944.png"   style="zoom:33%;" /></p>
]]></content>
      <categories>
        <category>tutorial</category>
        <category>multimodal</category>
      </categories>
      <tags>
        <tag>multimodal</tag>
      </tags>
  </entry>
</search>
