<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0">

<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/lxy-apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/lxy-favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/lxy-favicon-16x16.png">
  <link rel="mask-icon" href="/images/lxy-favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liuxiyang641.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"width":300},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":true,"preload":false}}</script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/config.min.js"></script>

    <meta name="description" content="基于数据增强策略的信息抽取论文合集。">
<meta property="og:type" content="blog">
<meta property="og:title" content="IE-data-augment-collection1">
<meta property="og:url" content="https://liuxiyang641.github.io/collection/IE-data-augment-collection1/index.html">
<meta property="og:site_name" content="Liu Xiyang">
<meta property="og:description" content="基于数据增强策略的信息抽取论文合集。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912161946176.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912162201735.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912162711987.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163003964.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163929108.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163954188.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912200034085.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912200407792.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912201243434.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201331433.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201751825.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201830377.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909170611490.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909170816949.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909171308055.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230917152104901.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909171514198.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191701967.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191955856.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193116491.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193212164.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214754741.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223735026.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223753805.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221-20230917171137150.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913185736771.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913191836826.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913190334476.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913192010655.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913215520630.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913220118855.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913230108250.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530110812914.png">
<meta property="article:published_time" content="2023-09-17T02:42:34.000Z">
<meta property="article:modified_time" content="2023-09-17T09:21:57.901Z">
<meta property="article:author" content="Liu Xiyang">
<meta property="article:tag" content="IE">
<meta property="article:tag" content="Data Augment">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912161946176.png">


<link rel="canonical" href="https://liuxiyang641.github.io/collection/IE-data-augment-collection1/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://liuxiyang641.github.io/collection/IE-data-augment-collection1/","path":"collection/IE-data-augment-collection1/","title":"IE-data-augment-collection1"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>IE-data-augment-collection1 | Liu Xiyang</title>
  




<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Liu Xiyang</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">40</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">51</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">139</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#data-augment-for-ie-papers"><span class="nav-number">1.</span> <span class="nav-text">Data Augment for IE papers</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#daga"><span class="nav-number">1.1.</span> <span class="nav-text">DAGA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#melm"><span class="nav-number">1.2.</span> <span class="nav-text">MELM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gpda"><span class="nav-number">1.3.</span> <span class="nav-text">GPDA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gda"><span class="nav-number">1.4.</span> <span class="nav-text">GDA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#entda"><span class="nav-number">1.5.</span> <span class="nav-text">ENTDA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#paraphrase-ner"><span class="nav-number">1.6.</span> <span class="nav-text">Paraphrase NER</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#cross-domain-ie"><span class="nav-number">2.</span> <span class="nav-text">Cross-domain IE</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#cda"><span class="nav-number">2.1.</span> <span class="nav-text">CDA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#style-transfer"><span class="nav-number">2.2.</span> <span class="nav-text">Style Transfer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fact-mix"><span class="nav-number">2.3.</span> <span class="nav-text">Fact-Mix</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Liu Xiyang"
      src="/images/lxy-avatar.jpg">
  <p class="site-author-name" itemprop="name">Liu Xiyang</p>
  <div class="site-description" itemprop="description">Try your best to be an ordinary man.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">139</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/liuxiyang641" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;liuxiyang641" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liuxiyang@buaa.edu.cn" title="E-Mail → mailto:liuxiyang@buaa.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liuxiyang641.github.io/collection/IE-data-augment-collection1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lxy-avatar.jpg">
      <meta itemprop="name" content="Liu Xiyang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liu Xiyang">
      <meta itemprop="description" content="Try your best to be an ordinary man.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="IE-data-augment-collection1 | Liu Xiyang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          IE-data-augment-collection1<a href="https://github.com/liuxiyang641/liuxiyang641.github.io/edit/hexo/source/_posts/collection/IE-data-augment-collection1.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pen-nib"></i></a>
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-09-17 10:42:34 / 修改时间：17:21:57" itemprop="dateCreated datePublished" datetime="2023-09-17T10:42:34+08:00">2023-09-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/IE/" itemprop="url" rel="index"><span itemprop="name">IE</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Paper/IE/Data-Augment/" itemprop="url" rel="index"><span itemprop="name">Data Augment</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>20k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>19 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>基于数据增强策略的信息抽取论文合集。</p>
<span id="more"></span>
<h1 id="data-augment-for-ie-papers">Data Augment for IE papers</h1>
<h2 id="daga">DAGA</h2>
<p>DAGA: Data Augmentation with a Generation Approach for Low-resource Tagging Tasks</p>
<p>南洋理工与阿里达摩，EMNLP 2020，<a target="_blank" rel="noopener" href="https://github.com/ntunlp/daga">代码</a>。</p>
<blockquote>
<p>Data augmentation techniques have been widely used to improve machine learning performance as they enhance the generalization capability of models. In this work, to generate high quality synthetic data for low-resource tagging tasks, <strong>we propose a novel augmentation method with language models trained on the linearized labeled sentences. Our method is applicable to both supervised and semi-supervised settings.</strong> For the supervised settings, we conduct extensive experiments on named entity recognition (NER), part of speech (POS) tagging and end-to-end target based sentiment analysis (E2E-TBSA) tasks. For the semi-supervised settings, we evaluate our method on the NER task under the conditions of given unlabeled data only and unlabeled data plus a knowledge base. The results show that our method can consistently outperform the baselines, particularly when the given gold training data are less.</p>
</blockquote>
<p>作者声称是首个在序列标注task上，引入LM做数据增强的文章。</p>
<p>数据增强是用来人造数据的一种在各个领域都被广泛应用的方法。NLP上的数据增强有它自己独特的特征：在image上简单的修改通常不会改变image本身的信息；但是在natural language上删除或替换一个词就可能完全改变整个sentence的意思。</p>
<p>而一般的NLP 数据增强方法包括synonym replacement, random deletion/swap/insertion, generation with VAE or pre-trained language models、back translation、systematically reordering the dependents of some nodes in gold data、leveraging knowledge base for question generation等等。</p>
<p>和上面的NLP任务相比，类似NER这类的token-level的sequence tagging任务对数据增强时引入的噪音更加敏感。序列标注有的3种尝试（2020年前）：</p>
<ul>
<li>Annotating unlabeled data with a weak tagger [<em>Automated phrase mining from massive text corpora. 2018</em>] 使用已有的标注工具直接进行标注，需要标注工具已经提前具备了相应的domain knowledge，否则面临domain-shift problem [<em>Multimix: A robust data augmentation framework for cross-lingual nlp. 2020</em>]</li>
<li>leveraging aligned bilingual corpora to induce annotation [<em>Inducing multilingual text analysis tools via robust projection across aligned corpora. 2001</em>] 要求有额外的外语语料，很多情况下不实际</li>
<li>synonym replacement [<em>Biomedical named entity recognition via reference-set augmented bootstrapping. 2019</em>] 需要WordNet这类外部知识和人工设计的规则，难以覆盖所有的低资源场景</li>
</ul>
<p>因此，作者提出使用生成式的数据增强方法。作者首先训练一个LM学会现有gold data中语言的特征：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912161946176.png"   style="zoom:30%;" /></p>
<p>单层的LSTM作为语言模型，使用一般的单向language objectives进行优化。作者通过sentence linearization把所有的序列标注sentence都转换为带有tag的句子（NER任务中忽略tag <span class="math inline">\(O\)</span>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912162201735.png"   style="zoom:30%;" /></p>
<p>将tag放在对应的word前面，作者发现这样比tag在word后面效果好。推测原因是这样子可能更加符合一般的语言中形容词-名词的pattern（Modifier-Noun pattern）。</p>
<p>在生成的时候，输入是[BOS]，让LSTM LM直接输出各种不同的句子。对于输出的句子进行后处理，比如删除没有tag的句子、删除有错误tag的情况等。</p>
<p>除了上面直接在gold data上让LM学习特征外，作者还提出了conditional generation method让LM能够利用unlabeled data or knowledge bases。从外部的数据源中获取更多的knowledge：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912162711987.png"  style="zoom:50%;" /></p>
<p>conditional generation本质就是在sentence之前添加condition tags：<span class="math inline">\(\{ [labeled], [unlabeled], [KB] \}\)</span>。</p>
<p>在实验中，作者的NER使用BiLSTM-CRF模型在gold data和生成的data上进行训练，然后评估。作者使用了过采样gold data的策略，采样1个generated data，过采样4个gold data。</p>
<p>在CoNLL2002/2003 NER数据集的多个语言子集（English, German, Dutch and Spanish）上进行验证：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163003964.png"  style="zoom:30%;" /></p>
<p>实验中有一个可以注意的是作者如何评估生成数据的多样性，一个是用entity出现的周围token作为上下文；计算unique上下文token数量；一个是统计unique entity的数量：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163929108.png"   style="zoom:25%;" /> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912163954188.png" style="zoom:25%;" /></p>
<h2 id="melm">MELM</h2>
<p>MELM: Data Augmentation with Masked Entity Language Modeling for Low-Resource NER</p>
<p>阿里达摩与南洋理工，ACL 2022，<a target="_blank" rel="noopener" href="https://github.com/RandyZhouRan/MELM/">代码</a>。</p>
<blockquote>
<p>Data augmentation is an effective solution to data scarcity in low-resource scenarios. However, when applied to token-level tasks such as NER, <strong>data augmentation methods often suffer from token-label misalignment, which leads to unsatsifactory performance.</strong> In this work, <strong>we propose Masked Entity Language Modeling (MELM) as a novel data augmentation framework for low-resource NER.</strong> To alleviate the token-label misalignment issue, we explicitly inject NER labels into sentence context, and thus the fine-tuned MELM is able to predict masked entity tokens by explicitly conditioning on their labels. Thereby, MELM generates high-quality augmented data with novel entities, which provides rich entity regularity knowledge and boosts NER performance. When training data from multiple languages are available, we also integrate MELM with codemixing for further improvement. We demonstrate the effectiveness of MELM on monolingual, cross-lingual and multilingual NER across various low-resource levels. Experimental results show that our MELM presents substantial improvement over the baseline methods.</p>
</blockquote>
<p>前人工作指出，增强上下文带来的提升比较少[<em>A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land? EMNLP 2020</em>]。作者也发现，增强新entity多样性带来的效果要大于增强上下文patterns：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912200034085.png"  style="zoom:30%;" /></p>
<p>作者使用masked LM来给low-resource NER任务做数据增强。作者只会根据一定的概率mask entity的token。然后在mask data上fine-tuning pretrained MLM，让MLM学会根据context预测entity。</p>
<p>如果只是mask entity，然后让MLM预测，可能能够符合context，但是不一定符合原来的entity label。为了让生成的entity和原来的entity有相同的label，作者在原来的句子中插入entity type marker：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912200407792.png"   style="zoom:50%;" /></p>
<p>在进行数据生成的时候，输入masked sentence，为了增强生成数据的多样性。没有使用greedy decoding策略，而是在top-K的候选项上进行随机选择。</p>
<p>同时在生成的时候，采用了新的mask策略。每一次生成都有不同的mask阈值，这样进一步增大了mask结果的差异。</p>
<p>生成的数据需要经过处理以减低噪音，作者用一个训练好的NER模型，去处理增强的句子；只有NER model的标注和生成句子原来的entity label标注一致，才会被保留。</p>
<p>最后，作者在这篇论文中着重考虑多语言场景，引入code-mixing技术。随机从某个其它语言中，选择有相同label的entity作为候选项，之后选择在embedding space上余弦相似度的外语entity替换原来language entity（使用MUSE作为编码方法）。并且在替换后的entity前加入language tag表示替换后的entity原来的语言是什么。</p>
<p>增强的数据比例是3倍。作者实现中使用的LM是XLM-RoBERTa-base，使用的NER model是XLM-RoBERTa-Large+CRF。</p>
<p>在CoNLL数据集的不同语言子集上的实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230912201243434.png"   style="zoom:30%;" /></p>
<h2 id="gpda">GPDA</h2>
<p>Improving Low-resource Named Entity Recognition with Graph Propagated Data Augmentation</p>
<p>ACL 2023 short paper，上海科技与阿里达摩，<a target="_blank" rel="noopener" href="https://github.com/modelscope/AdaSeq/tree/master/examples/GPDA">代码</a>。</p>
<blockquote>
<p>Data augmentation is an effective solution to improve model performance and robustness for low-resource named entity recognition (NER). <strong>However, synthetic data often suffer from poor diversity, which leads to performance limitations. In this paper, we propose a novel Graph Propagated Data Augmentation (GPDA) framework for Named Entity Recognition (NER), leveraging graph propagation to build relationships between labeled data and unlabeled natural texts.</strong> By projecting the annotations from the labeled text to the unlabeled text, the unlabeled texts are partially labeled, which has more diversity rather than synthetic annotated data. To strengthen the propagation precision, a simple search engine built on Wikipedia is utilized to fetch related texts of labeled data and to propagate the entity labels to them in the light of the anchor links. Besides, we construct and perform experiments on a real-world lowresource dataset of the E-commerce domain, which will be publicly available to facilitate the low-resource NER research. Experimental results show that GPDA presents substantial improvements over previous data augmentation methods on multiple low-resource NER datasets.</p>
</blockquote>
<p>data augmentation对于sentence-level NLP task两大思路：</p>
<ol type="1">
<li>One is manipulating a few words in the original sentence, which can be based on synonym replacement (Zhang et al., 2015; Kobayashi, 2018; Wu et al., 2019; Wei and Zou, 2019), random insertion or deletion (Wei and Zou, 2019), random swap (¸Sahin and Steedman, 2018; Wei and Zou, 2019; Min et al., 2020). 修改原有句子的部分表述，获得新data。</li>
<li>The other is generating the whole sentence with the help of back-translation (Yu et al., 2018; Dong et al., 2017; Iyyer et al., 2018), sequence to sequence models (Kurata et al., 2016; Hou et al., 2018) or pre-trained language models (Kumar et al., 2020). 构造完全新的data。</li>
</ol>
<p>作者认为之前的 Data Augmentation会使用人造的数据，这可能inevitably introduces incoherence, semantic errors and lacking in diversity.</p>
<p>因此作者提出要直接使用已有的natural text作为辅助数据增强的来源。</p>
<p>方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201331433.png"  style="zoom:30%;" /></p>
<p>步骤：</p>
<ul>
<li>从外部源如Wikipedia corpus中，通过BM25 sparse retrieval或者L2 dense retrieval的方法检索和句子相似的sentence</li>
<li>然后进行label propagation，在Wikipedia中带有链接的anchor text如果和有label的entity是完全匹配的，就赋值给anchor text对应的label。（但是完全一样text的entity就是相同的entity吗？）使用这样的新标注的数据和原有的有标注数据训练一个NER model</li>
<li>使用训练好的NER model，重新标注一次外部的text，然后使用重新标注后的数据和原有的有标注数据训练一个更好的NER model（Explored Entity Annotations，EEA）</li>
</ul>
<p>实验：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201751825.png"   style="zoom:40%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230908201830377.png"   style="zoom:40%;" /></p>
<h2 id="gda">GDA</h2>
<p>GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks</p>
<p>ACL 2023 Findings，清华与浙大，<a target="_blank" rel="noopener" href="https://github.com/THU-BPM/GDA">代码</a>。</p>
<blockquote>
<p>Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. <strong>These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations.</strong> In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augment diverse sentences. Experimental results in three datasets under a low-resource setting showed that GDA could bring 2.0% F1 improvements compared with no augmentation technique. Source code and data are available.</p>
</blockquote>
<p>之前方法存在的问题：</p>
<ul>
<li>之前的rule-based techniques的数据增强方法不能够保证构造出来的句子和原来的句子是语义一致的，并且由于忽略了语法结构还有可能扭曲原来的语义</li>
<li>model-based techniques能够保持语义一致性 [<em>Data augmentation in natural language processing: a novel text generation approach for long and short text classifiers. 2022</em>]，但是不能够生成多样性的表达。the model generates less diverse sentences – it includes similar entities and identical relational expressions under the same relation.</li>
</ul>
<p>生成的数据既需要多样性，又需要和原来句子的语义一致性。</p>
<p>作者基于多任务学习提出的数据增强方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909170611490.png"  style="zoom:30%;" /></p>
<p>基于BART或T5这样的encoder+decoder结构，有两个decoder：</p>
<ul>
<li><p>Original sentence restructuring. 左侧的decoder，重建原来的sentence，让模型学会产生和原来句子语义一致的句子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909170816949.png"   style="zoom:30%;" /></p></li>
<li><p>Original sentence pattern approximation. 右侧的decoder用来生成新的sentence。由于归纳偏执，seq2seq decoder总是会倾向高频率出现的pattern，就失去生成数据的多样性。因此作者限制生成的新句子的pattern和原来的句子一致。具体做法是使用两个entity之间的语法路径作为relation pattern，生成句子的relation pattern和原来句子的relation pattern要接近：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909171308055.png"   style="zoom:30%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230917152104901.png"   style="zoom:40%;" /></p>
<p>另外，为了进一步控制输出句子。作者会从数据集中同属于一个relation的样例中选择entity，输入解码器，让模型输出带有entity的句子。</p></li>
</ul>
<p>训练的时候，先训练编码器和restructuring decoder；然后使用restructuring decoder的参数初始化pattern approximation decoder参数，和编码器一起训练；pattern approximation decoder参数继续用来初始化restructuring decoder。</p>
<p>两个decoder分别独立迭代优化；encoder一直进行优化。</p>
<p>实验结果：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230909171514198.png"   style="zoom:40%;" /></p>
<p>可以看到，利用作者的数据增强方法生成的数据来训练，能够有效提升Base model的效果。</p>
<h2 id="entda">ENTDA</h2>
<p>Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks</p>
<p>ACL 2023 Findings，清华与阿里达摩，<a href="/nlp/ENTDA/" title="[详细博客]">[详细博客]</a></p>
<blockquote>
<p>Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). <strong>Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks.</strong> In this work, we propose a novel Entity-toText based data augmentation technique named ENTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data and low resource settings) show that ENTDA could bring more performance improvements compared to the baseline augmentation techniques.</p>
</blockquote>
<p>基于entity list生成对应的新data：</p>
<p>作者提出的方法：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191701967.png"   style="zoom:50%;" /></p>
<p>作者的生成data思路是根据entity list，让language model来直接生成相应的句子。</p>
<p>然后，让language model基于entity list生成对应的句子。为了提升生成句子的多样性diversity，作者提出了一种diversity beam search decoding策略：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911191955856.png"  style="zoom:30%;" /></p>
<p>作者在flat, nested, and discontinuous NER tasks都进行了实验。在full data的情况下，提升不太大，但是在低资源的情况下提升很多。we randomly choose 10% training data from CoNLL2003/ACE2005/CADEC：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193116491.png"  style="zoom:30%;" /></p>
<p>低资源的情况下，效果提升明显，有<span class="math inline">\(2\)</span>%的提升幅度。</p>
<p>在真实的低资源NER数据集CrossNER的表现：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230911193212164.png"   style="zoom:40%;" /></p>
<p>同样提升比较明显。</p>
<h2 id="paraphrase-ner">Paraphrase NER</h2>
<p>When and how to paraphrase for named entity recognition?</p>
<p>ACL 2023，<a href="/nlp/when-how-paraphrase-NER/" title="[详细博客]">[详细博客]</a>。</p>
<blockquote>
<p>While paraphrasing is a promising approach for data augmentation in classification tasks, its effect on named entity recognition (NER) is not investigated systematically due to the difficulty of <strong>span-level label preservation</strong>. In this paper, <strong>we utilize simple strategies to annotate entity spans in generations and compare established and novel methods of paraphrasing in NLP such as back translation, specialized encoder-decoder models such as Pegasus, and GPT-3 variants for their effectiveness in improving downstream performance for NER</strong> across different levels of gold annotations and paraphrasing strength on 5 datasets. We thoroughly explore the influence of paraphrasers, dynamics between paraphrasing strength and gold dataset size on the NER performance with visualizations and statistical testing. We find that the choice of the paraphraser greatly impacts NER performance, with one of the <strong>larger GPT-3 variants exceedingly capable of generating high quality paraphrases, yielding statistically significant improvements in NER performance with increasing paraphrasing strength,</strong> while other paraphrasers show more mixed results. Additionally, inline auto annotations generated by larger GPT-3 are strictly better than heuristic based annotations. We also find diminishing benefits of paraphrasing as gold annotations increase for most datasets. Furthermore, while most paraphrasers promote entity memorization in NER, the proposed GPT-3 configuration performs most favorably among the compared paraphrasers when tested on unseen entities, with memorization reducing further with paraphrasing strength. Finally, we explore mention replacement using GPT-3, which provides additional benefits over base paraphrasing for specific datasets.</p>
</blockquote>
<p>作者选择了5个不同领域的NER数据集。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221.png"   style="zoom:40%;" /></p>
<p>作者先对比两个已有的Paraphrasers工具：</p>
<ul>
<li>基于Back-translation（BT）：For our experiments we use pre-trained English-German and German-English models (∼738M parameters) available from Huggingface model hub via Tiedemann and Thottingal (2020) and the model architecture used is BART (Lewis et al., 2019).</li>
<li>基于PEGASUS：We use an off-the-shelf version of PEGASUS fine-tuned for paraphrasing released on Huggingface model hub. 3</li>
</ul>
<p>然后，作者利用两个GPT-3模型：<code>text-ada-001</code> (∼350M parameters), and <code>text-davinci-002</code> (∼175B parameters)。使用的temperature为0.8。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214754741.png"   style="zoom:40%;" /></p>
<p>作者关注数据增强可能带来的一个问题Entity Memorization。即目前基于改写的数据增强方法，没有改变entity mention，生成的data中出现了entity的重复。因此作者想检查模型是不是直接记住了entity和它对应的label，而不是学会从feature推测label。</p>
<p>如果是记忆，那么model意味着模型走了捷径shortcut learning [<em>Shortcut learning in deep neural networks. Nature 2020</em>]，那么此时model应该无法准确处理没有见过的entity。</p>
<p>因此，作者又进行了在test set中，不同entity type里，没有在训练集里出现过的entity作为新的测试集unseen entity (UE) test sets。</p>
<p>为了缓解entity memorization问题，作者提出了一种解决方法Mention replacement（MR）。那就是不要重复entity mention，用GPT生成新的entity mention，然后去替换生成句子中的entity mention：</p>
<blockquote>
<p>In particular, for every entity mention in the gold set, we prompt GPT-3 DaVinci model to generate entity mentions that are similar to the gold entity mention, while also providing a phrase level definition of the entity type being replaced.</p>
</blockquote>
<p>使用到的prompt：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223735026.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916223753805.png"   style="zoom:50%;" /></p>
<p>作者选择了5个不同领域的NER数据集，微调distilbert-base-cased作为NER model。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230916214229221-20230917171137150.png"   style="zoom:40%;" /></p>
<h1 id="cross-domain-ie">Cross-domain IE</h1>
<h2 id="cda">CDA</h2>
<p>Data Augmentation for Cross-Domain Named Entity Recognition</p>
<p>简写是Cross-domain Data Augmentation (CDA)方法。</p>
<p>EMNLP 2021，休斯顿大学与Snap，<a target="_blank" rel="noopener" href="https://github.com/RiTUAL-UH/style_NER">代码</a>。</p>
<blockquote>
<p>Current work in named entity recognition (NER) shows that data augmentation techniques can produce more robust models. However, most existing techniques focus on augmenting in-domain data in low-resource scenarios where annotated data is quite limited. In contrast, <strong>we study cross-domain data augmentation for the NER task.</strong> We investigate the possibility of leveraging data from highresource domains by projecting it into the lowresource domains. Specifically, we propose a novel neural architecture to transform the data representation from a high-resource to a <strong>low-resource domain by learning the patterns (e.g. style, noise, abbreviations, etc.)</strong> in the text that differentiate them and a shared feature space where both domains are aligned. We experiment with diverse datasets and show that transforming the data to the low-resource domain representation achieves significant improvements over only using data from high-resource domains.</p>
</blockquote>
<p>应该是首个考虑用数据增强策略做跨域NER任务的方法。</p>
<p>之前的数据增强IE方法主要是利用in-domain data进行数据增强。作者发现不同domain有不同的patterns：</p>
<blockquote>
<p>Based on our observations, the text in different domains usually presents unique patterns (e.g. style, noise abbreviations, etc.).</p>
</blockquote>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913185736771.png"   style="zoom:30%;" /></p>
<p>例如上面例子中新闻domain的句子更长，表达也更加正式；而social domain的句子有更多的噪音，句子更短，有更多口语/个性化的表达。</p>
<p>但是，作者认为不同domain的text的语义是可以迁移的，并且是存在领域不变量invariables的。作者研究从high-resource domain到low-resource domain数据增强NER方法。</p>
<p>和之前的数据增强方法一样，作者同样训练了一个LM来生成数据，编码器+解码器。编码器是biLSTM，解码器是另一层LSTM。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913191836826.png"   style="zoom:30%;" /></p>
<p>作者提出的训练模型包括两步：</p>
<ul>
<li><p>Denoising Reconstruction：learn the textual pattern and generate compressed representations of the data from each domain</p>
<ul>
<li><p>在输入的text中加入噪音，能够强迫model更加学会保留原始的数据结构信息，所以作者首先通过几种word-level operation来插入噪音：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913190334476.png"  style="zoom:30%;" /></p></li>
<li><p>使用相同参数的encoder和decoder去重建两个domain的input sentence。模型的参数可以看做是学习了隐式的领域对齐。loss是解码器输出和input text之间的差异。</p></li>
<li><p>这一步还额外训练了一个对抗式判别器discriminator用来判断编码器的输出是来自哪个领域，为下一步model学习domain mapping做准备。</p></li>
</ul></li>
<li><p>Detransforming Reconstruction：align the compressed representations of the data from different domains so that the model can project the data from one domain to another</p>
<ul>
<li>首先，用上一步学习好的encoder+decoder，把source domain的sentence转化为target domain style的sentence；把target domain的sentence转化为source domain style的sentence</li>
<li>然后，利用跨域转化后的句子，经过编码器和解码器，期望能够恢复在原来domain的句子</li>
<li>这一步继续训练对抗式判别器discriminator，如果判别器根据编码器的输出，判断领域变换后的sentence是原来domain的概率越小，则认为domain mapping效果越好</li>
</ul></li>
</ul>
<p>作者基于Ontonotes 5.0 Dataset（domains：Broadcast Conversation (BC), Broadcast News (BN), Magazine (MZ), Newswire (NW), and Web Data (WB).）和Temporal Twitter Dataset（Social Media (SM) domain）进行实验。基于source domain的data生成target domain的新training data。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913192010655.png"   style="zoom:30%;" /></p>
<p>上面实验结果中能够看出，原来的in-domain的数据增强方法（如DAGA方法）无法很好的处理跨域问题。这说明原来数据增强方法无法直接生成对应domain的数据。</p>
<p>实验用的NER model是BERT+Linear Layer。</p>
<h2 id="style-transfer">Style Transfer</h2>
<p>Style Transfer as Data Augmentation: A Case Study on Named Entity Recognition</p>
<p>与前面CDA是同一作者。EMNLP 2022，<a target="_blank" rel="noopener" href="https://github.com/RiTUAL-UH/DA_NER">代码</a>。</p>
<blockquote>
<p>In this work, we take the named entity recognition task in the English language as a case study and explore style transfer as a data augmentation method to increase the size and diversity of training data in low-resource scenarios. We propose a new method to effectively transform the text from a high-resource domain to a low-resource domain by <strong>changing its style-related attributes to generate synthetic data for training.</strong> Moreover, we design a constrained decoding algorithm along with a set of key ingredients for data selection to guarantee the generation of valid and coherent data. Experiments and analysis on five different domain pairs under different data regimes demonstrate that our approach can significantly improve results compared to current state-of-the-art data augmentation methods. Our approach is a practical solution to data scarcity, and we expect it to be applicable to other NLP tasks.</p>
</blockquote>
<p>作者探究使用style transfer来为cross-domain NER任务做数据增强的方法。由于并没有带有NER label的style transfer数据集，因此作者提出可以利用非NER任务的style transfer数据集。（风格转换一定程度上不局限在特定任务，但是作者这种做法有个隐含的前提，就是NER的source domain和target domain中的styles已经包括在了非NER任务的style transfer数据集中）。</p>
<p>作者同样训练一个encoder+decoder的LM进行数据生成。这篇论文中作者使用的是T5-base。</p>
<p>第一步就是在非NER任务的style transfer数据集GYAFC (Rao and Tetreault, 2018)上进行训练。这个数据集包括了formal and informal的句子对。通过输入某个style的句子，让T5学会输出对应其它style的句子，优化重建loss <span class="math inline">\(L_{pg}\)</span>。作者follow前人的工作，将style transfer看做是改写生成的问题paraphrase generation problem。和作者之前工作CDA中的domain判别器类似，这一步也额外训练了一个对抗性的style判别器，用来判断编码器输出的embedding是属于哪种style。</p>
<p>第二步是想办法让T5能够学会在NER的句子上进行风格转换。首先要把label注入到sentence中，这里作者把<code>&lt;START_ENTITY_TYPE&gt;</code> and <code>&lt;END_ENTITY_TYPE&gt;</code>插入到entity span的左右侧。然后就是作者提出的cycle-consistent reconstruction，简单说是输入某个sentence，让T5转化为另一种style的sentence，把这个转换后的sentence再输入到T5中，让T5重新回复原来style的sentence。第二步同样优化对抗性style判别器。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913215520630.png"   style="zoom:40%;" /></p>
<p>第三步是生成。为了保证生成数据是valid的，提出了基于prefix tree的Constrained Decoding策略，是保留top-K或top-p的token候选项，然后约束生成句子的输出范围，比如之前输出的span是属于<code>&lt;Text&gt;</code>，那么接下来输出的span就必须是<code>&lt;EOS&gt;</code> or <code>&lt;B_ENT&gt;</code>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913220118855.png"   style="zoom:30%;" /></p>
<p>即使经过上一步，也不能保证生成数据是可靠的。为了进一步提升质量，比如过滤掉简单的重复、胡言乱语等生成的text，计算四个方法的4个metric，然后加权求和作为对于生成data质量的评估：</p>
<ul>
<li>Consistency: a confidence score from a pretrained style classifier as the extent a generated sentence is in the target style. 基于T5 base，用一个外部的model判断是否符合特定style</li>
<li>Adequacy: a confidence score from a pretrained NLU model on how much semantics is preserved in the generated sentence. 基于<a target="_blank" rel="noopener" href="https://github.com/%20PrithivirajDamodaran/Parrot_Paraphraser">开源model</a>，判断生成句子保留的语义</li>
<li>Fluency: a confidence score from a pretrained NLU model indicating the fluency of the generated sentence. 基于<a target="_blank" rel="noopener" href="https://github.com/%20PrithivirajDamodaran/Parrot_Paraphraser">开源model</a>，判断生成句子的流程程度</li>
<li>Diversity: the edit distance between original sentences and the generated sentences at the character level. 利用原始sentence和生成sentence的编辑距离来衡量生成句子的多样性。</li>
</ul>
<p>实验数据集与CDA中的一样，使用OntoNotes 5.0作为source domain和Temporal Twitter Corpus作为target domain。OntoNotes 5.0的domain style是formal的，Temporal Twitter Corpus的domain style是informal的。</p>
<p>作者的NER model是基于BERT base+Linear，与CDA的一致。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230913230108250.png"   style="zoom:30%;" /></p>
<h2 id="fact-mix">Fact-Mix</h2>
<p>FactMix: Using a Few Labeled In-domain Examples to Generalize to Cross-domain Named Entity Recognition</p>
<p>COLING 2022，西湖大学 ，<a href="https://github.%20com/lifan-yuan/FactMix">代码</a>。</p>
<blockquote>
<p>Few-shot Named Entity Recognition (NER) is imperative for entity tagging in limited resource domains and thus received proper attention in recent years. Existing approaches for few-shot NER are evaluated mainly under in-domain settings. In contrast, little is known about how these inherently faithful models perform in cross-domain NER using a few labeled in-domain examples. <strong>This paper proposes a two-step rationale-centric data augmentation method to improve the model’s generalization ability.</strong> Results on several datasets show that our model-agnostic method significantly improves the performance of crossdomain NER tasks compared to previous state-of-the-art methods, including the data augmentation and prompt-tuning methods. Our codes are available at https://github.com/lifan-yuan/FactMix.</p>
</blockquote>
<p>作者主要从数据增强的角度解决跨域NER问题。作者认为跨域的NER任务要考虑两个核心问题：</p>
<ul>
<li>NER任务作为序列标注任务，它的label之间是相互依赖的，而不是相互独立的。不同领域这种label依赖不一样。it is essential to understand dependencies within the labels instead of classifying each token independently.</li>
<li>不同domain的文本中的non-entity tokens的语义是不一致的，这种不一致可能增大NER模型进行跨域NER的困难程度。non-entity tokens in NER do not hold unified semantic meanings, but they could become noisy when combined with entity tokens in the training set.</li>
</ul>
<p>因此，作者认为NER模型学习到的non-entity token和要预测的label之间隐式联系可能影响跨域性能。比如在医学domain上的句子'Jane monitored the patient’s heart rate'，Jane是一个person，在医学domain上训练好的一个NER model可能学习到Jane和monitored之间的潜在关联。但是如果迁移到关于movie review的跨域数据集上，Jane和monitor之间的在医疗领域的潜在关联就不再合适了。</p>
<p>因此，作者提出了一种新的数据增强策略Context-level semi-fact generations：</p>
<ul>
<li>随机使用MLM的[MASK] token代替source domain文本中的某个non-entity token，选择预测时概率最大的词进行替换。这样就引入了out-of-domain的context信息（被预训练model在预训练阶段学习到的信息）</li>
<li>为了避免替换后的词引起entity label标注的影响，作者只保留那些能够被NER模型正确预测所有token NER tag的替换后的样例</li>
</ul>
<p>这种数据增强策略Context-level semi-fact generations和之前研究者提出的Entity-level semi-fact generations结合起来：</p>
<figure>
<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20230530110812914.png" alt="image-20230530110812914" /><figcaption>image-20230530110812914</figcaption>
</figure>
<p>实验以CONLL2003作为source domain，CrossNER数据集下的多个子集作为target domain。训练的时候应用到了fine-tuning based和prompt-tuning based两种NER微调策略，具体参考论文。作者在BERT和RoBERT两类模型不同size的LM上进行了实验。</p>
<p>只使用source domain的数据来进行训练，然后测试在target domain上的效果，验证模型的领域泛化性。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Liu Xiyang
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://liuxiyang641.github.io/collection/IE-data-augment-collection1/" title="IE-data-augment-collection1">https://liuxiyang641.github.io/collection/IE-data-augment-collection1/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/IE/" rel="tag"><i class="fa fa-tag"></i> IE</a>
              <a href="/tags/Data-Augment/" rel="tag"><i class="fa fa-tag"></i> Data Augment</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/nlp/when-how-paraphrase-NER/" rel="prev" title="when-how-paraphrase-NER">
                  <i class="fa fa-chevron-left"></i> when-how-paraphrase-NER
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-flag"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liu Xiyang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">513k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">7:46</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="//cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/comments.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/motion.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/next-boot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/pjax.min.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.8/pdfobject.min.js","integrity":"sha256-tu9j5pBilBQrWSDePOOajCUdz6hWsid/lBNzK4KgEPM="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/tags/pdf.min.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/fancybox.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"//cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"}}</script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/math/mathjax.min.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"liuxiyang641","repo":"liuxiyang_blog_comment","client_id":"b800b344e096846a4608","client_secret":"45ac194feea7e642c29f8e13180184cc98afb3e6","admin_user":"liuxiyang641","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"253900edce1d7a7e85b195ecc848d51c"}</script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/comments/gitalk.min.js"></script>
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>
