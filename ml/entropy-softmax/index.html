<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0">

<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/lxy-apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/lxy-favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/lxy-favicon-16x16.png">
  <link rel="mask-icon" href="/images/lxy-favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liuxiyang641.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"width":300},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":true,"preload":false}}</script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/config.min.js"></script>

    <meta name="description" content="机器学习中的Sigmoid、Softmax与entropy 这篇文章期望总结与讨论机器学习中常见的sigmoid、softmax函数与entropy熵。 参考资料：  熵，维基百科 sigmoid函数推导，知乎 一文详解Softmax函数，知乎 S型函数，维基百科 信息熵越大，信息量到底是越大还是越小？，知乎 softmax和cross-entropy是什么关系？  总结：  sigmoid可以看">
<meta property="og:type" content="blog">
<meta property="og:title" content="entropy-softmax">
<meta property="og:url" content="https://liuxiyang641.github.io/ml/entropy-softmax/index.html">
<meta property="og:site_name" content="Liu Xiyang">
<meta property="og:description" content="机器学习中的Sigmoid、Softmax与entropy 这篇文章期望总结与讨论机器学习中常见的sigmoid、softmax函数与entropy熵。 参考资料：  熵，维基百科 sigmoid函数推导，知乎 一文详解Softmax函数，知乎 S型函数，维基百科 信息熵越大，信息量到底是越大还是越小？，知乎 softmax和cross-entropy是什么关系？  总结：  sigmoid可以看">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/v2-24758bffbd6a9a5d243ff226cb1e3306_1440w.jpg">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220923161828071.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924151830047.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924151900166.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152207932.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152223554.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152709867.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152740503.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152803996.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152907614.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924153634383.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154005224.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154019920.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924155220119.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930164612247.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930165237326.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930173153047.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154019920.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174029787.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174059045.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174650609.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174806703.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174914329.png">
<meta property="og:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930212116078.png">
<meta property="article:published_time" content="2022-09-22T11:04:35.000Z">
<meta property="article:modified_time" content="2022-11-22T07:02:18.114Z">
<meta property="article:author" content="Liu Xiyang">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/v2-24758bffbd6a9a5d243ff226cb1e3306_1440w.jpg">


<link rel="canonical" href="https://liuxiyang641.github.io/ml/entropy-softmax/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://liuxiyang641.github.io/ml/entropy-softmax/","path":"ml/entropy-softmax/","title":"entropy-softmax"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>entropy-softmax | Liu Xiyang</title>
  




<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Liu Xiyang</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">26</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">33</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">113</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84sigmoidsoftmax%E4%B8%8Eentropy"><span class="nav-number">1.</span> <span class="nav-text">机器学习中的Sigmoid、Softmax与entropy</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#sigmoid%E5%87%BD%E6%95%B0"><span class="nav-number">1.1.</span> <span class="nav-text">Sigmoid函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax%E5%87%BD%E6%95%B0"><span class="nav-number">1.2.</span> <span class="nav-text">Softmax函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#entropy%E7%86%B5"><span class="nav-number">1.3.</span> <span class="nav-text">Entropy熵</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Liu Xiyang"
      src="/images/lxy-avatar.jpg">
  <p class="site-author-name" itemprop="name">Liu Xiyang</p>
  <div class="site-description" itemprop="description">Try your best to be an ordinary man.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">113</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/liuxiyang641" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;liuxiyang641" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liuxiyang@buaa.edu.cn" title="E-Mail → mailto:liuxiyang@buaa.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liuxiyang641.github.io/ml/entropy-softmax/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lxy-avatar.jpg">
      <meta itemprop="name" content="Liu Xiyang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liu Xiyang">
      <meta itemprop="description" content="Try your best to be an ordinary man.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="entropy-softmax | Liu Xiyang">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          entropy-softmax<a href="https://github.com/liuxiyang641/liuxiyang641.github.io/edit/hexo/source/_posts/ml/entropy-softmax.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pen-nib"></i></a>
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-09-22 19:04:35" itemprop="dateCreated datePublished" datetime="2022-09-22T19:04:35+08:00">2022-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-11-22 15:02:18" itemprop="dateModified" datetime="2022-11-22T15:02:18+08:00">2022-11-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/Theory/" itemprop="url" rel="index"><span itemprop="name">Theory</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="机器学习中的sigmoidsoftmax与entropy">机器学习中的Sigmoid、Softmax与entropy</h1>
<p>这篇文章期望总结与讨论机器学习中常见的sigmoid、softmax函数与entropy熵。</p>
<p>参考资料：</p>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)">熵，维基百科</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/55016125">sigmoid函数推导，知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105722023">一文详解Softmax函数，知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-tw/S%E5%9E%8B%E5%87%BD%E6%95%B0">S型函数，维基百科</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/274997106/answer/1055696026">信息熵越大，信息量到底是越大还是越小？，知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/294679135/answer/885285177">softmax和cross-entropy是什么关系？</a></li>
</ol>
<p>总结：</p>
<ol type="1">
<li>sigmoid可以看做是神经网络输出<span class="math inline">\([p,0]\)</span>的softmax变形<span class="math inline">\([e^x/(e^x+1), 1/(e^x+e^0)]\)</span>，只不过由于对应标签1的概率<span class="math inline">\(p\)</span>是我们的期望值，另外一个0不做过多讨论。</li>
<li>softmax+交叉熵基本是绑定的，这是因为会使得loss的计算和求导都更简单。</li>
<li>我们经常使用交叉熵，是因为它作为KL散度的核心变化部分，能够衡量输出分布和真实分布之间的差异。</li>
<li>使用softmax而不是hardmax的目的是期望能够让模型从不同类的预测值上获得更多的梯度。</li>
</ol>
<span id="more"></span>
<h2 id="sigmoid函数">Sigmoid函数</h2>
<p>在机器学习领域，如果在了解完线性回归（linear regression）后，发现线性回归很难拟合非线性的分布；那么你很快能看到一个强大的分类器，逻辑斯蒂回归。</p>
<p>逻辑斯蒂回归，logistics regression，就是在线性回归的输出加上了一个特殊的非线性函数，sigmoid函数（在很多文章，也把sigmoid函数叫做S型函数，而把逻辑斯蒂回归中使用的非线性函数单独称作logistic function）：</p>
<p><span class="math display">\[
f(x)=\frac{1}{1+e^{-x}}=\frac{e^x}{e^x+1}
\]</span> <img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/v2-24758bffbd6a9a5d243ff226cb1e3306_1440w.jpg"  style="zoom:40%;" /></p>
<p>该函数是S型函数的一种，指其函数形状类似于S。S型函数在实数范围内可微，并且只有一个拐点（指函数凹凸发生变化的点）。S型函数还包括了很多其它的函数形式。</p>
<p>sigmoid函数取值在<span class="math inline">\([0,1]\)</span>，常被用来输出单类预测区间在<span class="math inline">\([0,1]\)</span>的任务。sigmoid函数的导数是以他自身为因变量的函数，<span class="math inline">\(f^\prime(x)=F(f(x))\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220923161828071.png"  style="zoom:50%;" /></p>
<h2 id="softmax函数">Softmax函数</h2>
<p>如果我们期望进行单标签多类预测，比如某篇文章/某张图片属于什么主题，最后输出的一个序列<span class="math inline">\([0,0,1,0,0,\dots]\)</span>。注意这种情况下，所有类的和是1，仍然是单标签预测。如果是多标签预测，那么会出现多个同时成立的<span class="math inline">\(1\)</span>。</p>
<p>在这种情景中，在模型不变的情况下，试想下我们还可以使用sigmoid函数来预测吗？</p>
<p>模型此时的输出<span class="math inline">\(\bf{x}\)</span>是一个实数向量<span class="math inline">\([0.23472,11.78,-99.99,0.0,\dots]\)</span>，我们可以对每个element分别应用sigmoid函数，那么它可以转化成期望的01预测序列。</p>
<p>但这样做有什么问题？</p>
<p>每个element是独立判别的，比如每个主题都会得到自己的<span class="math inline">\(0-1\)</span>估计，它们的和不能保证是<span class="math inline">\(1\)</span>。这种做法适用于多标签的情况，但不适用于单标签多分类。单标签多分类的概率和应该是1，并且从直觉角度看，不同类之间应该存在信息的互相影响。</p>
<p>为了解决上述问题，softmax是对于sigmoid函数的拓展： <span class="math display">\[
softmax(x_i)=\frac{e^{x_i}}{\sum_{j=1}e^{x_j}}
\]</span> 上述形式和sigmoid进行对比后可以发现，sigmoid函数的分母部分是两个元素和，除了<span class="math inline">\(e^x\)</span>之外多了<span class="math inline">\(1\)</span>。而softmax函数是所有预测元素/概率的<span class="math inline">\(e\)</span>指数和作为总的分母。</p>
<p>从值的角度来看，softmax通过平均，保证了输出值在<span class="math inline">\([0,1]\)</span>。</p>
<p><strong>为什么叫做soft的max？</strong></p>
<p>想一下，我们完全可以直接把最大的那个实数拿出来作为预测结果（这就叫做hard max）。我们为什么非要求和以后，再计算最大实数在和中的占比呢？</p>
<p>因为在很多情况下，我们并不想直接丢掉其它类的预测值，我们往往希望能够获得神经网络对所有类的预测概率。</p>
<p>从优化的角度讲，直接把最大的实数挑出来，那么就只会依据这个实数对应的类进行优化，比如它对应的类不是真实标签，那么优化器会强迫神经网络在接下来对这个类的预测值减小，但是不会同时强迫神经网络对其它标签（包括真实标签）的预测值增大/减小。如果它对应的类是真实标签的话，那么优化器会会强迫神经网络在接下来对这个类的预测值增大，但是不会同时强迫神经网络对其它标签的预测值更小。这种做法不是一种很理想的决策。</p>
<p>另外，softmax对于目标标签的概率输出考虑到了其它类（作为分母）。这样在优化的时候，其它类对应的神经元也能够得到对应的梯度。相反，直接hardmax把最大的挑出来，那就只有最大值对应的神经元可以得到优化了。</p>
<p>接下来讨论<strong>为什么引入指数底<span class="math inline">\(e\)</span></strong>？而不是直接求和？下面解答来自<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105722023">一文详解Softmax函数，知乎</a>。</p>
<p><span class="math inline">\(e^x\)</span>的斜率逐渐增加，随着<span class="math inline">\(x\)</span>越来越大，斜率也越来越大。这就导致了，引入<span class="math inline">\(e^x\)</span>会拉大不同预测概率之间的差距，这实际相当于增加了马太效应，即强者越强，一个输出值<span class="math inline">\(z_i\)</span>增加很小的幅度，也会被<span class="math inline">\(e^x\)</span>放大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tf.__version__) <span class="comment"># 2.0.0</span></span><br><span class="line">a = tf.constant([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], dtype = tf.float32)</span><br><span class="line"></span><br><span class="line">b1 = a / tf.reduce_sum(a) <span class="comment"># 不使用指数</span></span><br><span class="line"><span class="built_in">print</span>(b1) <span class="comment"># tf.Tensor([0.2 0.3 0.5], shape=(3,), dtype=float32)</span></span><br><span class="line"></span><br><span class="line">b2 = tf.nn.softmax(a) <span class="comment"># 使用指数的Softmax</span></span><br><span class="line"><span class="built_in">print</span>(b2) <span class="comment"># tf.Tensor([0.04201007 0.11419519 0.8437947 ], shape=(3,), dtype=float32)</span></span><br></pre></td></tr></table></figure>
<p>同时，<span class="math inline">\((e^x)^\prime=e^x\)</span>，求导比较方便。</p>
<p>引入指数就没有缺点吗？</p>
<p>当然有，指数函数在<span class="math inline">\(x\)</span>比较大时，会输出过于大的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">scores = np.array([<span class="number">123</span>, <span class="number">456</span>, <span class="number">789</span>])</span><br><span class="line">softmax = np.exp(scores) / np.<span class="built_in">sum</span>(np.exp(scores))</span><br><span class="line"><span class="built_in">print</span>(softmax) <span class="comment"># [ 0.  0. nan]</span></span><br></pre></td></tr></table></figure>
<p>在深度学习框架TensorFlow中，因为softmax和交叉熵通常是一起的，因此设置了额外的loss函数同时实现了softmax和交叉熵的计算，避免出现上述情况。</p>
<p>接下来我们要讨论<strong>softmax函数的求导</strong>。</p>
<p><span class="math inline">\(p_i=softmax(x_i)\)</span>函数，分母包括了所有的<span class="math inline">\(x_j\)</span>，而分子只包括<span class="math inline">\(x_i\)</span>。所以我们要分类讨论。</p>
<p>当<span class="math inline">\(j==i\)</span>时，对<span class="math inline">\(x_j\)</span>也就是<span class="math inline">\(x_i\)</span>进行求导，此时分子要参与求导（下面的<span class="math inline">\(z\)</span>就是前面的<span class="math inline">\(x\)</span>）：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924151830047.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924151900166.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152207932.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152223554.png"   style="zoom:50%;" /></p>
<p>上述公式可以写成，<span class="math inline">\(p_i\times (1-p_j)\)</span>，由于<span class="math inline">\(i==j\)</span>，因此最终结果为<span class="math inline">\(p_i-p_i^2\)</span>。</p>
<p>当<span class="math inline">\(j\ne i\)</span>时，对<span class="math inline">\(x_j\)</span>进行求导，分子导数是<span class="math inline">\(0\)</span>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152709867.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152740503.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152803996.png"   style="zoom:50%;" /></p>
<p>最终结果为，<span class="math inline">\(-p_j\times p_i\)</span>。</p>
<p>即，<img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924152907614.png"   style="zoom:50%;" /></p>
<p>softmax的导数形式意外的简单，可以直接利用前馈过程中计算出的结果算出导数。</p>
<p>在使用了softmax之后，我们得到了预测序列<span class="math inline">\([0.11,0.43,0.006,\dots]\)</span>，那么怎么样计算loss呢？</p>
<p>我们首先可以给softmax输出结果加上一个<span class="math inline">\(log\)</span>，这样不改变它的单调性：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924153634383.png"   style="zoom:50%;" /></p>
<p>那么接下来假设<span class="math inline">\(i\)</span>的真实标签就是<span class="math inline">\(1\)</span>，如果我们让<span class="math inline">\(log(p_i)\)</span>不断增大不就可以了吗？当然，loss一般是越小越好，所以有：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154005224.png"  style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154019920.png"   style="zoom:50%;" /></p>
<p>记住上面的式子，在推导交叉熵的时候，两者会统一起来。</p>
<h2 id="entropy熵">Entropy熵</h2>
<p>信息论中的熵的概念，由1948年，<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/克劳德·艾尔伍德·香农">克劳德·艾尔伍德·香农</a>將<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/熱力學">熱力學</a>的熵引入，因此也叫做香农熵。熵是对不确定性的度量，不确定性越大，熵越大。</p>
<p>熵的数学定义为： <span class="math display">\[
H(X)=E[I(X)]=E[-ln(P(X))]=E[ln(\frac{1}{P(X)})]
\]</span> 即随机事件/变量，概率的平均期望。</p>
<p>对于有限样本：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924155220119.png"   style="zoom:50%;" /></p>
<p>在这里<span class="math inline">\(b\)</span>是对数所使用的底，通常是2,自然常数e，或是10。当<span class="math inline">\(b = 2\)</span>，熵的单位是bit；当<span class="math inline">\(b = e\)</span>，熵的单位是nat；而当<span class="math inline">\(b\)</span> = 10,熵的单位是Hart。</p>
<p>投一次硬币，出现的花纹（正反面）这个事件的不确定性是1 bit。</p>
<p>熵和信息量有什么区别？</p>
<p>不能简单的把熵就认为是信息量。事实上熵减才能衡量信息量的增加。我们往一个事件/随机变量当中注入新的信息，比如额外事件的发生，不确定性才会减小。</p>
<p>在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。这句话表达的是随机变量能够容纳/表达的信息量的大小和熵是有关的。</p>
<p>香农对于某个确定的事件发生后的信息量的定义，核心是发生概率越小，一旦发生后，信息量越大： <span class="math display">\[
h(x)=-log_2(p(x))
\]</span> 然后介绍下交叉熵，用来衡量两个独立变量的分布差异：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930164612247.png"   style="zoom:50%;" /></p>
<p>评估变量Q和变量P分布差异的大小，如果两者分布完全一致，KL散度值为0；KL散度值越大，分布差异越大；KL散度值越小，分布差异越小。</p>
<p>在机器学习中，如果我们把P看做是真实分布，Q是模型预测的分布，那么KL散度可以衡量机器学习模型的预测性能。在这种情况下，对KL散度进一步推导：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930165237326.png"  style="zoom:50%;" /></p>
<p>公式的前半部分是真实分布P的负熵，后半部分就是真实分布P做系数、log预测分布Q的交叉熵（同时包括了真实和预测分布，所以叫做交叉）。</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930173153047.png"   style="zoom:50%;" /></p>
<p>前半部分是个固定常量，只要后半部分越小，KL散度就越小。</p>
<p>在了解到什么是交叉熵之后，我们再回到使用softmax推导出的式子：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220924154019920.png"   style="zoom:50%;" /></p>
<p>对于常常使用one-hot编码标签值的机器学习算法来说，只有正确类标签值是1，其它是0：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174029787.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174059045.png"   style="zoom:50%;" /></p>
<p>也就是两者完全等价。</p>
<p>然后使用交叉熵进行求导：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174650609.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174806703.png"   style="zoom:50%;" /></p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930174914329.png"   style="zoom:50%;" /></p>
<p>最后的求导结果，只需要预测值和实际标签就能得到导数。</p>
<p>这就是当拿交叉熵和softmax一起做loss时候的优点，求导更加简单。</p>
<p>另外一点是，当计算出softmax之后，再计算交叉熵： <span class="math display">\[
S= \sum_j y_k\times log(S_j)
\]</span> 如果<span class="math inline">\(S_j\)</span>是softmax输出结果，那么，可以一步到位直接计算<code>logSoftmax</code>：</p>
<p><img src="https://lxy-blog-pics.oss-cn-beijing.aliyuncs.com/asssets/image-20220930212116078.png"   style="zoom:50%;" /></p>
<p>在pytorch的<code>nn.CrossEntropyLoss()</code>函数实现中，就是直接输入神经网络计算得到的激活值<span class="math inline">\(a_j\)</span>（无需经过<code>Softmax</code>）即可，<code>nn.CrossEntropyLoss()</code>会按照<code>logSoftmax</code>来计算最终的loss</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Liu Xiyang
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://liuxiyang641.github.io/ml/entropy-softmax/" title="entropy-softmax">https://liuxiyang641.github.io/ml/entropy-softmax/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"><i class="fa fa-tag"></i> ML</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/mmml/IKRL/" rel="prev" title="IKRL">
                  <i class="fa fa-chevron-left"></i> IKRL
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/mmml/MNRE-dataset/" rel="next" title="MNRE-dataset">
                  MNRE-dataset <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-flag"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liu Xiyang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">379k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">5:45</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="//cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/comments.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/motion.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/next-boot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/pjax.min.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/search/local-search.min.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.8/pdfobject.min.js","integrity":"sha256-tu9j5pBilBQrWSDePOOajCUdz6hWsid/lBNzK4KgEPM="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/tags/pdf.min.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/fancybox.min.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"//cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"}}</script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/math/mathjax.min.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"liuxiyang641","repo":"liuxiyang_blog_comment","client_id":"b800b344e096846a4608","client_secret":"45ac194feea7e642c29f8e13180184cc98afb3e6","admin_user":"liuxiyang641","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"fab0fc1c3153cc4264187e0bf032de3a"}</script>
<script src="https://cdn.jsdelivr.net/npm/hexo-theme-next@8.12.2/source/js/third-party/comments/gitalk.min.js"></script>
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>
